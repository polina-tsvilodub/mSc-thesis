import torch
import torch.nn as nn
from agents import resnet_encoder
from . import image_captioner
# language drift metric (a)
def compute_discrete_overlap(generated_cap, target_cap, distractor_cap):
    """
    Compute an overlap score over the generated caption with the two ground truth captions.
    This score is an attempt to capture language drift, while being agnostic towards compositional alternations.
    
    For batched input, expected input shape is (batch_size, caption_len), output is (batch_size,)
    generated_cap: index lists
        Caption generated by the speaker.
    target_cap:
        Ground truth caption for the target image.
    distractor_cap:
        Ground truth caption for the distractor image.
    """
    target_score_list = [i == j for i, j in list(zip(generated_cap, target_cap))]
    # target_score_list = torch.eq(generated_cap, target_cap)
    distractor_score_list = [i == j for i, j in list(zip(generated_cap, distractor_cap))]
    # distractor_score_list = torch.eq(generated_cap, distractor_cap)
    overlap_score = sum(target_score_list) - sum(distractor_score_list)
    # overlap_score = target_score_list.sum(dim=1) - distractor_score_list.sum(dim=1) 
    
    return overlap_score

# metric (b)

def compute_cont_overlap(generated_cap, target_cap, distractor_cap):
    """
    Compute an overlap score over the generated caption with the two ground truth captions.
    This score is an attempt to capture language drift, while being agnostic towards compositional alternations.
    
    generated_cap: embeddings tensors (batch_size, len_caption, embed_size)
        Caption generated by the speaker.
    target_cap:
        Ground truth caption for the target image.
    distractor_cap:
        Ground truth caption for the distractor image.
        
    Returns:
        overlap_scor (batch_size,)
            tensor of cosine similarity scores by-caption.
    """
    target_dist = nn.functional.cosine_similarity(generated_cap, target_cap, dim=-1) # elementwise, then take average 
    print(target_dist)
    distractor_dist = nn.functional.cosine_similarity(generated_cap, distractor_cap, dim=-1)
    print(distractor_dist)
    overlap_score = target_dist.mean(dim=1) - distractor_dist.mean(dim=1)
    return overlap_score

# old metric
def semantic_drift(caption, image, visual_embed_size, embed_size, hidden_size, vocab_size):
    """
    P(caption|image) under image caption model pretrained on one image only.
    
    image: (batch_size, 3, 224, 224)
    caption: (batch_size, caption_len)
    
    Returns:
    -------
        prob: (batch_size,)
            Tensor of conditional log probabilities measuring the semantic drift. 
    """
    # load pretrained models
    encoder = resnet_encoder.EncoderCNN(visual_embed_size)
    decoder = image_captioner.ImageCaptioner(embed_size, hidden_size, vocab_size) # this is a 1-image conditioned one now (with prepenading of embedding)
    encoder.load_state_dict(torch.load("../models/encoder-earlystoppiing-4_semantic-drift.pkl"))
    decoder.load_state_dict(torch.load("../models/decoder-earlystopping-4_semantic-drift.pkl"))
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    encoder.to(device)
    decoder.to(device)
    # set to .eval()
    encoder.eval()
    decoder.eval()
    # softmax for computing the probabilities over the scores
    softmax = nn.Softmax(dim=-1)
    sent_probs = []
    with torch.no_grad():   
        # embed image
        features = encoder(image)
        # pass image, embedded caption through lstm
        scores = decoder(features, caption) # TODO which format does the caption have to have?
        # retrieve log probs of the target tokens (probs at given indices) 
        scores_prob = softmax(scores) 
        # exclude START and END tokens
        sent_probs = []
        for num, cap in enumerate(caption.tolist()):
            sent_probs.append(torch.stack([scores_prob[num][i][j] for i, j in enumerate(cap[1:-1])]))
        # compute log probability of the sentence
        prob = torch.log(torch.stack(sent_probs)).sum(dim=1)
    return prob

