{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659a0e16",
   "metadata": {},
   "source": [
    "## Baseline thesis experiment MVP\n",
    " \n",
    "This notebook provides the proof of concept for the baseline experiment for the thesis. That is, this implements the **multi-task learning** experiment from Lazaridou, Potapenko and Tieleman (2020), using the MS COCO dataset. The goal of the notebook is to ensure the conceptal and technical correctness of the code; the efficiency and minor updates to the flow of the process are still subject to improvement. \n",
    "\n",
    "I would really appreciate feedback on code contained in cells indicated with **<-- please check me -->**; these are also the ones containing code which I have questions about. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0029df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets as dset\n",
    "from torchvision import transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import json\n",
    "from random import shuffle\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from torchtext.data import get_tokenizer\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9eb3b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe5783a3e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86342e2d",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "\n",
    "First, some utility functions are implemented. The Vocabulary class instantiates or loads the vocabulary (full vocabulary constructed from the entire dataset for now). The Dataset class loads image-caption pairs. The `get_loader` provides a DataLoader for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134c2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils: vocab used by the agents (shared)\n",
    "\n",
    "class Vocabulary(object):\n",
    "\n",
    "    def __init__(self,\n",
    "        vocab_threshold,\n",
    "        vocab_file='./vocab.pkl',\n",
    "        start_word=\"START\",\n",
    "        end_word=\"END\",\n",
    "        unk_word=\"UNK\",         \n",
    "        annotations_file=\"captions_val2014.json\",\n",
    "        pad_word=\"PAD\",\n",
    "        vocab_from_file=False):\n",
    "        \"\"\"\n",
    "        Initialize the vocabulary.\n",
    "        Args:\n",
    "        -----\n",
    "          vocab_threshold: Minimum word count threshold.\n",
    "          vocab_file: File containing the vocabulary.\n",
    "          start_word: Special word denoting sentence start.\n",
    "          end_word: Special word denoting sentence end.\n",
    "          unk_word: Special word denoting unknown words.\n",
    "          annotations_file: Path for train annotation file.\n",
    "          pad_word: Pad token.\n",
    "          vocab_from_file: If False, create vocab from scratch & override any existing vocab_file\n",
    "                           If True, load vocab from from existing vocab_file, if it exists\n",
    "        \"\"\"\n",
    "        self.vocab_threshold = vocab_threshold\n",
    "        self.vocab_file = vocab_file\n",
    "        self.start_word = start_word\n",
    "        self.end_word = end_word\n",
    "        self.unk_word = unk_word\n",
    "        self.pad_word = pad_word\n",
    "        self.annotations_file = annotations_file\n",
    "        self.vocab_from_file = vocab_from_file\n",
    "        # create / load the vocab\n",
    "        self.get_vocab()\n",
    "\n",
    "    def get_vocab(self):\n",
    "        \"\"\"\n",
    "        Load the vocabulary from file OR build the vocabulary from scratch.\n",
    "        \"\"\"\n",
    "        if os.path.exists(self.vocab_file) & self.vocab_from_file:\n",
    "            with open(self.vocab_file, 'rb') as f:\n",
    "                vocab = pickle.load(f)\n",
    "                self.word2idx = vocab.word2idx\n",
    "                self.idx2word = vocab.idx2word\n",
    "            print('Vocabulary successfully loaded from vocab.pkl file!')\n",
    "        else:\n",
    "            self.build_vocab()\n",
    "            with open(self.vocab_file, 'wb') as f:\n",
    "                pickle.dump(self, f)\n",
    "        \n",
    "    def build_vocab(self):\n",
    "        \"\"\"\n",
    "        Populate the dictionaries for converting tokens to integers (and vice-versa).\n",
    "        \"\"\"\n",
    "        self.init_vocab()\n",
    "        # add special tokens andd all tokens from all captions\n",
    "        self.add_word(self.start_word)\n",
    "        self.add_word(self.end_word)\n",
    "        self.add_word(self.unk_word)\n",
    "        self.add_word(self.pad_word)\n",
    "        self.add_captions()\n",
    "\n",
    "    def init_vocab(self):\n",
    "        \"\"\"\n",
    "        Initialize the dictionaries for converting tokens to integers (and vice-versa).\n",
    "        \"\"\"\n",
    "        self.word2idx = {} \n",
    "        self.idx2word = {} \n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        \"\"\"\n",
    "        Add a token to the vocabulary.\n",
    "        Args:\n",
    "        ----\n",
    "            word: str\n",
    "                Token to be added.\n",
    "        \"\"\"\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def add_captions(self):\n",
    "        \"\"\"\n",
    "        Loop over training captions and add all tokens to the vocabulary that meet or exceed the threshold.\n",
    "        \"\"\"\n",
    "        coco = COCO(self.annotations_file)\n",
    "        counter = Counter()\n",
    "        ids = coco.anns.keys()\n",
    "        for i, id in enumerate(ids):\n",
    "            caption = str(coco.anns[id]['caption'])\n",
    "            caption = caption.lower().strip()\n",
    "            caption = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", caption)\n",
    "            tokenizer = get_tokenizer(\"basic_english\")\n",
    "            tokens = tokenizer(caption) \n",
    "            counter.update(tokens)\n",
    "\n",
    "            if i % 100000 == 0:\n",
    "                print(\"[%d/%d] Tokenizing captions...\" % (i, len(ids)))\n",
    "\n",
    "        words = [word for word, cnt in counter.items() if cnt >= self.vocab_threshold]\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def __call__(self, word):\n",
    "        \"\"\"\n",
    "        Return index of given word.\n",
    "        Args:\n",
    "        ----\n",
    "            word: str\n",
    "        Returns:\n",
    "            int: index of word\n",
    "        \"\"\"\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx[self.unk_word]\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns number of unique tokens in vocabulary. \n",
    "        \"\"\"\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7999f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataset generator\n",
    "# padding will be made more consistent across pre-training and reference game training\n",
    "\n",
    "class COCOCaptionsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom class for preprocessing datapoints and sampling a random caption per image.\n",
    "    For training, 70.000 images are sampled.\n",
    "    \n",
    "    Args:\n",
    "    ----\n",
    "        file: str\n",
    "            Path to annotations json file.\n",
    "        download_dir: str\n",
    "            Path to root directory containing images and annotations.\n",
    "        img_transform: transformations.Compose\n",
    "            Transformations to be applied to the loaded image before it is embedded.\n",
    "        batch_size: int\n",
    "            Batch size.\n",
    "        mode: str\n",
    "            Train, test or validation.\n",
    "        vocab_threshold: int\n",
    "            Minimal token frequency to be considered in the vocab.\n",
    "        vocb_file: str\n",
    "            Path to vocab file.\n",
    "        start_toke, end_token, unk_token, pad_token: str\n",
    "            Special tokens.\n",
    "        vocab_from_file: bool\n",
    "            Load existing vocab from file?\n",
    "        max_sequence_length: int\n",
    "            Max length to which captions will be truncated.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, file, download_dir, img_transform, batch_size, mode, \n",
    "                 vocab_threshold, vocab_file, start_token, end_token, unk_token, pad_token, \n",
    "                vocab_from_file, max_sequence_length=0):\n",
    "        \"\"\"\n",
    "        Initialize a dataset instance loading image-caption pairs from the MS COCO Captions dataset.\n",
    "        \"\"\"\n",
    "        self.transform = img_transform\n",
    "        self.mode = mode\n",
    "        self.batch_size = batch_size\n",
    "        # instantiating the vocab object \n",
    "        self.vocab = Vocabulary(vocab_threshold, vocab_file, \n",
    "                                start_token, end_token, unk_token, file, pad_token, vocab_from_file) \n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.pad_token = pad_token\n",
    "        \n",
    "        # some distinctions below for Train and test mode (root dir and whether there are captions)\n",
    "        if mode == \"train\":\n",
    "            self.image_dir = os.path.join(download_dir, \"train2014\")\n",
    "            self.coco = COCO(file) \n",
    "#             _ids = list(self.coco.anns.keys())\n",
    "#             shuffle(_ids)\n",
    "            # take 70.000 images from the dataset\n",
    "            self.ids = torch.load(\"val_split_IDs_from_COCO_train.pt\") #_ids[:70000]\n",
    "            print('Obtaining caption lengths...')\n",
    "            tokenizer = get_tokenizer(\"basic_english\") \n",
    "            all_tokens = [tokenizer(str(self.coco.anns[self.ids[index]]['caption']).lower()) for index in np.arange(len(self.ids))]\n",
    "            self.caption_lengths = [len(token) for token in all_tokens]\n",
    "            # get maximum caption length for padding\n",
    "            self.max_caption_length = max(self.caption_lengths)\n",
    "            \n",
    "            # print pretraining IDs for later separation from functional training\n",
    "#             with open(\"pretrain_img_IDs.txt\", 'w') as f:\n",
    "#                 f.write(\",\".join([str(i) for i in self.ids]))\n",
    "                \n",
    "        elif mode == \"val\":\n",
    "            self.image_dir = os.path.join(download_dir, \"val2014\")\n",
    "            self.coco = COCO(file) \n",
    "            self.ids = torch.load(\"../pretrain_img_IDs_2imgs_512dim.pt\").tolist() #list(self.coco.anns.keys())\n",
    "            print('Obtaining caption lengths...')\n",
    "            tokenizer = get_tokenizer(\"basic_english\")\n",
    "            all_tokens = [tokenizer(str(self.coco.anns[self.ids[index]]['caption']).lower()) for index in np.arange(len(self.ids))] # tqdm(np.arange(len(self.ids)))\n",
    "            self.caption_lengths = [len(token) for token in all_tokens]\n",
    "            \n",
    "        else:\n",
    "            self.image_dir = os.path.join(download_dir, \"val2014\")\n",
    "            # no annotations here \n",
    "            test_info = json.loads(open(file).read())\n",
    "            self.paths = [item['file_name'] for item in test_info['images']]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return number of available data points.\n",
    "        \"\"\"\n",
    "        if self.mode != \"test\":\n",
    "            return len(self.ids)\n",
    "        else:\n",
    "            return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return an image-caption tuple. A random caption per images is chosen since the dataset maps captions onto images.\n",
    "        \n",
    "        Arguments:\n",
    "        -------\n",
    "        idx: int\n",
    "            Index of the item to be returned.\n",
    "        Returns:\n",
    "        -----\n",
    "        image: torch.tensor((3,224,224))\n",
    "        caption: torch.tensor((len_caption))\n",
    "        \"\"\"\n",
    "        \n",
    "        # obtain image and caption if in training mode\n",
    "        if self.mode != 'test':\n",
    "            # get target and distractor indices\n",
    "            target_idx = idx[0]\n",
    "            distractor_idx = idx[1]\n",
    "            \n",
    "            ann_id = self.ids[target_idx]\n",
    "            target_caption = self.coco.anns[ann_id]['caption']\n",
    "            img_id = self.coco.anns[ann_id]['image_id']\n",
    "            target_path = self.coco.loadImgs(img_id)[0]['file_name']\n",
    "\n",
    "            # get distarctor\n",
    "            dist_id = self.ids[distractor_idx]\n",
    "            dist_img_id = self.coco.anns[dist_id]['image_id']\n",
    "            distractor_path = self.coco.loadImgs(dist_img_id)[0]['file_name']\n",
    "\n",
    "            # Convert image to tensor and pre-process using transform\n",
    "            target_image = Image.open(os.path.join(self.image_dir, target_path)).convert('RGB')\n",
    "            target_image = self.transform(target_image)\n",
    "\n",
    "            distractor_image = Image.open(os.path.join(self.image_dir, distractor_path)).convert('RGB')\n",
    "            distractor_image = self.transform(distractor_image)\n",
    "\n",
    "            tokenizer = get_tokenizer(\"basic_english\")\n",
    "            tokens = tokenizer(str(target_caption).lower())\n",
    "            # Convert caption to tensor of word ids, append start and end tokens.\n",
    "            target_caption = []\n",
    "            target_caption.append(self.vocab(self.vocab.start_word))\n",
    "\n",
    "            # check if the sequence needs to be padded or truncated\n",
    "            if self.max_sequence_length != 0:\n",
    "                tokens = tokens[:self.max_sequence_length]\n",
    "\n",
    "            target_caption.extend([self.vocab(token) for token in tokens])\n",
    "            target_caption.append(self.vocab(self.vocab.end_word))\n",
    "            target_caption = torch.Tensor(target_caption).long()\n",
    "            return target_image, distractor_image, target_caption\n",
    "\n",
    "        # obtain image if in test mode\n",
    "        else:\n",
    "            path = self.paths[idx[0]]\n",
    "\n",
    "            # Convert image to tensor and pre-process using transform\n",
    "            PIL_image = Image.open(os.path.join(self.image_dir, path)).convert('RGB')\n",
    "            orig_image = np.array(PIL_image)\n",
    "            image = self.transform(PIL_image)\n",
    "            # return original image and pre-processed image tensor\n",
    "            return orig_image, image\n",
    "        \n",
    "#     def get_train_indices(self):\n",
    "#         \"\"\"\n",
    "#         Return a list of indices at which the captions have the same length which was sampled at random \n",
    "#         for the given batch. To be used for pretraining the speaker (base image-captioning model).\n",
    "        \n",
    "#         Returns:\n",
    "#         -----\n",
    "#             indices: list\n",
    "#                 List of indices of caption-image pairs to be used in the batch.\n",
    "#         \"\"\"\n",
    "#         sel_length = np.random.choice(self.caption_lengths)\n",
    "#         all_indices = np.where([self.caption_lengths[i] == sel_length for i in np.arange(len(self.caption_lengths))])[0]\n",
    "#         indices = list(np.random.choice(all_indices, size=self.batch_size))\n",
    "        \n",
    "#         return indices\n",
    "    \n",
    "    def get_func_train_indices(self):\n",
    "        \"\"\"\n",
    "        Simple POC function returning two lists on indices for the functional training. \n",
    "        Returns a list of inidces for targets and a list f indices for distractors. \n",
    "        Captions are of same lengths for targets and distractors (will be optimized).\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "            list: (int, int)\n",
    "                List of tuples of target and distractor indices, each for a single reference game iteration.\n",
    "        \"\"\"\n",
    "        \n",
    "        sel_length_t = np.random.choice(self.caption_lengths)\n",
    "\n",
    "        all_indices_t = np.where([self.caption_lengths[i] == sel_length_t for i in np.arange(len(self.caption_lengths))])[0]\n",
    "\n",
    "        indices_t = list(np.random.choice(all_indices_t, size=self.batch_size))\n",
    "        possible_inds_dist = [x for x in np.arange(len(self.caption_lengths)) if x not in indices_t]\n",
    "        indices_d = list(np.random.choice(possible_inds_dist, size=self.batch_size))\n",
    "        \n",
    "        return list(zip(indices_t, indices_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa355abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# torch.load(\"../pretrain_val_img_IDs_2imgs.pt\").tolist()[:10] # 649113\n",
    "coco_train = COCO(\"../../../data/train/annotations/captions_train2014.json\")\n",
    "# list(coco_val.anns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb205006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility wrapper returning a DataLoader for training \n",
    "def get_loader(transform,\n",
    "               mode='val',\n",
    "               batch_size=1,\n",
    "               vocab_threshold=None,\n",
    "               vocab_file='./vocab.pkl',\n",
    "               start_word=\"START\",\n",
    "               end_word=\"END\",\n",
    "               unk_word=\"UNK\",\n",
    "               pad_word=\"PAD\",\n",
    "               vocab_from_file=True,\n",
    "               num_workers=0,\n",
    "               download_dir=\"../../../data/val/\",\n",
    "              ):\n",
    "    \"\"\"\n",
    "    Returns the data loader.\n",
    "    Args:\n",
    "    ----\n",
    "      transform: transforms.Compose\n",
    "          Image transform.\n",
    "      mode: str \n",
    "          One of 'train', 'val' or 'test'.\n",
    "      batch_size: int\n",
    "          Batch size (if in testing mode, must have batch_size=1).\n",
    "      vocab_threshold: int\n",
    "          Minimum word count threshold.\n",
    "      vocab_file: str\n",
    "          File containing the vocabulary. \n",
    "      start_word, end_word, unk_word, pad_word: str\n",
    "          Special tokens.\n",
    "      vocab_from_file: bool\n",
    "          If False, create vocab from scratch & override any existing vocab_file.\n",
    "          If True, load vocab from from existing vocab_file, if it exists.\n",
    "      num_workers: int\n",
    "          Number of subprocesses to use for data loading \n",
    "      \n",
    "    Returns:\n",
    "    ------\n",
    "        data_loader: torch.DataLoader\n",
    "    \"\"\"\n",
    "    \n",
    "    assert mode in ['train', 'test', 'val'], \"mode must be one of 'train' or 'test'.\"\n",
    "    if vocab_from_file==False: assert mode=='train' or mode=='val', \"To generate vocab from captions file, must be in training mode (mode='train').\"\n",
    "\n",
    "    # Based on mode (train, val, test), obtain img_folder and annotations_file.\n",
    "    if mode == 'val':\n",
    "        if vocab_from_file==True: assert os.path.exists(vocab_file), \"vocab_file does not exist.  Change vocab_from_file to False to create vocab_file.\"\n",
    "        img_folder = os.path.join(download_dir, \"val2014/\") \n",
    "        annotations_file = os.path.join(download_dir, 'annotations/captions_val2014.json')\n",
    "    if mode == 'train':\n",
    "        if vocab_from_file==True: assert os.path.exists(vocab_file), \"vocab_file does not exist.  Change vocab_from_file to False to create vocab_file.\"\n",
    "        img_folder = os.path.join(download_dir, \"train2014/\") \n",
    "        annotations_file = os.path.join(download_dir, 'annotations/captions_train2014.json')\n",
    "    if mode == 'test':\n",
    "        # TBD\n",
    "        assert batch_size==1, \"Please change batch_size to 1 if testing your model.\"\n",
    "        assert os.path.exists(vocab_file), \"Must first generate vocab.pkl from training data.\"\n",
    "        assert vocab_from_file==True, \"Change vocab_from_file to True.\"\n",
    "        img_folder = os.path.join(download_dir, \"val2014/\") #'test2014/'\n",
    "        annotations_file = os.path.join(download_dir, 'annotations/captions_val2014.json') \n",
    "\n",
    "    # build COCO caption dataset.\n",
    "    dataset = COCOCaptionsDataset(\n",
    "        file=annotations_file,\n",
    "        download_dir = download_dir, \n",
    "        img_transform=transform,\n",
    "        batch_size=batch_size,\n",
    "        mode=mode,\n",
    "        vocab_threshold=vocab_threshold,\n",
    "        vocab_file=vocab_file,\n",
    "        start_token=start_word,\n",
    "        end_token=end_word,\n",
    "        unk_token=unk_word,\n",
    "        pad_token=pad_word, \n",
    "        vocab_from_file=vocab_from_file,\n",
    "        max_sequence_length=25,\n",
    "    )\n",
    "    \n",
    "\n",
    "    if mode == 'train':\n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = dataset.get_func_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        initial_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        # data loader for COCO dataset.\n",
    "        data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                      num_workers=num_workers,\n",
    "                                      batch_sampler=torch.utils.data.sampler.BatchSampler(\n",
    "                                          sampler=initial_sampler,\n",
    "                                          batch_size=dataset.batch_size,\n",
    "                                          drop_last=False),\n",
    "                                                 )\n",
    "    else:\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=dataset.batch_size,\n",
    "            shuffle=True)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc46db",
   "metadata": {},
   "source": [
    "### Agents\n",
    "Next, the agents (speaker and listener) are implemented. Each agent consists of a CNN encoder embedding the images, and an RNN language module. The RNN is decoder in case of the speaker, and an encoder in case of thelistener. All four models are coded separately for purposes of explicitness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b20e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker visual module\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        \"\"\"\n",
    "        Initialize pretrained Resnet 50 for the speaker. \n",
    "        Put a linear layer on top, mapping ResNet features to desired visual embedding dimensionality.\n",
    "        \"\"\"\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "        # remove the last fully connected layer, adding a Linear one\n",
    "        modules = list(resnet.children())[:-1] \n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.embed = nn.Linear(resnet.fc.in_features, embed_size)\n",
    "        self.embed.weight.data.normal_(0., 0.02)\n",
    "        self.embed.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Performs a forward step for embedding a batch of images received by the speaker.\n",
    "        Args:\n",
    "        -----\n",
    "            images: torch.tensor((batch_size, 3, 224, 224))\n",
    "            \n",
    "        Returns:\n",
    "        ------\n",
    "            features: torch.tensor((batch_size, visual_embed_size))\n",
    "        \"\"\"\n",
    "        features = self.resnet(images)\n",
    "        # reshape features to shape (batch_size, -1)\n",
    "        resnet_features = features.view(features.size(0), -1)\n",
    "        features = self.embed(resnet_features)\n",
    "        return features, resnet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5e04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCaptioner(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initialize the langauge module consisting of a one-layer LSTM and \n",
    "        trainable embeddings. The image embedding is used as additional context at every step of the training \n",
    "        (prepended at the sentence beginning).\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            embed_size: int\n",
    "                Dimensionality of trainable embeddings.\n",
    "            hidden_size: int\n",
    "                Hidden/ cell state dimensionality of the LSTM.\n",
    "            vocab_size: int\n",
    "                Length of vocabulary.\n",
    "            num_layers: int\n",
    "                Number of LST layers.\n",
    "        \"\"\"\n",
    "        super(ImageCaptioner, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size= embed_size\n",
    "        self.vocabulary_size = vocab_size\n",
    "        self.lstm = nn.LSTM(self.embed_size, self.hidden_size , self.num_layers, batch_first=True)\n",
    "        self.embed = nn.Embedding(self.vocabulary_size, self.embed_size) \n",
    "        self.linear = nn.Linear(hidden_size, self.vocabulary_size)\n",
    "        self.embed.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "        self.linear.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        \"\"\"\n",
    "        Perform forward step through the LSTM.\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            features: torch.tensor((batch_size, embedd_size))\n",
    "                Embeddings of images.\n",
    "            captions: torch.tensor((batch_size, caption_length))\n",
    "                Lists of indices representing tokens of each caption.\n",
    "        Returns:\n",
    "        ------\n",
    "            outputs: torch.tensor((batch_size, caption_length, embedding_dim))\n",
    "                Scores over vocabulary for each token in each caption.\n",
    "        \"\"\"\n",
    "        \n",
    "        embeddings = self.embed(captions)\n",
    "        features = features.unsqueeze(1)\n",
    "        # PREpend the feature embedding as additional context, cut off END token        \n",
    "        embeddings = torch.cat((features, embeddings[:, :-1,:]), dim=1)\n",
    "        hiddens, self.hidden = self.lstm(embeddings)\n",
    "        \n",
    "        outputs = self.linear(hiddens)\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285132e",
   "metadata": {},
   "source": [
    "**<-- Please check me below -->**\n",
    "\n",
    "Especially the sampling procedure and the retireval of the action probabilities therein is an important block which is employed in the reference game training and which is part of REINFORCE - quite unsure about the conceptual correctness of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "045c7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker language module\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, visual_embed_size, batch_size=1, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initialize the langauge module consisting of a one-layer LSTM and \n",
    "        trainable embeddings. The image embedding is used as additional context at every step of the training \n",
    "        (prepended at the sentence beginning).\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            embed_size: int\n",
    "                Dimensionality of trainable embeddings.\n",
    "            hidden_size: int\n",
    "                Hidden/ cell state dimensionality of the LSTM.\n",
    "            vocab_size: int\n",
    "                Length of vocabulary.\n",
    "            visual_embed_size: int\n",
    "                Dimensionality of the image embedding to be appended at each time step as additional context.\n",
    "            num_layers: int\n",
    "                Number of LST layers.\n",
    "        \"\"\"\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size= embed_size\n",
    "        self.vocabulary_size = vocab_size\n",
    "        self.visual_embed_size = visual_embed_size\n",
    "        self.embed = nn.Embedding(self.vocabulary_size, self.embed_size) \n",
    "        # LSTM takes as input the word embedding with prepended embeddings of the two images at each time step\n",
    "        self.lstm = nn.LSTM(self.embed_size + 2*self.visual_embed_size, self.hidden_size , self.num_layers, batch_first=True) #self.embed_size+\n",
    "        self.linear = nn.Linear(hidden_size, self.vocabulary_size)\n",
    "        self.project = nn.Linear(2048, self.visual_embed_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden = self.init_hidden(self.batch_size)\n",
    "        self.embed.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "        self.linear.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "            \n",
    "        \"\"\" \n",
    "        At the start of training, we need to initialize a hidden state;\n",
    "        Defines a hidden state with all zeroes\n",
    "        The axes are (num_layers, batch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return (torch.zeros((1, batch_size, self.hidden_size), device=device), \\\n",
    "                torch.zeros((1, batch_size, self.hidden_size), device=device))\n",
    "    \n",
    "    def forward(self, features, captions, prev_hidden):\n",
    "        \"\"\"\n",
    "        Perform forward step through the LSTM.\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            features: torch.tensor((batch_size, embedd_size))\n",
    "                Embeddings of images.\n",
    "            captions: torch.tensor((batch_size, caption_length))\n",
    "                Lists of indices representing tokens of each caption.\n",
    "        Returns:\n",
    "        ------\n",
    "            outputs: torch.tensor((batch_size, caption_length, embedding_dim))\n",
    "                Scores over vocabulary for each token in each caption.\n",
    "        \"\"\"\n",
    "        \n",
    "        image_emb = self.project(features)\n",
    "        # print(\"Target emb after unsqueeze: \", target_emb.shape)\n",
    "        # concat\n",
    "        img_features = torch.cat((image_emb[:, 0, :], image_emb[:, 1, :]), dim=-1).unsqueeze(1)\n",
    "        # print(\"concat features: \", img_features.shape)\n",
    "        embeddings = self.embed(captions)\n",
    "        # features = features.unsqueeze(1)\n",
    "        \n",
    "        # print(\"repeated img features: \", features_reps.shape)\n",
    "        # PREpend the feature embedding as additional context AT EACH TIMESTEP, cut off END token \n",
    "        if self.training:\n",
    "            features_reps = img_features.repeat(1, captions.shape[1]-1, 1) # captions.shape[1]-1\n",
    "            embeddings = torch.cat((features_reps, embeddings[:, :-1,:]), dim=-1) # features_reps, dim=-1 # :-1\n",
    "#         print(\"embeddings: \", embeddings.shape)\n",
    "        else:\n",
    "        # PUT BACK THE SHIFT FOR VALIDATION -- REMOVE FOR SAMPLING\n",
    "            features_reps = img_features.repeat(1, captions.shape[1]-1, 1) # captions.shape[1]-1\n",
    "            print(\"reps \", features_reps.shape)\n",
    "            print(\"embs \", embeddings.shape)\n",
    "            embeddings = torch.cat((features_reps, embeddings[:, :-1,:]), dim=-1)\n",
    "        hiddens, hidden_state = self.lstm(embeddings, prev_hidden)\n",
    "        # print(\"Hidden_state within forward: \", hidden_state)\n",
    "        \n",
    "        outputs = self.linear(hiddens)\n",
    "        return outputs, hidden_state\n",
    "    \n",
    "    def sample(self, inputs, max_sequence_length):\n",
    "        \"\"\"\n",
    "        Function for sampling a caption during functional (reference game) training.\n",
    "        Implements greedy sampling. Sampling stops when END token is sampled or when max_sequence_length is reached.\n",
    "        Also returns the log probabilities of the action (the sampled caption) for REINFORCE.\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            inputs: torch.tensor(1, 1, embed_size)\n",
    "                pre-processed image tensor.\n",
    "            max_sequence_length: int\n",
    "                Max length of sequence which the nodel should generate. \n",
    "        Returns:\n",
    "        ------\n",
    "            output: list\n",
    "                predicted sentence (list of tensor ids). \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        output = []\n",
    "        raw_outputs = [] # for structural loss computation\n",
    "        log_probs = []\n",
    "        entropies = []\n",
    "        batch_size = inputs.shape[0] # batch_size is 1 at inference, inputs shape : (1, 1, embed_size)\n",
    "        hidden = self.init_hidden(batch_size) # Get initial hidden state of the LSTM\n",
    "        softmax = nn.Softmax(dim=-1)\n",
    "        # create initial caption input: \"START\"\n",
    "        caption = torch.tensor([0]).repeat(batch_size, 1) # two 0s since we cut off last token in forward step, so that we actually keep one\n",
    "        # make initial forward step, get output of shape (batch_size, 1, vocab_size)\n",
    "        init_hiddens = self.init_hidden(batch_size)\n",
    "        ####\n",
    "        # outsource first step bc of image projection\n",
    "        out, hidden_state = self.forward(inputs, caption, init_hiddens)\n",
    "        raw_outputs.extend(out)\n",
    "        probs = softmax(out)\n",
    "        if self.training:\n",
    "            cat_dist = torch.distributions.categorical.Categorical(probs)\n",
    "            cat_samples = cat_dist.sample()\n",
    "            entropy = cat_dist.entropy()\n",
    "            entropies.append(entropy)\n",
    "            log_p = cat_dist.log_prob(cat_samples)\n",
    "        else:\n",
    "            max_probs, cat_samples = torch.max(probs, dim = -1)\n",
    "            log_p = torch.log(max_probs)\n",
    "            entropy = -max_probs * log_p\n",
    "            entropies.append(entropy)\n",
    "\n",
    "        log_probs.append(log_p)\n",
    "        output.append(cat_samples)\n",
    "        word_emb = self.embed(cat_samples)\n",
    "\n",
    "        # while True:\n",
    "        for i in range(max_sequence_length):\n",
    "            print(\"CAT SAMPLES AT BEGINNING OF SAMPLING LOOP \", cat_samples)\n",
    "            out, hidden_state = self.forward(inputs, cat_samples, hidden_state)\n",
    "            # lstm_out, hidden_state = self.lstm(word_emb, hidden_state)\n",
    "            # print(\"Self hidden after an iter of sampling loop: \", hidden_state )\n",
    "            # out = self.linear(lstm_out)\n",
    "            \n",
    "            # get and save probabilities and save raw outputs\n",
    "            raw_outputs.extend(out)\n",
    "            probs = softmax(out)\n",
    "            ####\n",
    "            if self.training:\n",
    "                # try sampling from a categorical\n",
    "                cat_dist = torch.distributions.categorical.Categorical(probs)\n",
    "                cat_samples = cat_dist.sample()\n",
    "                entropy = cat_dist.entropy()\n",
    "                entropies.append(entropy)\n",
    "                log_p = cat_dist.log_prob(cat_samples)\n",
    "            else: \n",
    "                # if in eval mode, take argmax\n",
    "                max_probs, cat_samples = torch.max(probs, dim = -1)\n",
    "                log_p = torch.log(max_probs)\n",
    "                \n",
    "                top5_probs, top5_inds = torch.topk(probs, 5, dim=-1)\n",
    "                print(\"Top 5 inds: \", top5_inds)\n",
    "\n",
    "            log_probs.append(log_p)\n",
    "            ####\n",
    "            output.append(cat_samples)\n",
    "            # embed predicted tokens\n",
    "            word_emb = self.embed(cat_samples)\n",
    "            \n",
    "        print(\"log probs\", log_probs)\n",
    "        print(entropies)\n",
    "        output = torch.stack(output, dim=-1).squeeze(1)\n",
    "        # stack\n",
    "        log_probs = torch.stack(log_probs, dim=1).squeeze(-1)\n",
    "        entropies = torch.stack(entropies, dim=1).squeeze(-1)\n",
    "        \n",
    "        ####\n",
    "        # get effective log prob and entropy values - the ones up to (including) END (word2idx = 1)  \n",
    "        # mask positions after END - both entropy and log P should be 0 at those positions\n",
    "        end_mask = output.size(-1) - (torch.eq(output, 1).to(torch.int64).cumsum(dim=-1) > 0).sum(dim=-1)\n",
    "        # include the END token\n",
    "        end_inds = end_mask.add_(1).clamp_(max=output.size(-1)) # shape: (batch_size,)\n",
    "        for pos, i in enumerate(end_inds):  \n",
    "            # zero out log Ps and entropies\n",
    "            log_probs[pos, i:] = 0\n",
    "            entropies[pos, i:] = 0\n",
    "        ####\n",
    "    \n",
    "        raw_outputs = torch.stack(raw_outputs, dim=1).view(batch_size, -1, self.vocabulary_size)\n",
    "        return output, log_probs, raw_outputs, entropies\n",
    "    \n",
    "#     def sample(self, inputs, max_sequence_length):\n",
    "#         \"\"\"\n",
    "#         Function for sampling a caption during functional (reference game) training.\n",
    "#         Implements greedy sampling. Sampling stops when END token is sampled or when max_sequence_length is reached.\n",
    "#         Also returns the log probabilities of the action (the sampled caption) for REINFORCE.\n",
    "        \n",
    "#         Args:\n",
    "#         ----\n",
    "#             inputs: torch.tensor(1, 1, embed_size)\n",
    "#                 pre-processed image tensor.\n",
    "#             max_sequence_length: int\n",
    "#                 Max length of sequence which the nodel should generate. \n",
    "#         Returns:\n",
    "#         ------\n",
    "#             output: list\n",
    "#                 predicted sentence (list of tensor ids). \n",
    "#         \"\"\"\n",
    "        \n",
    "        \n",
    "#         output = []\n",
    "#         raw_outputs = [] # for structural loss computation\n",
    "#         scores = []\n",
    "#         topk = []\n",
    "#         batch_size = inputs.shape[0] # batch_size is 1 at inference, inputs shape : (1, 1, embed_size)\n",
    "#         hidden = self.init_hidden(batch_size) # Get initial hidden state of the LSTM\n",
    "#         softmax = nn.Softmax(dim=-1)\n",
    "#         # embed the start token, repeat once for each item in the batch\n",
    "#         word_emb = torch.tensor([0, 0]).unsqueeze(0).repeat(1, 1).long()\n",
    "#         print(\"Init start tensor: \", word_emb.shape)\n",
    "#         # init hidden\n",
    "#         hiddens = self.init_hidden(batch_size)\n",
    "#         # make initial forward step:\n",
    "\n",
    "#         # below will be optimized\n",
    "#         for i in range(max_sequence_length):\n",
    "#             out, hiddens = self.forward(inputs, word_emb, hiddens)\n",
    "\n",
    "\n",
    "\n",
    "#             # inputs_lstm = torch.cat((inputs, word_emb), dim=-1)\n",
    "#             # lstm_out, hidden = self.lstm(inputs_lstm, hidden) # lstm_out shape : (1, 1, hidden_size)\n",
    "#             # outputs = self.linear(lstm_out)  # outputs shape : (1, 1, vocab_size)\n",
    "#             raw_outputs.extend(out) # outputs\n",
    "#             # get the log probs of the actions\n",
    "#             probs = softmax(out) # outputs\n",
    "#             max_probs, max_inds = torch.max(probs, dim=-1)\n",
    "#             top5_probs, top5_inds = torch.topk(probs, 5, dim=-1)\n",
    "#             print(\"Top 5 inds: \", top5_inds)\n",
    "#             scores.append(max_probs)\n",
    "            \n",
    "#             out = out.squeeze(1) # outputs shape : (1, vocab_size)\n",
    "#             # _, max_indice = torch.max(out, dim=1) # predict the most likely next word, max_indice shape : (1)\n",
    "#             output.append(max_inds)\n",
    "#             topk.append(top5_inds)\n",
    "#             if (torch.equal(max_inds, torch.ones((batch_size, 1), dtype=torch.int64))) or (len(output) == max_sequence_length):\n",
    "#                 # We predicted the <end> word or reached max length, so there is no further prediction to do\n",
    "#                 break\n",
    "            \n",
    "#             ## Prepare to embed the last predicted word to be the new input of the lstm\n",
    "#             word_emb = torch.cat((word_emb, max_inds.long()), dim=-1) # inputs shape : (1, embed_size) # torch.tensor([max_inds.item(), max_inds.item()]).long() #\n",
    "# #             word_emb = word_emb.unsqueeze(1) # inputs shape : (1, 1, embed_size)\n",
    "            \n",
    "#         # turn raw scores into log probabilities\n",
    "#         log_probs = torch.log(scores[-1])#torch.log(torch.stack(scores, dim=1))\n",
    "        \n",
    "# #         if len(output) < max_sequence_length:\n",
    "# #             # get the embedding and softmax output for pad\n",
    "# #             pad = torch.tensor([3]).repeat(batch_size)\n",
    "# #             pad_input = self.embed(pad).unsqueeze(1)\n",
    "# #             pad_lstm_input = torch.cat((inputs, pad_input), dim=-1)\n",
    "# #             lstm_pad, _ = self.lstm(pad_lstm_input, hidden)\n",
    "# #             pad_output = self.linear(lstm_pad)\n",
    "            \n",
    "# #             while len(output) < max_sequence_length:\n",
    "# #                 output.append(pad) # pad\n",
    "# #                 raw_outputs.extend(pad_output)\n",
    "        \n",
    "#         return output, log_probs, raw_outputs, topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf44d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper where the image embeddings are prepended as token 0\n",
    "# speaker language module\n",
    "class DecoderRNN_token0(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, visual_embed_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initialize the langauge module consisting of a one-layer LSTM and \n",
    "        trainable embeddings. The image embedding is used as additional context at every step of the training \n",
    "        (prepended at the sentence beginning).\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            embed_size: int\n",
    "                Dimensionality of trainable embeddings.\n",
    "            hidden_size: int\n",
    "                Hidden/ cell state dimensionality of the LSTM.\n",
    "            vocab_size: int\n",
    "                Length of vocabulary.\n",
    "            visual_embed_size: int\n",
    "                Dimensionality of the image embedding to be appended at each time step as additional context.\n",
    "            num_layers: int\n",
    "                Number of LST layers.\n",
    "        \"\"\"\n",
    "        super(DecoderRNN_token0, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size= embed_size\n",
    "        self.vocabulary_size = vocab_size\n",
    "        self.visual_embed_size = visual_embed_size\n",
    "        self.embed = nn.Embedding(self.vocabulary_size, self.embed_size) \n",
    "        # LSTM takes as input the word embedding with prepended embeddings of the two images at each time step\n",
    "        self.lstm = nn.LSTM(2*self.visual_embed_size, self.hidden_size , self.num_layers, batch_first=True) #self.embed_size+\n",
    "        self.linear = nn.Linear(hidden_size, self.vocabulary_size)\n",
    "        self.project = nn.Linear(2048, self.visual_embed_size)\n",
    "        \n",
    "        self.embed.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "        self.linear.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "            \n",
    "        \"\"\" \n",
    "        At the start of training, we need to initialize a hidden state;\n",
    "        Defines a hidden state with all zeroes\n",
    "        The axes are (num_layers, batch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        return (torch.zeros((1, batch_size, self.hidden_size), device=device), \\\n",
    "                torch.zeros((1, batch_size, self.hidden_size), device=device))\n",
    "    \n",
    "    def forward(self, features, captions, prev_hidden):\n",
    "        \"\"\"\n",
    "        Perform forward step through the LSTM.\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            features: torch.tensor((batch_size, embedd_size))\n",
    "                Embeddings of images.\n",
    "            captions: torch.tensor((batch_size, caption_length))\n",
    "                Lists of indices representing tokens of each caption.\n",
    "        Returns:\n",
    "        ------\n",
    "            outputs: torch.tensor((batch_size, caption_length, embedding_dim))\n",
    "                Scores over vocabulary for each token in each caption.\n",
    "        \"\"\"\n",
    "        target_emb = self.project(features[0]).unsqueeze(1)\n",
    "        # print(\"Target emb after unsqueeze: \", target_emb.shape)\n",
    "        dist_emb = self.project(features[1]).unsqueeze(1)\n",
    "        # concat\n",
    "        img_features = torch.cat((target_emb, dist_emb), dim=-1) \n",
    "        # print(\"concat features: \", img_features.shape)\n",
    "        \n",
    "        embeddings = self.embed(captions)\n",
    "#         features = features.unsqueeze(1)\n",
    "#         features_reps = features.repeat(1, embeddings.shape[1]-1, 1)\n",
    "        # PREpend the feature embedding as additional context AT EACH TIMESTEP, cut off END token        \n",
    "        embeddings = torch.cat((img_features, embeddings[:, :-1,:]), dim=1) #\n",
    "        hiddens, hidden_state = self.lstm(embeddings, prev_hidden)\n",
    "        \n",
    "        outputs = self.linear(hiddens)\n",
    "        return outputs, hidden_state\n",
    "    \n",
    "    def sample(self, inputs, max_sequence_length):\n",
    "        \"\"\"\n",
    "        Function for sampling a caption during functional (reference game) training.\n",
    "        Implements greedy sampling. Sampling stops when END token is sampled or when max_sequence_length is reached.\n",
    "        Also returns the log probabilities of the action (the sampled caption) for REINFORCE.\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            inputs: torch.tensor(1, 1, embed_size)\n",
    "                pre-processed image tensor.\n",
    "            max_sequence_length: int\n",
    "                Max length of sequence which the nodel should generate. \n",
    "        Returns:\n",
    "        ------\n",
    "            output: list\n",
    "                predicted sentence (list of tensor ids). \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        output = []\n",
    "        raw_outputs = [] # for structural loss computation\n",
    "        scores = []\n",
    "        topk = []\n",
    "        batch_size = inputs[0].shape[0] # batch_size is 1 at inference, inputs shape : (1, 1, embed_size)\n",
    "        hidden = self.init_hidden(batch_size) # Get initial hidden state of the LSTM\n",
    "        softmax = nn.Softmax(dim=-1)\n",
    "        # embed the start token, repeat once for each item in the batch\n",
    "#         word_emb = self.embed(torch.tensor([0])).unsqueeze(0).repeat(inputs.shape[0], 1, 1)\n",
    "        # below will be optimized\n",
    "        target_ft = self.project(inputs[0]).unsqueeze(1)\n",
    "        distractor_ft = self.project(inputs[1]).unsqueeze(1)\n",
    "        inputs = torch.cat((target_ft, distractor_ft), dim=-1)\n",
    "        \n",
    "        start_emb = self.embed(torch.tensor([0]).unsqueeze(0).long())\n",
    "        print(\"Start: \", start_emb.shape)\n",
    "        inputs = torch.cat((inputs, start_emb), dim=1)\n",
    "        print(\"embs concat: \", inputs.shape)\n",
    "\n",
    "        while True:\n",
    "#             inputs_lstm = torch.cat((inputs, word_emb), dim=1)\n",
    "            lstm_out, hidden = self.lstm(inputs, hidden) # lstm_out shape : (1, 1, hidden_size) # _lstm\n",
    "            print(\"Hidden after step \", hidden[0].shape)\n",
    "            outputs = self.linear(lstm_out)  # outputs shape : (1, 1, vocab_size)\n",
    "            raw_outputs.extend(outputs)\n",
    "            # get the log probs of the actions\n",
    "            probs = softmax(outputs)\n",
    "            print(\"probs shape: \", probs.shape)\n",
    "            max_probs, max_inds = torch.max(probs, dim=-1)\n",
    "            print(\"max INDS: \", max_inds)\n",
    "            scores.append(max_probs)\n",
    "            top5_probs, top5_inds = torch.topk(probs, 5, dim=-1)\n",
    "            topk.append(top5_inds)\n",
    "            outputs = outputs.squeeze(1) # outputs shape : (1, vocab_size)\n",
    "            _, max_indice = torch.max(outputs, dim=-1) # predict the most likely next word, max_indice shape : (1)\n",
    "            output.append(max_indice)\n",
    "            if (torch.equal(max_indice, torch.ones((inputs[0].shape[0], 1), dtype=torch.int64))) or (len(output) == max_sequence_length):\n",
    "                # We predicted the <end> word or reached max length, so there is no further prediction to do\n",
    "                break\n",
    "            print(\"Max indice: \", max_indice)\n",
    "            ## Prepare to embed the last predicted word to be the new input of the lstm\n",
    "            word_emb = self.embed(max_indice) # inputs shape : (1, embed_size)\n",
    "#             print(\"word emb hape at end: \", word_emb)\n",
    "            inputs  = word_emb#.unsqueeze(1).unsqueeze(0) # inputs shape : (1, 1, embed_size) # word_emb\n",
    "            print(\"Inputs shape at end of step: \", inputs.shape)\n",
    "            \n",
    "        # turn raw scores into log probabilities\n",
    "        log_probs = torch.log(torch.stack(scores, dim=1))\n",
    "        \n",
    "        if len(output) < max_sequence_length:\n",
    "            # get the embedding and softmax output for pad\n",
    "            pad = torch.tensor([3]).repeat(batch_size)\n",
    "            pad_input = self.embed(pad).unsqueeze(1)\n",
    "            pad_lstm_input = torch.cat((inputs, pad_input), dim=-1)\n",
    "            lstm_pad, _ = self.lstm(pad_lstm_input, hidden)\n",
    "            pad_output = self.linear(lstm_pad)\n",
    "            \n",
    "            while len(output) < max_sequence_length:\n",
    "                output.append(pad) # pad\n",
    "                raw_outputs.extend(pad_output)\n",
    "        \n",
    "        return output, log_probs, raw_outputs, topk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a16461",
   "metadata": {},
   "source": [
    "**<-- Please check me below -->**\n",
    "\n",
    "The forward steps includes the computation of the dot product based on which the listener makes its guess - not sure if the output scores are correct for cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fda189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listener visual module\n",
    "# has a different forward step than the speaker visual module\n",
    "\n",
    "class ListenerEncoderCNN(EncoderCNN):\n",
    "       \n",
    "    def forward(self, features1, features2, caption): # self, images, caption\n",
    "        \"\"\"\n",
    "        Performs forward pass through the listener ResNet 50 CNN.\n",
    "        Computes the dot product between two images and the caption provided by the speaker.\n",
    "        Outputs the index of the image which has the highest dot product with the caption - it is the predicted target.\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "        images1: torch.tensor((batch_size, 3, 224, 224))\n",
    "            List of images (potentially containing either targets or distractors).\n",
    "        images2: torch.tensor((batch_size, 3, 224, 224))\n",
    "            List of images (potentially containing either targets or distractors).\n",
    "        caption: torch.tensor((batch_size, sentence_length, embed_size))\n",
    "            Last hidden state of the RNN.\n",
    "        Returns:\n",
    "        ----\n",
    "            indices: torch.tensor(batch_size)\n",
    "                List of predicted target indices. \n",
    "            \n",
    "        \"\"\"\n",
    "        # will be improved\n",
    "#         images1 = torch.stack([im[0] for im in image_pairs])\n",
    "#         images2 = torch.stack([im[1] for im in image_pairs])\n",
    "#         features1 = self.resnet(images1) #images[0]\n",
    "#         features2 = self.resnet(images2) # images[1]\n",
    "        # reshape features to shape (batch_size, -1) - adapt to first dim\n",
    "        features1 = features1.view(features1.size(0), -1)\n",
    "        features1 = self.embed(features1)\n",
    "        features2 = features2.view(features2.size(0), -1)\n",
    "        features2 = self.embed(features2)\n",
    "        # compute dot product between images and caption\n",
    "        # compute mean over words as sentence embedding representation\n",
    "        print(\"Caption shape in forward of listener CNN: \", caption.shape)\n",
    "#         caption = caption.mean(1)\n",
    "        dot_products_1 = torch.bmm(features1.view(images1.size()[0], 1, features1.size()[1]),\n",
    "                                   caption.view(images1.size()[0], features1.size()[1], 1))\n",
    "        dot_products_2 = torch.bmm(features2.view(images2.size()[0], 1, features2.size()[1]),\n",
    "                                   caption.view(images2.size()[0], features2.size()[1], 1))\n",
    "        # compose targets and distractors dot products\n",
    "        # stack into pairs, assuming dim=0 is the batch dimension\n",
    "        pairs = torch.stack((dot_products_1, dot_products_2), dim=1) \n",
    "        pairs_flat = pairs.squeeze(-1).squeeze(-1)\n",
    "        \n",
    "        return pairs_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32cdbaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listener language module\n",
    "class ListenerEncoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initialize the langauge module consisting of a one-layer LSTM and \n",
    "        trainable embeddings. The image embedding is used as additional context at every step of the training \n",
    "        (prepended at the embedding beginning). \n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            embed_size: int\n",
    "                Dimensionality of trainable embeddings.\n",
    "            hidden_size: int\n",
    "                Hidden/ cell state dimensionality of the LSTM.\n",
    "            vocab_size: int\n",
    "                Length of vocabulary.\n",
    "            num_layers: int\n",
    "                Number of LST layers.\n",
    "        \"\"\"\n",
    "        super(ListenerEncoderRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size= embed_size\n",
    "        self.vocabulary_size = vocab_size\n",
    "        self.embed = nn.Embedding(self.vocabulary_size, self.embed_size) \n",
    "        self.lstm = nn.LSTM(self.embed_size, self.hidden_size , self.num_layers, batch_first=True)\n",
    "        self.embed.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\" \n",
    "        Initialize a hidden state with all zeroes.\n",
    "        The axes are (num_layers, batch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        return (torch.zeros((1, batch_size, self.hidden_size), device=device), \\\n",
    "                torch.zeros((1, batch_size, self.hidden_size), device=device))\n",
    "    \n",
    "    def forward(self, captions):\n",
    "        \"\"\"\n",
    "        Compute forward step through the listener LSTM.\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            captions: torch.tensor((1, caption_length))\n",
    "                Caption received from speaker\n",
    "        Returns:\n",
    "        -----\n",
    "            hiddens: torch.tensor((1, caption_length, embed_size))\n",
    "                Hidden sentence representations.\n",
    "        \"\"\"\n",
    "        embeddings = self.embed(captions)\n",
    "        hiddens, self.hidden = self.lstm(embeddings)\n",
    "        print(\"LISTENER encoder last hidden out: \", self.hidden[0].shape)\n",
    "        return hiddens, self.hidden[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cfcc81",
   "metadata": {},
   "source": [
    "**<-- Please check me below -->**\n",
    "\n",
    "Not sure if it is okay to just treat the LSTM time steps as iterations, and to use no discount factor. Also not sure about the computation of the batch update as sum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e606e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "def update_policy(rewards, log_probs):\n",
    "    \"\"\"\n",
    "    This function calculates the weight updates accoring to the REINFORCE rule.\n",
    "    \n",
    "    Args:\n",
    "    ----\n",
    "        rewards: list\n",
    "            List of rewards of length batch_size\n",
    "        log_probs: torch.tensor((batch_size, caption_length))\n",
    "            Log probabilities of each word in each predicted sentence.\n",
    "    Returns:\n",
    "    -----\n",
    "        policy_gradient: torch.tensor\n",
    "            Update to be applied together with the other loss components to the speaker parameters. \n",
    "    \"\"\"\n",
    "\n",
    "    policy_gradient = []\n",
    "    print(\"Policy log probs in: \", log_probs.shape)\n",
    "    sentence_prob = log_probs.sum(dim=1)\n",
    "    print(\"Policy log probs by sentence (num=batch size): \", sentence_prob.shape, sentence_prob)\n",
    "    for log_prob, Gt in zip(sentence_prob, rewards):\n",
    "        policy_gradient.append(-log_prob * Gt)\n",
    "    # here, we just sum to get the batch loss - consider average\n",
    "    print(\"Policy update by datapoint: \", policy_gradient)\n",
    "    policy_gradient = torch.stack(policy_gradient).mean()\n",
    "    print(\"Policy gradient out: \", policy_gradient.shape, policy_gradient)\n",
    "    return policy_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706ecb6",
   "metadata": {},
   "source": [
    "### Pre-training set up\n",
    "\n",
    "First, the speaker pretraining will be completed. The loop below exempliefies how that will be done; the full scale model has not been pretrained yet. The training details like the optimizer are kept maximally simple. For exploration purposes, the entire vocabulary is used.\n",
    "\n",
    "All components are loaded, a training loop is started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d523e46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n",
      "Vocab size:  6039\n"
     ]
    }
   ],
   "source": [
    "# pre-training set up \n",
    "\n",
    "batch_size = 128         # batch size\n",
    "vocab_threshold = 11        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 300           # dimensionality of word embeddings\n",
    "visual_embed_size = 1024   # dimensionality of the image embeding\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 1             # number of training epochs (1 for testing)\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 200          # determines window for printing average loss\n",
    "log_file = 'training_log_train_prepend_2imgs.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file,\n",
    "                         download_dir=\"../../../data/train\", \n",
    "                        )\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "print(\"Vocab size: \", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "995b2e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps:  547\n"
     ]
    }
   ],
   "source": [
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(visual_embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, visual_embed_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# Specify the learnable parameters of the model.\n",
    "params = list(decoder.lstm.parameters()) + list(decoder.linear.parameters()) + list(encoder.embed.parameters()) \n",
    "\n",
    "# Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)\n",
    "print(\"Total steps: \", total_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dfb9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 1024])\n",
      "torch.Size([128, 12, 1024])\n"
     ]
    }
   ],
   "source": [
    "test_emb = torch.zeros([128, 13, 300])\n",
    "test_vis = torch.ones([128, 1, 1024])\n",
    "print(test_vis.shape)\n",
    "test_vis_rep = test_vis.repeat(1, test_emb.shape[1]-1, 1)\n",
    "print(test_vis_rep.shape)\n",
    "test_concat = torch.cat((test_vis_rep, test_emb[:, :-1,:]), dim=-1)\n",
    "# test_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d40cb45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of possible dist indices:  70000\n",
      "Filtered number of possible dist indices:  69872\n",
      "target caption shape:  torch.Size([128, 14])\n",
      "target images shape:  torch.Size([128, 3, 224, 224])\n",
      "distractors imgaes shape:  torch.Size([128, 3, 224, 224])\n",
      "Concatenated images shape:  torch.Size([128, 2048])\n",
      "Embeddings:  torch.Size([128, 14, 300])\n",
      "Features:  torch.Size([128, 1, 2048])\n",
      "Repeated features:  torch.Size([128, 13, 2048])\n",
      "EMBEDDING At EACH TIMESTEP:  torch.Size([128, 13, 2348])\n",
      "Outputs shape:  torch.Size([128, 13, 6039])\n",
      "Without START:  torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1/547], Loss: 8.6951, Perplexity: 5973.5405Original number of possible dist indices:  70000\n",
      "Filtered number of possible dist indices:  69887\n",
      "target caption shape:  torch.Size([128, 20])\n",
      "target images shape:  torch.Size([128, 3, 224, 224])\n",
      "distractors imgaes shape:  torch.Size([128, 3, 224, 224])\n",
      "Concatenated images shape:  torch.Size([128, 2048])\n",
      "Embeddings:  torch.Size([128, 20, 300])\n",
      "Features:  torch.Size([128, 1, 2048])\n",
      "Repeated features:  torch.Size([128, 19, 2048])\n",
      "EMBEDDING At EACH TIMESTEP:  torch.Size([128, 19, 2348])\n",
      "Outputs shape:  torch.Size([128, 19, 6039])\n",
      "Without START:  torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2/547], Loss: 7.5022, Perplexity: 1812.1111Original number of possible dist indices:  70000\n",
      "Filtered number of possible dist indices:  69872\n",
      "target caption shape:  torch.Size([128, 11])\n",
      "target images shape:  torch.Size([128, 3, 224, 224])\n",
      "distractors imgaes shape:  torch.Size([128, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6deb42fc37ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Pass the inputs through the CNN-RNN model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtarget_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mdistractor_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistractors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mboth_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractor_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-93494f4886b5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_embed_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# reshape features to shape (batch_size, -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "csv_out = \"pretraining_losses_2imgs_\"\n",
    "\n",
    "speaker_losses=[]\n",
    "perplexities = []\n",
    "steps = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "                \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_func_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        targets, distractors, target_captions = next(iter(data_loader))\n",
    "        print(\"target caption shape: \", target_captions.shape)\n",
    "        print(\"target images shape: \", targets.shape)\n",
    "        print(\"distractors imgaes shape: \", distractors.shape)\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        targets = targets.to(device)\n",
    "        distractors = distractors.to(device)\n",
    "        target_captions = target_captions.to(device)\n",
    "        \n",
    "        # Zero the gradients (reset).\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        target_features = encoder(targets)\n",
    "        distractor_features = encoder(distractors)\n",
    "        both_images = torch.cat((target_features, distractor_features), dim=-1)\n",
    "        print(\"Concatenated images shape: \", both_images.shape)\n",
    "        outputs = decoder(both_images, target_captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        print(\"Without START: \", target_captions[:, 1:].shape)\n",
    "        loss = criterion(outputs.contiguous().view(-1, vocab_size), target_captions[:, 1:].reshape(-1))\n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), torch.exp(loss))\n",
    "        \n",
    "        speaker_losses.append(loss.item())\n",
    "        steps.append(i_step)\n",
    "        perplexities.append(torch.exp(loss).item())\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'func-decoder-2imgs-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'func-encoder-2imgs-%d.pkl' % epoch))\n",
    "    \n",
    "    # save the training metrics\n",
    "    df_out = pd.DataFrame({\n",
    "        \"steps\": steps,\n",
    "        \"losses\": speaker_losses,\n",
    "        \"perplexities\": perplexities\n",
    "    })\n",
    "    df_out.to_csv(csv_out + \"epoch_\" + str(epoch) + \".csv\", index=False )\n",
    "    \n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "825852b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO preprocess all images with ResNet and save them to avoid the CNN computations over and over again\n",
    "\n",
    "# the architecture will then be: 1) ResNet preprocessed images from file \n",
    "# 2) a trainable model with 1 linear layer (MLP)\n",
    "\n",
    "class ResNetPreprocessor(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize pretrained Resnet 50.\n",
    "        \"\"\"\n",
    "        super(ResNetPreprocessor, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "        # remove the last fully connected layer\n",
    "        modules = list(resnet.children())[:-1] \n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.resnet(images)\n",
    "        # reshape features to shape (300, -1) - adapt to first dim\n",
    "        features = features.view(features.size(0), -1)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "class EncoderMLP(nn.Module):\n",
    "    def __init__(self, feature_size, embed_size):\n",
    "        \"\"\"\n",
    "        Create the trainable projection layer on top of the resnet features.\n",
    "        \"\"\"\n",
    "        super(EncoderMLP, self).__init__()\n",
    "        self.embed = nn.Linear(feature_size, embed_size)\n",
    "        self.embed.weight.data.normal_(0., 0.02)\n",
    "        self.embed.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        embedded_features = self.embed(features)\n",
    "        \n",
    "        return embedded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b273f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNetPreprocessor()\n",
    "resnet.eval()\n",
    "steps_total = 1#274\n",
    "batch_size = 256\n",
    "# load target image IDs\n",
    "img_ids = torch.load(\"../pretrain_img_IDs_2imgs.pt\")\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=1,\n",
    "                         vocab_threshold=93,\n",
    "                         vocab_from_file=True,\n",
    "                         download_dir=\"../../../data/train\", \n",
    "                        )\n",
    "# saved_target_features = torch.index_select(embedded_imgs, 0,  test_targets)\n",
    "# print(saved_target_features.shape)\n",
    "# extract features for target from model\n",
    "encoder_cnn = EncoderCNN(1048)\n",
    "\n",
    "# print(resnet_ftr.shape)\n",
    "# print(\"features equal?: \", torch.equal(saved_target_features, resnet_ftr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "436e79b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inds:  (0, 0)\n",
      "Idx at the i:  541501\n",
      "Ann_id in getitem:  541501\n",
      "tensor([[0.3498, 0.5552, 0.4481,  ..., 0.2971, 0.4736, 0.3348]])\n",
      "tensor([[0.1604, 0.1163, 0.1399,  ..., 0.0016, 0.2591, 0.2636]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3697, 0.5119, 0.4790,  ..., 0.3194, 0.4705, 0.3377])\n",
      "tensor([[0.3697, 0.5119, 0.4790,  ..., 0.3194, 0.4705, 0.3377]])\n",
      "Inds:  (1, 0)\n",
      "Idx at the i:  774587\n",
      "Ann_id in getitem:  774587\n",
      "tensor([[0.3984, 0.5538, 0.4955,  ..., 0.3621, 0.4461, 0.2992]])\n",
      "tensor([[0.0669, 0.9167, 0.1100,  ..., 0.5856, 0.3734, 0.0842]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3307, 0.5159, 0.4600,  ..., 0.3671, 0.4328, 0.3210])\n",
      "tensor([[0.3307, 0.5159, 0.4600,  ..., 0.3671, 0.4328, 0.3210]])\n",
      "Inds:  (2, 0)\n",
      "Idx at the i:  90649\n",
      "Ann_id in getitem:  90649\n",
      "tensor([[0.3258, 0.5500, 0.4559,  ..., 0.3508, 0.4057, 0.3086]])\n",
      "tensor([[0.7959, 1.1476, 0.6615,  ..., 0.1006, 0.2585, 0.2124]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3805, 0.5755, 0.4919,  ..., 0.3446, 0.4459, 0.3334])\n",
      "tensor([[0.3805, 0.5755, 0.4919,  ..., 0.3446, 0.4459, 0.3334]])\n",
      "Inds:  (3, 0)\n",
      "Idx at the i:  467675\n",
      "Ann_id in getitem:  467675\n",
      "tensor([[0.3881, 0.5300, 0.4755,  ..., 0.3281, 0.4055, 0.3755]])\n",
      "tensor([[0.1504, 0.5666, 0.4018,  ..., 0.9176, 0.6141, 0.1212]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3520, 0.5360, 0.4506,  ..., 0.3684, 0.4729, 0.3055])\n",
      "tensor([[0.3520, 0.5360, 0.4506,  ..., 0.3684, 0.4729, 0.3055]])\n",
      "Inds:  (4, 0)\n",
      "Idx at the i:  341514\n",
      "Ann_id in getitem:  341514\n",
      "tensor([[0.3721, 0.5448, 0.5385,  ..., 0.3449, 0.4292, 0.3067]])\n",
      "tensor([[0.1137, 0.4624, 0.6029,  ..., 0.3057, 0.1133, 0.2921]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3413, 0.5808, 0.5703,  ..., 0.3429, 0.4523, 0.3476])\n",
      "tensor([[0.3413, 0.5808, 0.5703,  ..., 0.3429, 0.4523, 0.3476]])\n",
      "Inds:  (5, 0)\n",
      "Idx at the i:  614642\n",
      "Ann_id in getitem:  614642\n",
      "tensor([[0.3734, 0.5660, 0.5060,  ..., 0.3014, 0.4285, 0.3150]])\n",
      "tensor([[0.1530, 2.3591, 0.8678,  ..., 0.0098, 0.1711, 0.4753]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3618, 0.5533, 0.4416,  ..., 0.3127, 0.3999, 0.2922])\n",
      "tensor([[0.3618, 0.5533, 0.4416,  ..., 0.3127, 0.3999, 0.2922]])\n",
      "Inds:  (6, 0)\n",
      "Idx at the i:  315041\n",
      "Ann_id in getitem:  315041\n",
      "tensor([[0.3524, 0.5570, 0.4501,  ..., 0.3452, 0.4726, 0.2939]])\n",
      "tensor([[0.1407, 0.1735, 0.3342,  ..., 0.0775, 0.1718, 0.0997]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3986, 0.5681, 0.4993,  ..., 0.3357, 0.4717, 0.3663])\n",
      "tensor([[0.3986, 0.5681, 0.4993,  ..., 0.3357, 0.4717, 0.3663]])\n",
      "Inds:  (7, 0)\n",
      "Idx at the i:  60744\n",
      "Ann_id in getitem:  60744\n",
      "tensor([[0.3698, 0.5742, 0.5619,  ..., 0.3441, 0.4817, 0.3182]])\n",
      "tensor([[0.4701, 0.7710, 0.2935,  ..., 0.1078, 0.4144, 0.2343]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3716, 0.5531, 0.5107,  ..., 0.3604, 0.4141, 0.3171])\n",
      "tensor([[0.3716, 0.5531, 0.5107,  ..., 0.3604, 0.4141, 0.3171]])\n",
      "Inds:  (8, 0)\n",
      "Idx at the i:  821793\n",
      "Ann_id in getitem:  821793\n",
      "tensor([[0.3700, 0.5863, 0.5206,  ..., 0.3468, 0.4026, 0.3332]])\n",
      "tensor([[0.4068, 0.3891, 0.1755,  ..., 0.0392, 0.0851, 0.4351]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3680, 0.5174, 0.4990,  ..., 0.3294, 0.4729, 0.3395])\n",
      "tensor([[0.3680, 0.5174, 0.4990,  ..., 0.3294, 0.4729, 0.3395]])\n",
      "Inds:  (9, 0)\n",
      "Idx at the i:  123564\n",
      "Ann_id in getitem:  123564\n",
      "tensor([[0.4058, 0.5060, 0.4351,  ..., 0.3405, 0.4521, 0.3857]])\n",
      "tensor([[0.0513, 1.2681, 0.0921,  ..., 0.4718, 1.6714, 0.5727]])\n",
      "features equal?:  False\n",
      "Equals to saved features?:  False\n",
      "Embedded index selected and indexed equal?  False\n",
      "tensor([0.3738, 0.4950, 0.5038,  ..., 0.3429, 0.4359, 0.3638])\n",
      "tensor([[0.3738, 0.4950, 0.5038,  ..., 0.3429, 0.4359, 0.3638]])\n",
      "torch.Size([10, 1, 2048])\n"
     ]
    }
   ],
   "source": [
    "# data_loader = torch.utils.data.DataLoader(\n",
    "#             dataset=dataset,\n",
    "#             batch_size=dataset.batch_size,\n",
    "#             shuffle=True)\n",
    "data_loader.dataset.ids = img_ids.tolist()\n",
    "img_ids_list = img_ids.tolist()\n",
    "preprocessed_images = []\n",
    "for i in range(10): # 70000\n",
    "    torch.manual_seed(42)\n",
    "    resnet.eval()\n",
    "    # get the batch of ids (256)\n",
    "    # Obtain the batch.\n",
    "    index_tup = [(i, 0)]\n",
    "    print(\"Inds: \", index_tup[0])\n",
    "    print(\"Idx at the i: \", img_ids_list[i])\n",
    "    new_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices=index_tup)\n",
    "    data_loader.batch_sampler.sampler = new_sampler\n",
    "#     data_loader.dataset.batch_size = 1    \n",
    "    # get the images from the data loader\n",
    "    targets, distractors, target_captions = next(iter(data_loader))\n",
    "#     print(\"Target sgape\", targets.shape)\n",
    "    ftr, resnet_ftr = encoder_cnn(targets)\n",
    "    print(resnet_ftr)\n",
    "    # pass them through the resnet\n",
    "    features = resnet(targets)\n",
    "    print(features)\n",
    "    print(\"features equal?: \", torch.equal(features, resnet_ftr))\n",
    "    print(\"Equals to saved features?: \", torch.equal(embedded_imgs[i, :], resnet_ftr))\n",
    "    print(\"Embedded index selected and indexed equal? \", torch.equal(embedded_imgs[i, :], torch.index_select(embedded_imgs, 0, torch.tensor([i]).long())))\n",
    "    print(embedded_imgs[i, :])\n",
    "    print(torch.index_select(embedded_imgs, 0, torch.tensor([i]).long()))\n",
    "    #     print(\"Targets features shape: \", features.shape)\n",
    "    # get the out dimensionality for future reference\n",
    "    # intermediate save \n",
    "    preprocessed_images.append(features)\n",
    "#     print(preprocessed_images)\n",
    "    \n",
    "    # save all images then\n",
    "preprocessed_images_tensor = torch.stack(preprocessed_images)\n",
    "print(preprocessed_images_tensor.shape)\n",
    "torch.save(preprocessed_images_tensor, \"resnet_pretrain_embedded_imgs_10.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eab57ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.sampler.SubsetRandomSampler object at 0x7fc2b22d4d10>\n",
      "Ann_id in getitem:  774587\n",
      "tensor([[0.0669, 0.9167, 0.1100,  ..., 0.5856, 0.3734, 0.0842]])\n",
      "tensor([[0.3984, 0.5538, 0.4955,  ..., 0.3621, 0.4461, 0.2992]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "test_saved_features = torch.load(\"resnet_pretrain_embedded_imgs_10.pt\")\n",
    "new_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices=[(1,0)])\n",
    "print(new_sampler)\n",
    "data_loader.batch_sampler.sampler = new_sampler\n",
    "#     data_loader.dataset.batch_size = 1    \n",
    "    # get the images from the data loader\n",
    "targets, distractors, target_captions = next(iter(data_loader))\n",
    "#     print(\"Target sgape\", targets.shape)\n",
    "ftr, resnet_ftr = encoder_cnn(targets)\n",
    "    \n",
    "print(test_saved_features[1, :])\n",
    "print(resnet_ftr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "425e4c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 651428 : 0.3464...\n",
    "# resnet.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd0d22f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700\n",
      "Inds:  (0, 0)\n",
      "Ann_id in getitem:  649113\n",
      "Inds:  (1, 0)\n",
      "Ann_id in getitem:  651428\n",
      "Inds:  (2, 0)\n",
      "Ann_id in getitem:  782868\n",
      "Inds:  (3, 0)\n",
      "Ann_id in getitem:  430837\n",
      "Inds:  (4, 0)\n",
      "Ann_id in getitem:  145409\n",
      "Inds:  (5, 0)\n",
      "Ann_id in getitem:  279459\n",
      "Inds:  (6, 0)\n",
      "Ann_id in getitem:  769124\n",
      "Inds:  (7, 0)\n",
      "Ann_id in getitem:  558327\n",
      "Inds:  (8, 0)\n",
      "Ann_id in getitem:  786836\n",
      "Inds:  (9, 0)\n",
      "Ann_id in getitem:  569827\n",
      "Inds:  (10, 0)\n",
      "Ann_id in getitem:  258587\n",
      "Inds:  (11, 0)\n",
      "Ann_id in getitem:  460519\n",
      "Inds:  (12, 0)\n",
      "Ann_id in getitem:  511418\n",
      "Inds:  (13, 0)\n",
      "Ann_id in getitem:  829135\n",
      "Inds:  (14, 0)\n",
      "Ann_id in getitem:  463000\n",
      "Inds:  (15, 0)\n",
      "Ann_id in getitem:  44567\n",
      "Inds:  (16, 0)\n",
      "Ann_id in getitem:  228182\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-eaaad4b45294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     print(\"Target sgape\", targets.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# pass them through the resnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#     print(\"Targets features shape: \", features.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# get the out dimensionality for future reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-b7e485353dda>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# reshape features to shape (300, -1) - adapt to first dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# same for the validation images\n",
    "resnet = ResNetPreprocessor()\n",
    "img_ids = torch.load(\"../pretrain_val_img_IDs_2imgs.pt\")\n",
    "# data_loader = torch.utils.data.DataLoader(\n",
    "#             dataset=dataset,\n",
    "#             batch_size=dataset.batch_size,\n",
    "#             shuffle=True)\n",
    "data_loader.dataset.ids = img_ids.tolist()\n",
    "print(len(data_loader.dataset.ids))\n",
    "preprocessed_images = []\n",
    "for i in range(0, 3700):\n",
    "    # get the batch of ids (256)\n",
    "    # Obtain the batch.\n",
    "    index_tup = [(i, 0)]\n",
    "    print(\"Inds: \", index_tup[0])\n",
    "    new_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices=index_tup)\n",
    "    data_loader.batch_sampler.sampler = new_sampler\n",
    "#     data_loader.dataset.batch_size = 1    \n",
    "    # get the images from the data loader\n",
    "    targets, distractors, target_captions = next(iter(data_loader))\n",
    "#     print(\"Target sgape\", targets.shape)\n",
    "    # pass them through the resnet\n",
    "    features = resnet(targets)\n",
    "#     print(\"Targets features shape: \", features.shape)\n",
    "    # get the out dimensionality for future reference\n",
    "    # intermediate save \n",
    "    preprocessed_images.extend(features)\n",
    "    \n",
    "    # save all images then\n",
    "preprocessed_images_tensor = torch.stack(preprocessed_images)\n",
    "print(preprocessed_images_tensor.shape)\n",
    "torch.save(preprocessed_images_tensor, \"resnet_pretrain_embedded_val_imgs.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eae7c1",
   "metadata": {},
   "source": [
    "## Reference game setup\n",
    "\n",
    "Here, the actually interesting steps are hapenning. Both agents, the speaker and the listener, are trained in the reference game set up. \n",
    "\n",
    "For this, the speaker is initialized with a pretrained model and then further fine-tuned. To do so, a functional training dataset object is created which samples image pairs rather than single image-caption pairs as for pretraining the speaker. A respective data_loader is defined. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f5efb",
   "metadata": {},
   "source": [
    "Below, all the training parameters are instantiated, the pretrained speaker model is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2b1129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "vocab_threshold = 1        # minimum word count threshold\n",
    "listener_embed_size = 512\n",
    "\n",
    "# NOTE: embed_size for speaker is 1024, different from listener\n",
    "speaker_vis_embed_size = 1024\n",
    "speaker_embed_size = 300\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 1             # number of training epochs (1 for testing)\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 1          # determines window for printing average loss\n",
    "log_file = 'reference_game_log_train_2imgs_notebook.txt'       # name of file with saved training loss and perplexity\n",
    "lambda_s = 0.1 # weight of the structural loss from the original paper\n",
    "\n",
    "# define a data loader returning two images\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader_pairs = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file,\n",
    "                         download_dir=\"../../../data/train\", \n",
    "                        )\n",
    "vocab_size = len(data_loader_pairs.dataset.vocab)\n",
    "\n",
    "# data_loader_pairs.dataset.ids = torch.load(\"../pretrain_img_IDs_2imgs.pt\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be12be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 2048])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_imgs = torch.load(\"resnet_pretrain_embedded_imgs.pt\")\n",
    "embedded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0e122f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader_pairs.dataset.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aae23584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps:  14000\n"
     ]
    }
   ],
   "source": [
    "speaker_encoder = EncoderCNN(speaker_vis_embed_size)\n",
    "speaker_decoder = DecoderRNN(speaker_embed_size, hidden_size, vocab_size, speaker_vis_embed_size)\n",
    "# out features from resnet to desired embed size\n",
    "speaker_mlp = EncoderMLP(2048, speaker_vis_embed_size)\n",
    "# speaker_encoder.load_state_dict(torch.load(os.path.join('../models', 'encoder-earlystoppiing-4.pkl')))\n",
    "# speaker_decoder.load_state_dict(torch.load(os.path.join('../models', 'decoder-earlystopping-4.pkl')))\n",
    "\n",
    "\n",
    "listener_encoder = ListenerEncoderCNN(listener_embed_size)\n",
    "listener_rnn = ListenerEncoderRNN(listener_embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "speaker_encoder.to(device)\n",
    "speaker_encoder.eval()\n",
    "speaker_decoder.to(device)\n",
    "listener_encoder.to(device)\n",
    "listener_rnn.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# Specify the learnable parameters of the model.\n",
    "# different sets of params are defined because they are optimized with different losses\n",
    "speaker_params = list(speaker_decoder.embed.parameters()) + list(speaker_decoder.lstm.parameters()) + list(speaker_decoder.linear.parameters()) + list(speaker_mlp.embed.parameters()) \n",
    "listener_params = list(listener_rnn.lstm.parameters()) + list(listener_encoder.embed.parameters()) # + list(listener_rnn.linear.parameters())\n",
    "\n",
    "# Define the optimizer.\n",
    "speaker_optimizer = torch.optim.Adam(speaker_params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "listener_optimizer = torch.optim.Adam(listener_params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "total_step = math.ceil(len(data_loader_pairs.dataset.caption_lengths) / data_loader_pairs.batch_sampler.batch_size)\n",
    "print(\"Total steps: \", total_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09911d2e",
   "metadata": {},
   "source": [
    "Below, the model is trained. The conceptual steps are:\n",
    "* sample (target, distractor, target_index) tuples\n",
    "* pass target images to the speaker which samples corresponding captions\n",
    "* pass the produced captions to the listener LSTM\n",
    "* pass both images and corresponding captions through the listener CNN\n",
    "* compute speaker loss consisting of the structural (cross entropy) and the functional (REINFORCE) loss\n",
    "* compute listener loss consisting of the cross entropy loss (predicted vs target image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c275b9",
   "metadata": {},
   "source": [
    "**<-- Please check me below -->**\n",
    "\n",
    "Really not sure if the training loop is technically correct for computing all the loss components and training the model as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9550d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language drift metric (a)\n",
    "# compute the difference between the token overlap between the ground truth caption of the target \n",
    "# and the ground truth caption of the distractor\n",
    "# the larger the difference, the more discriminative the caption\n",
    "# overlap computed as sum over 1 iff token match, 0 otherwise\n",
    "# pretty instable since we might get semantically similar tokens but would count them as bad as completely unrelated ones\n",
    "# check if START END etc need to be treated separately smh to avoid biasing the computation\n",
    "# TODO: also return distractor caps during training \n",
    "def compute_discrete_overlap(generated_cap, target_cap, distractor_cap):\n",
    "    \"\"\"\n",
    "    Compute an overlap score over the generated caption with the two ground truth captions.\n",
    "    This score is an attempt to capture language drift, while being agnostic towards compositional alternations.\n",
    "    \n",
    "    For batched input, expected input shape is (batch_size, caption_len), output is (batch_size,)\n",
    "    generated_cap: index lists\n",
    "        Caption generated by the speaker.\n",
    "    target_cap:\n",
    "        Ground truth caption for the target image.\n",
    "    distractor_cap:\n",
    "        Ground truth caption for the distractor image.\n",
    "    \"\"\"\n",
    "    target_score_list = [i == j for i, j in list(zip(generated_cap, target_cap))]\n",
    "    # target_score_list = torch.eq(generated_cap, target_cap)\n",
    "    distractor_score_list = [i == j for i, j in list(zip(generated_cap, distractor_cap))]\n",
    "    # distractor_score_list = torch.eq(generated_cap, distractor_cap)\n",
    "    overlap_score = sum(target_score_list) - sum(distractor_score_list)\n",
    "    # overlap_score = target_score_list.sum(dim=1) - distractor_score_list.sum(dim=1) \n",
    "    \n",
    "    return overlap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4b83de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language drift metric (b)\n",
    "# same as above, but on the embeddings, to be more sensitive to actual semantic similarity\n",
    "\n",
    "def compute_cont_overlap(generated_cap, target_cap, distractor_cap):\n",
    "    \"\"\"\n",
    "    Compute an overlap score over the generated caption with the two ground truth captions.\n",
    "    This score is an attempt to capture language drift, while being agnostic towards compositional alternations.\n",
    "    \n",
    "    generated_cap: embeddings tensors (batch_size, len_caption, embed_size)\n",
    "        Caption generated by the speaker.\n",
    "    target_cap:\n",
    "        Ground truth caption for the target image.\n",
    "    distractor_cap:\n",
    "        Ground truth caption for the distractor image.\n",
    "        \n",
    "    Returns:\n",
    "        overlap_scor (batch_size,)\n",
    "            tensor of cosine similarity scores by-caption.\n",
    "    \"\"\"\n",
    "    target_dist = nn.functional.cosine_similarity(generated_cap, target_cap, dim=-1) # elementwise, then take average \n",
    "    print(target_dist)\n",
    "    distractor_dist = nn.functional.cosine_similarity(generated_cap, distractor_cap, dim=-1)\n",
    "    print(distractor_dist)\n",
    "    overlap_score = target_dist.mean(dim=1) - distractor_dist.mean(dim=1)\n",
    "    return overlap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ea9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TransfoXLLMHeadModel, TransfoXLTokenizer, TransfoXLConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18f201cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazaridou's original drift metrics\n",
    "\n",
    "\n",
    "def structural_drift(caption, tokenizer, model):\n",
    "    \"\"\"\n",
    "    P(caption) under some pretrained language model. \n",
    "    \n",
    "    Caption needs to be natural language str.\n",
    "    \"\"\"\n",
    "    inputs_str = clean_sentence(caption)\n",
    "    inputs = tokenizer(inputs_str, return_tensors=\"pt\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # pass labels in order to get neg LL estimates of the inputs as the loss\n",
    "        outputs = model(**inputs, labels = inputs[\"input_ids\"])\n",
    "        neg_ll = outputs[0]\n",
    "    # compute sentence-level LL\n",
    "    sent_ll = -neg_ll.sum(-1)\n",
    "    return sent_ll\n",
    "\n",
    "\n",
    "def semantic_drift(caption, image, visual_embed_size, embed_size, hidden_size, vocab_size):\n",
    "    \"\"\"\n",
    "    P(caption|image) under image caption model pretrained on one image only.\n",
    "    \n",
    "    image: (batch_size, 3, 224, 224)\n",
    "    caption: (batch_size, caption_len)\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "        prob: (batch_size,)\n",
    "            Tensor of conditional log probabilities measuring the semantic drift. \n",
    "    \"\"\"\n",
    "    # load pretrained models\n",
    "    encoder = EncoderCNN(visual_embed_size)\n",
    "    decoder = ImageCaptioner(embed_size, hidden_size, vocab_size) # this is a 1-image conditioned one now (with prepenading of embedding)\n",
    "    encoder.load_state_dict(torch.load(\"../models/encoder-earlystoppiing-4_semantic-drift.pkl\"))\n",
    "    decoder.load_state_dict(torch.load(\"../models/decoder-earlystopping-4_semantic-drift.pkl\"))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    # set to .eval()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    # softmax for computing the probabilities over the scores\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    sent_probs = []\n",
    "    with torch.no_grad():   \n",
    "        # embed image\n",
    "        features = encoder(image)\n",
    "        # pass image, embedded caption through lstm\n",
    "        scores = decoder(features, caption) # TODO which format does the caption have to have?\n",
    "        # retrieve log probs of the target tokens (probs at given indices) \n",
    "        scores_prob = softmax(scores) \n",
    "        # exclude START and END tokens\n",
    "        sent_probs = []\n",
    "        for num, cap in enumerate(caption.tolist()):\n",
    "            sent_probs.append(torch.stack([scores_prob[num][i][j] for i, j in enumerate(cap[1:-1])]))\n",
    "        # compute log probability of the sentence\n",
    "        prob = torch.log(torch.stack(sent_probs)).sum(dim=1)\n",
    "    return prob\n",
    "\n",
    "def ngram_drift():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9f40d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.8832],\n",
      "        [1.0000, 1.0000]], dtype=torch.float64)\n",
      "tensor([[0.9037, 0.0000],\n",
      "        [1.0000, 1.0000]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 4, 1173, 2114, 22, 1173, 328, 78, 4, 1208, 1],\n",
       " [0, 4, 134, 336, 136, 36, 4, 714, 205, 19, 1]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([[[1,2,3,1], [4,5,6,7]], [[1,2,3,1], [4,5,6,7]]]).to(torch.float64)\n",
    "ground = torch.tensor([[[1,2,3,1], [8,9,10,3]], [[1,2,3,1], [4,5,6,7]]]).to(torch.float64)\n",
    "dist = torch.tensor([[[2,2,2,2], [0,0,0,0]], [[1,2,3,1], [4,5,6,7]]]).to(torch.float64)\n",
    "compute_cont_overlap(ground,target,dist)\n",
    "# torch.eq(target, ground).sum(dim=1) - torch.eq(target, ground).sum(dim=1)\n",
    "# target.shape\n",
    "cap.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6dce8fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-75.5244, -73.8117])\n",
      "tensor([-82.0249, -84.7585])\n"
     ]
    }
   ],
   "source": [
    "embed_size = 1024\n",
    "hidden_size = 512\n",
    "visual_embed_size = 1024\n",
    "vocab_size = len(data_loader_pairs.dataset.vocab)\n",
    "\n",
    "print(semantic_drift(cap, orig_image, visual_embed_size, embed_size, hidden_size, vocab_size))\n",
    "print(semantic_drift(cap, image, visual_embed_size, embed_size, hidden_size, vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af923673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "# huggingface GPT-2 (Masked models don't really work?)\n",
    "# check out smaller ones\n",
    "# TODO\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_id = \"transfo-xl-wt103\"\n",
    "# configuration = TransfoXLConfig(sample_softmax = 1) # try returning softmaxed probs already from model\n",
    "model = TransfoXLLMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f16b9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ann_id in getitem:  54684\n",
      "Start a cat and dog laying next to each other on a couch .\n",
      "Out shape:  torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-62.3742])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, dist, cap = next(iter(data_loader))\n",
    "print(clean_sentence(cap))\n",
    "str_drift = structural_drift(cap, tokenizer, model)\n",
    "print(\"Out shape: \", str_drift.shape)\n",
    "str_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3412631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001, 1.0001,\n",
       "         1.0000, 1.0001, 1.0000, 1.0001, 1.0000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_drift.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b66ae00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target inds:  tensor([12951, 60545, 40509, 59784, 65574])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 0, 0, 0, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 0, 0, 0, 1])\n",
      "Stacked preds out:  torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "Log probs out: torch.Size([5, 11, 1]) tensor([[[-8.1754],\n",
      "         [-7.8983],\n",
      "         [-7.7656],\n",
      "         [-7.6954],\n",
      "         [-7.6557],\n",
      "         [-7.6324],\n",
      "         [-7.6184],\n",
      "         [-7.6098],\n",
      "         [-7.6044],\n",
      "         [-7.6010],\n",
      "         [-7.5989]],\n",
      "\n",
      "        [[-8.1493],\n",
      "         [-7.8583],\n",
      "         [-7.7185],\n",
      "         [-7.6449],\n",
      "         [-7.6039],\n",
      "         [-7.5802],\n",
      "         [-7.5660],\n",
      "         [-7.5574],\n",
      "         [-7.5522],\n",
      "         [-7.5489],\n",
      "         [-7.5468]],\n",
      "\n",
      "        [[-8.1747],\n",
      "         [-7.8961],\n",
      "         [-7.7621],\n",
      "         [-7.6908],\n",
      "         [-7.6505],\n",
      "         [-7.6266],\n",
      "         [-7.6121],\n",
      "         [-7.6032],\n",
      "         [-7.5976],\n",
      "         [-7.5941],\n",
      "         [-7.5919]],\n",
      "\n",
      "        [[-8.1729],\n",
      "         [-7.8916],\n",
      "         [-7.7561],\n",
      "         [-7.6839],\n",
      "         [-7.6430],\n",
      "         [-7.6188],\n",
      "         [-7.6041],\n",
      "         [-7.5950],\n",
      "         [-7.5893],\n",
      "         [-7.5857],\n",
      "         [-7.5834]],\n",
      "\n",
      "        [[-8.1735],\n",
      "         [-7.8945],\n",
      "         [-7.7609],\n",
      "         [-7.6900],\n",
      "         [-7.6500],\n",
      "         [-7.6264],\n",
      "         [-7.6121],\n",
      "         [-7.6032],\n",
      "         [-7.5976],\n",
      "         [-7.5940],\n",
      "         [-7.5918]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([0.3514, 0.3516, 0.3925, 0.3472, 0.3443], grad_fn=<MaxBackward0>) tensor([0, 0, 1, 0, 1])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [1, 1, -1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 11, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-84.8552],\n",
      "        [-84.3264],\n",
      "        [-84.7998],\n",
      "        [-84.7240],\n",
      "        [-84.7941]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([84.8552], grad_fn=<MulBackward0>), tensor([84.3264], grad_fn=<MulBackward0>), tensor([-84.7998], grad_fn=<MulBackward0>), tensor([84.7240], grad_fn=<MulBackward0>), tensor([84.7941], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(50.7800, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[-0.1117, -0.1460, -0.0027,  ..., -0.3633, -0.0355,  0.2737]],\n",
      "\n",
      "        [[-0.1162, -0.1614, -0.0331,  ..., -0.3717, -0.0771,  0.2766]],\n",
      "\n",
      "        [[-0.1169, -0.1570, -0.0097,  ..., -0.3600, -0.0540,  0.2958]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2840, -0.3084,  0.0929,  ..., -0.6770, -0.1137,  0.4639]],\n",
      "\n",
      "        [[-0.2799, -0.2732,  0.1022,  ..., -0.7402, -0.0983,  0.4360]],\n",
      "\n",
      "        [[-0.2621, -0.3200,  0.0643,  ..., -0.7686, -0.1367,  0.4362]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(8.7541, grad_fn=<NllLossBackward0>)  L_f:  tensor(50.7800, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [1/14000], Speaker loss: 51.6554, Listener loss: 0.6920, Perplexity: 27142505903418991706112.0000\n",
      "Target inds:  tensor([46687, 55527, 33581, 56426, 22170])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 0, 1, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 0, 1, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 12])\n",
      "torch.Size([5, 12])\n",
      "Log probs out: torch.Size([5, 12, 1]) tensor([[[-2.0179],\n",
      "         [-0.3944],\n",
      "         [-0.1689],\n",
      "         [-0.1152],\n",
      "         [-0.0954],\n",
      "         [-0.0860],\n",
      "         [-0.0809],\n",
      "         [-0.0778],\n",
      "         [-0.0758],\n",
      "         [-0.0744],\n",
      "         [-0.0734],\n",
      "         [-0.0727]],\n",
      "\n",
      "        [[-2.0046],\n",
      "         [-0.3873],\n",
      "         [-0.1653],\n",
      "         [-0.1128],\n",
      "         [-0.0934],\n",
      "         [-0.0843],\n",
      "         [-0.0794],\n",
      "         [-0.0764],\n",
      "         [-0.0745],\n",
      "         [-0.0732],\n",
      "         [-0.0722],\n",
      "         [-0.0715]],\n",
      "\n",
      "        [[-2.0171],\n",
      "         [-0.3915],\n",
      "         [-0.1671],\n",
      "         [-0.1139],\n",
      "         [-0.0944],\n",
      "         [-0.0852],\n",
      "         [-0.0802],\n",
      "         [-0.0772],\n",
      "         [-0.0753],\n",
      "         [-0.0740],\n",
      "         [-0.0731],\n",
      "         [-0.0724]],\n",
      "\n",
      "        [[-1.9979],\n",
      "         [-0.3861],\n",
      "         [-0.1652],\n",
      "         [-0.1128],\n",
      "         [-0.0934],\n",
      "         [-0.0843],\n",
      "         [-0.0793],\n",
      "         [-0.0763],\n",
      "         [-0.0744],\n",
      "         [-0.0730],\n",
      "         [-0.0721],\n",
      "         [-0.0714]],\n",
      "\n",
      "        [[-2.0298],\n",
      "         [-0.3963],\n",
      "         [-0.1691],\n",
      "         [-0.1153],\n",
      "         [-0.0954],\n",
      "         [-0.0862],\n",
      "         [-0.0811],\n",
      "         [-0.0781],\n",
      "         [-0.0761],\n",
      "         [-0.0748],\n",
      "         [-0.0738],\n",
      "         [-0.0731]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([2.8486, 2.9429, 2.8508, 2.8892, 2.8380], grad_fn=<MaxBackward0>) tensor([1, 0, 1, 1, 0])\n",
      "Batch average accuracy:  tensor(0.6000)\n",
      "Rewards:  [-1, 1, 1, 1, -1]\n",
      "Policy log probs in:  torch.Size([5, 12, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-3.3329],\n",
      "        [-3.2949],\n",
      "        [-3.3212],\n",
      "        [-3.2862],\n",
      "        [-3.3489]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-3.3329], grad_fn=<MulBackward0>), tensor([3.2949], grad_fn=<MulBackward0>), tensor([3.3212], grad_fn=<MulBackward0>), tensor([3.2862], grad_fn=<MulBackward0>), tensor([-3.3489], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.6441, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[-0.1517,  0.0542, -0.3113,  ..., -0.9402, -0.6262,  0.4062]],\n",
      "\n",
      "        [[-0.1374,  0.0685, -0.3045,  ..., -0.9491, -0.6367,  0.4002]],\n",
      "\n",
      "        [[-0.1430,  0.0526, -0.3143,  ..., -0.9357, -0.6333,  0.3952]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0518,  0.3786, -0.4617,  ..., -1.8005, -0.9680,  0.7942]],\n",
      "\n",
      "        [[-0.0479,  0.4098, -0.4724,  ..., -1.8391, -0.9982,  0.8333]],\n",
      "\n",
      "        [[-0.0576,  0.3886, -0.5003,  ..., -1.8270, -0.9712,  0.7975]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.8207, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.6441, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [2/14000], Speaker loss: 1.7262, Listener loss: 0.6907, Perplexity: 5.6192\n",
      "Target inds:  tensor([33991, 55738, 32135,  2109, 19392])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 1, 0, 0, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 1, 0, 0, 0])\n",
      "Stacked preds out:  torch.Size([5, 14])\n",
      "torch.Size([5, 14])\n",
      "Log probs out: torch.Size([5, 14, 1]) tensor([[[-0.0881],\n",
      "         [-0.0034],\n",
      "         [-0.0015],\n",
      "         [-0.0011],\n",
      "         [-0.0010],\n",
      "         [-0.0010],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009]],\n",
      "\n",
      "        [[-0.0875],\n",
      "         [-0.0033],\n",
      "         [-0.0014],\n",
      "         [-0.0011],\n",
      "         [-0.0010],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009]],\n",
      "\n",
      "        [[-0.0867],\n",
      "         [-0.0033],\n",
      "         [-0.0014],\n",
      "         [-0.0011],\n",
      "         [-0.0010],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009]],\n",
      "\n",
      "        [[-0.0897],\n",
      "         [-0.0034],\n",
      "         [-0.0015],\n",
      "         [-0.0011],\n",
      "         [-0.0010],\n",
      "         [-0.0010],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009]],\n",
      "\n",
      "        [[-0.0869],\n",
      "         [-0.0033],\n",
      "         [-0.0014],\n",
      "         [-0.0011],\n",
      "         [-0.0010],\n",
      "         [-0.0010],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009],\n",
      "         [-0.0009]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([4.7563, 4.8898, 4.9401, 4.7302, 4.9206], grad_fn=<MaxBackward0>) tensor([1, 0, 1, 1, 0])\n",
      "Batch average accuracy:  tensor(0.4000)\n",
      "Rewards:  [1, -1, -1, -1, 1]\n",
      "Policy log probs in:  torch.Size([5, 14, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.1034],\n",
      "        [-0.1026],\n",
      "        [-0.1018],\n",
      "        [-0.1050],\n",
      "        [-0.1021]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.1034], grad_fn=<MulBackward0>), tensor([-0.1026], grad_fn=<MulBackward0>), tensor([-0.1018], grad_fn=<MulBackward0>), tensor([-0.1050], grad_fn=<MulBackward0>), tensor([0.1021], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.0208, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[-0.0994,  0.6503, -0.3402,  ..., -1.7710, -1.0388,  0.3764]],\n",
      "\n",
      "        [[-0.1008,  0.6413, -0.3359,  ..., -1.7780, -1.0464,  0.3748]],\n",
      "\n",
      "        [[-0.1069,  0.6436, -0.3391,  ..., -1.7764, -1.0365,  0.3758]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1261,  1.1869, -0.3180,  ..., -2.4046, -1.2169,  0.6339]],\n",
      "\n",
      "        [[ 0.1286,  1.1869, -0.3162,  ..., -2.4092, -1.2256,  0.6373]],\n",
      "\n",
      "        [[ 0.1299,  1.1886, -0.3252,  ..., -2.3983, -1.2271,  0.6413]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(15.1362, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.0208, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3/14000], Speaker loss: 1.4928, Listener loss: 0.7168, Perplexity: 4.4498\n",
      "Target inds:  tensor([43805, 48311, 66067, 68747, 12549])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 0, 1, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 0, 1, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 13])\n",
      "torch.Size([5, 13])\n",
      "Log probs out: torch.Size([5, 13, 1]) tensor([[[-0.0356],\n",
      "         [-0.0018],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008]],\n",
      "\n",
      "        [[-0.0354],\n",
      "         [-0.0018],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008]],\n",
      "\n",
      "        [[-0.0357],\n",
      "         [-0.0018],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008]],\n",
      "\n",
      "        [[-0.0355],\n",
      "         [-0.0018],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008]],\n",
      "\n",
      "        [[-0.0358],\n",
      "         [-0.0018],\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008],\n",
      "         [-0.0008]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([3.3840, 3.3975, 3.4768, 3.2228, 3.3425], grad_fn=<MaxBackward0>) tensor([1, 1, 0, 0, 0])\n",
      "Batch average accuracy:  tensor(0.)\n",
      "Rewards:  [-1, -1, -1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 13, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.0466],\n",
      "        [-0.0464],\n",
      "        [-0.0467],\n",
      "        [-0.0464],\n",
      "        [-0.0468]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.0466], grad_fn=<MulBackward0>), tensor([-0.0464], grad_fn=<MulBackward0>), tensor([-0.0467], grad_fn=<MulBackward0>), tensor([-0.0464], grad_fn=<MulBackward0>), tensor([-0.0468], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.0466, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 0.3876,  1.1870, -0.2853,  ..., -2.1166, -1.0745,  0.0946]],\n",
      "\n",
      "        [[ 0.3938,  1.1830, -0.2814,  ..., -2.1187, -1.0676,  0.0953]],\n",
      "\n",
      "        [[ 0.3901,  1.1800, -0.2836,  ..., -2.1180, -1.0731,  0.0875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6433,  1.7879, -0.2534,  ..., -2.6432, -1.3287,  0.1039]],\n",
      "\n",
      "        [[ 0.6347,  1.7944, -0.2589,  ..., -2.6309, -1.3320,  0.1134]],\n",
      "\n",
      "        [[ 0.6468,  1.7817, -0.2580,  ..., -2.6441, -1.3239,  0.1246]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(14.8768, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.0466, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [4/14000], Speaker loss: 1.4411, Listener loss: 0.7252, Perplexity: 4.2254\n",
      "Target inds:  tensor([61682,  4650, 16882, 62179, 18143])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 0, 1, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 0, 1, 0])\n",
      "Stacked preds out:  torch.Size([5, 12])\n",
      "torch.Size([5, 12])\n",
      "Log probs out: torch.Size([5, 12, 1]) tensor([[[-0.0673],\n",
      "         [-0.0049],\n",
      "         [-0.0031],\n",
      "         [-0.0028],\n",
      "         [-0.0028],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026]],\n",
      "\n",
      "        [[-0.0671],\n",
      "         [-0.0049],\n",
      "         [-0.0031],\n",
      "         [-0.0028],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026]],\n",
      "\n",
      "        [[-0.0671],\n",
      "         [-0.0049],\n",
      "         [-0.0031],\n",
      "         [-0.0028],\n",
      "         [-0.0028],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026]],\n",
      "\n",
      "        [[-0.0670],\n",
      "         [-0.0049],\n",
      "         [-0.0031],\n",
      "         [-0.0028],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026]],\n",
      "\n",
      "        [[-0.0673],\n",
      "         [-0.0049],\n",
      "         [-0.0031],\n",
      "         [-0.0028],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0026],\n",
      "         [-0.0025]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([3.5683, 3.4855, 3.5328, 3.5134, 3.4797], grad_fn=<MaxBackward0>) tensor([0, 0, 0, 1, 1])\n",
      "Batch average accuracy:  tensor(0.6000)\n",
      "Rewards:  [-1, 1, 1, 1, -1]\n",
      "Policy log probs in:  torch.Size([5, 12, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.0993],\n",
      "        [-0.0990],\n",
      "        [-0.0991],\n",
      "        [-0.0990],\n",
      "        [-0.0991]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.0993], grad_fn=<MulBackward0>), tensor([0.0990], grad_fn=<MulBackward0>), tensor([0.0991], grad_fn=<MulBackward0>), tensor([0.0990], grad_fn=<MulBackward0>), tensor([-0.0991], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.0197, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 0.8301,  1.4658, -0.0275,  ..., -2.1204, -1.2837, -0.1102]],\n",
      "\n",
      "        [[ 0.8309,  1.4642, -0.0299,  ..., -2.1250, -1.2877, -0.1137]],\n",
      "\n",
      "        [[ 0.8332,  1.4638, -0.0289,  ..., -2.1260, -1.2850, -0.1103]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1388,  2.0903, -0.0150,  ..., -2.7228, -1.3571, -0.2072]],\n",
      "\n",
      "        [[ 1.1399,  2.1035, -0.0141,  ..., -2.7198, -1.3577, -0.2107]],\n",
      "\n",
      "        [[ 1.1287,  2.0981, -0.0173,  ..., -2.7166, -1.3598, -0.2053]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(13.5364, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.0197, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [5/14000], Speaker loss: 1.3734, Listener loss: 0.7027, Perplexity: 3.9487\n",
      "Target inds:  tensor([21104, 14008, 55084, 49079, 29991])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 1, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 1, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "Log probs out: torch.Size([5, 11, 1]) tensor([[[-0.1049],\n",
      "         [-0.0095],\n",
      "         [-0.0064],\n",
      "         [-0.0059],\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057]],\n",
      "\n",
      "        [[-0.1042],\n",
      "         [-0.0094],\n",
      "         [-0.0063],\n",
      "         [-0.0059],\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0056],\n",
      "         [-0.0056]],\n",
      "\n",
      "        [[-0.1049],\n",
      "         [-0.0094],\n",
      "         [-0.0063],\n",
      "         [-0.0059],\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057]],\n",
      "\n",
      "        [[-0.1046],\n",
      "         [-0.0094],\n",
      "         [-0.0063],\n",
      "         [-0.0059],\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0056]],\n",
      "\n",
      "        [[-0.1048],\n",
      "         [-0.0094],\n",
      "         [-0.0063],\n",
      "         [-0.0059],\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([2.4458, 2.5178, 2.4955, 2.5447, 2.6613], grad_fn=<MaxBackward0>) tensor([0, 1, 1, 0, 0])\n",
      "Batch average accuracy:  tensor(0.2000)\n",
      "Rewards:  [-1, -1, 1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 11, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.1668],\n",
      "        [-0.1656],\n",
      "        [-0.1667],\n",
      "        [-0.1662],\n",
      "        [-0.1666]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.1668], grad_fn=<MulBackward0>), tensor([-0.1656], grad_fn=<MulBackward0>), tensor([0.1667], grad_fn=<MulBackward0>), tensor([-0.1662], grad_fn=<MulBackward0>), tensor([-0.1666], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.0997, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 0.9544,  1.7892,  0.3277,  ..., -1.9378, -1.3464, -0.1274]],\n",
      "\n",
      "        [[ 0.9561,  1.7861,  0.3247,  ..., -1.9475, -1.3447, -0.1260]],\n",
      "\n",
      "        [[ 0.9573,  1.7904,  0.3261,  ..., -1.9375, -1.3475, -0.1267]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3014,  2.3817,  0.4010,  ..., -2.5998, -1.4848, -0.1197]],\n",
      "\n",
      "        [[ 1.3020,  2.3771,  0.4016,  ..., -2.6074, -1.4849, -0.1173]],\n",
      "\n",
      "        [[ 1.2968,  2.3812,  0.4027,  ..., -2.6038, -1.4849, -0.1239]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_s:  tensor(12.6014, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.0997, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [6/14000], Speaker loss: 1.1604, Listener loss: 0.7346, Perplexity: 3.1913\n",
      "Target inds:  tensor([21923, 52183, 17939,  5367, 57829])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 0, 0, 0, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 0, 0, 0, 0])\n",
      "Stacked preds out:  torch.Size([5, 10])\n",
      "torch.Size([5, 10])\n",
      "Log probs out: torch.Size([5, 10, 1]) tensor([[[-0.1511],\n",
      "         [-0.0156],\n",
      "         [-0.0108],\n",
      "         [-0.0102],\n",
      "         [-0.0101],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100]],\n",
      "\n",
      "        [[-0.1516],\n",
      "         [-0.0157],\n",
      "         [-0.0108],\n",
      "         [-0.0102],\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100]],\n",
      "\n",
      "        [[-0.1512],\n",
      "         [-0.0156],\n",
      "         [-0.0108],\n",
      "         [-0.0102],\n",
      "         [-0.0101],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100]],\n",
      "\n",
      "        [[-0.1511],\n",
      "         [-0.0156],\n",
      "         [-0.0108],\n",
      "         [-0.0102],\n",
      "         [-0.0101],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100]],\n",
      "\n",
      "        [[-0.1511],\n",
      "         [-0.0156],\n",
      "         [-0.0108],\n",
      "         [-0.0101],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0099]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([0.8884, 0.8828, 0.7769, 0.7003, 0.8183], grad_fn=<MaxBackward0>) tensor([0, 1, 0, 1, 1])\n",
      "Batch average accuracy:  tensor(0.4000)\n",
      "Rewards:  [1, -1, 1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 10, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.2476],\n",
      "        [-0.2486],\n",
      "        [-0.2478],\n",
      "        [-0.2477],\n",
      "        [-0.2475]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.2476], grad_fn=<MulBackward0>), tensor([-0.2486], grad_fn=<MulBackward0>), tensor([0.2478], grad_fn=<MulBackward0>), tensor([-0.2477], grad_fn=<MulBackward0>), tensor([-0.2475], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.0497, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 1.1316,  2.0762,  0.5418,  ..., -1.8554, -1.3854, -0.1409]],\n",
      "\n",
      "        [[ 1.1332,  2.0701,  0.5432,  ..., -1.8543, -1.3881, -0.1368]],\n",
      "\n",
      "        [[ 1.1280,  2.0787,  0.5409,  ..., -1.8499, -1.3857, -0.1399]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4711,  2.8242,  0.6227,  ..., -2.5119, -1.5732, -0.1932]],\n",
      "\n",
      "        [[ 1.4744,  2.8244,  0.6245,  ..., -2.5111, -1.5724, -0.1956]],\n",
      "\n",
      "        [[ 1.4733,  2.8254,  0.6236,  ..., -2.5129, -1.5727, -0.1942]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(12.0458, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.0497, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [7/14000], Speaker loss: 1.1549, Listener loss: 0.7097, Perplexity: 3.1737\n",
      "Target inds:  tensor([67327, 55787,  2015, 23943, 38506])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 1, 0, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 1, 0, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 13])\n",
      "torch.Size([5, 13])\n",
      "Log probs out: torch.Size([5, 13, 1]) tensor([[[-0.1801],\n",
      "         [-0.0211],\n",
      "         [-0.0150],\n",
      "         [-0.0142],\n",
      "         [-0.0140],\n",
      "         [-0.0139],\n",
      "         [-0.0139],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0137],\n",
      "         [-0.0137],\n",
      "         [-0.0137]],\n",
      "\n",
      "        [[-0.1801],\n",
      "         [-0.0211],\n",
      "         [-0.0150],\n",
      "         [-0.0142],\n",
      "         [-0.0140],\n",
      "         [-0.0140],\n",
      "         [-0.0139],\n",
      "         [-0.0139],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0137],\n",
      "         [-0.0137]],\n",
      "\n",
      "        [[-0.1803],\n",
      "         [-0.0211],\n",
      "         [-0.0150],\n",
      "         [-0.0142],\n",
      "         [-0.0140],\n",
      "         [-0.0139],\n",
      "         [-0.0139],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0137],\n",
      "         [-0.0137],\n",
      "         [-0.0137]],\n",
      "\n",
      "        [[-0.1801],\n",
      "         [-0.0211],\n",
      "         [-0.0149],\n",
      "         [-0.0142],\n",
      "         [-0.0140],\n",
      "         [-0.0139],\n",
      "         [-0.0139],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0137],\n",
      "         [-0.0137],\n",
      "         [-0.0137],\n",
      "         [-0.0137]],\n",
      "\n",
      "        [[-0.1801],\n",
      "         [-0.0211],\n",
      "         [-0.0150],\n",
      "         [-0.0142],\n",
      "         [-0.0141],\n",
      "         [-0.0140],\n",
      "         [-0.0139],\n",
      "         [-0.0139],\n",
      "         [-0.0139],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0137]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-3.3922, -3.3209, -3.1719, -3.3536, -3.3071], grad_fn=<MaxBackward0>) tensor([0, 1, 1, 1, 0])\n",
      "Batch average accuracy:  tensor(0.4000)\n",
      "Rewards:  [-1, 1, -1, 1, -1]\n",
      "Policy log probs in:  torch.Size([5, 13, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.3547],\n",
      "        [-0.3550],\n",
      "        [-0.3549],\n",
      "        [-0.3545],\n",
      "        [-0.3553]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.3547], grad_fn=<MulBackward0>), tensor([0.3550], grad_fn=<MulBackward0>), tensor([-0.3549], grad_fn=<MulBackward0>), tensor([0.3545], grad_fn=<MulBackward0>), tensor([-0.3553], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.0711, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 1.3075,  2.1802,  0.6888,  ..., -1.8702, -1.5470, -0.1777]],\n",
      "\n",
      "        [[ 1.3067,  2.1799,  0.6880,  ..., -1.8704, -1.5472, -0.1778]],\n",
      "\n",
      "        [[ 1.3056,  2.1782,  0.6888,  ..., -1.8683, -1.5487, -0.1764]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.8370,  2.9187,  0.8517,  ..., -2.5493, -1.7994, -0.2899]],\n",
      "\n",
      "        [[ 1.8395,  2.9188,  0.8536,  ..., -2.5509, -1.7991, -0.2915]],\n",
      "\n",
      "        [[ 1.8347,  2.9181,  0.8505,  ..., -2.5477, -1.8019, -0.2911]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(11.5056, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.0711, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [8/14000], Speaker loss: 1.0795, Listener loss: 0.7237, Perplexity: 2.9431\n",
      "Target inds:  tensor([ 2793, 24710, 19521, 58192, 17966])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 1, 1, 0, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 1, 1, 0, 1])\n",
      "Stacked preds out:  torch.Size([5, 12])\n",
      "torch.Size([5, 12])\n",
      "Log probs out: torch.Size([5, 12, 1]) tensor([[[-0.1998],\n",
      "         [-0.0248],\n",
      "         [-0.0176],\n",
      "         [-0.0167],\n",
      "         [-0.0165],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164]],\n",
      "\n",
      "        [[-0.1996],\n",
      "         [-0.0248],\n",
      "         [-0.0176],\n",
      "         [-0.0166],\n",
      "         [-0.0165],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164]],\n",
      "\n",
      "        [[-0.1995],\n",
      "         [-0.0247],\n",
      "         [-0.0176],\n",
      "         [-0.0166],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164]],\n",
      "\n",
      "        [[-0.1996],\n",
      "         [-0.0248],\n",
      "         [-0.0176],\n",
      "         [-0.0167],\n",
      "         [-0.0165],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0164]],\n",
      "\n",
      "        [[-0.1991],\n",
      "         [-0.0247],\n",
      "         [-0.0175],\n",
      "         [-0.0166],\n",
      "         [-0.0164],\n",
      "         [-0.0164],\n",
      "         [-0.0163],\n",
      "         [-0.0163],\n",
      "         [-0.0163],\n",
      "         [-0.0163],\n",
      "         [-0.0163],\n",
      "         [-0.0163]]], grad_fn=<LogBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-5.7924, -6.1392, -5.7091, -5.8610, -5.9224], grad_fn=<MaxBackward0>) tensor([1, 1, 0, 1, 0])\n",
      "Batch average accuracy:  tensor(0.2000)\n",
      "Rewards:  [-1, 1, -1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 12, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.3900],\n",
      "        [-0.3896],\n",
      "        [-0.3895],\n",
      "        [-0.3897],\n",
      "        [-0.3886]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.3900], grad_fn=<MulBackward0>), tensor([0.3896], grad_fn=<MulBackward0>), tensor([-0.3895], grad_fn=<MulBackward0>), tensor([-0.3897], grad_fn=<MulBackward0>), tensor([-0.3886], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.2336, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 1.4164,  2.4222,  0.8410,  ..., -1.8845, -1.6362, -0.1992]],\n",
      "\n",
      "        [[ 1.4167,  2.4229,  0.8408,  ..., -1.8852, -1.6353, -0.1998]],\n",
      "\n",
      "        [[ 1.4168,  2.4233,  0.8407,  ..., -1.8854, -1.6351, -0.2001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.9820,  3.2730,  0.9760,  ..., -2.5449, -1.8861, -0.3521]],\n",
      "\n",
      "        [[ 1.9821,  3.2729,  0.9760,  ..., -2.5449, -1.8860, -0.3519]],\n",
      "\n",
      "        [[ 1.9794,  3.2742,  0.9778,  ..., -2.5431, -1.8867, -0.3531]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(11.4416, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.2336, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [9/14000], Speaker loss: 0.9105, Listener loss: 0.7599, Perplexity: 2.4856\n",
      "Target inds:  tensor([36490, 43979, 15074, 30313, 15213])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 1, 1, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 1, 1, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 10])\n",
      "torch.Size([5, 10])\n",
      "Log probs out: torch.Size([5, 10, 1]) tensor([[[-0.2308],\n",
      "         [-0.0306],\n",
      "         [-0.0222],\n",
      "         [-0.0212],\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.2314],\n",
      "         [-0.0306],\n",
      "         [-0.0223],\n",
      "         [-0.0213],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.2321],\n",
      "         [-0.0307],\n",
      "         [-0.0223],\n",
      "         [-0.0214],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.2317],\n",
      "         [-0.0307],\n",
      "         [-0.0223],\n",
      "         [-0.0213],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.2316],\n",
      "         [-0.0307],\n",
      "         [-0.0223],\n",
      "         [-0.0213],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-8.9830, -8.9025, -8.9433, -8.7492, -8.9370], grad_fn=<MaxBackward0>) tensor([0, 1, 0, 1, 1])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [1, 1, -1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 10, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.4314],\n",
      "        [-0.4326],\n",
      "        [-0.4338],\n",
      "        [-0.4329],\n",
      "        [-0.4328]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.4314], grad_fn=<MulBackward0>), tensor([0.4326], grad_fn=<MulBackward0>), tensor([-0.4338], grad_fn=<MulBackward0>), tensor([0.4329], grad_fn=<MulBackward0>), tensor([0.4328], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.2592, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 1.6738,  2.5482,  0.9437,  ..., -1.9309, -1.7005, -0.1472]],\n",
      "\n",
      "        [[ 1.6775,  2.5459,  0.9406,  ..., -1.9330, -1.6988, -0.1451]],\n",
      "\n",
      "        [[ 1.6814,  2.5435,  0.9374,  ..., -1.9353, -1.6970, -0.1432]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.2328,  3.3574,  1.1283,  ..., -2.5282, -2.0454, -0.2278]],\n",
      "\n",
      "        [[ 2.2306,  3.3589,  1.1295,  ..., -2.5272, -2.0457, -0.2292]],\n",
      "\n",
      "        [[ 2.2301,  3.3591,  1.1299,  ..., -2.5270, -2.0459, -0.2295]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(11.0608, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.2592, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [10/14000], Speaker loss: 1.3653, Listener loss: 0.6441, Perplexity: 3.9167\n",
      "Target inds:  tensor([42881,  9578, 30771, 25582, 55088])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 1, 1, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 1, 1, 0])\n",
      "Stacked preds out:  torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "Log probs out: torch.Size([5, 11, 1]) tensor([[[-0.2315],\n",
      "         [-0.0312],\n",
      "         [-0.0227],\n",
      "         [-0.0218],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216]],\n",
      "\n",
      "        [[-0.2315],\n",
      "         [-0.0312],\n",
      "         [-0.0227],\n",
      "         [-0.0218],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216]],\n",
      "\n",
      "        [[-0.2315],\n",
      "         [-0.0312],\n",
      "         [-0.0227],\n",
      "         [-0.0218],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216]],\n",
      "\n",
      "        [[-0.2315],\n",
      "         [-0.0312],\n",
      "         [-0.0227],\n",
      "         [-0.0218],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216]],\n",
      "\n",
      "        [[-0.2314],\n",
      "         [-0.0312],\n",
      "         [-0.0227],\n",
      "         [-0.0218],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-11.8936, -11.3797, -12.1109, -12.0040, -11.7657],\n",
      "       grad_fn=<MaxBackward0>) tensor([1, 0, 0, 1, 0])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [1, 1, -1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 11, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.4585],\n",
      "        [-0.4585],\n",
      "        [-0.4585],\n",
      "        [-0.4585],\n",
      "        [-0.4584]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.4585], grad_fn=<MulBackward0>), tensor([0.4585], grad_fn=<MulBackward0>), tensor([-0.4585], grad_fn=<MulBackward0>), tensor([0.4585], grad_fn=<MulBackward0>), tensor([0.4584], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.2751, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 1.8272,  2.7306,  1.0848,  ..., -1.9460, -1.7383, -0.1828]],\n",
      "\n",
      "        [[ 1.8273,  2.7305,  1.0848,  ..., -1.9461, -1.7384, -0.1828]],\n",
      "\n",
      "        [[ 1.8272,  2.7307,  1.0848,  ..., -1.9459, -1.7383, -0.1828]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4372,  3.5795,  1.2987,  ..., -2.5524, -2.0906, -0.2656]],\n",
      "\n",
      "        [[ 2.4372,  3.5795,  1.2986,  ..., -2.5524, -2.0905, -0.2656]],\n",
      "\n",
      "        [[ 2.4373,  3.5795,  1.2987,  ..., -2.5523, -2.0906, -0.2656]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.7932, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.2751, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [11/14000], Speaker loss: 1.3544, Listener loss: 0.5798, Perplexity: 3.8745\n",
      "Target inds:  tensor([ 7518, 57070, 41251, 19162, 46798])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 0, 1, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 0, 1, 0])\n",
      "Stacked preds out:  torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "Log probs out: torch.Size([5, 11, 1]) tensor([[[-0.2280],\n",
      "         [-0.0307],\n",
      "         [-0.0224],\n",
      "         [-0.0214],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213]],\n",
      "\n",
      "        [[-0.2280],\n",
      "         [-0.0307],\n",
      "         [-0.0224],\n",
      "         [-0.0214],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213]],\n",
      "\n",
      "        [[-0.2280],\n",
      "         [-0.0307],\n",
      "         [-0.0224],\n",
      "         [-0.0214],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213]],\n",
      "\n",
      "        [[-0.2280],\n",
      "         [-0.0307],\n",
      "         [-0.0224],\n",
      "         [-0.0214],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213]],\n",
      "\n",
      "        [[-0.2280],\n",
      "         [-0.0307],\n",
      "         [-0.0224],\n",
      "         [-0.0214],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-16.4736, -17.0264, -16.8805, -16.8380, -16.5510],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 1, 1, 0, 0])\n",
      "Batch average accuracy:  tensor(0.2000)\n",
      "Rewards:  [-1, -1, -1, -1, 1]\n",
      "Policy log probs in:  torch.Size([5, 11, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.4515],\n",
      "        [-0.4515],\n",
      "        [-0.4515],\n",
      "        [-0.4514],\n",
      "        [-0.4515]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.4515], grad_fn=<MulBackward0>), tensor([-0.4515], grad_fn=<MulBackward0>), tensor([-0.4515], grad_fn=<MulBackward0>), tensor([-0.4514], grad_fn=<MulBackward0>), tensor([0.4515], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.2709, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 1.9997,  2.9017,  1.1898,  ..., -1.9803, -1.7684, -0.2250]],\n",
      "\n",
      "        [[ 1.9998,  2.9016,  1.1898,  ..., -1.9804, -1.7684, -0.2250]],\n",
      "\n",
      "        [[ 1.9998,  2.9016,  1.1898,  ..., -1.9804, -1.7683, -0.2250]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6542,  3.7947,  1.4309,  ..., -2.5958, -2.1293, -0.3182]],\n",
      "\n",
      "        [[ 2.6543,  3.7947,  1.4309,  ..., -2.5958, -2.1294, -0.3182]],\n",
      "\n",
      "        [[ 2.6542,  3.7947,  1.4309,  ..., -2.5958, -2.1294, -0.3182]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.8334, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.2709, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [12/14000], Speaker loss: 0.8125, Listener loss: 0.7880, Perplexity: 2.2534\n",
      "Target inds:  tensor([50705, 49584, 58762, 19281, 48704])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 1, 0, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 1, 0, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 12])\n",
      "torch.Size([5, 12])\n",
      "Log probs out: torch.Size([5, 12, 1]) tensor([[[-0.2347],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]],\n",
      "\n",
      "        [[-0.2347],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]],\n",
      "\n",
      "        [[-0.2347],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]],\n",
      "\n",
      "        [[-0.2347],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]],\n",
      "\n",
      "        [[-0.2347],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-21.2237, -21.3537, -21.2661, -20.9622, -20.3166],\n",
      "       grad_fn=<MaxBackward0>) tensor([1, 1, 0, 1, 1])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [-1, 1, 1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 12, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.4926],\n",
      "        [-0.4926],\n",
      "        [-0.4926],\n",
      "        [-0.4926],\n",
      "        [-0.4927]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.4926], grad_fn=<MulBackward0>), tensor([0.4926], grad_fn=<MulBackward0>), tensor([0.4926], grad_fn=<MulBackward0>), tensor([0.4926], grad_fn=<MulBackward0>), tensor([0.4927], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.2956, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 2.1728,  3.0748,  1.2881,  ..., -2.0015, -1.7872, -0.2455]],\n",
      "\n",
      "        [[ 2.1727,  3.0747,  1.2881,  ..., -2.0016, -1.7871, -0.2456]],\n",
      "\n",
      "        [[ 2.1728,  3.0748,  1.2881,  ..., -2.0016, -1.7872, -0.2455]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.8733,  4.0180,  1.5662,  ..., -2.6263, -2.1395, -0.3415]],\n",
      "\n",
      "        [[ 2.8734,  4.0180,  1.5662,  ..., -2.6262, -2.1397, -0.3415]],\n",
      "\n",
      "        [[ 2.8732,  4.0180,  1.5662,  ..., -2.6264, -2.1392, -0.3415]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.6976, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.2956, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [13/14000], Speaker loss: 1.3653, Listener loss: 0.5809, Perplexity: 3.9170\n",
      "Target inds:  tensor([16601, 47977, 64244, 14214, 53584])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 0, 1, 1, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 0, 1, 1, 0])\n",
      "Stacked preds out:  torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "Log probs out: torch.Size([5, 11, 1]) tensor([[[-0.2341],\n",
      "         [-0.0321],\n",
      "         [-0.0235],\n",
      "         [-0.0226],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]],\n",
      "\n",
      "        [[-0.2341],\n",
      "         [-0.0321],\n",
      "         [-0.0235],\n",
      "         [-0.0226],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]],\n",
      "\n",
      "        [[-0.2341],\n",
      "         [-0.0321],\n",
      "         [-0.0235],\n",
      "         [-0.0226],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]],\n",
      "\n",
      "        [[-0.2341],\n",
      "         [-0.0321],\n",
      "         [-0.0235],\n",
      "         [-0.0226],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]],\n",
      "\n",
      "        [[-0.2341],\n",
      "         [-0.0321],\n",
      "         [-0.0235],\n",
      "         [-0.0226],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224],\n",
      "         [-0.0224]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-27.0881, -26.5084, -27.1624, -26.9817, -27.0923],\n",
      "       grad_fn=<MaxBackward0>) tensor([1, 0, 0, 1, 0])\n",
      "Batch average accuracy:  tensor(0.6000)\n",
      "Rewards:  [-1, 1, -1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 11, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.4692],\n",
      "        [-0.4692],\n",
      "        [-0.4692],\n",
      "        [-0.4692],\n",
      "        [-0.4692]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.4692], grad_fn=<MulBackward0>), tensor([0.4692], grad_fn=<MulBackward0>), tensor([-0.4692], grad_fn=<MulBackward0>), tensor([0.4692], grad_fn=<MulBackward0>), tensor([0.4692], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 2.3457,  3.2439,  1.3715,  ..., -2.0303, -1.8137, -0.2806]],\n",
      "\n",
      "        [[ 2.3457,  3.2439,  1.3715,  ..., -2.0304, -1.8137, -0.2805]],\n",
      "\n",
      "        [[ 2.3457,  3.2439,  1.3714,  ..., -2.0304, -1.8137, -0.2806]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.0895,  4.2253,  1.6595,  ..., -2.6594, -2.1871, -0.3886]],\n",
      "\n",
      "        [[ 3.0895,  4.2253,  1.6595,  ..., -2.6594, -2.1871, -0.3886]],\n",
      "\n",
      "        [[ 3.0895,  4.2252,  1.6595,  ..., -2.6594, -2.1871, -0.3886]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.4331, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.0938, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [14/14000], Speaker loss: 1.1372, Listener loss: 0.5935, Perplexity: 3.1179\n",
      "Target inds:  tensor([61737, 42422, 62045, 22738, 45108])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 1, 0, 1, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 1, 0, 1, 0])\n",
      "Stacked preds out:  torch.Size([5, 13])\n",
      "torch.Size([5, 13])\n",
      "Log probs out: torch.Size([5, 13, 1]) tensor([[[-0.2331],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225]],\n",
      "\n",
      "        [[-0.2331],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225]],\n",
      "\n",
      "        [[-0.2331],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225]],\n",
      "\n",
      "        [[-0.2331],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225]],\n",
      "\n",
      "        [[-0.2331],\n",
      "         [-0.0322],\n",
      "         [-0.0236],\n",
      "         [-0.0226],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225],\n",
      "         [-0.0225]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-34.4065, -34.4530, -34.4138, -34.5473, -34.6232],\n",
      "       grad_fn=<MaxBackward0>) tensor([1, 0, 0, 0, 0])\n",
      "Batch average accuracy:  tensor(0.6000)\n",
      "Rewards:  [1, -1, 1, -1, 1]\n",
      "Policy log probs in:  torch.Size([5, 13, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.5141],\n",
      "        [-0.5141],\n",
      "        [-0.5141],\n",
      "        [-0.5141],\n",
      "        [-0.5141]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.5141], grad_fn=<MulBackward0>), tensor([-0.5141], grad_fn=<MulBackward0>), tensor([0.5141], grad_fn=<MulBackward0>), tensor([-0.5141], grad_fn=<MulBackward0>), tensor([0.5141], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.1028, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 2.5186,  3.4131,  1.4723,  ..., -2.0598, -1.8399, -0.3175]],\n",
      "\n",
      "        [[ 2.5186,  3.4131,  1.4723,  ..., -2.0598, -1.8399, -0.3176]],\n",
      "\n",
      "        [[ 2.5186,  3.4131,  1.4723,  ..., -2.0598, -1.8399, -0.3175]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.3072,  4.4383,  1.7867,  ..., -2.6964, -2.2206, -0.4351]],\n",
      "\n",
      "        [[ 3.3072,  4.4383,  1.7867,  ..., -2.6964, -2.2206, -0.4351]],\n",
      "\n",
      "        [[ 3.3072,  4.4383,  1.7867,  ..., -2.6964, -2.2206, -0.4351]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.6239, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.1028, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [15/14000], Speaker loss: 1.1652, Listener loss: 0.6661, Perplexity: 3.2066\n",
      "Target inds:  tensor([56886, 68926, 55710,  3110, 31480])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 1, 1, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 1, 1, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 12])\n",
      "torch.Size([5, 12])\n",
      "Log probs out: torch.Size([5, 12, 1]) tensor([[[-0.2316],\n",
      "         [-0.0322],\n",
      "         [-0.0237],\n",
      "         [-0.0227],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226]],\n",
      "\n",
      "        [[-0.2316],\n",
      "         [-0.0322],\n",
      "         [-0.0237],\n",
      "         [-0.0227],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226]],\n",
      "\n",
      "        [[-0.2316],\n",
      "         [-0.0322],\n",
      "         [-0.0237],\n",
      "         [-0.0227],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226]],\n",
      "\n",
      "        [[-0.2316],\n",
      "         [-0.0322],\n",
      "         [-0.0237],\n",
      "         [-0.0227],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226]],\n",
      "\n",
      "        [[-0.2316],\n",
      "         [-0.0322],\n",
      "         [-0.0237],\n",
      "         [-0.0227],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226],\n",
      "         [-0.0226]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-41.3537, -42.3909, -42.1257, -42.6113, -42.4686],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 0, 1, 1, 0])\n",
      "Batch average accuracy:  tensor(0.6000)\n",
      "Rewards:  [1, -1, 1, 1, -1]\n",
      "Policy log probs in:  torch.Size([5, 12, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.4908],\n",
      "        [-0.4908],\n",
      "        [-0.4908],\n",
      "        [-0.4908],\n",
      "        [-0.4908]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.4908], grad_fn=<MulBackward0>), tensor([-0.4908], grad_fn=<MulBackward0>), tensor([0.4908], grad_fn=<MulBackward0>), tensor([0.4908], grad_fn=<MulBackward0>), tensor([-0.4908], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.0982, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 2.6897,  3.5796,  1.5612,  ..., -2.0900, -1.8665, -0.3567]],\n",
      "\n",
      "        [[ 2.6897,  3.5797,  1.5612,  ..., -2.0899, -1.8665, -0.3567]],\n",
      "\n",
      "        [[ 2.6897,  3.5797,  1.5612,  ..., -2.0899, -1.8665, -0.3567]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.5227,  4.6481,  1.8986,  ..., -2.7343, -2.2543, -0.4845]],\n",
      "\n",
      "        [[ 3.5227,  4.6481,  1.8986,  ..., -2.7343, -2.2543, -0.4845]],\n",
      "\n",
      "        [[ 3.5227,  4.6481,  1.8986,  ..., -2.7343, -2.2543, -0.4845]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.3139, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.0982, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [16/14000], Speaker loss: 1.1296, Listener loss: 0.5703, Perplexity: 3.0943\n",
      "Target inds:  tensor([33406, 42046, 28245, 48907, 18830])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 1, 0, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 1, 0, 1])\n",
      "Stacked preds out:  torch.Size([5, 12])\n",
      "torch.Size([5, 12])\n",
      "Log probs out: torch.Size([5, 12, 1]) tensor([[[-0.2298],\n",
      "         [-0.0323],\n",
      "         [-0.0238],\n",
      "         [-0.0228],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227]],\n",
      "\n",
      "        [[-0.2298],\n",
      "         [-0.0323],\n",
      "         [-0.0238],\n",
      "         [-0.0228],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227]],\n",
      "\n",
      "        [[-0.2298],\n",
      "         [-0.0323],\n",
      "         [-0.0238],\n",
      "         [-0.0228],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227]],\n",
      "\n",
      "        [[-0.2298],\n",
      "         [-0.0323],\n",
      "         [-0.0238],\n",
      "         [-0.0228],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227]],\n",
      "\n",
      "        [[-0.2298],\n",
      "         [-0.0323],\n",
      "         [-0.0238],\n",
      "         [-0.0228],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227],\n",
      "         [-0.0227]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-51.7428, -51.1909, -52.5209, -51.3139, -51.5234],\n",
      "       grad_fn=<MaxBackward0>) tensor([1, 0, 0, 1, 1])\n",
      "Batch average accuracy:  tensor(0.6000)\n",
      "Rewards:  [1, 1, -1, -1, 1]\n",
      "Policy log probs in:  torch.Size([5, 12, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.4904],\n",
      "        [-0.4903],\n",
      "        [-0.4904],\n",
      "        [-0.4904],\n",
      "        [-0.4904]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.4904], grad_fn=<MulBackward0>), tensor([0.4903], grad_fn=<MulBackward0>), tensor([-0.4904], grad_fn=<MulBackward0>), tensor([-0.4904], grad_fn=<MulBackward0>), tensor([0.4904], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.0981, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 2.8602,  3.7447,  1.6642,  ..., -2.1205, -1.8933, -0.3976]],\n",
      "\n",
      "        [[ 2.8602,  3.7447,  1.6642,  ..., -2.1205, -1.8933, -0.3976]],\n",
      "\n",
      "        [[ 2.8602,  3.7447,  1.6642,  ..., -2.1206, -1.8933, -0.3976]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.7372,  4.8559,  2.0283,  ..., -2.7729, -2.2882, -0.5359]],\n",
      "\n",
      "        [[ 3.7372,  4.8559,  2.0283,  ..., -2.7728, -2.2882, -0.5360]],\n",
      "\n",
      "        [[ 3.7372,  4.8559,  2.0283,  ..., -2.7728, -2.2882, -0.5359]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.9416, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.0981, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [17/14000], Speaker loss: 1.0922, Listener loss: 0.8013, Perplexity: 2.9809\n",
      "Target inds:  tensor([13647, 24974, 20902, 56017, 27727])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 1, 0, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 1, 0, 0])\n",
      "Stacked preds out:  torch.Size([5, 12])\n",
      "torch.Size([5, 12])\n",
      "Log probs out: torch.Size([5, 12, 1]) tensor([[[-0.2279],\n",
      "         [-0.0325],\n",
      "         [-0.0241],\n",
      "         [-0.0231],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229]],\n",
      "\n",
      "        [[-0.2279],\n",
      "         [-0.0325],\n",
      "         [-0.0241],\n",
      "         [-0.0231],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229]],\n",
      "\n",
      "        [[-0.2279],\n",
      "         [-0.0325],\n",
      "         [-0.0240],\n",
      "         [-0.0231],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229]],\n",
      "\n",
      "        [[-0.2279],\n",
      "         [-0.0325],\n",
      "         [-0.0241],\n",
      "         [-0.0231],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229]],\n",
      "\n",
      "        [[-0.2279],\n",
      "         [-0.0325],\n",
      "         [-0.0240],\n",
      "         [-0.0231],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-55.6350, -54.5390, -55.6944, -55.4015, -54.3000],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 1, 1, 0, 0])\n",
      "Batch average accuracy:  tensor(0.6000)\n",
      "Rewards:  [-1, -1, 1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 12, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.4910],\n",
      "        [-0.4909],\n",
      "        [-0.4909],\n",
      "        [-0.4909],\n",
      "        [-0.4909]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.4910], grad_fn=<MulBackward0>), tensor([-0.4909], grad_fn=<MulBackward0>), tensor([0.4909], grad_fn=<MulBackward0>), tensor([0.4909], grad_fn=<MulBackward0>), tensor([0.4909], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.0982, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 3.0300,  3.9078,  1.7548,  ..., -2.1516, -1.9205, -0.4399]],\n",
      "\n",
      "        [[ 3.0300,  3.9078,  1.7548,  ..., -2.1516, -1.9205, -0.4399]],\n",
      "\n",
      "        [[ 3.0300,  3.9078,  1.7548,  ..., -2.1516, -1.9205, -0.4399]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.9492,  5.0625,  2.1406,  ..., -2.8119, -2.3218, -0.5909]],\n",
      "\n",
      "        [[ 3.9481,  5.0633,  2.1395,  ..., -2.8119, -2.3215, -0.5920]],\n",
      "\n",
      "        [[ 3.9495,  5.0623,  2.1409,  ..., -2.8119, -2.3219, -0.5906]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.0259, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.0982, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [18/14000], Speaker loss: 1.1007, Listener loss: 0.5780, Perplexity: 3.0064\n",
      "Target inds:  tensor([ 8596, 15709, 15709, 26147, 60331])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 1, 1, 1, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 1, 1, 1, 0])\n",
      "Stacked preds out:  torch.Size([5, 27])\n",
      "torch.Size([5, 27])\n",
      "Log probs out: torch.Size([5, 27, 1]) tensor([[[-0.2262],\n",
      "         [-0.0328],\n",
      "         [-0.0244],\n",
      "         [-0.0235],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233]],\n",
      "\n",
      "        [[-0.2262],\n",
      "         [-0.0328],\n",
      "         [-0.0244],\n",
      "         [-0.0235],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233]],\n",
      "\n",
      "        [[-0.2262],\n",
      "         [-0.0328],\n",
      "         [-0.0244],\n",
      "         [-0.0235],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233]],\n",
      "\n",
      "        [[-0.2262],\n",
      "         [-0.0328],\n",
      "         [-0.0244],\n",
      "         [-0.0235],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233]],\n",
      "\n",
      "        [[-0.2262],\n",
      "         [-0.0328],\n",
      "         [-0.0244],\n",
      "         [-0.0235],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-59.4576, -60.2947, -60.2947, -59.5091, -59.6635],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 1, 1, 0, 1])\n",
      "Batch average accuracy:  tensor(0.4000)\n",
      "Rewards:  [-1, 1, 1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 27, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.8434],\n",
      "        [-0.8434],\n",
      "        [-0.8434],\n",
      "        [-0.8434],\n",
      "        [-0.8434]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.8434], grad_fn=<MulBackward0>), tensor([0.8434], grad_fn=<MulBackward0>), tensor([0.8434], grad_fn=<MulBackward0>), tensor([-0.8434], grad_fn=<MulBackward0>), tensor([-0.8434], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.1687, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 3.1989,  4.0682,  1.8585,  ..., -2.1831, -1.9478, -0.4834]],\n",
      "\n",
      "        [[ 3.1988,  4.0682,  1.8585,  ..., -2.1831, -1.9478, -0.4834]],\n",
      "\n",
      "        [[ 3.1988,  4.0682,  1.8585,  ..., -2.1831, -1.9478, -0.4834]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.1459,  5.2763,  2.2548,  ..., -2.8508, -2.3511, -0.6616]],\n",
      "\n",
      "        [[ 4.1459,  5.2763,  2.2548,  ..., -2.8508, -2.3511, -0.6616]],\n",
      "\n",
      "        [[ 4.1459,  5.2763,  2.2548,  ..., -2.8508, -2.3511, -0.6616]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(10.3264, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.1687, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [19/14000], Speaker loss: 0.8640, Listener loss: 0.7796, Perplexity: 2.3725\n",
      "Target inds:  tensor([11437, 30596, 29716, 47830, 50280])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 1, 1, 0, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 1, 1, 0, 0])\n",
      "Stacked preds out:  torch.Size([5, 12])\n",
      "torch.Size([5, 12])\n",
      "Log probs out: torch.Size([5, 12, 1]) tensor([[[-0.2325],\n",
      "         [-0.0348],\n",
      "         [-0.0260],\n",
      "         [-0.0250],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249]],\n",
      "\n",
      "        [[-0.2327],\n",
      "         [-0.0348],\n",
      "         [-0.0261],\n",
      "         [-0.0250],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249]],\n",
      "\n",
      "        [[-0.2325],\n",
      "         [-0.0348],\n",
      "         [-0.0260],\n",
      "         [-0.0250],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249]],\n",
      "\n",
      "        [[-0.2326],\n",
      "         [-0.0348],\n",
      "         [-0.0260],\n",
      "         [-0.0250],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249]],\n",
      "\n",
      "        [[-0.2326],\n",
      "         [-0.0348],\n",
      "         [-0.0260],\n",
      "         [-0.0250],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-58.5303, -58.9083, -60.5152, -60.4955, -59.4893],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 0, 1, 1, 1])\n",
      "Batch average accuracy:  tensor(0.4000)\n",
      "Rewards:  [1, -1, 1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 12, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.5173],\n",
      "        [-0.5178],\n",
      "        [-0.5173],\n",
      "        [-0.5175],\n",
      "        [-0.5175]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.5173], grad_fn=<MulBackward0>), tensor([-0.5178], grad_fn=<MulBackward0>), tensor([0.5173], grad_fn=<MulBackward0>), tensor([-0.5175], grad_fn=<MulBackward0>), tensor([-0.5175], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.1036, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 3.3694,  4.2354,  1.9734,  ..., -2.2027, -1.9652, -0.5308]],\n",
      "\n",
      "        [[ 3.3702,  4.2358,  1.9717,  ..., -2.2020, -1.9646, -0.5339]],\n",
      "\n",
      "        [[ 3.3694,  4.2354,  1.9734,  ..., -2.2027, -1.9651, -0.5309]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.3573,  5.4852,  2.4053,  ..., -2.8782, -2.3750, -0.7102]],\n",
      "\n",
      "        [[ 4.3575,  5.4853,  2.4049,  ..., -2.8781, -2.3749, -0.7109]],\n",
      "\n",
      "        [[ 4.3576,  5.4853,  2.4047,  ..., -2.8780, -2.3749, -0.7112]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.8071, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.1036, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [20/14000], Speaker loss: 0.8771, Listener loss: 0.7756, Perplexity: 2.4039\n",
      "Target inds:  tensor([ 3979, 48556, 56264, 53895, 22418])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 1, 0, 0, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 1, 0, 0, 1])\n",
      "Stacked preds out:  torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "Log probs out: torch.Size([5, 11, 1]) tensor([[[-0.2492],\n",
      "         [-0.0394],\n",
      "         [-0.0298],\n",
      "         [-0.0287],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285]],\n",
      "\n",
      "        [[-0.2492],\n",
      "         [-0.0394],\n",
      "         [-0.0298],\n",
      "         [-0.0287],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285]],\n",
      "\n",
      "        [[-0.2492],\n",
      "         [-0.0394],\n",
      "         [-0.0298],\n",
      "         [-0.0287],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285]],\n",
      "\n",
      "        [[-0.2492],\n",
      "         [-0.0394],\n",
      "         [-0.0298],\n",
      "         [-0.0287],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285]],\n",
      "\n",
      "        [[-0.2492],\n",
      "         [-0.0394],\n",
      "         [-0.0298],\n",
      "         [-0.0287],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-57.8364, -55.9700, -57.1262, -56.7947, -57.0505],\n",
      "       grad_fn=<MaxBackward0>) tensor([1, 1, 0, 0, 0])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [1, 1, 1, 1, -1]\n",
      "Policy log probs in:  torch.Size([5, 11, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.5466],\n",
      "        [-0.5466],\n",
      "        [-0.5466],\n",
      "        [-0.5466],\n",
      "        [-0.5466]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.5466], grad_fn=<MulBackward0>), tensor([0.5466], grad_fn=<MulBackward0>), tensor([0.5466], grad_fn=<MulBackward0>), tensor([0.5466], grad_fn=<MulBackward0>), tensor([-0.5466], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.3280, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 3.5743,  4.4377,  2.0410,  ..., -2.1525, -1.9554, -0.6627]],\n",
      "\n",
      "        [[ 3.5743,  4.4377,  2.0410,  ..., -2.1525, -1.9554, -0.6626]],\n",
      "\n",
      "        [[ 3.5743,  4.4377,  2.0410,  ..., -2.1525, -1.9554, -0.6627]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.6135,  5.7350,  2.4865,  ..., -2.8262, -2.3639, -0.8768]],\n",
      "\n",
      "        [[ 4.6135,  5.7350,  2.4865,  ..., -2.8262, -2.3639, -0.8768]],\n",
      "\n",
      "        [[ 4.6135,  5.7350,  2.4865,  ..., -2.8262, -2.3639, -0.8768]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.5933, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.3280, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [21/14000], Speaker loss: 1.2873, Listener loss: 0.4590, Perplexity: 3.6230\n",
      "Target inds:  tensor([34115, 50142, 32924, 45628, 18927])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 0, 0, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 0, 0, 1])\n",
      "Stacked preds out:  torch.Size([5, 15])\n",
      "torch.Size([5, 15])\n",
      "Log probs out: torch.Size([5, 15, 1]) tensor([[[-0.2526],\n",
      "         [-0.0413],\n",
      "         [-0.0315],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]],\n",
      "\n",
      "        [[-0.2526],\n",
      "         [-0.0413],\n",
      "         [-0.0315],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]],\n",
      "\n",
      "        [[-0.2526],\n",
      "         [-0.0413],\n",
      "         [-0.0315],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]],\n",
      "\n",
      "        [[-0.2526],\n",
      "         [-0.0413],\n",
      "         [-0.0315],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]],\n",
      "\n",
      "        [[-0.2526],\n",
      "         [-0.0413],\n",
      "         [-0.0315],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-61.2894, -59.8719, -61.1768, -60.9973, -59.6093],\n",
      "       grad_fn=<MaxBackward0>) tensor([1, 0, 0, 1, 1])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [1, 1, 1, -1, 1]\n",
      "Policy log probs in:  torch.Size([5, 15, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.6876],\n",
      "        [-0.6876],\n",
      "        [-0.6876],\n",
      "        [-0.6876],\n",
      "        [-0.6876]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.6876], grad_fn=<MulBackward0>), tensor([0.6876], grad_fn=<MulBackward0>), tensor([0.6876], grad_fn=<MulBackward0>), tensor([-0.6876], grad_fn=<MulBackward0>), tensor([0.6876], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.4126, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 3.7351,  4.5719,  2.1365,  ..., -2.1791, -1.9781, -0.6963]],\n",
      "\n",
      "        [[ 3.7351,  4.5719,  2.1365,  ..., -2.1791, -1.9781, -0.6963]],\n",
      "\n",
      "        [[ 3.7351,  4.5719,  2.1365,  ..., -2.1791, -1.9781, -0.6963]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.8159,  5.9040,  2.6067,  ..., -2.8597, -2.3924, -0.9192]],\n",
      "\n",
      "        [[ 4.8159,  5.9040,  2.6067,  ..., -2.8597, -2.3924, -0.9192]],\n",
      "\n",
      "        [[ 4.8159,  5.9040,  2.6067,  ..., -2.8597, -2.3924, -0.9192]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.2964, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.4126, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [22/14000], Speaker loss: 1.3422, Listener loss: 0.6147, Perplexity: 3.8275\n",
      "Target inds:  tensor([34276,   659, 57861, 33076, 25347])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 0, 0, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 0, 0, 0])\n",
      "Stacked preds out:  torch.Size([5, 14])\n",
      "torch.Size([5, 14])\n",
      "Log probs out: torch.Size([5, 14, 1]) tensor([[[-0.2478],\n",
      "         [-0.0414],\n",
      "         [-0.0317],\n",
      "         [-0.0306],\n",
      "         [-0.0305],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304]],\n",
      "\n",
      "        [[-0.2478],\n",
      "         [-0.0414],\n",
      "         [-0.0317],\n",
      "         [-0.0306],\n",
      "         [-0.0305],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304]],\n",
      "\n",
      "        [[-0.2478],\n",
      "         [-0.0414],\n",
      "         [-0.0317],\n",
      "         [-0.0306],\n",
      "         [-0.0305],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304]],\n",
      "\n",
      "        [[-0.2478],\n",
      "         [-0.0414],\n",
      "         [-0.0317],\n",
      "         [-0.0306],\n",
      "         [-0.0305],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304]],\n",
      "\n",
      "        [[-0.2478],\n",
      "         [-0.0414],\n",
      "         [-0.0317],\n",
      "         [-0.0306],\n",
      "         [-0.0305],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304],\n",
      "         [-0.0304]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-62.0535, -62.7515, -61.9484, -61.9154, -59.5270],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 0, 0, 0, 0])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [-1, 1, 1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 14, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.6558],\n",
      "        [-0.6558],\n",
      "        [-0.6558],\n",
      "        [-0.6558],\n",
      "        [-0.6558]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.6558], grad_fn=<MulBackward0>), tensor([0.6558], grad_fn=<MulBackward0>), tensor([0.6558], grad_fn=<MulBackward0>), tensor([0.6558], grad_fn=<MulBackward0>), tensor([0.6558], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.3935, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 3.8737,  4.6386,  2.2379,  ..., -2.2146, -2.0082, -0.7412]],\n",
      "\n",
      "        [[ 3.8737,  4.6386,  2.2379,  ..., -2.2146, -2.0082, -0.7412]],\n",
      "\n",
      "        [[ 3.8737,  4.6386,  2.2379,  ..., -2.2146, -2.0082, -0.7412]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.9902,  5.9880,  2.7344,  ..., -2.9041, -2.4303, -0.9756]],\n",
      "\n",
      "        [[ 4.9903,  5.9880,  2.7344,  ..., -2.9041, -2.4303, -0.9756]],\n",
      "\n",
      "        [[ 4.9902,  5.9880,  2.7344,  ..., -2.9041, -2.4303, -0.9756]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.2391, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.3935, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [23/14000], Speaker loss: 1.3174, Listener loss: 0.5819, Perplexity: 3.7337\n",
      "Target inds:  tensor([10673, 60931, 10356, 64039, 34729])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 1, 0, 0, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 1, 0, 0, 0])\n",
      "Stacked preds out:  torch.Size([5, 17])\n",
      "torch.Size([5, 17])\n",
      "Log probs out: torch.Size([5, 17, 1]) tensor([[[-0.2369],\n",
      "         [-0.0400],\n",
      "         [-0.0308],\n",
      "         [-0.0297],\n",
      "         [-0.0296],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295]],\n",
      "\n",
      "        [[-0.2369],\n",
      "         [-0.0400],\n",
      "         [-0.0308],\n",
      "         [-0.0297],\n",
      "         [-0.0296],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295]],\n",
      "\n",
      "        [[-0.2369],\n",
      "         [-0.0400],\n",
      "         [-0.0308],\n",
      "         [-0.0297],\n",
      "         [-0.0296],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295]],\n",
      "\n",
      "        [[-0.2369],\n",
      "         [-0.0400],\n",
      "         [-0.0308],\n",
      "         [-0.0297],\n",
      "         [-0.0296],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295]],\n",
      "\n",
      "        [[-0.2369],\n",
      "         [-0.0400],\n",
      "         [-0.0308],\n",
      "         [-0.0297],\n",
      "         [-0.0296],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-64.0429, -61.2690, -62.6170, -62.8055, -61.7602],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 0, 1, 0, 0])\n",
      "Batch average accuracy:  tensor(0.6000)\n",
      "Rewards:  [1, -1, -1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 17, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.7213],\n",
      "        [-0.7213],\n",
      "        [-0.7213],\n",
      "        [-0.7213],\n",
      "        [-0.7213]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.7213], grad_fn=<MulBackward0>), tensor([-0.7213], grad_fn=<MulBackward0>), tensor([-0.7213], grad_fn=<MulBackward0>), tensor([0.7213], grad_fn=<MulBackward0>), tensor([0.7213], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.1443, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 3.9904,  4.6557,  2.3324,  ..., -2.2570, -2.0443, -0.7949]],\n",
      "\n",
      "        [[ 3.9904,  4.6557,  2.3324,  ..., -2.2570, -2.0443, -0.7949]],\n",
      "\n",
      "        [[ 3.9904,  4.6557,  2.3324,  ..., -2.2570, -2.0443, -0.7949]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.1371,  6.0097,  2.8534,  ..., -2.9574, -2.4756, -1.0431]],\n",
      "\n",
      "        [[ 5.1371,  6.0097,  2.8534,  ..., -2.9574, -2.4756, -1.0431]],\n",
      "\n",
      "        [[ 5.1371,  6.0097,  2.8534,  ..., -2.9574, -2.4756, -1.0431]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.5259, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.1443, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [24/14000], Speaker loss: 1.0969, Listener loss: 0.7361, Perplexity: 2.9948\n",
      "Target inds:  tensor([ 4037, 49327, 28464, 48925, 42848])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 1, 0, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 1, 0, 0])\n",
      "Stacked preds out:  torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "Log probs out: torch.Size([5, 11, 1]) tensor([[[-0.2267],\n",
      "         [-0.0387],\n",
      "         [-0.0299],\n",
      "         [-0.0289],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288]],\n",
      "\n",
      "        [[-0.2267],\n",
      "         [-0.0387],\n",
      "         [-0.0299],\n",
      "         [-0.0289],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288]],\n",
      "\n",
      "        [[-0.2267],\n",
      "         [-0.0387],\n",
      "         [-0.0299],\n",
      "         [-0.0289],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288]],\n",
      "\n",
      "        [[-0.2267],\n",
      "         [-0.0387],\n",
      "         [-0.0299],\n",
      "         [-0.0289],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288]],\n",
      "\n",
      "        [[-0.2267],\n",
      "         [-0.0387],\n",
      "         [-0.0299],\n",
      "         [-0.0289],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-59.6084, -60.5493, -59.5285, -59.8032, -60.0258],\n",
      "       grad_fn=<MaxBackward0>) tensor([1, 1, 0, 1, 1])\n",
      "Batch average accuracy:  tensor(0.2000)\n",
      "Rewards:  [1, -1, -1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 11, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.5256],\n",
      "        [-0.5256],\n",
      "        [-0.5256],\n",
      "        [-0.5256],\n",
      "        [-0.5256]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.5256], grad_fn=<MulBackward0>), tensor([-0.5256], grad_fn=<MulBackward0>), tensor([-0.5256], grad_fn=<MulBackward0>), tensor([-0.5256], grad_fn=<MulBackward0>), tensor([-0.5256], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.3153, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 4.0993,  4.6614,  2.4128,  ..., -2.2994, -2.0804, -0.8485]],\n",
      "\n",
      "        [[ 4.0993,  4.6614,  2.4128,  ..., -2.2994, -2.0804, -0.8485]],\n",
      "\n",
      "        [[ 4.0993,  4.6614,  2.4128,  ..., -2.2994, -2.0804, -0.8485]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.2740,  6.0171,  2.9546,  ..., -3.0106, -2.5209, -1.1105]],\n",
      "\n",
      "        [[ 5.2740,  6.0171,  2.9546,  ..., -3.0106, -2.5209, -1.1105]],\n",
      "\n",
      "        [[ 5.2740,  6.0171,  2.9546,  ..., -3.0106, -2.5209, -1.1105]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.1998, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.3153, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [25/14000], Speaker loss: 0.6046, Listener loss: 1.0023, Perplexity: 1.8306\n",
      "Target inds:  tensor([18147, 14819, 60129, 10298, 19229])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 0, 0, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 0, 0, 0])\n",
      "Stacked preds out:  torch.Size([5, 14])\n",
      "torch.Size([5, 14])\n",
      "Log probs out: torch.Size([5, 14, 1]) tensor([[[-0.2271],\n",
      "         [-0.0401],\n",
      "         [-0.0313],\n",
      "         [-0.0302],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301]],\n",
      "\n",
      "        [[-0.2271],\n",
      "         [-0.0401],\n",
      "         [-0.0313],\n",
      "         [-0.0302],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301]],\n",
      "\n",
      "        [[-0.2271],\n",
      "         [-0.0401],\n",
      "         [-0.0313],\n",
      "         [-0.0302],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301]],\n",
      "\n",
      "        [[-0.2271],\n",
      "         [-0.0401],\n",
      "         [-0.0313],\n",
      "         [-0.0302],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301]],\n",
      "\n",
      "        [[-0.2271],\n",
      "         [-0.0401],\n",
      "         [-0.0313],\n",
      "         [-0.0302],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-52.1518, -51.0181, -51.1520, -50.1759, -51.1807],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 0, 0, 0, 0])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [-1, 1, 1, 1, 1]\n",
      "Policy log probs in:  torch.Size([5, 14, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.6297],\n",
      "        [-0.6297],\n",
      "        [-0.6297],\n",
      "        [-0.6297],\n",
      "        [-0.6297]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.6297], grad_fn=<MulBackward0>), tensor([0.6297], grad_fn=<MulBackward0>), tensor([0.6297], grad_fn=<MulBackward0>), tensor([0.6297], grad_fn=<MulBackward0>), tensor([0.6297], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.3778, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 4.2302,  4.7151,  2.4975,  ..., -2.3292, -2.1060, -0.8869]],\n",
      "\n",
      "        [[ 4.2302,  4.7151,  2.4975,  ..., -2.3292, -2.1060, -0.8869]],\n",
      "\n",
      "        [[ 4.2302,  4.7151,  2.4975,  ..., -2.3292, -2.1060, -0.8869]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.4387,  6.0847,  3.0612,  ..., -3.0480, -2.5530, -1.1589]],\n",
      "\n",
      "        [[ 5.4387,  6.0847,  3.0612,  ..., -3.0480, -2.5530, -1.1589]],\n",
      "\n",
      "        [[ 5.4387,  6.0847,  3.0612,  ..., -3.0480, -2.5530, -1.1589]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.0187, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.3778, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [26/14000], Speaker loss: 1.2797, Listener loss: 0.5351, Perplexity: 3.5955\n",
      "Target inds:  tensor([53917, 33840, 20366, 10512,  8823])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 0, 1, 0, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 0, 1, 0, 1])\n",
      "Stacked preds out:  torch.Size([5, 13])\n",
      "torch.Size([5, 13])\n",
      "Log probs out: torch.Size([5, 13, 1]) tensor([[[-0.2218],\n",
      "         [-0.0400],\n",
      "         [-0.0314],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]],\n",
      "\n",
      "        [[-0.2218],\n",
      "         [-0.0400],\n",
      "         [-0.0314],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]],\n",
      "\n",
      "        [[-0.2218],\n",
      "         [-0.0400],\n",
      "         [-0.0314],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]],\n",
      "\n",
      "        [[-0.2218],\n",
      "         [-0.0400],\n",
      "         [-0.0314],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]],\n",
      "\n",
      "        [[-0.2218],\n",
      "         [-0.0400],\n",
      "         [-0.0314],\n",
      "         [-0.0303],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302],\n",
      "         [-0.0302]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-42.0327, -44.8350, -43.7412, -44.2819, -44.6024],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 1, 0, 1, 0])\n",
      "Batch average accuracy:  tensor(0.)\n",
      "Rewards:  [-1, -1, -1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 13, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.5951],\n",
      "        [-0.5951],\n",
      "        [-0.5951],\n",
      "        [-0.5951],\n",
      "        [-0.5951]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.5951], grad_fn=<MulBackward0>), tensor([-0.5951], grad_fn=<MulBackward0>), tensor([-0.5951], grad_fn=<MulBackward0>), tensor([-0.5951], grad_fn=<MulBackward0>), tensor([-0.5951], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.5951, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 4.3273,  4.7272,  2.5566,  ..., -2.3654, -2.1371, -0.9329]],\n",
      "\n",
      "        [[ 4.3273,  4.7272,  2.5566,  ..., -2.3654, -2.1371, -0.9329]],\n",
      "\n",
      "        [[ 4.3273,  4.7272,  2.5566,  ..., -2.3654, -2.1371, -0.9329]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.5608,  6.1000,  3.1358,  ..., -3.0934, -2.5920, -1.2167]],\n",
      "\n",
      "        [[ 5.5608,  6.1000,  3.1358,  ..., -3.0934, -2.5920, -1.2167]],\n",
      "\n",
      "        [[ 5.5608,  6.1000,  3.1358,  ..., -3.0934, -2.5920, -1.2167]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(8.8868, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.5951, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [27/14000], Speaker loss: 0.2936, Listener loss: 1.1905, Perplexity: 1.3412\n",
      "Target inds:  tensor([17555, 10753, 13941, 43700, 57999])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 1, 1, 1, 0]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 1, 1, 1, 0])\n",
      "Stacked preds out:  torch.Size([5, 14])\n",
      "torch.Size([5, 14])\n",
      "Log probs out: torch.Size([5, 14, 1]) tensor([[[-0.2308],\n",
      "         [-0.0437],\n",
      "         [-0.0346],\n",
      "         [-0.0335],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333]],\n",
      "\n",
      "        [[-0.2308],\n",
      "         [-0.0437],\n",
      "         [-0.0346],\n",
      "         [-0.0335],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333]],\n",
      "\n",
      "        [[-0.2308],\n",
      "         [-0.0437],\n",
      "         [-0.0346],\n",
      "         [-0.0335],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333]],\n",
      "\n",
      "        [[-0.2308],\n",
      "         [-0.0437],\n",
      "         [-0.0346],\n",
      "         [-0.0335],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333]],\n",
      "\n",
      "        [[-0.2308],\n",
      "         [-0.0437],\n",
      "         [-0.0346],\n",
      "         [-0.0335],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-31.7805, -31.1065, -31.8945, -31.8009, -32.0943],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 1, 1, 0, 1])\n",
      "Batch average accuracy:  tensor(0.4000)\n",
      "Rewards:  [-1, 1, 1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 14, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.6758],\n",
      "        [-0.6758],\n",
      "        [-0.6758],\n",
      "        [-0.6758],\n",
      "        [-0.6758]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.6758], grad_fn=<MulBackward0>), tensor([0.6758], grad_fn=<MulBackward0>), tensor([0.6758], grad_fn=<MulBackward0>), tensor([-0.6758], grad_fn=<MulBackward0>), tensor([-0.6758], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.1352, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 4.4549,  4.7968,  2.6348,  ..., -2.3835, -2.1528, -0.9573]],\n",
      "\n",
      "        [[ 4.4549,  4.7968,  2.6348,  ..., -2.3835, -2.1528, -0.9573]],\n",
      "\n",
      "        [[ 4.4549,  4.7968,  2.6348,  ..., -2.3835, -2.1528, -0.9573]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.7215,  6.1877,  3.2342,  ..., -3.1162, -2.6118, -1.2475]],\n",
      "\n",
      "        [[ 5.7215,  6.1877,  3.2342,  ..., -3.1162, -2.6118, -1.2475]],\n",
      "\n",
      "        [[ 5.7215,  6.1877,  3.2342,  ..., -3.1162, -2.6118, -1.2475]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(9.1114, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.1352, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [28/14000], Speaker loss: 0.7760, Listener loss: 0.7905, Perplexity: 2.1727\n",
      "Target inds:  tensor([ 4106, 18652, 53966, 66604, 46676])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [1, 1, 0, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 1, 0, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 14])\n",
      "torch.Size([5, 14])\n",
      "Log probs out: torch.Size([5, 14, 1]) tensor([[[-0.2445],\n",
      "         [-0.0491],\n",
      "         [-0.0392],\n",
      "         [-0.0380],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379]],\n",
      "\n",
      "        [[-0.2445],\n",
      "         [-0.0491],\n",
      "         [-0.0392],\n",
      "         [-0.0380],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379]],\n",
      "\n",
      "        [[-0.2445],\n",
      "         [-0.0491],\n",
      "         [-0.0392],\n",
      "         [-0.0380],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379]],\n",
      "\n",
      "        [[-0.2445],\n",
      "         [-0.0491],\n",
      "         [-0.0392],\n",
      "         [-0.0380],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379]],\n",
      "\n",
      "        [[-0.2445],\n",
      "         [-0.0491],\n",
      "         [-0.0392],\n",
      "         [-0.0380],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379],\n",
      "         [-0.0379]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-20.8565, -20.8444, -20.6906, -20.7266, -20.5273],\n",
      "       grad_fn=<MaxBackward0>) tensor([0, 0, 1, 0, 0])\n",
      "Batch average accuracy:  tensor(0.)\n",
      "Rewards:  [-1, -1, -1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 14, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.7495],\n",
      "        [-0.7495],\n",
      "        [-0.7495],\n",
      "        [-0.7495],\n",
      "        [-0.7495]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-0.7495], grad_fn=<MulBackward0>), tensor([-0.7495], grad_fn=<MulBackward0>), tensor([-0.7495], grad_fn=<MulBackward0>), tensor([-0.7495], grad_fn=<MulBackward0>), tensor([-0.7495], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-0.7495, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 4.5910,  4.8793,  2.7418,  ..., -2.3972, -2.1645, -0.9762]],\n",
      "\n",
      "        [[ 4.5910,  4.8793,  2.7418,  ..., -2.3972, -2.1645, -0.9762]],\n",
      "\n",
      "        [[ 4.5910,  4.8793,  2.7418,  ..., -2.3972, -2.1645, -0.9762]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.8927,  6.2916,  3.3688,  ..., -3.1335, -2.6266, -1.2713]],\n",
      "\n",
      "        [[ 5.8927,  6.2916,  3.3688,  ..., -3.1335, -2.6266, -1.2713]],\n",
      "\n",
      "        [[ 5.8927,  6.2916,  3.3687,  ..., -3.1335, -2.6266, -1.2713]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(8.7223, grad_fn=<NllLossBackward0>)  L_f:  tensor(-0.7495, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [29/14000], Speaker loss: 0.1227, Listener loss: 0.9599, Perplexity: 1.1306\n",
      "Target inds:  tensor([66220, 34702, 36793, 10422,  7462])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n",
      "Sampled target indices:  [0, 1, 1, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([0, 1, 1, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 19])\n",
      "torch.Size([5, 19])\n",
      "Log probs out: torch.Size([5, 19, 1]) tensor([[[-0.2728],\n",
      "         [-0.0594],\n",
      "         [-0.0481],\n",
      "         [-0.0467],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465]],\n",
      "\n",
      "        [[-0.2728],\n",
      "         [-0.0594],\n",
      "         [-0.0481],\n",
      "         [-0.0467],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465]],\n",
      "\n",
      "        [[-0.2728],\n",
      "         [-0.0594],\n",
      "         [-0.0481],\n",
      "         [-0.0467],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465]],\n",
      "\n",
      "        [[-0.2728],\n",
      "         [-0.0594],\n",
      "         [-0.0481],\n",
      "         [-0.0467],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465]],\n",
      "\n",
      "        [[-0.2728],\n",
      "         [-0.0594],\n",
      "         [-0.0481],\n",
      "         [-0.0467],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0465]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-9.0354, -9.4152, -8.7790, -8.8717, -9.2006], grad_fn=<MaxBackward0>) tensor([1, 0, 0, 0, 0])\n",
      "Batch average accuracy:  tensor(0.)\n",
      "Rewards:  [-1, -1, -1, -1, -1]\n",
      "Policy log probs in:  torch.Size([5, 19, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-1.1243],\n",
      "        [-1.1243],\n",
      "        [-1.1243],\n",
      "        [-1.1243],\n",
      "        [-1.1243]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([-1.1243], grad_fn=<MulBackward0>), tensor([-1.1243], grad_fn=<MulBackward0>), tensor([-1.1243], grad_fn=<MulBackward0>), tensor([-1.1243], grad_fn=<MulBackward0>), tensor([-1.1243], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(-1.1243, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 4.7471,  4.9984,  2.8657,  ..., -2.3947, -2.1622, -0.9754]],\n",
      "\n",
      "        [[ 4.7471,  4.9984,  2.8657,  ..., -2.3947, -2.1622, -0.9754]],\n",
      "\n",
      "        [[ 4.7471,  4.9984,  2.8657,  ..., -2.3947, -2.1622, -0.9754]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.0890,  6.4415,  3.5247,  ..., -3.1303, -2.6237, -1.2703]],\n",
      "\n",
      "        [[ 6.0890,  6.4415,  3.5247,  ..., -3.1303, -2.6237, -1.2703]],\n",
      "\n",
      "        [[ 6.0890,  6.4415,  3.5247,  ..., -3.1303, -2.6237, -1.2703]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(8.7012, grad_fn=<NllLossBackward0>)  L_f:  tensor(-1.1243, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [30/14000], Speaker loss: -0.2542, Listener loss: 0.8723, Perplexity: 0.7755\n",
      "Target inds:  tensor([45479, 31264, 68959, 11039, 54667])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled target indices:  [1, 1, 1, 1, 1]\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Optimized features1 / 2 lists:  torch.Size([5, 2048])\n",
      "Tensor targets list:  tensor([1, 1, 1, 1, 1])\n",
      "Stacked preds out:  torch.Size([5, 10])\n",
      "torch.Size([5, 10])\n",
      "Log probs out: torch.Size([5, 10, 1]) tensor([[[-0.3197],\n",
      "         [-0.0768],\n",
      "         [-0.0631],\n",
      "         [-0.0614],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612]],\n",
      "\n",
      "        [[-0.3197],\n",
      "         [-0.0768],\n",
      "         [-0.0631],\n",
      "         [-0.0614],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612]],\n",
      "\n",
      "        [[-0.3197],\n",
      "         [-0.0768],\n",
      "         [-0.0631],\n",
      "         [-0.0614],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612]],\n",
      "\n",
      "        [[-0.3197],\n",
      "         [-0.0768],\n",
      "         [-0.0631],\n",
      "         [-0.0614],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612]],\n",
      "\n",
      "        [[-0.3197],\n",
      "         [-0.0768],\n",
      "         [-0.0631],\n",
      "         [-0.0614],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612],\n",
      "         [-0.0612]]], grad_fn=<LogBackward0>)\n",
      "LISTENER encoder last hidden out:  torch.Size([1, 5, 512])\n",
      "Listener RNN output:  torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "Caption shape in forward of listener CNN:  torch.Size([5, 512])\n",
      "Listener CNN output:  torch.Size([5, 2])\n",
      "Max dots and inds:  tensor([-1.4387, -1.6278, -1.8329, -1.8450, -1.7801], grad_fn=<MaxBackward0>) tensor([1, 1, 1, 0, 1])\n",
      "Batch average accuracy:  tensor(0.8000)\n",
      "Rewards:  [1, 1, 1, -1, 1]\n",
      "Policy log probs in:  torch.Size([5, 10, 1])\n",
      "Policy log probs by sentence (num=batch size):  torch.Size([5, 1]) tensor([[-0.8882],\n",
      "        [-0.8882],\n",
      "        [-0.8882],\n",
      "        [-0.8882],\n",
      "        [-0.8882]], grad_fn=<SumBackward1>)\n",
      "Policy update by datapoint:  [tensor([0.8882], grad_fn=<MulBackward0>), tensor([0.8882], grad_fn=<MulBackward0>), tensor([0.8882], grad_fn=<MulBackward0>), tensor([-0.8882], grad_fn=<MulBackward0>), tensor([0.8882], grad_fn=<MulBackward0>)]\n",
      "Policy gradient out:  torch.Size([]) tensor(0.5329, grad_fn=<MeanBackward0>)\n",
      "Raw outputs:  tensor([[[ 4.9144,  5.1433,  3.0130,  ..., -2.3744, -2.1439, -0.9523]],\n",
      "\n",
      "        [[ 4.9144,  5.1433,  3.0130,  ..., -2.3744, -2.1439, -0.9523]],\n",
      "\n",
      "        [[ 4.9145,  5.1433,  3.0130,  ..., -2.3744, -2.1439, -0.9523]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.2996,  6.6238,  3.7100,  ..., -3.1049, -2.6009, -1.2413]],\n",
      "\n",
      "        [[ 6.2996,  6.6238,  3.7100,  ..., -3.1049, -2.6009, -1.2413]],\n",
      "\n",
      "        [[ 6.2996,  6.6238,  3.7100,  ..., -3.1049, -2.6009, -1.2413]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "L_s:  tensor(8.5476, grad_fn=<NllLossBackward0>)  L_f:  tensor(0.5329, grad_fn=<MeanBackward0>)\n",
      "Epoch [1/1], Step [31/14000], Speaker loss: 1.3877, Listener loss: 0.6337, Perplexity: 4.0054\n",
      "Target inds:  tensor([60674, 24941, 54931, 33303,  2470])\n",
      "Retrieved target features shape:  torch.Size([5, 2048])\n",
      "Projected features target:  torch.Size([5, 1024])\n",
      "Projected features dist:  torch.Size([5, 1024])\n",
      "Feature pairs shape before sampling:  torch.Size([5, 2048])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5843d2ffcefd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mfeature_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_speaker_features_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractor_speaker_features_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Feature pairs shape before sampling: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mcaptions_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeaker_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#         preds_out.append(captions_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ba0f13233c48>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, inputs, max_sequence_length)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0minputs_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# lstm_out shape : (1, 1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# outputs shape : (1, 1, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# get the log probs of the actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "csv_out = \"functional_training_losses_2imgs_\"\n",
    "\n",
    "speaker_losses_structural = []\n",
    "speaker_losses_functional = []\n",
    "listener_losses = []\n",
    "perplexities = []\n",
    "steps = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices_pairs = data_loader_pairs.dataset.get_func_train_indices()\n",
    "        # get separate lists for retrieving image embeddings\n",
    "        target_inds = torch.tensor([x[0] for x in indices_pairs]).long()\n",
    "        distractor_inds = torch.tensor([x[1] for x in indices_pairs]).long()\n",
    "        print(\"Target inds: \", target_inds)\n",
    "        \n",
    "        # Create and assign a batch sampler to retrieve a target batch with the sampled indices.\n",
    "        new_sampler_pairs = torch.utils.data.sampler.SubsetRandomSampler(indices=indices_pairs)\n",
    "        \n",
    "        data_loader_pairs.batch_sampler.sampler = new_sampler_pairs\n",
    "        # Obtain the target batch.\n",
    "        images1, images2, captions = next(iter(data_loader_pairs))\n",
    "        # create target-distractor image tuples\n",
    "#         train_pairs = list(zip(images1, images2))\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "#         images1 = images1.to(device)\n",
    "#         images2 = images2.to(device)\n",
    "        captions = captions.to(device)\n",
    "        #######\n",
    "        # NB  I did this weird shuffling before the training loop in order to not induce any bias\n",
    "        # now Lazaridou et al 2017 just always have the first image as the target - maybe it's fine?\n",
    "        # try to do this at a different point / avoid the wrangling for the speaker embedding\n",
    "        # only the targets need to have the same length captions for batching because these are the only ones used\n",
    "        #######\n",
    "        \n",
    "        # Zero the gradients (reset).\n",
    "        speaker_encoder.zero_grad()\n",
    "        speaker_decoder.zero_grad()\n",
    "        speaker_mlp.zero_grad()\n",
    "        listener_encoder.zero_grad()\n",
    "        listener_rnn.zero_grad()\n",
    "        \n",
    "        ###### Pass the targets through the speaker model.\n",
    "        \n",
    "        # sample caption from speaker \n",
    "        # zip images and target indices such that we can input correct image into speaker\n",
    "#         train_pairs = list(zip(zip(images1, images2), targets))\n",
    "#         target_images = [im[j] for im, j in train_pairs]\n",
    "        preds_out = []\n",
    "        log_probs_batch = []\n",
    "        speaker_features_batch = []\n",
    "        speaker_raw_output = []\n",
    "        # get predicted captions for each image in the batch (to be made more efficient)\n",
    "#         for i, im in enumerate(images1): \n",
    "            # TODO\n",
    "            # can I only embed this by-image, or can I concatenate more efficiently?\n",
    "            # is this even correct to just call the visual encoder twice? because of the learning of the Linear layer later?\n",
    "        #################\n",
    "        # get image features\n",
    "        target_speaker_features = torch.index_select(embedded_imgs, 0, target_inds)\n",
    "        print(\"Retrieved target features shape: \", target_speaker_features.shape)\n",
    "        distractor_speaker_features = torch.index_select(embedded_imgs, 0, distractor_inds)\n",
    "        # project them with the linear layer\n",
    "        target_speaker_features_emb = speaker_mlp(target_speaker_features)\n",
    "        print(\"Projected features target: \", target_speaker_features_emb.shape )\n",
    "        distractor_speaker_features_emb = speaker_mlp(distractor_speaker_features)\n",
    "        print(\"Projected features dist: \", distractor_speaker_features_emb.shape )\n",
    "        \n",
    "        ##########\n",
    "#         target_speaker_features = speaker_encoder(images1)\n",
    "#         distractor_speaker_features = speaker_encoder(images2)\n",
    "#         speaker_features_batch.append(speaker_features)\n",
    "            # get predicted caption and its log probability\n",
    "        # concatenate the two images \n",
    "        feature_pairs = torch.cat((target_speaker_features_emb, distractor_speaker_features_emb), dim=-1)\n",
    "        print(\"Feature pairs shape before sampling: \", feature_pairs.shape)\n",
    "        captions_pred, log_probs, raw_outputs = speaker_decoder.sample(feature_pairs.unsqueeze(1), max_sequence_length=captions[i].shape[0])\n",
    "\n",
    "#         preds_out.append(captions_pred)\n",
    "#         log_probs_batch.append(log_probs)\n",
    "#         speaker_raw_output.extend(raw_outputs)\n",
    "            \n",
    "        #########################\n",
    "        # assume train_pairs is just (img1, img2, cap_img1)\n",
    "        # TODO make this batch-level\n",
    "        targets_list = []\n",
    "        features1_list = []\n",
    "        features2_list = []\n",
    "        target_indices = np.random.choice([0,1], size=captions.shape[0]).tolist()\n",
    "        print(\"Sampled target indices: \", target_indices)\n",
    "        for i, target in enumerate(target_indices):\n",
    "            if target == 0:\n",
    "#                 listener_img = (train_pairs[i][0], train_pairs[i][1])  \n",
    "                features1_list.append(target_speaker_features[i])\n",
    "                features2_list.append(distractor_speaker_features[i])\n",
    "            else:\n",
    "#                 listener_img = (train_pairs[i][1], train_pairs[i][0])\n",
    "                features2_list.append(target_speaker_features[i])\n",
    "                features1_list.append(distractor_speaker_features[i])\n",
    "#             train_pairs[i] = listener_img    \n",
    "            # memorize the target index    \n",
    "            targets_list.append(target)\n",
    "        features1 = torch.stack(features1_list)\n",
    "        features2 = torch.stack(features2_list)\n",
    "        print(\"Optimized features1 / 2 lists: \", features1.shape)\n",
    "        print(\"Optimized features1 / 2 lists: \", features2.shape)\n",
    "#         train_pairs.to(device)\n",
    "#         target_idx = idx[target]\n",
    "#         distractor_idx = idx[(1-target)]\n",
    "        #######    \n",
    "        \n",
    "#         targets = targets.to(device)\n",
    "        # TODO\n",
    "        targets_list = torch.tensor(targets_list).to(device)\n",
    "        print(\"Tensor targets list: \", targets_list)\n",
    "        ############################\n",
    "        # transform predicted word indices to tensor\n",
    "#         preds_out_tensor = [torch.stack(x) for x in preds_out]\n",
    "        preds_out = torch.stack(captions_pred, dim=-1)#.squeeze(-1)    \n",
    "        print(\"Stacked preds out: \", preds_out.shape)\n",
    "        print(torch.stack(captions_pred, dim=-1).squeeze(-1).shape  )\n",
    "        print(\"Log probs out:\", log_probs.shape, log_probs)\n",
    "        #######\n",
    "        # pass images and generated message form speaker through listener\n",
    "        hiddens_scores, hidden = listener_rnn(preds_out) #  captions_pred\n",
    "        print(\"Listener RNN output: \", hidden.shape)\n",
    "        print(hidden.shape)\n",
    "        # TODO this will change for new sampler, it will just take images which is batch of tuples (img1, img2)\n",
    "        predictions = listener_encoder(features1, features2, hidden.squeeze(0)) # train_pairs\n",
    "        print(\"Listener CNN output: \", predictions.shape)\n",
    "        # retrieve the index of the larger dot product\n",
    "        predicted_max_dots, predicted_inds = torch.max(predictions, dim = 1)\n",
    "        print(\"Max dots and inds: \", predicted_max_dots, predicted_inds)\n",
    "        ######\n",
    "        # RL step\n",
    "#         log_probs = torch.stack(log_probs_batch)\n",
    "        # if target index and output index match, 1, else -1\n",
    "        \n",
    "        accuracy = torch.sum(torch.eq(targets_list, predicted_inds).to(torch.int64))/predicted_inds.shape[0]\n",
    "        print(\"Batch average accuracy: \", accuracy)\n",
    "        accuracies.append(accuracy.item())\n",
    "        rewards = [1 if x else -1 for x in torch.eq(targets_list, predicted_inds).tolist()]\n",
    "        print(\"Rewards: \", rewards)\n",
    "        # compute REINFORCE update\n",
    "        rl_grads = update_policy(rewards,  log_probs)\n",
    "        \n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        \n",
    "        # REINFORCE for functional part, applied to speaker LSTM weights (maybe also Linear ones)\n",
    "        # cross entropy for Listener\n",
    "        # and also cross entropy for Speaker params, optimizing against target caption of the target image\n",
    "        # (last implemented just like for pretraining), this is the structural loss component\n",
    "        \n",
    "        # combine structural loss and functional loss for the speaker # torch.stack(speaker_raw_output)\n",
    "        print(\"Raw outputs: \", torch.stack(raw_outputs))\n",
    "        loss_structural = criterion(torch.stack(raw_outputs).contiguous().view(-1, vocab_size), captions.reshape(-1)) \n",
    "        speaker_loss =  lambda_s*loss_structural + rl_grads\n",
    "        \n",
    "        print(\"L_s: \", loss_structural, \" L_f: \", rl_grads)\n",
    "        \n",
    "        # listener loss\n",
    "        listener_loss = criterion(predictions, targets_list)\n",
    "        \n",
    "        \n",
    "        # Backward pass.\n",
    "        speaker_loss.backward(retain_graph=True)\n",
    "        listener_loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Update the parameters in the respective optimizer.\n",
    "        speaker_optimizer.step()\n",
    "        listener_optimizer.step()\n",
    "        \n",
    "        # Get training statistics.\n",
    "        # perplexity computation questionable\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Speaker loss: %.4f, Listener loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, speaker_loss.item(), listener_loss.item(), torch.exp(speaker_loss))\n",
    "        \n",
    "        speaker_losses_structural.append(loss_structural.item())\n",
    "        speaker_losses_functional.append(rl_grads.item())\n",
    "        listener_losses.append(listener_loss.item())\n",
    "        perplexities.append(torch.exp(speaker_loss).item())\n",
    "        steps.append(i_step)\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-2imgs-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-2imgs-%d.pkl' % epoch))\n",
    "        \n",
    "    # save the training metrics\n",
    "    df_out = pd.DataFrame({\n",
    "        \"steps\": steps,\n",
    "        \"speaker_s\": speaker_losses_structural,\n",
    "        \"speaker_f\": speaker_losses_functional,\n",
    "        \"listener\": listener_losses,\n",
    "        \"perplexities\": perplexities\n",
    "    })\n",
    "    df_out.to_csv(csv_out + \"epoch_\" + str(epoch) + \".csv\", index=False )\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b926bf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.6000), tensor(0.2000), tensor(0.6000), tensor(0.)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1e4affa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps, speaker_losses_structural, label=\"Speaker structural\")\n",
    "plt.plot(steps, speaker_losses_functional, label=\"Speaker functional\")\n",
    "plt.plot(steps, listener_losses, label=\"Listener\")\n",
    "plt.plot(steps, perplexities, label=\"Perplexity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166982c5",
   "metadata": {},
   "source": [
    "### Testing the pretrained sepaker\n",
    "\n",
    "Below, some initial code for testing the pretrained speaker (basic image captioning model) is provided. Ignore for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe93276",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_imgs = torch.load(\"../COCO_train_ResNet_features_reshaped_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "719a2729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n",
      "tensor([138448]) tensor([59246])\n"
     ]
    }
   ],
   "source": [
    "# transforms like in train\n",
    "transform_test = transforms.Compose([transforms.Resize((224, 224)), \\\n",
    "                                     transforms.ToTensor(), \\\n",
    "                                     transforms.Normalize((0.485, 0.456, 0.406), \\\n",
    "                                                          (0.229, 0.224, 0.225))])\n",
    "data_loader_test = get_loader(transform=transform_test,\n",
    "                         mode='train',\n",
    "                         batch_size=1,\n",
    "                         vocab_threshold=25,\n",
    "                         vocab_from_file=True,\n",
    "                         download_dir=\"../../../data/train\", \n",
    "                              vocab_file=\"vocab4000.pkl\"\n",
    "#                          vocab_file='../../../data/vocab.pkl'\n",
    "                        )\n",
    "test_indices = data_loader_test.dataset.get_func_train_indices() # [(649113, 651428), (782868, 430837)] \n",
    "test_targets = torch.tensor([x[0] for x in test_indices]).long()\n",
    "test_dists = torch.tensor([x[1] for x in test_indices]).long()\n",
    "print(test_targets, test_dists)        \n",
    "# Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "new_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices=test_indices)\n",
    "data_loader_test.batch_sampler.sampler = new_sampler        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b1c31c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508123\n",
      "291765\n"
     ]
    }
   ],
   "source": [
    "# extract features for target from file\n",
    "sanity_check = torch.load(\"../pretrain_img_IDs_2imgs_512dim.pt\").tolist()\n",
    "\n",
    "saved_target_features = embedded_imgs[str(sanity_check[test_targets.item()])]#torch.index_select(embedded_imgs, 0,  test_targets).squeeze(1)\n",
    "print(str(sanity_check[test_targets.item()]))\n",
    "saved_dist_features = embedded_imgs[str(sanity_check[test_dists.item()])]#torch.index_select(embedded_imgs, 0,  test_dists).squeeze(1)\n",
    "print(str(sanity_check[test_dists.item()]))\n",
    "# print(saved_target_features.shape)\n",
    "# # extract features for target from model\n",
    "# encoder_cnn = EncoderCNN(1048)\n",
    "# ftr, resnet_ftr = encoder_cnn(orig_image)\n",
    "# print(resnet_ftr.shape)\n",
    "# print(\"features equal?: \", torch.equal(saved_target_features, resnet_ftr))\n",
    "# print(\"features equal?: \", torch.equal(embedded_imgs[test_targets.item(), :], resnet_ftr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2dac6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a testing split from the unused part of the train split bc i have extracted features for those\n",
    "coco_train_keys = coco_train.anns.keys()\n",
    "val_split = set(coco_train_keys) - set(sanity_check) #[i for i in coco_train_keys if i not in sanity_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a71cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(list(val_split), \"val_split_IDs_from_COCO_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f667a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183396\n",
      "380523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_id': 347351,\n",
       " 'id': 183396,\n",
       " 'caption': 'An animal with horns eating grass next to cattails and a pond.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_train.anns[12238]\n",
    "print(list(coco_train.anns.keys())[138448])\n",
    "print(list(coco_train.anns.keys()).index(508123))\n",
    "coco_train.anns[183396]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "759500f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "538e8d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508123"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_check[138448]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "088631e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(output):\n",
    "    \"\"\"\n",
    "    Transform list of indices to a sentence.\n",
    "    \"\"\"\n",
    "    list_string = []\n",
    "    \n",
    "    for idx in output:\n",
    "#         print(idx)\n",
    "        for i in idx:\n",
    "#             print(\"i: \", i)\n",
    "            try:\n",
    "                list_string.append(data_loader_test.dataset.vocab.idx2word[i.item()])\n",
    "            except ValueError:\n",
    "                for y in i:\n",
    "                    list_string.append(data_loader_test.dataset.vocab.idx2word[y.item()])\n",
    "    list_string = list_string[:-1] # Discard <start> and <end> words\n",
    "    sentence = ' '.join(list_string) # Convert list of string to full string\n",
    "    sentence = sentence.capitalize()  # Capitalize the first letter of the first word\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bf1fdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150065"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader_test.dataset.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c296557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target idx in getitem:  138448\n",
      "Ann_id in getitem:  508123\n",
      "A person holding a cell phone in their left hand.\n",
      "IMG  228330\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize sample image, before pre-processing.\n",
    "# for img, dist, cap in iter(data_loader_test):\n",
    "orig_image, dist_image, cap = next(iter(data_loader_test))\n",
    "# print(cap)\n",
    "#     dist_img, dist, cap_dist = next(iter(data_loader_test))\n",
    "plt.imshow(orig_image[0].squeeze(0).permute(1,2,0))\n",
    "plt.title(clean_sentence(cap))\n",
    "#     plt.imshow(dist_image[0].squeeze(0).permute(1,2,0))\n",
    "#     plt.title(\"Distractor\")\n",
    "    \n",
    "plt.show()\n",
    "# orig_image.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20f09cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Start a car dashboard with a led display and a plush rabbit'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentence(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b06cdf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dist_image[0].squeeze(0).permute(1,2,0))\n",
    "# plt.title(clean_sentence(cap_dist))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db3f2641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7d6a148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB:  4054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecoderRNN(\n",
       "  (embed): Embedding(4054, 512)\n",
       "  (lstm): LSTM(1536, 512, batch_first=True)\n",
       "  (linear): Linear(in_features=512, out_features=4054, bias=True)\n",
       "  (project): Linear(in_features=2048, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# encoder_file = 'speaker-encoder-jointImgs-preprend-vocab6000-1.pkl' \n",
    "decoder_file = 'decoder-noEnc-prepend-512dim-4000vocab-rs1234-leon-cont-7.pkl' # 'decoder-noEnc-prepend-1024dim-4000vocab-rs1234-1.pkl'\n",
    "\n",
    "embed_size = 512\n",
    "visual_embed_size = 512\n",
    "hidden_size = 512\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader_test.dataset.vocab)\n",
    "print(\"VOCAB: \", vocab_size)\n",
    "# Initialize the encoder and decoder, and set each to inference mode.\n",
    "# encoder = EncoderMLP(2*2048, 2*visual_embed_size)\n",
    "# encoder.eval()\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, visual_embed_size)\n",
    "decoder.eval()\n",
    "\n",
    "# Load the trained weights.\n",
    "# encoder.load_state_dict(torch.load(os.path.join('./../models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./../models', decoder_file)))\n",
    "\n",
    "# Move models to GPU if CUDA is available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4275ea22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dists = torch.tensor([0, 1]).long()\n",
    "# test_target = torch.tensor([2, 3]).long()\n",
    "# torch.equal(embedded_imgs[0, :], embedded_imgs[1, :])\n",
    "data_loader_test.dataset.vocab.idx2word[49]\n",
    "# print(saved_target_features)\n",
    "# saved_dist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18547c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([138448])\n",
      "tensor([59246])\n",
      "torch.Size([1, 2, 2048])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[4]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 89, 165,  96,  38,  59]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[89]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[345, 126, 322, 217,  22]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[345]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[  4, 142, 280,  47, 156]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[4]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 303,  153, 1070, 1704,    2]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[303]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 153,  303, 1904, 2530,   76]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[153]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 76,  40, 201, 157,  22]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[76]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[  4,  34, 118,  99, 156]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[4]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[  38, 1245,  203,  324, 1104]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[38]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[19,  1, 38, 76, 22]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[19]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[  1,  19, 201,  22, 349]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[1]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[19,  1, 14, 22,  4]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[19]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 1, 19,  4, 34, 50]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[1]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[19, 14,  1, 22,  4]]])\n",
      "log probs [tensor([[-0.2988]], grad_fn=<LogBackward0>), tensor([[-1.7891]], grad_fn=<LogBackward0>), tensor([[-1.4480]], grad_fn=<LogBackward0>), tensor([[-0.4793]], grad_fn=<LogBackward0>), tensor([[-0.8269]], grad_fn=<LogBackward0>), tensor([[-0.0008]], grad_fn=<LogBackward0>), tensor([[-1.1602]], grad_fn=<LogBackward0>), tensor([[-1.0248]], grad_fn=<LogBackward0>), tensor([[-0.3513]], grad_fn=<LogBackward0>), tensor([[-0.8095]], grad_fn=<LogBackward0>), tensor([[-0.0029]], grad_fn=<LogBackward0>), tensor([[-0.4866]], grad_fn=<LogBackward0>), tensor([[-0.0042]], grad_fn=<LogBackward0>), tensor([[-0.7258]], grad_fn=<LogBackward0>)]\n",
      "[tensor([[0.2216]], grad_fn=<MulBackward0>)]\n",
      "example sentence for target:\n",
      " A woman holding a cell phone in a car . end . end\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[4]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[170,  20,  37, 575, 221]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[170]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[126,  63, 836,  22,  40]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[126]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 127,  836,  135, 1113,  874]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[127]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 40,  76, 108, 349, 466]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[40]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 34,   4, 250,  47,  35]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[34]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 179,   35,   41,  499, 1427]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[179]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[14, 98, 22, 40, 91]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[14]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 4, 34, 46, 47, 35]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[4]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 35,  41, 221, 497, 663]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[35]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[19,  1, 22, 76, 35]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[19]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[  1,  19, 391,   2,  22]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[1]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 19,  14,   1,  40, 157]]])\n",
      "CAT SAMPLES AT BEGINNING OF SAMPLING LOOP  tensor([[19]])\n",
      "reps  torch.Size([1, 1, 1024])\n",
      "embs  torch.Size([1, 1, 512])\n",
      "Top 5 inds:  tensor([[[ 1, 19, 50, 46, 34]]])\n",
      "log probs [tensor([[-0.1864]], grad_fn=<LogBackward0>), tensor([[-1.5860]], grad_fn=<LogBackward0>), tensor([[-1.9331]], grad_fn=<LogBackward0>), tensor([[-1.8230]], grad_fn=<LogBackward0>), tensor([[-0.7584]], grad_fn=<LogBackward0>), tensor([[-0.7034]], grad_fn=<LogBackward0>), tensor([[-0.6659]], grad_fn=<LogBackward0>), tensor([[-0.0508]], grad_fn=<LogBackward0>), tensor([[-0.6323]], grad_fn=<LogBackward0>), tensor([[-0.5918]], grad_fn=<LogBackward0>), tensor([[-0.2172]], grad_fn=<LogBackward0>), tensor([[-0.0078]], grad_fn=<LogBackward0>), tensor([[-0.6524]], grad_fn=<LogBackward0>), tensor([[-0.0088]], grad_fn=<LogBackward0>)]\n",
      "[tensor([[0.1547]], grad_fn=<MulBackward0>)]\n",
      "example sentence for distractor:\n",
      " A bus is parked on the side of a street . end .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(orig_image[0].squeeze(0).permute(1,2,0))\n",
    "plt.title(clean_sentence(cap))\n",
    "\n",
    "orig_image = orig_image.to(device)\n",
    "print(test_targets)\n",
    "print(test_dists)\n",
    "# both_images = [saved_target_features, saved_dist_features] #torch.cat((saved_target_features, saved_dist_features), dim=-1)\n",
    "both_images = torch.cat((saved_target_features.unsqueeze(0).unsqueeze(0), saved_dist_features.unsqueeze(0).unsqueeze(0)), dim=1)\n",
    "print(both_images.shape)\n",
    "# ad START token\n",
    "# start_emb = decoder.embed(torch.tensor([0]).unsqueeze(0).long())\n",
    "# print(\"Start: \", start_emb.shape)\n",
    "# embs_concat = torch.cat((both_images, start_emb), dim=1)\n",
    "# print(\"embs concat: \", embs_concat.shape)\n",
    "# print(\"ImGAE\", image.shape)\n",
    "# Obtain the embedded image features.\n",
    "# features_t = torch.index_select(embedded_imgs, 0,  test_targets)\n",
    "# features_emb = encoder(both_images)\n",
    "\n",
    "# image = orig_image.to(device)\n",
    "# print(\"ImGAE\", image.shape)\n",
    "# Obtain the embedded image features.\n",
    "# features_d = torch.index_select(embedded_imgs, 0, test_dists)\n",
    "# print(torch.equal(features_t, features_d))\n",
    "# features_d_emb, _ = encoder(dist_image)\n",
    "\n",
    "\n",
    "# out = decoder(both_images, cap)\n",
    "# print(out)\n",
    "# Pass the embedded image features through the model to get a predicted caption.\n",
    "# print(torch.cat((features_t, features_d), dim=-1).shape)\n",
    "output, log_p, raw, topk = decoder.sample(both_images, 13) # features_emb.unsqueeze(1)\n",
    "# out, hidden_state = decoder(both_images, cap, decoder.init_hidden(1))\n",
    "# print(\"Output\", out)\n",
    "sentence_t = clean_sentence(output)\n",
    "print('example sentence for target:\\n', sentence_t)\n",
    "# for k in topk:\n",
    "#     print(\"Top K words\")\n",
    "#     print(clean_sentence(k.squeeze(0)))\n",
    "    \n",
    "both_images_d = torch.cat((saved_dist_features.unsqueeze(0).unsqueeze(1), saved_target_features.unsqueeze(0).unsqueeze(1)), dim=1) #[saved_dist_features, saved_target_features] #torch.cat((saved_dist_features, saved_target_features), dim=-1)\n",
    "# print(\"concat: \", torch.equal(both_images, both_images_d))\n",
    "# both_features_d = encoder(both_images_d)\n",
    "# out_d = decoder(both_images_d, cap)\n",
    "# print(out_d)\n",
    "# torch.equal(out, out_d)\n",
    "# print(\"Features: \", torch.equal(both_features, both_features_d))\n",
    "# # Pass the embedded image features through the model to get a predicted caption.\n",
    "output2, log_p2, raw2, topk2 = decoder.sample(both_images_d, 13) #both_features_d.unsqueeze(1)\n",
    "# out2, hidden_state2 = decoder(both_images_d, cap, decoder.init_hidden(1))\n",
    "# print(\"Output 2: \", out2)\n",
    "# print(\"raw\", set(output) & set(output2))\n",
    "sentence_d = clean_sentence(output2)\n",
    "print('example sentence for distractor:\\n', sentence_d)\n",
    "# for k in topk2:\n",
    "#     print(\"Top K words2\")\n",
    "#     print(clean_sentence(k.squeeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7350a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n",
      "264048\n"
     ]
    }
   ],
   "source": [
    "# init validation data loader\n",
    "data_loader_val = get_loader(transform=transform_test,\n",
    "                         mode='train',\n",
    "                         batch_size=64,\n",
    "                         vocab_threshold=25,\n",
    "                         vocab_from_file=True,\n",
    "                         download_dir=\"../../../data/train\", \n",
    "                              vocab_file=\"vocab4000.pkl\"\n",
    "#                          vocab_file='../../../data/vocab.pkl'\n",
    "                        )\n",
    "# data_loader_val.dataset.ids = val_split\n",
    "print(len(data_loader_val.dataset.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "499cbf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val total steps:  4127\n",
      "Validating the model...\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4.511882305145264\n",
      "current PPL:  91.09312228974268\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9.003695011138916\n",
      "current PPL:  89.2831433684935\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13.430891513824463\n",
      "current PPL:  83.69644493391372\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18.309616565704346\n",
      "current PPL:  131.46294855525025\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  23.108072757720947\n",
      "current PPL:  121.32297349212436\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  28.075716495513916\n",
      "current PPL:  143.6879217621651\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  32.51902770996094\n",
      "current PPL:  85.05611494103412\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  37.40497064590454\n",
      "current PPL:  132.4152655991353\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  41.732025146484375\n",
      "current PPL:  75.7209218389666\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  46.11614656448364\n",
      "current PPL:  80.16775831334436\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  50.53307056427002\n",
      "current PPL:  82.84107388333553\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  54.840962409973145\n",
      "current PPL:  74.28372220601673\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  59.69815254211426\n",
      "current PPL:  128.66217001822147\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  64.65020275115967\n",
      "current PPL:  141.46469901676235\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  68.97374105453491\n",
      "current PPL:  75.45513969032773\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  73.78350591659546\n",
      "current PPL:  122.70276205025691\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  78.48993444442749\n",
      "current PPL:  110.65624762308762\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  82.91772842407227\n",
      "current PPL:  83.7464665732315\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  87.70000171661377\n",
      "current PPL:  119.37541706601382\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  92.13644218444824\n",
      "current PPL:  84.47371896611551\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  96.7721619606018\n",
      "current PPL:  103.10210172839197\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  101.77610349655151\n",
      "current PPL:  148.999289272328\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  107.22321844100952\n",
      "current PPL:  232.08761342685614\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  112.0591287612915\n",
      "current PPL:  125.95318877739534\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  116.56355857849121\n",
      "current PPL:  90.4167752583373\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  121.61042404174805\n",
      "current PPL:  155.53417202383847\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  126.08961868286133\n",
      "current PPL:  88.16364070484919\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  130.73872995376587\n",
      "current PPL:  104.49207914792214\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  135.9420394897461\n",
      "current PPL:  181.87316271793637\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  141.24496841430664\n",
      "current PPL:  200.92444152205624\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  145.77923727035522\n",
      "current PPL:  93.15538040632384\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  150.45879411697388\n",
      "current PPL:  107.72232447997789\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  155.40592575073242\n",
      "current PPL:  140.7706026262112\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  159.87849855422974\n",
      "current PPL:  87.58176406499132\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  164.575110912323\n",
      "current PPL:  109.57534097474323\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  169.02272844314575\n",
      "current PPL:  85.42318327058638\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  173.5844964981079\n",
      "current PPL:  95.7526261618229\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  178.31536865234375\n",
      "current PPL:  113.39441665509901\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  182.95648670196533\n",
      "current PPL:  103.66018004306619\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  187.40874910354614\n",
      "current PPL:  85.82088584010782\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  191.9067964553833\n",
      "current PPL:  89.8415310130475\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  196.36588096618652\n",
      "current PPL:  86.40836694851374\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  201.31181812286377\n",
      "current PPL:  140.6025557517041\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  206.0501308441162\n",
      "current PPL:  114.24128208400592\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  210.91767692565918\n",
      "current PPL:  130.0015120501536\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  215.67624855041504\n",
      "current PPL:  116.57928794767572\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  220.28334951400757\n",
      "current PPL:  100.1932642755721\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  225.8667893409729\n",
      "current PPL:  265.98497626113436\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  230.52673482894897\n",
      "current PPL:  105.6303238769707\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  234.92836475372314\n",
      "current PPL:  81.58373570590851\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  239.59991073608398\n",
      "current PPL:  106.86282283300716\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  244.90943908691406\n",
      "current PPL:  202.25481257405835\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  249.20519304275513\n",
      "current PPL:  73.38752454450926\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  254.0783405303955\n",
      "current PPL:  130.73174657317534\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  258.44680309295654\n",
      "current PPL:  78.92220043128592\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  262.96250009536743\n",
      "current PPL:  91.44127860754037\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  267.72372579574585\n",
      "current PPL:  116.88910915650368\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  272.31485080718994\n",
      "current PPL:  98.60529987621297\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  276.5698676109314\n",
      "current PPL:  70.45800113651968\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  280.7984838485718\n",
      "current PPL:  68.62220961399032\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  285.581440448761\n",
      "current PPL:  119.45701507654043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  290.18032217025757\n",
      "current PPL:  99.37312665204004\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  294.9081082344055\n",
      "current PPL:  113.04501069628107\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  299.699266910553\n",
      "current PPL:  120.44083977491395\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  304.5135803222656\n",
      "current PPL:  123.26215289996941\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  309.31597566604614\n",
      "current PPL:  121.80182561355659\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  313.5433006286621\n",
      "current PPL:  68.53365665401282\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  318.7255277633667\n",
      "current PPL:  178.07897554029017\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  322.9888391494751\n",
      "current PPL:  71.04485130427499\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  327.67129707336426\n",
      "current PPL:  108.03528901470317\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  333.47131395339966\n",
      "current PPL:  330.30513542497\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  338.1425561904907\n",
      "current PPL:  106.83036868520325\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  343.06254482269287\n",
      "current PPL:  137.00105577730932\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  347.72253465652466\n",
      "current PPL:  105.63500824793772\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  352.9169020652771\n",
      "current PPL:  180.25407957004123\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  357.6192774772644\n",
      "current PPL:  110.20865272226862\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  362.17090797424316\n",
      "current PPL:  94.78683203026343\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  366.59344577789307\n",
      "current PPL:  83.3074352297517\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  371.87180614471436\n",
      "current PPL:  196.04816460475345\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  376.7550721168518\n",
      "current PPL:  132.06126875551237\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  381.64993047714233\n",
      "current PPL:  133.60108205589628\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  386.5020604133606\n",
      "current PPL:  128.0127586900599\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  391.05552911758423\n",
      "current PPL:  94.9612301124214\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  396.08058500289917\n",
      "current PPL:  152.17876043298824\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  401.303005695343\n",
      "current PPL:  185.3823951243608\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  405.69808292388916\n",
      "current PPL:  81.05088996342533\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  410.333523273468\n",
      "current PPL:  103.07329628595139\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  414.52702045440674\n",
      "current PPL:  66.25408881596731\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  418.88490438461304\n",
      "current PPL:  78.0917119492667\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  423.21572256088257\n",
      "current PPL:  76.00644780822242\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  427.7820191383362\n",
      "current PPL:  96.1872273910175\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  432.2614936828613\n",
      "current PPL:  88.18832146263794\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  436.81417179107666\n",
      "current PPL:  94.88618381251268\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  441.62947177886963\n",
      "current PPL:  123.38382039888306\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  446.59664726257324\n",
      "current PPL:  143.62065505539334\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  451.34844493865967\n",
      "current PPL:  115.79225450677131\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  455.7787103652954\n",
      "current PPL:  83.95369750069267\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  460.07557678222656\n",
      "current PPL:  73.46921073799446\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  464.833149433136\n",
      "current PPL:  116.46288643869173\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  469.73285150527954\n",
      "current PPL:  134.2497769779877\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  474.32844066619873\n",
      "current PPL:  99.04647267188543\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  478.9951853752136\n",
      "current PPL:  106.35097495412442\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  483.4268012046814\n",
      "current PPL:  84.06714539449545\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  487.70208406448364\n",
      "current PPL:  71.90047418747378\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  492.3502540588379\n",
      "current PPL:  104.39376947968007\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  497.1062259674072\n",
      "current PPL:  116.27660849659111\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  502.1484375\n",
      "current PPL:  154.81200852422353\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  506.87929105758667\n",
      "current PPL:  113.39230791852242\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  511.77059030532837\n",
      "current PPL:  133.1264259465219\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  516.6020216941833\n",
      "current PPL:  125.3903145603358\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  521.1377959251404\n",
      "current PPL:  93.29571978376057\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  525.5148148536682\n",
      "current PPL:  79.60038492085926\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  530.2442750930786\n",
      "current PPL:  113.23442637000777\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  535.0383582115173\n",
      "current PPL:  120.793577589643\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  540.2908520698547\n",
      "current PPL:  191.04210682617702\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  544.8181085586548\n",
      "current PPL:  92.50442570192584\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  549.1529726982117\n",
      "current PPL:  76.31459005140563\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  554.2885756492615\n",
      "current PPL:  169.96677062796664\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  558.9084048271179\n",
      "current PPL:  101.47669618214324\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  563.7627172470093\n",
      "current PPL:  128.29244954519191\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  568.8451180458069\n",
      "current PPL:  161.16050579733783\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  573.8201069831848\n",
      "current PPL:  144.74722385549046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  578.2440257072449\n",
      "current PPL:  83.42255563514297\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  582.7654714584351\n",
      "current PPL:  91.9684654267278\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  587.2325792312622\n",
      "current PPL:  87.1044325419558\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  592.3207511901855\n",
      "current PPL:  162.09327788183856\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  596.8967337608337\n",
      "current PPL:  97.12342289320668\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  601.2382760047913\n",
      "current PPL:  76.82593234932257\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  605.9460082054138\n",
      "current PPL:  110.80060123671001\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  611.2596211433411\n",
      "current PPL:  203.08262946600544\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  616.0766558647156\n",
      "current PPL:  123.59804421244776\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  620.7490200996399\n",
      "current PPL:  106.95029939581076\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  625.4255938529968\n",
      "current PPL:  107.40145756559548\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  630.2914710044861\n",
      "current PPL:  129.78472956738307\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  634.4131126403809\n",
      "current PPL:  61.66038312170156\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  639.2828812599182\n",
      "current PPL:  130.29076667063592\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  643.8334450721741\n",
      "current PPL:  94.68577827043724\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  648.1709871292114\n",
      "current PPL:  76.51922810573812\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  652.5346059799194\n",
      "current PPL:  78.54084835895844\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  656.8087630271912\n",
      "current PPL:  71.81957328085541\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  661.1295394897461\n",
      "current PPL:  75.2470321177061\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  665.6265168190002\n",
      "current PPL:  89.74544995958736\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  670.0571427345276\n",
      "current PPL:  83.98396733169166\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  674.4873847961426\n",
      "current PPL:  83.95173594372436\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  679.8984217643738\n",
      "current PPL:  223.863606809906\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  684.5965261459351\n",
      "current PPL:  109.73895198037192\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  689.6031556129456\n",
      "current PPL:  149.40032783053977\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  693.9845561981201\n",
      "current PPL:  79.94993171430221\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  698.3745536804199\n",
      "current PPL:  80.64021595233397\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  702.7276291847229\n",
      "current PPL:  77.71711507111432\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  707.4428100585938\n",
      "current PPL:  111.62900011717709\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  712.4567079544067\n",
      "current PPL:  150.49018946919045\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  717.0661792755127\n",
      "current PPL:  100.43103982754526\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  721.3284087181091\n",
      "current PPL:  70.96802635596943\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  726.0108141899109\n",
      "current PPL:  108.02962248689315\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  730.336021900177\n",
      "current PPL:  75.58121022270697\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  736.0069704055786\n",
      "current PPL:  290.309764222115\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  740.8723568916321\n",
      "current PPL:  129.72106430693952\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  745.2229256629944\n",
      "current PPL:  77.52254299071924\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  750.2180280685425\n",
      "current PPL:  147.68806868672553\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  754.7515163421631\n",
      "current PPL:  93.08269332612653\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  759.7673444747925\n",
      "current PPL:  150.78095170311906\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  764.7273788452148\n",
      "current PPL:  142.5986969902063\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  769.5626645088196\n",
      "current PPL:  125.87453584510227\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  774.3471541404724\n",
      "current PPL:  119.64028688403334\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  778.6039905548096\n",
      "current PPL:  70.58632397533212\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  783.3490724563599\n",
      "current PPL:  115.01722520641476\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  788.6662726402283\n",
      "current PPL:  203.81244503562218\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  793.5359597206116\n",
      "current PPL:  130.28014330485672\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  798.3753437995911\n",
      "current PPL:  126.39148058163458\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  802.5013070106506\n",
      "current PPL:  61.927429717406305\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  807.6767182350159\n",
      "current PPL:  176.86933230260107\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  812.4473176002502\n",
      "current PPL:  117.98993983957467\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  817.0104341506958\n",
      "current PPL:  95.88183524507834\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  821.2650356292725\n",
      "current PPL:  70.42874423157153\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  825.685366153717\n",
      "current PPL:  83.12375525139399\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  830.3013253211975\n",
      "current PPL:  101.08473924290358\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  835.329363822937\n",
      "current PPL:  152.63332886797835\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  839.8874454498291\n",
      "current PPL:  95.40029082141407\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  844.5960454940796\n",
      "current PPL:  110.89680056941529\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  849.1618204116821\n",
      "current PPL:  96.13706346169299\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  853.7230834960938\n",
      "current PPL:  95.70428611165266\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  858.6539716720581\n",
      "current PPL:  138.50247229373485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  862.9480080604553\n",
      "current PPL:  73.26158470760953\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  867.5019583702087\n",
      "current PPL:  95.00697498056529\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  872.4704251289368\n",
      "current PPL:  143.80622860771769\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  877.2444081306458\n",
      "current PPL:  118.38985109926682\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  881.6007614135742\n",
      "current PPL:  77.9722725160913\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  886.3144111633301\n",
      "current PPL:  111.45821304463334\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  890.6830611228943\n",
      "current PPL:  78.93699160099777\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  895.155601978302\n",
      "current PPL:  87.5789660396417\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  899.7289094924927\n",
      "current PPL:  96.86395944802717\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  903.8622364997864\n",
      "current PPL:  62.385133842838826\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  908.7309565544128\n",
      "current PPL:  130.15421994605532\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  913.7846069335938\n",
      "current PPL:  156.5930464291362\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  918.4199342727661\n",
      "current PPL:  103.0616485890073\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  923.100266456604\n",
      "current PPL:  107.80587799437917\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  928.411383152008\n",
      "current PPL:  202.5763181714139\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  932.9544591903687\n",
      "current PPL:  93.97944032124987\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  937.8422837257385\n",
      "current PPL:  132.66465263659143\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  942.5830664634705\n",
      "current PPL:  114.52380871246503\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  947.328106880188\n",
      "current PPL:  115.01245383503259\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  951.5303654670715\n",
      "current PPL:  66.83711813229954\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  956.7879548072815\n",
      "current PPL:  192.01804273868683\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  961.5549335479736\n",
      "current PPL:  117.56351499561299\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  965.9954581260681\n",
      "current PPL:  84.8194244175075\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  970.8842415809631\n",
      "current PPL:  132.7919283761445\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  975.7973523139954\n",
      "current PPL:  136.06200936460655\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  980.5684967041016\n",
      "current PPL:  118.05426481917708\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  985.2431530952454\n",
      "current PPL:  107.1957273619097\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  989.6599712371826\n",
      "current PPL:  82.83230496957272\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  994.4456806182861\n",
      "current PPL:  119.78630709417138\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  998.8937311172485\n",
      "current PPL:  85.46017679526076\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  1004.7889385223389\n",
      "current PPL:  363.29217673232574\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1009.2394766807556\n",
      "current PPL:  85.67303726444185\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1015.1173024177551\n",
      "current PPL:  357.03211545794943\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1019.5071949958801\n",
      "current PPL:  80.63175690072609\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1023.8852438926697\n",
      "current PPL:  79.6824130268697\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1028.233018875122\n",
      "current PPL:  77.30626362995966\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1032.6376271247864\n",
      "current PPL:  81.82708077705185\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1037.4421072006226\n",
      "current PPL:  122.05601464980653\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1042.134253025055\n",
      "current PPL:  109.08701041017449\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1047.2387623786926\n",
      "current PPL:  164.76321022661682\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1051.9057807922363\n",
      "current PPL:  106.3800876815735\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1056.9894533157349\n",
      "current PPL:  161.36558796976684\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  1061.8801412582397\n",
      "current PPL:  133.04506993439378\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1066.5612692832947\n",
      "current PPL:  107.89170850472514\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1071.4291214942932\n",
      "current PPL:  130.04131543444365\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1076.7391757965088\n",
      "current PPL:  202.36121675221494\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1081.2353806495667\n",
      "current PPL:  89.67615050530378\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1085.8243975639343\n",
      "current PPL:  98.39764928253072\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1090.5623211860657\n",
      "current PPL:  114.1968395483909\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1095.0977578163147\n",
      "current PPL:  93.2642283987635\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1099.378336429596\n",
      "current PPL:  72.28225138049834\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1103.9585800170898\n",
      "current PPL:  97.53815038719446\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1108.167977809906\n",
      "current PPL:  67.31598942905534\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1112.371651172638\n",
      "current PPL:  66.93174459464215\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1116.868703365326\n",
      "current PPL:  89.75216886363964\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1121.5729050636292\n",
      "current PPL:  110.41010917922284\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1126.7146739959717\n",
      "current PPL:  171.0180202180488\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  1131.8140335083008\n",
      "current PPL:  163.91688692623634\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  1136.5492725372314\n",
      "current PPL:  113.89067863203307\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1141.2516226768494\n",
      "current PPL:  110.20586752368206\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1145.8285012245178\n",
      "current PPL:  97.21048224401312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1150.5998539924622\n",
      "current PPL:  118.07886727487693\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  1155.295367717743\n",
      "current PPL:  109.45502401388987\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1160.1176915168762\n",
      "current PPL:  124.25349571812723\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1164.811912059784\n",
      "current PPL:  109.31357018870337\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1169.5113878250122\n",
      "current PPL:  109.88954942658735\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1174.1159362792969\n",
      "current PPL:  99.93784615316832\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1179.4457573890686\n",
      "current PPL:  206.40104772297502\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1184.3570284843445\n",
      "current PPL:  135.81193464894594\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1188.9669666290283\n",
      "current PPL:  100.47793434977056\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1193.191879749298\n",
      "current PPL:  68.36856344817647\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1198.7551617622375\n",
      "current PPL:  260.6769791208781\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1202.9667983055115\n",
      "current PPL:  67.46686195115394\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1208.64195394516\n",
      "current PPL:  291.533709218501\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1213.0167469978333\n",
      "current PPL:  79.42340139081114\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1217.9793682098389\n",
      "current PPL:  142.96805475834418\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  1222.864272594452\n",
      "current PPL:  132.27781693496075\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1227.4852714538574\n",
      "current PPL:  101.59546104632274\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  1232.457561969757\n",
      "current PPL:  144.35716135092468\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1237.298668384552\n",
      "current PPL:  126.60935672949219\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  1241.9915795326233\n",
      "current PPL:  109.17052923332834\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1246.6748623847961\n",
      "current PPL:  108.12444714972577\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1251.2039890289307\n",
      "current PPL:  92.67758521423895\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1256.9073672294617\n",
      "current PPL:  299.87874227477334\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1261.553207397461\n",
      "current PPL:  104.1508332337747\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1266.3215236663818\n",
      "current PPL:  117.72086472198427\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  1271.0247464179993\n",
      "current PPL:  110.30207645652959\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1275.5844407081604\n",
      "current PPL:  95.55426348593853\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1279.921429157257\n",
      "current PPL:  76.47687817715456\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  1284.4749236106873\n",
      "current PPL:  94.9636753202301\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  1289.2525453567505\n",
      "current PPL:  118.82142622113594\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1294.5469369888306\n",
      "current PPL:  199.21639223079632\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1299.3001952171326\n",
      "current PPL:  115.96149870554633\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1303.7491693496704\n",
      "current PPL:  85.53914714813243\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1308.4463992118835\n",
      "current PPL:  109.64302509469236\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1313.1701335906982\n",
      "current PPL:  112.58791451470628\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1318.3160529136658\n",
      "current PPL:  171.72928680194107\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1322.8694353103638\n",
      "current PPL:  94.95303459729158\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1327.6480641365051\n",
      "current PPL:  118.94114918752614\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1332.3039321899414\n",
      "current PPL:  105.20050003074522\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1337.0319237709045\n",
      "current PPL:  113.0682457343657\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1342.1071257591248\n",
      "current PPL:  160.00450774132003\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1346.9534845352173\n",
      "current PPL:  127.27610428139863\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1351.4780235290527\n",
      "current PPL:  92.25338664405449\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1356.3621878623962\n",
      "current PPL:  132.1799607823583\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  1360.959433555603\n",
      "current PPL:  99.21068232358343\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1365.7758593559265\n",
      "current PPL:  123.5228056709519\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1370.453215122223\n",
      "current PPL:  107.48547974406134\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1375.2454953193665\n",
      "current PPL:  120.57599247964033\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1379.9716839790344\n",
      "current PPL:  112.86457624152646\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1384.869257926941\n",
      "current PPL:  133.96438056100823\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1389.855393409729\n",
      "current PPL:  146.36968095652148\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1394.32363986969\n",
      "current PPL:  87.20367373019634\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1398.8877940177917\n",
      "current PPL:  95.98137364408001\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1403.3622007369995\n",
      "current PPL:  87.74252900767831\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1408.5763130187988\n",
      "current PPL:  183.84854282024148\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1413.0908222198486\n",
      "current PPL:  91.33272901279173\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1417.7043800354004\n",
      "current PPL:  100.8422904283302\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1422.2675251960754\n",
      "current PPL:  95.88457848563101\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1426.9420881271362\n",
      "current PPL:  107.18570930848372\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1431.298662662506\n",
      "current PPL:  77.98952598036264\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1436.006796836853\n",
      "current PPL:  110.84514911999047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1440.783761024475\n",
      "current PPL:  118.74331987189225\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1446.0284571647644\n",
      "current PPL:  189.55820737555734\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1450.254286289215\n",
      "current PPL:  68.43121802968606\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1454.3886995315552\n",
      "current PPL:  62.452935579236936\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1458.9653849601746\n",
      "current PPL:  97.19171086073648\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1464.5773968696594\n",
      "current PPL:  273.69433267271916\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1469.0492420196533\n",
      "current PPL:  87.51805806829066\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1473.8285493850708\n",
      "current PPL:  119.02188281616846\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  1479.0970187187195\n",
      "current PPL:  194.1186041097755\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1483.7505531311035\n",
      "current PPL:  104.95528605713818\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1488.3405203819275\n",
      "current PPL:  98.49120460333292\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1493.1235942840576\n",
      "current PPL:  119.47102843814636\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1497.6058659553528\n",
      "current PPL:  88.4353406883939\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1502.6281342506409\n",
      "current PPL:  151.7551391536507\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1507.2367720603943\n",
      "current PPL:  100.34736429280018\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1511.6316738128662\n",
      "current PPL:  81.03666871922316\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1516.200839996338\n",
      "current PPL:  96.46364325022438\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1520.590533733368\n",
      "current PPL:  80.61572558778927\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1525.5517468452454\n",
      "current PPL:  142.76688309027935\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1530.5472340583801\n",
      "current PPL:  147.74491111201363\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1535.4028658866882\n",
      "current PPL:  128.46183140027748\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1540.2561974525452\n",
      "current PPL:  128.16667507175293\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1545.3382625579834\n",
      "current PPL:  161.1064143653234\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1550.0529088974\n",
      "current PPL:  111.56934651538343\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1555.0564408302307\n",
      "current PPL:  148.93827119617896\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1559.850818157196\n",
      "current PPL:  120.82912131850742\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1565.773027896881\n",
      "current PPL:  373.2355567234001\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1570.7160749435425\n",
      "current PPL:  140.19678553978702\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1575.2088222503662\n",
      "current PPL:  89.3666264740108\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1579.5568556785583\n",
      "current PPL:  77.32624568647798\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1583.9192261695862\n",
      "current PPL:  78.4428623042654\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1588.3453669548035\n",
      "current PPL:  83.60813176004812\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1592.7078309059143\n",
      "current PPL:  78.45019392328925\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  1597.7257852554321\n",
      "current PPL:  151.10188577589975\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1602.1491527557373\n",
      "current PPL:  83.37658381232828\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1606.7080011367798\n",
      "current PPL:  95.47346744100314\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1610.9687938690186\n",
      "current PPL:  70.86613906622871\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1615.320149898529\n",
      "current PPL:  77.583597273945\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1620.0767126083374\n",
      "current PPL:  116.34532515790475\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1624.6148929595947\n",
      "current PPL:  93.52047078961017\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1628.9085984230042\n",
      "current PPL:  73.23734462962943\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1633.240083694458\n",
      "current PPL:  76.05716825933642\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1638.052369594574\n",
      "current PPL:  123.01249063762513\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1642.687192440033\n",
      "current PPL:  103.00966774830984\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1647.5563650131226\n",
      "current PPL:  130.21313046167853\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  1652.7612590789795\n",
      "current PPL:  182.1615746163256\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1657.458716392517\n",
      "current PPL:  109.66796638232519\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1662.3265557289124\n",
      "current PPL:  130.039641214876\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1667.0306825637817\n",
      "current PPL:  110.40184380871014\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1671.4869718551636\n",
      "current PPL:  86.16717385390197\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1676.2079224586487\n",
      "current PPL:  112.27493089602811\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1680.7089223861694\n",
      "current PPL:  90.1071869244932\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1685.3052353858948\n",
      "current PPL:  99.11819230601361\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1689.7472925186157\n",
      "current PPL:  84.94951447841285\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1694.6116242408752\n",
      "current PPL:  129.5843113587042\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1699.9351663589478\n",
      "current PPL:  205.1091175117541\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1704.4509296417236\n",
      "current PPL:  91.44733956972082\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1709.5928211212158\n",
      "current PPL:  171.03897927317672\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1714.6554522514343\n",
      "current PPL:  158.00570345920198\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1719.206536769867\n",
      "current PPL:  94.73509457857263\n",
      "reps  torch.Size([64, 23, 1024])\n",
      "embs  torch.Size([64, 24, 512])\n",
      "val running loss:  1724.2895107269287\n",
      "current PPL:  161.25290274960074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1728.9471926689148\n",
      "current PPL:  105.39149518277684\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1733.563060283661\n",
      "current PPL:  101.07548508225062\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1738.3905639648438\n",
      "current PPL:  124.89878398593056\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1742.8245573043823\n",
      "current PPL:  84.26725366474801\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  1748.0455737113953\n",
      "current PPL:  185.12224803087864\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1752.777011871338\n",
      "current PPL:  113.45861670912812\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1757.3450474739075\n",
      "current PPL:  96.35464492474156\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1761.8100442886353\n",
      "current PPL:  86.92075267305289\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1766.5472536087036\n",
      "current PPL:  114.11529763655973\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  1771.3449130058289\n",
      "current PPL:  121.22634246930664\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1775.824553489685\n",
      "current PPL:  88.20295658794616\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1781.1965837478638\n",
      "current PPL:  215.299537925443\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1785.7465715408325\n",
      "current PPL:  94.63125314120914\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1790.182559967041\n",
      "current PPL:  84.43554195829023\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1794.5277462005615\n",
      "current PPL:  77.10639593781666\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1799.1203799247742\n",
      "current PPL:  98.75417923103507\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1804.2632641792297\n",
      "current PPL:  171.20886680565198\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1808.7282428741455\n",
      "current PPL:  86.91917769962369\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  1813.3009266853333\n",
      "current PPL:  96.80356394203085\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1818.7164821624756\n",
      "current PPL:  224.87742526108738\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1823.2041969299316\n",
      "current PPL:  88.91801518192871\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1827.6875267028809\n",
      "current PPL:  88.52896379129814\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1832.2839493751526\n",
      "current PPL:  99.129063446679\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1836.622329235077\n",
      "current PPL:  76.58336299840097\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1841.6218028068542\n",
      "current PPL:  148.33505078802585\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  1846.2714614868164\n",
      "current PPL:  104.54929471722865\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1851.3331995010376\n",
      "current PPL:  157.8646490361326\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1855.8582825660706\n",
      "current PPL:  92.30359271119931\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1860.5036001205444\n",
      "current PPL:  104.09641682026142\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1865.0667572021484\n",
      "current PPL:  95.88572152569206\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1869.3862147331238\n",
      "current PPL:  75.14785185114613\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1874.045021057129\n",
      "current PPL:  105.51006212970061\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  1878.643578529358\n",
      "current PPL:  99.340910211867\n",
      "reps  torch.Size([64, 23, 1024])\n",
      "embs  torch.Size([64, 24, 512])\n",
      "val running loss:  1883.8142790794373\n",
      "current PPL:  176.0381178144036\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1889.000325679779\n",
      "current PPL:  178.76044265974346\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1893.6922693252563\n",
      "current PPL:  109.06495754178522\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1898.922133922577\n",
      "current PPL:  186.7675129863124\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1903.290202140808\n",
      "current PPL:  78.89108404473635\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1907.8455367088318\n",
      "current PPL:  95.13858023823319\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  1912.4145283699036\n",
      "current PPL:  96.44680965266367\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  1916.7457933425903\n",
      "current PPL:  76.04041480439103\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1921.3671174049377\n",
      "current PPL:  101.62850556193375\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1926.2961964607239\n",
      "current PPL:  138.2521311932215\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1930.8157958984375\n",
      "current PPL:  91.79881946759376\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1935.0688028335571\n",
      "current PPL:  70.31653202566511\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1939.9115676879883\n",
      "current PPL:  126.81950491588458\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1944.441921710968\n",
      "current PPL:  92.79140555780862\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  1949.2309222221375\n",
      "current PPL:  120.1811888581259\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1953.8656311035156\n",
      "current PPL:  102.99792901511998\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1958.4865942001343\n",
      "current PPL:  101.59182777447121\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  1963.2330484390259\n",
      "current PPL:  115.17517599555305\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  1968.2005047798157\n",
      "current PPL:  143.66099759906714\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  1972.9655146598816\n",
      "current PPL:  117.33227653270842\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  1978.7118515968323\n",
      "current PPL:  313.0418654261088\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1983.0011577606201\n",
      "current PPL:  72.91585928079911\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1987.5425128936768\n",
      "current PPL:  93.81784968490929\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  1992.3902716636658\n",
      "current PPL:  127.45441483828274\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  1996.7989206314087\n",
      "current PPL:  82.158389854172\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2001.2148146629333\n",
      "current PPL:  82.75579413172673\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2005.941020488739\n",
      "current PPL:  112.8665137070125\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2010.3029556274414\n",
      "current PPL:  78.40871945437092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2015.7864451408386\n",
      "current PPL:  240.6851176440946\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2020.6650862693787\n",
      "current PPL:  131.45191620848396\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2025.0534582138062\n",
      "current PPL:  80.50923871034637\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  2029.9702100753784\n",
      "current PPL:  136.5583316684261\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2034.5885224342346\n",
      "current PPL:  101.32289107803308\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2039.1638913154602\n",
      "current PPL:  97.06383756120375\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2043.6917152404785\n",
      "current PPL:  92.55693095870195\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2048.4454293251038\n",
      "current PPL:  116.01437253850382\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2053.143798351288\n",
      "current PPL:  109.76799764714578\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2057.9763445854187\n",
      "current PPL:  125.53018331168603\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  2062.7932319641113\n",
      "current PPL:  123.57983428672038\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2067.4431233406067\n",
      "current PPL:  104.57362580642844\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2071.6469683647156\n",
      "current PPL:  66.94323517629746\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2076.825734615326\n",
      "current PPL:  177.46373010699455\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2082.4127340316772\n",
      "current PPL:  266.93346066547986\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2087.023748397827\n",
      "current PPL:  100.58612906988068\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2091.6055722236633\n",
      "current PPL:  97.69240576029948\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  2097.280616760254\n",
      "current PPL:  291.50132073120045\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2102.966932296753\n",
      "current PPL:  294.8054173487715\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2108.1065325737\n",
      "current PPL:  170.6475429297572\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2113.158568382263\n",
      "current PPL:  156.34041989400953\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2117.649393081665\n",
      "current PPL:  89.19497459714493\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2122.396224975586\n",
      "current PPL:  115.21868069438501\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2127.3681511878967\n",
      "current PPL:  144.30458109713496\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2132.088342666626\n",
      "current PPL:  112.18973255869749\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2136.877600669861\n",
      "current PPL:  120.21213854514919\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2142.2072744369507\n",
      "current PPL:  206.3706382794192\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2146.6898155212402\n",
      "current PPL:  88.45916952809358\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2151.6233701705933\n",
      "current PPL:  138.87227827015641\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2156.2389798164368\n",
      "current PPL:  101.04941411317964\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2161.127594947815\n",
      "current PPL:  132.76957825282997\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2165.774887561798\n",
      "current PPL:  104.30221660469492\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2171.0685238838196\n",
      "current PPL:  199.06597889741028\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2175.4477252960205\n",
      "current PPL:  79.77430117698223\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2179.817840576172\n",
      "current PPL:  79.05274438663727\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2184.6143651008606\n",
      "current PPL:  121.08884407098627\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2189.1530389785767\n",
      "current PPL:  93.56663700756667\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2193.626458644867\n",
      "current PPL:  87.65596521698332\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2197.9382734298706\n",
      "current PPL:  74.57570508034065\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2202.554952144623\n",
      "current PPL:  101.15750066574151\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2207.1115226745605\n",
      "current PPL:  95.25624059684847\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2212.1352109909058\n",
      "current PPL:  151.9707877232941\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2216.4969301223755\n",
      "current PPL:  78.3917844329741\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2221.434280872345\n",
      "current PPL:  139.40045327977936\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2226.731602191925\n",
      "current PPL:  199.80088978443314\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2231.1632556915283\n",
      "current PPL:  84.07031227490144\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2235.744104862213\n",
      "current PPL:  97.5972357402848\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2240.2617325782776\n",
      "current PPL:  91.61799607316404\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2245.223526954651\n",
      "current PPL:  142.84989253348672\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2249.874846458435\n",
      "current PPL:  104.72307694735858\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2254.4775795936584\n",
      "current PPL:  99.75659164326193\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2259.076331615448\n",
      "current PPL:  99.36023882241842\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2264.047231197357\n",
      "current PPL:  144.15650964742002\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2268.541049003601\n",
      "current PPL:  89.46234461980238\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2272.840416908264\n",
      "current PPL:  73.65322312373925\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2277.405358314514\n",
      "current PPL:  96.05696551380962\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2281.892467021942\n",
      "current PPL:  88.8641418540354\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2286.262086391449\n",
      "current PPL:  79.01355100822653\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2290.7148423194885\n",
      "current PPL:  85.86325117132849\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2295.700786113739\n",
      "current PPL:  146.3416262553985\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2299.584264755249\n",
      "current PPL:  48.592958885436836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2304.2699341773987\n",
      "current PPL:  108.38280187724389\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2308.7408809661865\n",
      "current PPL:  87.43947054536916\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2313.4697103500366\n",
      "current PPL:  113.16301433022412\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2318.019160270691\n",
      "current PPL:  94.58036729633287\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2322.9490208625793\n",
      "current PPL:  138.36022245807928\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  2327.9967107772827\n",
      "current PPL:  155.66245527133694\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2332.979455947876\n",
      "current PPL:  145.87428229480233\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2337.184305667877\n",
      "current PPL:  67.01052656773052\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2341.595491886139\n",
      "current PPL:  82.3671109483328\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2346.328851222992\n",
      "current PPL:  113.6768003013673\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2350.8855018615723\n",
      "current PPL:  95.26387175063638\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2355.1800179481506\n",
      "current PPL:  73.29673658701434\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2360.485766887665\n",
      "current PPL:  201.49185112745457\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2365.599425792694\n",
      "current PPL:  166.27763728521373\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2369.9112968444824\n",
      "current PPL:  74.5799013335336\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2374.9347171783447\n",
      "current PPL:  151.93006767064432\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2380.146008014679\n",
      "current PPL:  183.33055526328238\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2384.574387073517\n",
      "current PPL:  83.79547922506366\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2389.1800832748413\n",
      "current PPL:  100.05261537066991\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2393.9093112945557\n",
      "current PPL:  113.2081341588371\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2398.5304684638977\n",
      "current PPL:  101.61154589047378\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2403.0309619903564\n",
      "current PPL:  90.06156810102496\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2408.1482701301575\n",
      "current PPL:  166.88553192147128\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2413.1592106819153\n",
      "current PPL:  150.04579563861267\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2417.873342037201\n",
      "current PPL:  111.51190486447649\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  2423.6736917495728\n",
      "current PPL:  330.41508995212297\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2428.5660696029663\n",
      "current PPL:  133.27009432879515\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2432.9072136878967\n",
      "current PPL:  76.7953494996652\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2437.0786089897156\n",
      "current PPL:  64.80581272094025\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2442.2618441581726\n",
      "current PPL:  178.25857566452044\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2446.4732666015625\n",
      "current PPL:  67.45241885002243\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2451.170253276825\n",
      "current PPL:  109.61636458363144\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2455.742663860321\n",
      "current PPL:  96.77711814073858\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2460.734137058258\n",
      "current PPL:  147.15304945894277\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2465.1631202697754\n",
      "current PPL:  83.84611978413712\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2470.0088181495667\n",
      "current PPL:  127.19201576479456\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2474.4984254837036\n",
      "current PPL:  89.0864577989594\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2479.32652425766\n",
      "current PPL:  124.97313246962028\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2484.351023197174\n",
      "current PPL:  152.09402870907613\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2489.3535389900208\n",
      "current PPL:  148.7870059300074\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2494.0937094688416\n",
      "current PPL:  114.45371195091711\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2499.3089938163757\n",
      "current PPL:  184.06415172690893\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2503.5594091415405\n",
      "current PPL:  70.13453493587721\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2508.55589056015\n",
      "current PPL:  147.89187295455184\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2512.8084383010864\n",
      "current PPL:  70.28425049547829\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2517.20996427536\n",
      "current PPL:  81.57525547651986\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2522.0910081863403\n",
      "current PPL:  131.76814632842547\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2526.6536173820496\n",
      "current PPL:  95.83320148016763\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2531.88751077652\n",
      "current PPL:  187.5214791788894\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2536.4709486961365\n",
      "current PPL:  97.85021779228836\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2541.072488307953\n",
      "current PPL:  99.63760083941489\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2545.9185547828674\n",
      "current PPL:  127.23890676289274\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2551.2272901535034\n",
      "current PPL:  202.0944920874137\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2555.542640209198\n",
      "current PPL:  74.83981696318948\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2559.6606826782227\n",
      "current PPL:  61.43885600923172\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2564.466812610626\n",
      "current PPL:  122.25755577842573\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2569.8059644699097\n",
      "current PPL:  208.33593714442884\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2574.3760800361633\n",
      "current PPL:  96.55526765864936\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2579.2114243507385\n",
      "current PPL:  125.88191872529009\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2584.0230536460876\n",
      "current PPL:  122.93174656126455\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2589.619550704956\n",
      "current PPL:  269.4807768515825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  2593.9648303985596\n",
      "current PPL:  77.11360264474591\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  2599.331521511078\n",
      "current PPL:  214.15308559328093\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2603.6705751419067\n",
      "current PPL:  76.63498002723459\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2608.4421153068542\n",
      "current PPL:  118.1009969741973\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2612.7549896240234\n",
      "current PPL:  74.6547623130848\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2617.711263656616\n",
      "current PPL:  142.06348463576012\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2622.3577489852905\n",
      "current PPL:  104.21804893578309\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2627.016688346863\n",
      "current PPL:  105.5240998654274\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2632.525520324707\n",
      "current PPL:  246.86261760091244\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2637.191189289093\n",
      "current PPL:  106.23662997806241\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2642.295238494873\n",
      "current PPL:  164.68741222888943\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2647.4873361587524\n",
      "current PPL:  179.8454127572384\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2652.4387350082397\n",
      "current PPL:  141.3725846359712\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2657.0164346694946\n",
      "current PPL:  97.29033587168936\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2662.299307823181\n",
      "current PPL:  196.93488747774202\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2666.832588672638\n",
      "current PPL:  93.06338772859033\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2671.372938156128\n",
      "current PPL:  93.72354922958303\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2675.851101875305\n",
      "current PPL:  88.07279770775071\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2680.832453250885\n",
      "current PPL:  145.67110507414307\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2685.7336659431458\n",
      "current PPL:  134.452730646171\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2690.1195249557495\n",
      "current PPL:  80.30717847042169\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2694.581123352051\n",
      "current PPL:  86.6258609520663\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2699.552921295166\n",
      "current PPL:  144.2860724516724\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2703.941578388214\n",
      "current PPL:  80.5321990821142\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2708.674509048462\n",
      "current PPL:  113.62808015985982\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  2713.616373538971\n",
      "current PPL:  140.03109295820823\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2718.1748218536377\n",
      "current PPL:  95.43527935629908\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2723.2612414360046\n",
      "current PPL:  161.8094781563467\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2727.424855709076\n",
      "current PPL:  64.30351356551505\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  2732.4793033599854\n",
      "current PPL:  156.71794341974027\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2736.8016233444214\n",
      "current PPL:  75.36326724091876\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2741.3797454833984\n",
      "current PPL:  97.33144755495104\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2745.711287021637\n",
      "current PPL:  76.06144787204421\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2750.362711429596\n",
      "current PPL:  104.73406341158166\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2755.083327293396\n",
      "current PPL:  112.23735431055806\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2759.809558868408\n",
      "current PPL:  112.86941996760252\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2764.862494468689\n",
      "current PPL:  156.48115701649843\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2769.365170955658\n",
      "current PPL:  90.25838368985278\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2774.3376970291138\n",
      "current PPL:  144.39116977637912\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2778.701998233795\n",
      "current PPL:  78.59445930765129\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2783.7699704170227\n",
      "current PPL:  158.85187801713482\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2788.3797721862793\n",
      "current PPL:  100.46423256285956\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2793.136034011841\n",
      "current PPL:  116.31032394829323\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2797.870086669922\n",
      "current PPL:  113.75564216836224\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2803.342315196991\n",
      "current PPL:  237.9899693200139\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2807.800708770752\n",
      "current PPL:  86.34868482769821\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2812.411986351013\n",
      "current PPL:  100.6126082431489\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2816.8946747779846\n",
      "current PPL:  88.47220429963467\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2822.457311153412\n",
      "current PPL:  260.5087306042102\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2827.3619027137756\n",
      "current PPL:  134.9077970608648\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  2832.4224367141724\n",
      "current PPL:  157.6746921945783\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2837.2356820106506\n",
      "current PPL:  123.13056500466331\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2841.8415479660034\n",
      "current PPL:  100.06960114683424\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2846.6036682128906\n",
      "current PPL:  116.99371868308266\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2851.8070678710938\n",
      "current PPL:  181.88955427025692\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2856.2815289497375\n",
      "current PPL:  87.74729877171114\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2860.659236907959\n",
      "current PPL:  79.65525084964835\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2865.27854013443\n",
      "current PPL:  101.42333840621858\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2870.6620016098022\n",
      "current PPL:  217.77479434805616\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2875.1639351844788\n",
      "current PPL:  90.19135452858697\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2880.1201038360596\n",
      "current PPL:  142.04851463077722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  2885.1763129234314\n",
      "current PPL:  156.9942353835255\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2889.498956680298\n",
      "current PPL:  75.38767173965648\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  2896.346372127533\n",
      "current PPL:  941.4445464714795\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2900.7816371917725\n",
      "current PPL:  84.37448658363648\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  2904.994801044464\n",
      "current PPL:  67.56998345397174\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2909.448217868805\n",
      "current PPL:  85.92001663241804\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2914.035090446472\n",
      "current PPL:  98.1868776553688\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2918.9447565078735\n",
      "current PPL:  135.5941267345703\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2923.804578781128\n",
      "current PPL:  129.0012730934432\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2928.8349380493164\n",
      "current PPL:  152.98796653303586\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2933.853919506073\n",
      "current PPL:  151.25716334627936\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2938.463261127472\n",
      "current PPL:  100.41801479579244\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2944.089343070984\n",
      "current PPL:  277.572439818678\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  2948.4623732566833\n",
      "current PPL:  79.28351183910954\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  2952.9618577957153\n",
      "current PPL:  89.9707429396053\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2957.6200637817383\n",
      "current PPL:  105.44673944131154\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  2963.244197845459\n",
      "current PPL:  277.0322883184288\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2967.63525724411\n",
      "current PPL:  80.72589459995463\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2972.722990989685\n",
      "current PPL:  162.02226200497572\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  2977.3852372169495\n",
      "current PPL:  105.87363149952961\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  2982.420855998993\n",
      "current PPL:  153.79472859101963\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  2987.275363922119\n",
      "current PPL:  128.3175335860122\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2991.557767868042\n",
      "current PPL:  72.41431102307294\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  2996.2389068603516\n",
      "current PPL:  107.89289178705438\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3000.83340549469\n",
      "current PPL:  98.93851873471887\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3005.996519088745\n",
      "current PPL:  174.70757811143568\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3010.6403017044067\n",
      "current PPL:  103.93675775466238\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3015.276096343994\n",
      "current PPL:  103.10982059469008\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3019.9898676872253\n",
      "current PPL:  111.47176646009957\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3024.9290070533752\n",
      "current PPL:  139.65001030040514\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3029.346911907196\n",
      "current PPL:  82.92236874755012\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3034.1774344444275\n",
      "current PPL:  125.27640514059347\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3038.963536262512\n",
      "current PPL:  119.83332489607535\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3043.610556125641\n",
      "current PPL:  104.27377196531675\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3048.294969558716\n",
      "current PPL:  108.24675971381939\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  3053.9220762252808\n",
      "current PPL:  277.85702047991157\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3058.5442070961\n",
      "current PPL:  101.7105333871078\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3062.8408308029175\n",
      "current PPL:  73.45138118131001\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3067.6932730674744\n",
      "current PPL:  128.05274694671195\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3072.322057723999\n",
      "current PPL:  102.38954999058386\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3077.144007205963\n",
      "current PPL:  124.20699420504845\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3081.8078083992004\n",
      "current PPL:  106.03838945725016\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3086.362340927124\n",
      "current PPL:  95.0623058734541\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3091.315073490143\n",
      "current PPL:  141.56126095719588\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3096.055140018463\n",
      "current PPL:  114.44181504863226\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3100.565197944641\n",
      "current PPL:  90.92708541651511\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3104.922239303589\n",
      "current PPL:  78.02594182914511\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3109.448188304901\n",
      "current PPL:  92.38355635755188\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3114.53373670578\n",
      "current PPL:  161.66857411979376\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  3119.648901939392\n",
      "current PPL:  166.52829478181096\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3124.1155123710632\n",
      "current PPL:  87.06112269355991\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  3129.5527262687683\n",
      "current PPL:  229.8010415226994\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3134.1692543029785\n",
      "current PPL:  101.14225934702853\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3138.470866203308\n",
      "current PPL:  73.81868621705249\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3142.670082092285\n",
      "current PPL:  66.63406204870044\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3147.0623412132263\n",
      "current PPL:  80.82280137407459\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  3152.5459294319153\n",
      "current PPL:  240.70887571135526\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3157.334023475647\n",
      "current PPL:  120.0722978843138\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3161.9404611587524\n",
      "current PPL:  100.12683007313389\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3166.6916584968567\n",
      "current PPL:  115.72276088026783\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  3172.2026653289795\n",
      "current PPL:  247.40009207349345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3176.7148175239563\n",
      "current PPL:  91.11771071510593\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3181.1544971466064\n",
      "current PPL:  84.74778605293575\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3186.4695019721985\n",
      "current PPL:  203.3654944853915\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3191.0835938453674\n",
      "current PPL:  100.89616040522344\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3195.451591491699\n",
      "current PPL:  78.88551674753816\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3200.5119228363037\n",
      "current PPL:  157.64274174249744\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3205.5683732032776\n",
      "current PPL:  157.03211946030683\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3210.0438919067383\n",
      "current PPL:  87.84015158557249\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3214.9874353408813\n",
      "current PPL:  140.2663947442416\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3219.500515460968\n",
      "current PPL:  91.2023003671932\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3223.823932170868\n",
      "current PPL:  75.44596539543889\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  3228.616132259369\n",
      "current PPL:  120.56633368743681\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3233.2556018829346\n",
      "current PPL:  103.48944466230994\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3237.759388446808\n",
      "current PPL:  90.35863306897173\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3242.037410259247\n",
      "current PPL:  72.09767612092689\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3246.5553102493286\n",
      "current PPL:  91.6429446692881\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3251.0868101119995\n",
      "current PPL:  92.8977905717414\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3255.646201133728\n",
      "current PPL:  95.52528928792314\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3260.5014300346375\n",
      "current PPL:  128.4100810352416\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3265.241653442383\n",
      "current PPL:  114.45977002312485\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3269.9748272895813\n",
      "current PPL:  113.65571638643456\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3274.593647003174\n",
      "current PPL:  101.37431076962903\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3279.385573387146\n",
      "current PPL:  120.53333865153607\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3284.325681209564\n",
      "current PPL:  139.7853207387956\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  3289.2766308784485\n",
      "current PPL:  141.30909707291127\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3293.6721572875977\n",
      "current PPL:  81.08730462882342\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3297.8861780166626\n",
      "current PPL:  67.62790738961891\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3302.3789439201355\n",
      "current PPL:  89.36828840926401\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3306.942723751068\n",
      "current PPL:  95.9454528912993\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3311.451825618744\n",
      "current PPL:  90.84019534603644\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3316.350353240967\n",
      "current PPL:  134.09219988938025\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3320.836863040924\n",
      "current PPL:  88.81093638976677\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3325.2838411331177\n",
      "current PPL:  85.36857784764716\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3329.66597366333\n",
      "current PPL:  80.0084720916521\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3333.7139840126038\n",
      "current PPL:  57.28336968798028\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3338.4998965263367\n",
      "current PPL:  119.81064207322734\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3342.703158378601\n",
      "current PPL:  66.90420714749395\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3347.538327217102\n",
      "current PPL:  125.85983139833245\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3352.2860889434814\n",
      "current PPL:  115.3258645873286\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  3357.253782272339\n",
      "current PPL:  143.69504757584124\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3361.6823225021362\n",
      "current PPL:  83.80898571124726\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3365.946005821228\n",
      "current PPL:  71.07128014234931\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3370.5487756729126\n",
      "current PPL:  99.76025441952828\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3375.0544214248657\n",
      "current PPL:  90.52678302524549\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3380.1513628959656\n",
      "current PPL:  163.52100795420625\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3384.694013118744\n",
      "current PPL:  93.9394309300632\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3389.0987915992737\n",
      "current PPL:  81.84101145751437\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3393.714838027954\n",
      "current PPL:  101.09356040341359\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3398.204915046692\n",
      "current PPL:  89.12831016426642\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3402.7438912391663\n",
      "current PPL:  93.5949278589741\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3407.671253681183\n",
      "current PPL:  138.0150092627621\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3412.3364820480347\n",
      "current PPL:  106.18983269099621\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3416.7834367752075\n",
      "current PPL:  85.36658323235639\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3421.202540397644\n",
      "current PPL:  83.02183308619861\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3426.483850479126\n",
      "current PPL:  196.6273044788534\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3430.697766304016\n",
      "current PPL:  67.62081331190612\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3435.4203782081604\n",
      "current PPL:  112.46160833347541\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3440.2912306785583\n",
      "current PPL:  130.4320589862868\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3444.775137901306\n",
      "current PPL:  88.58009958636462\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3449.3990030288696\n",
      "current PPL:  101.8870786087312\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3453.6823358535767\n",
      "current PPL:  72.48160639003396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3458.1012663841248\n",
      "current PPL:  83.00746392395757\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3462.3460569381714\n",
      "current PPL:  69.74115161211917\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3467.166058063507\n",
      "current PPL:  123.9652302822438\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3471.9666047096252\n",
      "current PPL:  121.57685887508825\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3476.5958733558655\n",
      "current PPL:  102.43911747387025\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3481.657298564911\n",
      "current PPL:  157.81527587933329\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3486.2113704681396\n",
      "current PPL:  95.01852791120115\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3490.7942571640015\n",
      "current PPL:  97.79629529086799\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3495.1767234802246\n",
      "current PPL:  80.03518225786907\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3499.9863843917847\n",
      "current PPL:  122.69000769965254\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3504.7061610221863\n",
      "current PPL:  112.14320048831064\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3509.088276386261\n",
      "current PPL:  80.00709866699161\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3514.170883655548\n",
      "current PPL:  161.1937841212359\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3518.589988708496\n",
      "current PPL:  83.02195184996843\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  3524.0651688575745\n",
      "current PPL:  238.6934634651062\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3528.6507320404053\n",
      "current PPL:  98.05839639946554\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3533.3880548477173\n",
      "current PPL:  114.12824900204056\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  3537.997040748596\n",
      "current PPL:  100.3823003998983\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3542.640007019043\n",
      "current PPL:  103.8519441031424\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3547.6554827690125\n",
      "current PPL:  150.72782847069652\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3552.3017592430115\n",
      "current PPL:  104.1962847818647\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3556.9998722076416\n",
      "current PPL:  109.73989388139422\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3561.5290064811707\n",
      "current PPL:  92.67829229079803\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3566.0808444023132\n",
      "current PPL:  94.80649514887077\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3570.797965526581\n",
      "current PPL:  111.84579858258233\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3575.542248249054\n",
      "current PPL:  114.92534256675007\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3580.068675994873\n",
      "current PPL:  92.4277950663545\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3584.9353642463684\n",
      "current PPL:  129.8900406654699\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3589.2767429351807\n",
      "current PPL:  76.81336810029896\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3593.6840085983276\n",
      "current PPL:  82.04481834599594\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3597.9590454101562\n",
      "current PPL:  71.88278539773138\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3602.2610869407654\n",
      "current PPL:  73.85040777362994\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3607.333700656891\n",
      "current PPL:  159.59090802410321\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  3611.959928035736\n",
      "current PPL:  102.12804599146715\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3616.3709211349487\n",
      "current PPL:  82.3512058260321\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3620.9257287979126\n",
      "current PPL:  95.08846444321456\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3625.628131389618\n",
      "current PPL:  110.21164820308068\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3630.351972103119\n",
      "current PPL:  112.59988715181707\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3634.65500831604\n",
      "current PPL:  73.92390201362794\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3639.1890959739685\n",
      "current PPL:  93.13850235569711\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3643.9574785232544\n",
      "current PPL:  117.72866756244971\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3648.569616794586\n",
      "current PPL:  100.6992418937058\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3653.3064646720886\n",
      "current PPL:  114.0740589637263\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3657.689030647278\n",
      "current PPL:  80.04315887884597\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3662.8772621154785\n",
      "current PPL:  179.15143758593538\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3667.493127346039\n",
      "current PPL:  101.07524409980255\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  3673.172342777252\n",
      "current PPL:  292.7196810824443\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3677.826256752014\n",
      "current PPL:  104.99513069637496\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3682.4709157943726\n",
      "current PPL:  104.0278906337457\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3687.7270555496216\n",
      "current PPL:  191.73989791768432\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3692.1486554145813\n",
      "current PPL:  83.22933459559846\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3696.7387280464172\n",
      "current PPL:  98.50158425304285\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3701.6374320983887\n",
      "current PPL:  134.11585982958454\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3706.0756363868713\n",
      "current PPL:  84.62284693469053\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3711.0612211227417\n",
      "current PPL:  146.28909050039607\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  3716.221381664276\n",
      "current PPL:  174.19241847859698\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3720.698145389557\n",
      "current PPL:  87.94958259883873\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3725.749053478241\n",
      "current PPL:  156.16421107035148\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3730.4130940437317\n",
      "current PPL:  106.06377514367664\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3734.9815373420715\n",
      "current PPL:  96.39393631484518\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  3740.225200653076\n",
      "current PPL:  189.36252717734519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3744.7461981773376\n",
      "current PPL:  91.92725192112285\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  3749.6268367767334\n",
      "current PPL:  131.7147499940615\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3754.358551979065\n",
      "current PPL:  113.49005390986184\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3758.7651629447937\n",
      "current PPL:  81.99112139479273\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3763.1085023880005\n",
      "current PPL:  76.96412800263045\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  3767.861129283905\n",
      "current PPL:  115.88831155969444\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3772.148129940033\n",
      "current PPL:  72.74794484708194\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3777.1277551651\n",
      "current PPL:  145.41987171710963\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3781.6218609809875\n",
      "current PPL:  89.48811434857497\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  3786.695077419281\n",
      "current PPL:  159.68712599561502\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3791.317744731903\n",
      "current PPL:  101.76510980624744\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3796.403253555298\n",
      "current PPL:  161.66217581098238\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3801.2048683166504\n",
      "current PPL:  121.70678634660351\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3805.419611930847\n",
      "current PPL:  67.67681227254475\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3809.9065732955933\n",
      "current PPL:  88.85104933761816\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3814.6292452812195\n",
      "current PPL:  112.46836539654987\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  3819.2732315063477\n",
      "current PPL:  103.95792241705372\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3823.9694409370422\n",
      "current PPL:  109.53119896125516\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3828.7838950157166\n",
      "current PPL:  123.27949303207\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3833.971679210663\n",
      "current PPL:  179.07132585666935\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3839.0622506141663\n",
      "current PPL:  162.4826787049406\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3843.4508333206177\n",
      "current PPL:  80.52620878870289\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  3848.006838798523\n",
      "current PPL:  95.20243106851709\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3852.6695256233215\n",
      "current PPL:  105.92028943843458\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3857.4606142044067\n",
      "current PPL:  120.43239776262692\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3861.759847640991\n",
      "current PPL:  73.64331978219872\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3866.3956327438354\n",
      "current PPL:  103.10883726750224\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  3871.1572194099426\n",
      "current PPL:  116.9313097349975\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3875.6764307022095\n",
      "current PPL:  91.7631950879655\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3880.338109970093\n",
      "current PPL:  105.81362246388977\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3884.6296014785767\n",
      "current PPL:  73.07537980731864\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3888.9548239707947\n",
      "current PPL:  75.58232746877887\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3893.517201423645\n",
      "current PPL:  95.81099539323075\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3898.2985224723816\n",
      "current PPL:  119.26179667039612\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3902.940330505371\n",
      "current PPL:  103.73172852400386\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3907.545213699341\n",
      "current PPL:  99.97130491599052\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3911.8867721557617\n",
      "current PPL:  76.827177897034\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3916.625678539276\n",
      "current PPL:  114.30912295722811\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3921.7166147232056\n",
      "current PPL:  162.54196001737418\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3926.507040977478\n",
      "current PPL:  120.3526585660846\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3931.229259967804\n",
      "current PPL:  112.41742929337231\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  3935.992630004883\n",
      "current PPL:  117.14002769391656\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  3940.9132957458496\n",
      "current PPL:  137.09385180589896\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3945.757336139679\n",
      "current PPL:  126.9813714024582\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3950.273575782776\n",
      "current PPL:  91.49091183098119\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3955.267270565033\n",
      "current PPL:  147.48032576762458\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3960.0255651474\n",
      "current PPL:  116.54699501670649\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3964.2639117240906\n",
      "current PPL:  69.29318610029995\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3968.8013730049133\n",
      "current PPL:  93.45324715619847\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  3973.431658267975\n",
      "current PPL:  102.54331175770919\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  3978.090353012085\n",
      "current PPL:  105.49828998482424\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3982.4225244522095\n",
      "current PPL:  76.10937421437171\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  3987.8941645622253\n",
      "current PPL:  237.8499731556746\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  3992.1061568260193\n",
      "current PPL:  67.49086556740761\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  3996.834424495697\n",
      "current PPL:  113.09946691070145\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4002.3770236968994\n",
      "current PPL:  255.34081984958954\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4006.7838501930237\n",
      "current PPL:  82.00879487813309\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4011.349645614624\n",
      "current PPL:  96.1390346760398\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4016.767505645752\n",
      "current PPL:  225.3962650452611\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4021.917980670929\n",
      "current PPL:  172.51341907363326\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4026.767477989197\n",
      "current PPL:  127.67619322217885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 23, 1024])\n",
      "embs  torch.Size([64, 24, 512])\n",
      "val running loss:  4031.740933895111\n",
      "current PPL:  144.52549181157377\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4036.011944293976\n",
      "current PPL:  71.59393751938147\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4040.481168270111\n",
      "current PPL:  87.2889584085126\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  4045.0572023391724\n",
      "current PPL:  97.12842472415123\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4049.404504299164\n",
      "current PPL:  77.26970467817588\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4054.167856693268\n",
      "current PPL:  117.13796101358487\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  4059.685933113098\n",
      "current PPL:  249.15530573138255\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4065.20250415802\n",
      "current PPL:  248.78051575631784\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4070.134389400482\n",
      "current PPL:  138.64063733714346\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4074.5524139404297\n",
      "current PPL:  82.93229399862864\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4078.8223719596863\n",
      "current PPL:  71.51863315080953\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4083.6075954437256\n",
      "current PPL:  119.7281174174633\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4089.0228838920593\n",
      "current PPL:  224.8173845267999\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4093.9446988105774\n",
      "current PPL:  137.2514875411876\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4098.654779434204\n",
      "current PPL:  111.06111369452326\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4103.7782254219055\n",
      "current PPL:  167.91299992869318\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4108.845223903656\n",
      "current PPL:  158.69727898774343\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4113.617168903351\n",
      "current PPL:  118.1488180406265\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4118.276211738586\n",
      "current PPL:  105.53501939554224\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4122.618580341339\n",
      "current PPL:  76.88944437246153\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4127.485650062561\n",
      "current PPL:  129.9395992357119\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4132.393345832825\n",
      "current PPL:  135.32722984696997\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4137.1327266693115\n",
      "current PPL:  114.36337012823715\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4141.567140579224\n",
      "current PPL:  84.30270142871574\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4145.93443107605\n",
      "current PPL:  78.82975261248399\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4150.7127413749695\n",
      "current PPL:  118.90326922695161\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4155.211545944214\n",
      "current PPL:  89.90958634731255\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4160.070559978485\n",
      "current PPL:  128.8970513593603\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  4165.279931545258\n",
      "current PPL:  182.97903195072644\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4169.718646526337\n",
      "current PPL:  84.6660742331005\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4174.348448753357\n",
      "current PPL:  102.49379160331262\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4178.856634616852\n",
      "current PPL:  90.75702344602456\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4183.362825393677\n",
      "current PPL:  90.57613582158973\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  4188.200918197632\n",
      "current PPL:  126.22837974614121\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4192.710455417633\n",
      "current PPL:  90.87975144611902\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4197.380969047546\n",
      "current PPL:  106.75255966132805\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4201.960988998413\n",
      "current PPL:  97.51633972314139\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4206.456376075745\n",
      "current PPL:  89.60284550380156\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4211.706102848053\n",
      "current PPL:  190.51420758955203\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  4216.869793891907\n",
      "current PPL:  174.8084921008045\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4221.330544471741\n",
      "current PPL:  86.55244924488282\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4226.213004589081\n",
      "current PPL:  131.95488941744674\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4230.999960422516\n",
      "current PPL:  119.93570810721336\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4235.609733104706\n",
      "current PPL:  100.46131039552986\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4240.211287498474\n",
      "current PPL:  99.63907368852412\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4244.883999347687\n",
      "current PPL:  106.98748331047751\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4249.602304935455\n",
      "current PPL:  111.97835433696997\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4254.321664810181\n",
      "current PPL:  112.0964739104117\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4258.653419971466\n",
      "current PPL:  76.07769808593667\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4263.1726150512695\n",
      "current PPL:  91.76170739258524\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  4267.712220668793\n",
      "current PPL:  93.65385739492929\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4272.201406478882\n",
      "current PPL:  89.04891362810058\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4276.840462684631\n",
      "current PPL:  103.44666912479572\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4280.852144241333\n",
      "current PPL:  55.23968116450995\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4285.426045417786\n",
      "current PPL:  96.92148099779305\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4289.840522766113\n",
      "current PPL:  82.63863839460046\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4294.4976925849915\n",
      "current PPL:  105.33753558087538\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  4299.817840099335\n",
      "current PPL:  204.41403377094866\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4304.2374930381775\n",
      "current PPL:  83.06745086934106\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4308.819361209869\n",
      "current PPL:  97.69673810968973\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4313.876485824585\n",
      "current PPL:  157.13803371443802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4318.676758766174\n",
      "current PPL:  121.54358729171504\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4323.11717748642\n",
      "current PPL:  84.81044609089653\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4327.873908042908\n",
      "current PPL:  116.36485497339116\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4332.739928245544\n",
      "current PPL:  129.8032967498673\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4337.4511733055115\n",
      "current PPL:  111.19051261508854\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4342.310544490814\n",
      "current PPL:  128.94309529604016\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4347.5191469192505\n",
      "current PPL:  182.83834987146122\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4352.15158700943\n",
      "current PPL:  102.76451310638672\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4357.062729358673\n",
      "current PPL:  135.79445052669442\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4361.7188372612\n",
      "current PPL:  105.2257353012131\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4366.451266288757\n",
      "current PPL:  113.57109489433186\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4371.0958342552185\n",
      "current PPL:  104.01841663170383\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4376.246201515198\n",
      "current PPL:  172.4948291326039\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4381.077433109283\n",
      "current PPL:  125.36526473386286\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4386.153646945953\n",
      "current PPL:  160.16648999134821\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4390.617392539978\n",
      "current PPL:  86.81206363894186\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4396.105502605438\n",
      "current PPL:  241.79978897627828\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4400.689615726471\n",
      "current PPL:  97.9163087077281\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4404.989932060242\n",
      "current PPL:  73.72311112108993\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4409.8516211509705\n",
      "current PPL:  129.24231984941335\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4414.518926620483\n",
      "current PPL:  106.4106291040897\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4420.202787876129\n",
      "current PPL:  294.0827692110147\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4424.2984228134155\n",
      "current PPL:  60.077472477383324\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  4429.875261306763\n",
      "current PPL:  264.23490345795733\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4434.501007556915\n",
      "current PPL:  102.07892107686934\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4439.953766822815\n",
      "current PPL:  233.40129445100663\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4445.178161621094\n",
      "current PPL:  185.74872105638758\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4449.282392978668\n",
      "current PPL:  60.5961498709624\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4453.671662330627\n",
      "current PPL:  80.58152073590564\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4458.4555649757385\n",
      "current PPL:  119.57008025297115\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4462.711693763733\n",
      "current PPL:  70.53639290140276\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4467.225634098053\n",
      "current PPL:  91.28078763718129\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4472.048366069794\n",
      "current PPL:  124.30422294348341\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4476.687695980072\n",
      "current PPL:  103.4749868217895\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4481.387212753296\n",
      "current PPL:  109.89405586914678\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4485.757115364075\n",
      "current PPL:  79.03593407667192\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4490.30699300766\n",
      "current PPL:  94.62083014106562\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4495.485050201416\n",
      "current PPL:  177.33794283321618\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4500.533386707306\n",
      "current PPL:  155.76313778969472\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4504.96138048172\n",
      "current PPL:  83.76320035080406\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4509.436003684998\n",
      "current PPL:  87.76152592364522\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  4514.1711983680725\n",
      "current PPL:  113.88562816441589\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4518.533851146698\n",
      "current PPL:  78.46500887712291\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4523.030385017395\n",
      "current PPL:  89.70566039500292\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4527.722264766693\n",
      "current PPL:  109.05798893034998\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4532.3651213645935\n",
      "current PPL:  103.84055502053165\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4536.819507598877\n",
      "current PPL:  86.00334873577097\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4541.407935142517\n",
      "current PPL:  98.33967367462624\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4545.9609932899475\n",
      "current PPL:  94.92225113639611\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4550.670800209045\n",
      "current PPL:  111.03071992437656\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4555.209266662598\n",
      "current PPL:  93.54723103882708\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4560.159207344055\n",
      "current PPL:  141.16658987675282\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4564.672244548798\n",
      "current PPL:  91.19838647306128\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4569.197019100189\n",
      "current PPL:  92.27512018600866\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4574.001519680023\n",
      "current PPL:  122.05851731171992\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4578.470593452454\n",
      "current PPL:  87.27584826818901\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4582.899028778076\n",
      "current PPL:  83.80019425989803\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4587.676116466522\n",
      "current PPL:  118.75798567533869\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4592.269240856171\n",
      "current PPL:  98.80264638302938\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4597.006446838379\n",
      "current PPL:  114.1149167362958\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4601.831960678101\n",
      "current PPL:  124.65050230961295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4606.427128314972\n",
      "current PPL:  99.00473099997667\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4611.018502235413\n",
      "current PPL:  98.6298466772959\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4615.7689843177795\n",
      "current PPL:  115.64001910590339\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4620.864924430847\n",
      "current PPL:  163.35734683481726\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4625.424763679504\n",
      "current PPL:  95.56811589225654\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  4630.8749742507935\n",
      "current PPL:  232.80718325533897\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  4635.582476139069\n",
      "current PPL:  110.77508542856013\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  4639.788689613342\n",
      "current PPL:  67.10197480192402\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4644.799659729004\n",
      "current PPL:  150.0502316436543\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4649.577199935913\n",
      "current PPL:  118.81173801754785\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4653.917601108551\n",
      "current PPL:  76.73831847766326\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4658.702382564545\n",
      "current PPL:  119.67520592675433\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4663.271712303162\n",
      "current PPL:  96.47942166569418\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4668.074117183685\n",
      "current PPL:  121.8029872118233\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4672.447888851166\n",
      "current PPL:  79.3423209189086\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4677.073669433594\n",
      "current PPL:  102.08242573866049\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4681.538873672485\n",
      "current PPL:  86.93878400749713\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  4686.504506111145\n",
      "current PPL:  143.39921280702148\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4691.370946407318\n",
      "current PPL:  129.8578377311871\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  4696.786338806152\n",
      "current PPL:  224.84075562113736\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4701.67279958725\n",
      "current PPL:  132.48385396025856\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4706.197030067444\n",
      "current PPL:  92.22492960573135\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4710.799347877502\n",
      "current PPL:  99.71516882296358\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4715.65304517746\n",
      "current PPL:  128.21355856827822\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4719.917161464691\n",
      "current PPL:  71.10205840481768\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4724.415141582489\n",
      "current PPL:  89.835490807076\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4728.8394565582275\n",
      "current PPL:  83.45561851301319\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4733.510759830475\n",
      "current PPL:  106.83688929243932\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4738.535603523254\n",
      "current PPL:  152.14647266171104\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4743.142040729523\n",
      "current PPL:  100.12678232895216\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4748.261775016785\n",
      "current PPL:  167.29091238855966\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4752.679621696472\n",
      "current PPL:  82.91754495092844\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4757.434695243835\n",
      "current PPL:  116.17219700898326\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4762.232858181\n",
      "current PPL:  121.28740015773434\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4766.610122680664\n",
      "current PPL:  79.61993487820246\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4771.6702427864075\n",
      "current PPL:  157.60944498618184\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4776.167181491852\n",
      "current PPL:  89.74198371533662\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4780.658889293671\n",
      "current PPL:  89.27377768527268\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4785.1732387542725\n",
      "current PPL:  91.31814064694942\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4789.629621505737\n",
      "current PPL:  86.17522742146059\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4794.149531841278\n",
      "current PPL:  91.82736395808114\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4798.589852809906\n",
      "current PPL:  84.80215613780081\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4802.975214958191\n",
      "current PPL:  80.2672866101341\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4807.524862766266\n",
      "current PPL:  94.59908541324053\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4812.115119457245\n",
      "current PPL:  98.51971603884043\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4816.541152954102\n",
      "current PPL:  83.59916206183983\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4820.6636481285095\n",
      "current PPL:  61.71303510048289\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4825.420523643494\n",
      "current PPL:  116.3817242704107\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  4830.231051445007\n",
      "current PPL:  122.79641254871986\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  4835.199551105499\n",
      "current PPL:  143.81096016413886\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4840.067182064056\n",
      "current PPL:  130.01254665861842\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  4844.927017211914\n",
      "current PPL:  129.00293394434715\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4849.39280796051\n",
      "current PPL:  86.98978940414071\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4853.646470546722\n",
      "current PPL:  70.36265025379183\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4857.951098918915\n",
      "current PPL:  74.04169438681136\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4862.476737499237\n",
      "current PPL:  92.35488301316278\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4867.688874721527\n",
      "current PPL:  183.48578935523872\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4872.449666023254\n",
      "current PPL:  116.83834371217368\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4876.693619251251\n",
      "current PPL:  69.68277997058942\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  4881.3926339149475\n",
      "current PPL:  109.83889086726512\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4885.846095085144\n",
      "current PPL:  85.92382691356293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4890.586168766022\n",
      "current PPL:  114.44263360320765\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  4895.705592632294\n",
      "current PPL:  167.23898983726147\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4900.626976490021\n",
      "current PPL:  137.19233655615113\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4905.258116722107\n",
      "current PPL:  102.63102060177762\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4910.0647740364075\n",
      "current PPL:  122.3220492049494\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4914.593004703522\n",
      "current PPL:  92.59458541610188\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  4919.637335777283\n",
      "current PPL:  155.14048693841235\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4924.143977642059\n",
      "current PPL:  90.61700284178403\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  4928.951663970947\n",
      "current PPL:  122.44798516179807\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4933.418395042419\n",
      "current PPL:  87.0716263636463\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4937.723764896393\n",
      "current PPL:  74.09661531315085\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  4942.774522781372\n",
      "current PPL:  156.14075638882036\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4947.320566177368\n",
      "current PPL:  94.25872509503986\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4951.902491569519\n",
      "current PPL:  97.7023285218271\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4956.523703098297\n",
      "current PPL:  101.61706958693419\n",
      "reps  torch.Size([64, 24, 1024])\n",
      "embs  torch.Size([64, 25, 512])\n",
      "val running loss:  4961.822013378143\n",
      "current PPL:  199.99858266465307\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  4966.352411746979\n",
      "current PPL:  92.79552056333193\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4970.571858406067\n",
      "current PPL:  67.99584899272058\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4975.416631221771\n",
      "current PPL:  127.07440940396549\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  4979.942810058594\n",
      "current PPL:  92.40479181960454\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  4984.5159368515015\n",
      "current PPL:  96.84645565070524\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4989.115500450134\n",
      "current PPL:  99.44091002239868\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  4993.5882563591\n",
      "current PPL:  87.59780223324773\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  4998.339822292328\n",
      "current PPL:  115.765423587732\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5002.807286739349\n",
      "current PPL:  87.13550598647427\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5007.746445655823\n",
      "current PPL:  139.65274052996975\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5012.400520801544\n",
      "current PPL:  105.01205422608338\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5017.02014875412\n",
      "current PPL:  101.45627855980301\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5021.714663505554\n",
      "current PPL:  109.34573590460913\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5026.128514289856\n",
      "current PPL:  82.58687621448819\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5030.905511856079\n",
      "current PPL:  118.74728342394503\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5035.751822471619\n",
      "current PPL:  127.2699747414377\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  5040.67533826828\n",
      "current PPL:  137.4851342424389\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5045.6141448020935\n",
      "current PPL:  139.6035379953669\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5050.169316291809\n",
      "current PPL:  95.12306646454675\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5054.927572250366\n",
      "current PPL:  116.54249361466772\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5059.287388324738\n",
      "current PPL:  78.24274225402314\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5063.9405426979065\n",
      "current PPL:  104.91540651098138\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5068.646921157837\n",
      "current PPL:  110.6507074356629\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5073.7361760139465\n",
      "current PPL:  162.26890331135084\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5078.441904067993\n",
      "current PPL:  110.5787629635915\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5082.851613521576\n",
      "current PPL:  82.24556387847602\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5087.412800312042\n",
      "current PPL:  95.69698473261094\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5091.919989109039\n",
      "current PPL:  90.66657775618282\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5096.402417182922\n",
      "current PPL:  88.4491732862374\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5101.075321674347\n",
      "current PPL:  107.00809560124446\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5106.300496101379\n",
      "current PPL:  185.89359256593832\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5110.982699871063\n",
      "current PPL:  108.00783488061647\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5115.720325469971\n",
      "current PPL:  114.1628113089668\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5120.951668739319\n",
      "current PPL:  187.04388516497565\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5125.482018470764\n",
      "current PPL:  92.79100734115191\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5130.738370418549\n",
      "current PPL:  191.7805880096751\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5135.391758441925\n",
      "current PPL:  104.93992288150068\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5139.954439163208\n",
      "current PPL:  95.84005625002867\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5144.6113839149475\n",
      "current PPL:  105.31383023089515\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5149.279607772827\n",
      "current PPL:  106.50840027703396\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5153.85671710968\n",
      "current PPL:  97.23291996103352\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5158.6906995773315\n",
      "current PPL:  125.71060350054154\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5162.974670886993\n",
      "current PPL:  72.52789958239694\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  5168.393796443939\n",
      "current PPL:  225.68169040641567\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5173.206649780273\n",
      "current PPL:  123.08231218787625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5177.6992564201355\n",
      "current PPL:  89.35405642630596\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5182.196250915527\n",
      "current PPL:  89.7469905555619\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5187.177375793457\n",
      "current PPL:  145.63811464741764\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5191.7682638168335\n",
      "current PPL:  98.5819343655205\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5196.645299911499\n",
      "current PPL:  131.24110065840688\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5201.322126865387\n",
      "current PPL:  107.42865511475352\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5206.142194271088\n",
      "current PPL:  123.97344701525402\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5210.889099597931\n",
      "current PPL:  115.22714184947911\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5215.415807723999\n",
      "current PPL:  92.45371362790847\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5220.366828918457\n",
      "current PPL:  141.31920464862353\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5225.142601490021\n",
      "current PPL:  118.60190769635395\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5230.122666358948\n",
      "current PPL:  145.4838187267372\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5234.833656311035\n",
      "current PPL:  111.16215065701267\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5239.41835975647\n",
      "current PPL:  97.97412815853515\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5244.14236831665\n",
      "current PPL:  112.61878825520805\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5248.370014667511\n",
      "current PPL:  68.55568610543659\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5252.654029846191\n",
      "current PPL:  72.53108137996011\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5257.100940704346\n",
      "current PPL:  85.36283836627503\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5261.983891010284\n",
      "current PPL:  132.01958805574492\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5266.839541912079\n",
      "current PPL:  128.4642816386296\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  5271.568717479706\n",
      "current PPL:  113.20219631161714\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5276.411530017853\n",
      "current PPL:  126.82555228529684\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5280.841594219208\n",
      "current PPL:  83.93680559393844\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  5286.24734210968\n",
      "current PPL:  222.68270049171878\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5290.85546875\n",
      "current PPL:  100.29608289529008\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5295.511431694031\n",
      "current PPL:  105.21048304237245\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  5300.986777305603\n",
      "current PPL:  238.7329615484835\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5305.477339267731\n",
      "current PPL:  89.17154283098361\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5309.962986946106\n",
      "current PPL:  88.73440355982723\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  5315.016724586487\n",
      "current PPL:  156.60671152247917\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5319.81297492981\n",
      "current PPL:  121.05564831735204\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5324.338672161102\n",
      "current PPL:  92.3602998755287\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5328.818709373474\n",
      "current PPL:  88.23795615819175\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5333.3939509391785\n",
      "current PPL:  97.05148061476329\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5337.943090438843\n",
      "current PPL:  94.55101212155003\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5342.783728599548\n",
      "current PPL:  126.55008525859026\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5347.09503364563\n",
      "current PPL:  74.53770062781396\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  5352.567932605743\n",
      "current PPL:  238.14957915756597\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5357.337038516998\n",
      "current PPL:  117.81385881156488\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5361.876956939697\n",
      "current PPL:  93.68315738861023\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5366.753623962402\n",
      "current PPL:  131.1926721854408\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5371.412131309509\n",
      "current PPL:  105.47852177375073\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5375.971636772156\n",
      "current PPL:  95.5362219152765\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5381.034611701965\n",
      "current PPL:  158.06003509449894\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5385.776561260223\n",
      "current PPL:  114.65751543390424\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5390.743353366852\n",
      "current PPL:  143.5656047419089\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5395.2153244018555\n",
      "current PPL:  87.52907597336525\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5399.789115905762\n",
      "current PPL:  96.9108519550402\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5404.540794849396\n",
      "current PPL:  115.77850702457795\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5408.8852891922\n",
      "current PPL:  77.05306518993264\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5413.978384017944\n",
      "current PPL:  162.8932088628187\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5418.79736328125\n",
      "current PPL:  123.8386196207056\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5423.2819929122925\n",
      "current PPL:  88.6441137044302\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5427.643712520599\n",
      "current PPL:  78.39182181309873\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5431.994572162628\n",
      "current PPL:  77.54509530421225\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5436.47278213501\n",
      "current PPL:  88.0768714510715\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5441.542653083801\n",
      "current PPL:  159.15378702939657\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5446.341864109039\n",
      "current PPL:  121.41458667502665\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5451.625829219818\n",
      "current PPL:  197.15004937724342\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5456.199916362762\n",
      "current PPL:  96.93950682163218\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5461.063205718994\n",
      "current PPL:  129.44930744877234\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5465.77591085434\n",
      "current PPL:  111.35297772166028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  5471.011451721191\n",
      "current PPL:  187.83067025874124\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5475.496670722961\n",
      "current PPL:  88.69637334885581\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5480.124084472656\n",
      "current PPL:  102.2492796279657\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5484.414452075958\n",
      "current PPL:  72.9932961450521\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5489.351779937744\n",
      "current PPL:  139.39726269312516\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5493.898013591766\n",
      "current PPL:  94.27666028012366\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5498.916346549988\n",
      "current PPL:  151.1591050961697\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5503.693595409393\n",
      "current PPL:  118.77712755635125\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5508.28275680542\n",
      "current PPL:  98.41186696520688\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5513.091227531433\n",
      "current PPL:  122.54407068902998\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5517.517290592194\n",
      "current PPL:  83.60163361595973\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5522.306834220886\n",
      "current PPL:  120.24647909628426\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5527.144558906555\n",
      "current PPL:  126.18192132294995\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5531.8911147117615\n",
      "current PPL:  115.18687450780087\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5536.629101276398\n",
      "current PPL:  114.20402760973668\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5541.336590766907\n",
      "current PPL:  110.7737120734731\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5545.755865097046\n",
      "current PPL:  83.03600676233687\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  5550.717305183411\n",
      "current PPL:  142.79929120814168\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5555.616814613342\n",
      "current PPL:  134.22391729491494\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5560.185727596283\n",
      "current PPL:  96.43922169643633\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5565.130549430847\n",
      "current PPL:  140.44582603043355\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5569.594813346863\n",
      "current PPL:  86.85707190398625\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5573.956872463226\n",
      "current PPL:  78.41844098663526\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5578.746355056763\n",
      "current PPL:  120.23914005761607\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5583.315800666809\n",
      "current PPL:  96.4906015218949\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5588.378923892975\n",
      "current PPL:  158.08347655986347\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5593.368216991425\n",
      "current PPL:  146.83259061426747\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5597.859032154083\n",
      "current PPL:  89.19412397163678\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5603.154487133026\n",
      "current PPL:  199.42834102406306\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5608.2572956085205\n",
      "current PPL:  164.48320627732335\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5612.653780937195\n",
      "current PPL:  81.16509812136186\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5617.0499086380005\n",
      "current PPL:  81.13607641010745\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5621.702809333801\n",
      "current PPL:  104.88879522226138\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5626.453327655792\n",
      "current PPL:  115.64420993265438\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5631.206573009491\n",
      "current PPL:  115.96000575686631\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5636.234884738922\n",
      "current PPL:  152.6750382179091\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5641.533999919891\n",
      "current PPL:  200.15962655195594\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5646.253153324127\n",
      "current PPL:  112.0733316857474\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5651.29133605957\n",
      "current PPL:  154.18955705283312\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5655.806933403015\n",
      "current PPL:  91.4321661183369\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5660.256568908691\n",
      "current PPL:  85.5957391544938\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5664.937654495239\n",
      "current PPL:  107.88712983884643\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5669.7992424964905\n",
      "current PPL:  129.22925547117055\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5674.323837757111\n",
      "current PPL:  92.25857759153327\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5679.107003688812\n",
      "current PPL:  119.48202381164616\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5683.516705036163\n",
      "current PPL:  82.244897179582\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5688.119756698608\n",
      "current PPL:  99.78837189441114\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5693.003308773041\n",
      "current PPL:  132.0990571929952\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  5698.411549568176\n",
      "current PPL:  223.23851974852343\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5703.404300689697\n",
      "current PPL:  147.34122001949189\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5707.7680311203\n",
      "current PPL:  78.54961242751091\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5712.380834102631\n",
      "current PPL:  100.76620003877903\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5717.055126190186\n",
      "current PPL:  107.1566826862101\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  5722.484116077423\n",
      "current PPL:  227.9189053137853\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5726.805932998657\n",
      "current PPL:  75.3253642889841\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5731.438441753387\n",
      "current PPL:  102.77156962777907\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5735.886102676392\n",
      "current PPL:  85.42689004927234\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5740.679263114929\n",
      "current PPL:  120.68217518569924\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5745.411055088043\n",
      "current PPL:  113.49876696455289\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  5751.180475234985\n",
      "current PPL:  320.35192173963867\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5756.098886966705\n",
      "current PPL:  136.78518899134613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5760.891756057739\n",
      "current PPL:  120.64701985667972\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5765.918386936188\n",
      "current PPL:  152.4186297824457\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5770.851709365845\n",
      "current PPL:  138.84003313602997\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5775.301824092865\n",
      "current PPL:  85.63676828988508\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5779.8335337638855\n",
      "current PPL:  92.91728334866578\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5784.338864803314\n",
      "current PPL:  90.49829759542841\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5788.586706638336\n",
      "current PPL:  69.9542764477549\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5793.160617828369\n",
      "current PPL:  96.92245153368725\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5797.57718706131\n",
      "current PPL:  82.81168982941152\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5802.162781238556\n",
      "current PPL:  98.06143570922612\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5806.678019523621\n",
      "current PPL:  91.39934252602453\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5811.792182445526\n",
      "current PPL:  166.36146514409677\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5816.401148319244\n",
      "current PPL:  100.38029004757321\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  5821.666383743286\n",
      "current PPL:  193.49185606054888\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5826.047996997833\n",
      "current PPL:  79.9669364242424\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5831.064389228821\n",
      "current PPL:  150.86603098470118\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5835.419083595276\n",
      "current PPL:  77.84303025944071\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  5839.942087650299\n",
      "current PPL:  92.11189196095346\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5844.46697807312\n",
      "current PPL:  92.28581285556216\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5849.18213224411\n",
      "current PPL:  111.62601934108434\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5853.765654087067\n",
      "current PPL:  97.85843005396532\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  5858.336364269257\n",
      "current PPL:  96.61269803234649\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5863.203542709351\n",
      "current PPL:  129.9537268903355\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5868.156845092773\n",
      "current PPL:  141.6419484386161\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  5873.303987503052\n",
      "current PPL:  171.93945521447898\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5878.144837856293\n",
      "current PPL:  126.57694109123926\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5883.1280727386475\n",
      "current PPL:  145.9457361410052\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5887.579030513763\n",
      "current PPL:  85.7089946451819\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5892.357625961304\n",
      "current PPL:  118.93717916461337\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5896.705487728119\n",
      "current PPL:  77.31297289591417\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5901.281962394714\n",
      "current PPL:  97.17122869755357\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5905.794984817505\n",
      "current PPL:  91.19703839286234\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5910.9328989982605\n",
      "current PPL:  170.36005718996424\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5915.413331985474\n",
      "current PPL:  88.27288543289579\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  5920.222020149231\n",
      "current PPL:  122.57071929241953\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  5924.657003879547\n",
      "current PPL:  84.3507525170517\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5929.432153224945\n",
      "current PPL:  118.52801491251707\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5934.197302818298\n",
      "current PPL:  117.34867055598025\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5938.940917491913\n",
      "current PPL:  114.84859246208356\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5943.356824398041\n",
      "current PPL:  82.75685958660323\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5948.01476764679\n",
      "current PPL:  105.41903829164225\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5952.407616138458\n",
      "current PPL:  80.87045000729772\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5957.5946044921875\n",
      "current PPL:  178.92887020831955\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5962.4056391716\n",
      "current PPL:  122.85867111375049\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5967.541271209717\n",
      "current PPL:  169.97171453465376\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5972.030124664307\n",
      "current PPL:  89.01932264958708\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  5976.6197991371155\n",
      "current PPL:  98.46237276481091\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5981.59586763382\n",
      "current PPL:  144.9035714490079\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  5986.324975967407\n",
      "current PPL:  113.1945855265555\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  5990.829029560089\n",
      "current PPL:  90.38276464887642\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  5995.742094993591\n",
      "current PPL:  136.05584595912825\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  6000.4809193611145\n",
      "current PPL:  114.299748165651\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6005.157732963562\n",
      "current PPL:  107.42722079703945\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6009.570679187775\n",
      "current PPL:  82.51220519968157\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6014.147305965424\n",
      "current PPL:  97.18601063973732\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6018.811661243439\n",
      "current PPL:  106.09715999514087\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6023.804543018341\n",
      "current PPL:  147.36047190573396\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6028.656900405884\n",
      "current PPL:  128.04187867313595\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6033.317049026489\n",
      "current PPL:  105.65178302185612\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6037.943591594696\n",
      "current PPL:  102.16024073853617\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6042.366762638092\n",
      "current PPL:  83.36020551524204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6046.794546127319\n",
      "current PPL:  83.74558804244272\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  6052.342918395996\n",
      "current PPL:  256.8191828703336\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6057.223360538483\n",
      "current PPL:  131.68887626300412\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6062.051997661591\n",
      "current PPL:  125.04042976255445\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6066.46565580368\n",
      "current PPL:  82.57096802832243\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6071.03543138504\n",
      "current PPL:  96.52244590599491\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  6075.807555198669\n",
      "current PPL:  118.16994658459906\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6080.436815261841\n",
      "current PPL:  102.43823823564557\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6085.288443565369\n",
      "current PPL:  127.94855940908415\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6089.901485443115\n",
      "current PPL:  100.7902754977261\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6094.517890930176\n",
      "current PPL:  101.12986541087184\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6099.167633056641\n",
      "current PPL:  104.5580193542462\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6104.044456005096\n",
      "current PPL:  131.21313009625803\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  6108.715069293976\n",
      "current PPL:  106.76319904119462\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6113.549764633179\n",
      "current PPL:  125.80025096326715\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6117.992405414581\n",
      "current PPL:  84.99910962220648\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6122.545955181122\n",
      "current PPL:  94.96892820175773\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6127.079666137695\n",
      "current PPL:  93.10342356318803\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6131.791672229767\n",
      "current PPL:  111.27516437217034\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  6136.644773006439\n",
      "current PPL:  128.1370990023738\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6141.418224811554\n",
      "current PPL:  118.32697951363497\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6146.059754371643\n",
      "current PPL:  103.70284607037621\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6150.456732273102\n",
      "current PPL:  81.20508768781905\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6155.08232831955\n",
      "current PPL:  102.06358959618956\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6159.733061790466\n",
      "current PPL:  104.66172376153646\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6164.083241939545\n",
      "current PPL:  77.49242185625683\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6169.052763938904\n",
      "current PPL:  143.95805887779633\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6173.737463474274\n",
      "current PPL:  108.27773379085735\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6178.374924659729\n",
      "current PPL:  103.2818011070457\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6183.190371513367\n",
      "current PPL:  123.40194259862504\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6187.743677616119\n",
      "current PPL:  94.94579053200542\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6192.694487571716\n",
      "current PPL:  141.2893556935249\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6197.551632404327\n",
      "current PPL:  128.65634181439555\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6202.511079311371\n",
      "current PPL:  142.51495007937493\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6207.331294536591\n",
      "current PPL:  123.99177406508039\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6212.1595578193665\n",
      "current PPL:  124.99369334329825\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6217.107862472534\n",
      "current PPL:  140.93582616159532\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6221.935432434082\n",
      "current PPL:  124.90706259727165\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6226.527195453644\n",
      "current PPL:  98.66823093110709\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6231.101909160614\n",
      "current PPL:  97.00026466164377\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6236.424920558929\n",
      "current PPL:  205.00029093149584\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6240.856862068176\n",
      "current PPL:  84.09452882270551\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6245.37703704834\n",
      "current PPL:  91.85166879210875\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6249.592609405518\n",
      "current PPL:  67.7329222028332\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6254.2586550712585\n",
      "current PPL:  106.27665699916692\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6258.895581245422\n",
      "current PPL:  103.22655895615151\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6263.391450405121\n",
      "current PPL:  89.6460518693236\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6269.111036300659\n",
      "current PPL:  304.77868660724874\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6273.938016414642\n",
      "current PPL:  124.83340819515551\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  6278.614555835724\n",
      "current PPL:  107.39777029247358\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6282.99357509613\n",
      "current PPL:  79.7597714682196\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6287.457904815674\n",
      "current PPL:  86.86278759378892\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6292.075034618378\n",
      "current PPL:  101.20314188884088\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6296.820151805878\n",
      "current PPL:  115.02128377004355\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  6301.400181770325\n",
      "current PPL:  97.51731621573103\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6305.935813903809\n",
      "current PPL:  93.2824636395787\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6310.298958778381\n",
      "current PPL:  78.50363069203343\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6315.5706152915955\n",
      "current PPL:  194.73828194576885\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6319.5130388736725\n",
      "current PPL:  51.54336963314049\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6324.206755876541\n",
      "current PPL:  109.25854028534307\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6328.645309209824\n",
      "current PPL:  84.65238925485443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6333.113760709763\n",
      "current PPL:  87.22155580274912\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6338.0181176662445\n",
      "current PPL:  134.87615088028792\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6342.697586297989\n",
      "current PPL:  107.712822187796\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6347.244267702103\n",
      "current PPL:  94.31888211510524\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6351.7355806827545\n",
      "current PPL:  89.23853746543533\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  6356.826267004013\n",
      "current PPL:  162.50135192254598\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6361.571455717087\n",
      "current PPL:  115.02951102758257\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  6366.722018003464\n",
      "current PPL:  172.52847345841158\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6372.056589841843\n",
      "current PPL:  207.38393595396138\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6376.445986032486\n",
      "current PPL:  80.59174223818437\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6381.207525014877\n",
      "current PPL:  116.925734148587\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6385.9166605472565\n",
      "current PPL:  110.95620039215738\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6391.261974573135\n",
      "current PPL:  209.6237015313327\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6395.845069646835\n",
      "current PPL:  97.81667599482806\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6400.2969715595245\n",
      "current PPL:  85.78995393973328\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6404.662603139877\n",
      "current PPL:  78.69908904721798\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6409.364519834518\n",
      "current PPL:  110.15810969493249\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6413.748985528946\n",
      "current PPL:  80.19536293437261\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6418.110909700394\n",
      "current PPL:  78.40785953069428\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6423.828449487686\n",
      "current PPL:  304.15571397548445\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6428.647426843643\n",
      "current PPL:  123.83838341750904\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6433.201546430588\n",
      "current PPL:  95.02305885570901\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6438.13976931572\n",
      "current PPL:  139.5220823475166\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6442.6184985637665\n",
      "current PPL:  88.12261950398764\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6447.249567270279\n",
      "current PPL:  102.62368012166569\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6452.035266637802\n",
      "current PPL:  119.78510761036937\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6457.016661405563\n",
      "current PPL:  145.67742619830136\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6461.735067129135\n",
      "current PPL:  111.9895679408573\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6466.074019670486\n",
      "current PPL:  76.62723342869882\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6471.664162874222\n",
      "current PPL:  267.77396319987656\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6476.297337293625\n",
      "current PPL:  102.84000380563411\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6480.710876226425\n",
      "current PPL:  82.56112538856496\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6485.840208768845\n",
      "current PPL:  168.90434392835886\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6490.441715955734\n",
      "current PPL:  99.63437014988307\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6495.231389284134\n",
      "current PPL:  120.26207604083228\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6500.239345788956\n",
      "current PPL:  149.59871932197927\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6504.665378808975\n",
      "current PPL:  83.59912219866247\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6509.118832349777\n",
      "current PPL:  85.92317136928848\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6513.941252946854\n",
      "current PPL:  124.2655237830742\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  6518.434716463089\n",
      "current PPL:  89.43065461901938\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6523.225753068924\n",
      "current PPL:  120.42613842128253\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6527.874177694321\n",
      "current PPL:  104.42035475860615\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6532.394421815872\n",
      "current PPL:  91.85801976352856\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6536.937395811081\n",
      "current PPL:  93.969850852228\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6541.808096647263\n",
      "current PPL:  130.41228252267308\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6545.9426991939545\n",
      "current PPL:  62.4647593108318\n",
      "reps  torch.Size([64, 24, 1024])\n",
      "embs  torch.Size([64, 25, 512])\n",
      "val running loss:  6551.285878419876\n",
      "current PPL:  209.1766741890078\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6556.916386842728\n",
      "current PPL:  278.8038318438283\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6561.273548364639\n",
      "current PPL:  78.03531822091006\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6565.773076295853\n",
      "current PPL:  89.97464705110667\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6570.620220899582\n",
      "current PPL:  127.37616067002561\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6575.172390222549\n",
      "current PPL:  94.83791940111999\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6579.569082021713\n",
      "current PPL:  81.18185804905715\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6583.9149425029755\n",
      "current PPL:  77.15840228175806\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6588.5488159656525\n",
      "current PPL:  102.91191855141612\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6592.474364757538\n",
      "current PPL:  50.68088368610009\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6597.526207923889\n",
      "current PPL:  156.31030503049965\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6602.325114250183\n",
      "current PPL:  121.37759741424996\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6607.061194419861\n",
      "current PPL:  113.98651702367953\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6612.511250495911\n",
      "current PPL:  232.77121843212953\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6616.969476699829\n",
      "current PPL:  86.33423387127687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6621.691121578217\n",
      "current PPL:  112.35290762822349\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6626.041433811188\n",
      "current PPL:  77.50265803300198\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6630.711461544037\n",
      "current PPL:  106.70070150587485\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6635.351435661316\n",
      "current PPL:  103.54166760850956\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6639.819362163544\n",
      "current PPL:  87.17577670359958\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6644.596158981323\n",
      "current PPL:  118.72344748420949\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6649.388676166534\n",
      "current PPL:  120.60457093734325\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6654.126402854919\n",
      "current PPL:  114.17435255125565\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6658.458775043488\n",
      "current PPL:  76.12465458649302\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6663.010986328125\n",
      "current PPL:  94.84189904208559\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6667.488386154175\n",
      "current PPL:  88.00554519300447\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6672.352635383606\n",
      "current PPL:  129.5736220232508\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6677.5511684417725\n",
      "current PPL:  181.00652098648752\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6682.045179843903\n",
      "current PPL:  89.47966583829752\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6686.543942928314\n",
      "current PPL:  89.90585654052482\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6691.033863544464\n",
      "current PPL:  89.11437135596367\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6695.671856880188\n",
      "current PPL:  103.33677717170805\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  6701.148670196533\n",
      "current PPL:  239.0836083156297\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6705.454843044281\n",
      "current PPL:  74.15613832905971\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6709.966109275818\n",
      "current PPL:  91.03701950469045\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6714.4138770103455\n",
      "current PPL:  85.43601511286333\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6719.867779254913\n",
      "current PPL:  233.6682196675524\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  6724.636836051941\n",
      "current PPL:  117.80807261701811\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6729.432566165924\n",
      "current PPL:  120.99268799569633\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6734.116841316223\n",
      "current PPL:  108.23179208631265\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6739.6507177352905\n",
      "current PPL:  253.12322337415026\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6744.546654701233\n",
      "current PPL:  133.7452626811362\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6749.135306835175\n",
      "current PPL:  98.36176229193934\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6753.616514205933\n",
      "current PPL:  88.34126897696615\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6758.187572956085\n",
      "current PPL:  96.64637999355067\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6762.918603420258\n",
      "current PPL:  113.41236953902424\n",
      "reps  torch.Size([64, 24, 1024])\n",
      "embs  torch.Size([64, 25, 512])\n",
      "val running loss:  6767.8942131996155\n",
      "current PPL:  144.83711691034927\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6772.585426807404\n",
      "current PPL:  108.98536506849531\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6777.547846794128\n",
      "current PPL:  142.93928886569495\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6782.32839012146\n",
      "current PPL:  119.16908027675856\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6786.69740152359\n",
      "current PPL:  78.96552794660221\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6791.320630073547\n",
      "current PPL:  101.8222402156517\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6795.931044578552\n",
      "current PPL:  100.52580945282976\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6800.137800693512\n",
      "current PPL:  67.1383969447394\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6804.840283870697\n",
      "current PPL:  110.22053001949158\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6809.113401412964\n",
      "current PPL:  71.74495526460126\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6814.171788215637\n",
      "current PPL:  157.33649667072788\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6819.016977787018\n",
      "current PPL:  127.12737942240445\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6823.759028911591\n",
      "current PPL:  114.66916136660643\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6828.570333957672\n",
      "current PPL:  122.89189249415517\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6832.866568565369\n",
      "current PPL:  73.42280687292889\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6837.587869167328\n",
      "current PPL:  112.31423382810569\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6842.030077457428\n",
      "current PPL:  84.96235619491716\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6847.114059925079\n",
      "current PPL:  161.4156100418503\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6852.840355873108\n",
      "current PPL:  306.8306442650068\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6857.642446517944\n",
      "current PPL:  121.7647183794583\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6862.739285469055\n",
      "current PPL:  163.5042446415693\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6867.424441337585\n",
      "current PPL:  108.32715578690932\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6871.894693851471\n",
      "current PPL:  87.37878458430276\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6876.490479469299\n",
      "current PPL:  99.06593294726189\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6881.692461967468\n",
      "current PPL:  181.63197022532705\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6886.320966243744\n",
      "current PPL:  102.36084600726313\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  6891.569949626923\n",
      "current PPL:  190.37263402723167\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6896.346750736237\n",
      "current PPL:  118.72395699106455\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  6901.412381649017\n",
      "current PPL:  158.48039784718046\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6905.607837200165\n",
      "current PPL:  66.3839659819892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6910.647281169891\n",
      "current PPL:  154.38414889549435\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6915.201456069946\n",
      "current PPL:  95.02831502201555\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6919.478862762451\n",
      "current PPL:  72.05334104023781\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6924.243619441986\n",
      "current PPL:  117.30257169878477\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6928.370589256287\n",
      "current PPL:  61.989797453380994\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6932.515315532684\n",
      "current PPL:  63.10034748322569\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6937.156725883484\n",
      "current PPL:  103.69048446459553\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  6942.227477073669\n",
      "current PPL:  159.29394245701337\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6947.046297550201\n",
      "current PPL:  123.81895724694259\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  6951.104006290436\n",
      "current PPL:  57.84162893522004\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6955.906846523285\n",
      "current PPL:  121.85602596998707\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6960.975095748901\n",
      "current PPL:  158.8958928176057\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6965.905915737152\n",
      "current PPL:  138.49302844879875\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6970.653631687164\n",
      "current PPL:  115.32058550903447\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  6975.66161441803\n",
      "current PPL:  149.6026427559777\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  6980.405425071716\n",
      "current PPL:  114.87110270321313\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6984.8038902282715\n",
      "current PPL:  81.32595022277151\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  6989.438277244568\n",
      "current PPL:  102.96478291284625\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  6993.8067626953125\n",
      "current PPL:  78.92400683777161\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  6998.271345615387\n",
      "current PPL:  86.88478408237609\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7003.142063140869\n",
      "current PPL:  130.41445903061197\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7007.985357284546\n",
      "current PPL:  126.8866468831627\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  7013.050041675568\n",
      "current PPL:  158.33046367141165\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7017.739589214325\n",
      "current PPL:  108.80393910300631\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7022.305024147034\n",
      "current PPL:  96.10438386798073\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7026.80110502243\n",
      "current PPL:  89.66503335505813\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7032.047029972076\n",
      "current PPL:  189.79128144688957\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7037.6348576545715\n",
      "current PPL:  267.1546442003681\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7042.091728210449\n",
      "current PPL:  86.21727433217495\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7046.56513261795\n",
      "current PPL:  87.65462770330444\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7051.019994735718\n",
      "current PPL:  86.04428604891629\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7055.612823009491\n",
      "current PPL:  98.77339368222754\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7060.335015296936\n",
      "current PPL:  112.4144274642303\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7064.799986362457\n",
      "current PPL:  86.91851456145436\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  7069.237417221069\n",
      "current PPL:  84.55742240104124\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7073.81800031662\n",
      "current PPL:  97.57127099711956\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7078.375570297241\n",
      "current PPL:  95.35149210329226\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7082.913841724396\n",
      "current PPL:  93.52898863827494\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7087.544947147369\n",
      "current PPL:  102.62744816920745\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7092.613312244415\n",
      "current PPL:  158.91430537856343\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7097.675044536591\n",
      "current PPL:  157.86374572994944\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7102.118846893311\n",
      "current PPL:  85.09789985498335\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7106.515296459198\n",
      "current PPL:  81.16219548316039\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7111.27618265152\n",
      "current PPL:  116.84943109810287\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7115.631526470184\n",
      "current PPL:  77.893602007624\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7120.647785663605\n",
      "current PPL:  150.84596147000443\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  7125.692012310028\n",
      "current PPL:  155.1242868762796\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7130.4605894088745\n",
      "current PPL:  117.7515738511197\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7135.09953212738\n",
      "current PPL:  103.43492991358968\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  7139.495597362518\n",
      "current PPL:  81.1310083492095\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  7144.319260120392\n",
      "current PPL:  124.41997745343846\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7148.876302242279\n",
      "current PPL:  95.30117326716008\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7153.564870834351\n",
      "current PPL:  108.69747796581126\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7158.742321968079\n",
      "current PPL:  177.23049795691486\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  7164.541496753693\n",
      "current PPL:  330.02710439369326\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7168.8668003082275\n",
      "current PPL:  75.58845459569596\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7173.608778476715\n",
      "current PPL:  114.66079585866044\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7178.401084423065\n",
      "current PPL:  120.5790972557474\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7182.828022956848\n",
      "current PPL:  83.67485663853778\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7187.654151916504\n",
      "current PPL:  124.72720090537614\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7192.538275241852\n",
      "current PPL:  132.1745404582465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7197.069046974182\n",
      "current PPL:  92.83017349186471\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7202.2146191596985\n",
      "current PPL:  171.6696834809001\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7206.784268379211\n",
      "current PPL:  96.51024992203038\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7211.423264026642\n",
      "current PPL:  103.44040475807954\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7216.004437923431\n",
      "current PPL:  97.62893325670676\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7220.9945521354675\n",
      "current PPL:  146.95320636218875\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7225.673160076141\n",
      "current PPL:  107.62015460835417\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7230.226213932037\n",
      "current PPL:  94.92184377516188\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7234.745789527893\n",
      "current PPL:  91.79663083927427\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7240.27019071579\n",
      "current PPL:  250.73614921701676\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7245.217216014862\n",
      "current PPL:  140.7556346241666\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7249.701231479645\n",
      "current PPL:  88.5896881955325\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7253.917193412781\n",
      "current PPL:  67.75931446146649\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7258.727468490601\n",
      "current PPL:  122.7653829068773\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7263.388653278351\n",
      "current PPL:  105.7613126639189\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7268.133720397949\n",
      "current PPL:  115.01552503988952\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7272.564232826233\n",
      "current PPL:  83.97443676353738\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7277.330491542816\n",
      "current PPL:  117.47889689768171\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7281.737442493439\n",
      "current PPL:  82.01900187669536\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7286.439349651337\n",
      "current PPL:  110.15705915034229\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7291.022704124451\n",
      "current PPL:  97.84205287449822\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7295.565770149231\n",
      "current PPL:  93.97849925528729\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7300.222945690155\n",
      "current PPL:  105.33813832881327\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7305.755400657654\n",
      "current PPL:  252.7636765709582\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7310.558857917786\n",
      "current PPL:  121.93123766402114\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  7315.478992462158\n",
      "current PPL:  137.02104735717822\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7320.246005058289\n",
      "current PPL:  117.56749522730918\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  7324.836491584778\n",
      "current PPL:  98.54236197036622\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7329.35099697113\n",
      "current PPL:  91.33238060674464\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7335.030313968658\n",
      "current PPL:  292.7494130515489\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7339.19228553772\n",
      "current PPL:  64.19796863919431\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7343.762571811676\n",
      "current PPL:  96.5717517935132\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7348.18178319931\n",
      "current PPL:  83.03078043255665\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7352.749352931976\n",
      "current PPL:  96.3097666501329\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7357.611132144928\n",
      "current PPL:  129.25396797944077\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  7362.365221500397\n",
      "current PPL:  116.0579175200151\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7366.867537975311\n",
      "current PPL:  90.22589543214295\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7371.743159294128\n",
      "current PPL:  131.05555520244317\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7376.658200263977\n",
      "current PPL:  136.3248948984424\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7381.267029762268\n",
      "current PPL:  100.36660157603768\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  7385.8637499809265\n",
      "current PPL:  99.15856332990056\n",
      "reps  torch.Size([64, 23, 1024])\n",
      "embs  torch.Size([64, 24, 512])\n",
      "val running loss:  7391.049916267395\n",
      "current PPL:  178.78183908513628\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7395.479140281677\n",
      "current PPL:  83.86631259275116\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7400.446577548981\n",
      "current PPL:  143.65825750912515\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7404.743621826172\n",
      "current PPL:  73.48227915306043\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7409.26171541214\n",
      "current PPL:  91.66068808384873\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7413.546121120453\n",
      "current PPL:  72.55941244822199\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7418.721607208252\n",
      "current PPL:  176.8825738438053\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7423.581475734711\n",
      "current PPL:  129.00723995368057\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7428.400148391724\n",
      "current PPL:  123.80065574092718\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7432.641544342041\n",
      "current PPL:  69.50480940978947\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7436.877264022827\n",
      "current PPL:  69.11139898596994\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7441.443704128265\n",
      "current PPL:  96.20103394070046\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7446.07675743103\n",
      "current PPL:  102.8275489243643\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7450.655505657196\n",
      "current PPL:  97.3924046075485\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7454.952645301819\n",
      "current PPL:  73.4892873034637\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7459.658002376556\n",
      "current PPL:  110.53774813880419\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7464.514304637909\n",
      "current PPL:  128.54798533399168\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7469.732014656067\n",
      "current PPL:  184.51117267625156\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7474.464624881744\n",
      "current PPL:  113.59167562776516\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7479.112798690796\n",
      "current PPL:  104.39416771106663\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7483.87964963913\n",
      "current PPL:  117.54849223668744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7488.364547729492\n",
      "current PPL:  88.66791423751786\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  7493.368972301483\n",
      "current PPL:  149.07127868450925\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7497.896773338318\n",
      "current PPL:  92.55481252291696\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7502.725346088409\n",
      "current PPL:  125.03238079199505\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7507.626634597778\n",
      "current PPL:  134.4629248498347\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7512.295729637146\n",
      "current PPL:  106.60122885307318\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7516.924045562744\n",
      "current PPL:  102.34156808813074\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7521.362661361694\n",
      "current PPL:  84.65767728803226\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7525.531836032867\n",
      "current PPL:  64.66206261420714\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7529.815997123718\n",
      "current PPL:  72.54166531961049\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7534.494652271271\n",
      "current PPL:  107.62523513985144\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7539.20883846283\n",
      "current PPL:  111.5180199294181\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7544.35205078125\n",
      "current PPL:  171.26504347958\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7549.30929517746\n",
      "current PPL:  142.20140477806873\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7553.830483913422\n",
      "current PPL:  91.94483116790468\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7558.378558635712\n",
      "current PPL:  94.45038992275593\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7562.757730484009\n",
      "current PPL:  79.77194277207785\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7567.392486572266\n",
      "current PPL:  103.00279134062416\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7572.383097648621\n",
      "current PPL:  147.0262403094491\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7577.206635475159\n",
      "current PPL:  124.40443447042166\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  7581.3300886154175\n",
      "current PPL:  61.7721824066867\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7586.081081390381\n",
      "current PPL:  115.69909068993888\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7590.380933761597\n",
      "current PPL:  73.68891429173426\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  7595.165545940399\n",
      "current PPL:  119.65494935857915\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7599.79473733902\n",
      "current PPL:  102.43120460151772\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7605.303410053253\n",
      "current PPL:  246.82330449970826\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7609.957937717438\n",
      "current PPL:  105.05958487290894\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7614.933038234711\n",
      "current PPL:  144.7633756366229\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7619.314706802368\n",
      "current PPL:  79.9713597665546\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7624.256793022156\n",
      "current PPL:  140.0621453939163\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7629.252490997314\n",
      "current PPL:  147.77605341019594\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7634.437556743622\n",
      "current PPL:  178.58519072070143\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7638.9533677101135\n",
      "current PPL:  91.45170022263864\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7643.779350280762\n",
      "current PPL:  124.70894355058944\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7648.413398265839\n",
      "current PPL:  102.92988055376055\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  7653.233293056488\n",
      "current PPL:  123.95204917918883\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7657.735777378082\n",
      "current PPL:  90.24104082012906\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7662.112910270691\n",
      "current PPL:  79.60945702249597\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7666.601052284241\n",
      "current PPL:  88.95601317324787\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7670.989717006683\n",
      "current PPL:  80.53281349637727\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7675.710953235626\n",
      "current PPL:  112.30700405479796\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  7680.934538841248\n",
      "current PPL:  185.5984753522328\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7685.188821315765\n",
      "current PPL:  70.40628075946267\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  7690.295506954193\n",
      "current PPL:  165.12217235522454\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7694.422516345978\n",
      "current PPL:  61.99225090215633\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7699.022087097168\n",
      "current PPL:  99.4416212817565\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7703.949741840363\n",
      "current PPL:  138.05535710912258\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7708.3324518203735\n",
      "current PPL:  80.0546863096577\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7713.455369949341\n",
      "current PPL:  167.82438897419735\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7718.222266197205\n",
      "current PPL:  117.55381724875078\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7722.973826408386\n",
      "current PPL:  115.76476117455996\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7727.561760902405\n",
      "current PPL:  98.29119928685574\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7732.407066345215\n",
      "current PPL:  127.14211070703053\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7737.14685344696\n",
      "current PPL:  114.40984143159714\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7741.815893173218\n",
      "current PPL:  106.59533257061038\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7746.65185546875\n",
      "current PPL:  125.95973539603068\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7751.585917472839\n",
      "current PPL:  138.9427536547798\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7756.2672963142395\n",
      "current PPL:  107.91877290268609\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7760.810903072357\n",
      "current PPL:  94.0293303046166\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7765.418731689453\n",
      "current PPL:  100.26619678692178\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7770.607178688049\n",
      "current PPL:  179.1900543275254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7775.04016494751\n",
      "current PPL:  84.1824325103602\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7780.106333732605\n",
      "current PPL:  158.56566299439137\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7784.593298435211\n",
      "current PPL:  88.8513459104862\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  7789.339603900909\n",
      "current PPL:  115.15804229137402\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7793.938513278961\n",
      "current PPL:  99.37587500840515\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7799.38102722168\n",
      "current PPL:  231.02223070707828\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7803.799690723419\n",
      "current PPL:  82.98530149889625\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7808.21849155426\n",
      "current PPL:  82.99669857835141\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7813.6119203567505\n",
      "current PPL:  219.9562806949477\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7818.442989826202\n",
      "current PPL:  125.34494158371416\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7823.030170440674\n",
      "current PPL:  98.21712748616747\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7827.806092262268\n",
      "current PPL:  118.61961035572544\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7832.384848117828\n",
      "current PPL:  97.3931476554621\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7837.031608581543\n",
      "current PPL:  104.24672691785325\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7841.760680198669\n",
      "current PPL:  113.19042949824784\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7846.7995047569275\n",
      "current PPL:  154.28855119332601\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7852.105648994446\n",
      "current PPL:  201.5715161987423\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  7857.086574554443\n",
      "current PPL:  145.60908925230393\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7861.932577133179\n",
      "current PPL:  127.2307769426401\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7866.606320381165\n",
      "current PPL:  107.09788699483614\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7871.098951339722\n",
      "current PPL:  89.35622942677946\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7875.959396839142\n",
      "current PPL:  129.0816951202055\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  7880.461829662323\n",
      "current PPL:  90.23639366939307\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7884.89145565033\n",
      "current PPL:  83.90003142336077\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7889.155400276184\n",
      "current PPL:  71.08985397511229\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7893.7916440963745\n",
      "current PPL:  103.15614592952485\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7898.612196922302\n",
      "current PPL:  124.03364084252111\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7903.724205970764\n",
      "current PPL:  166.00352921500718\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7908.535848140717\n",
      "current PPL:  122.93332926891934\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7912.976009845734\n",
      "current PPL:  84.78865131564922\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7917.639833450317\n",
      "current PPL:  106.04076594696183\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7922.4362897872925\n",
      "current PPL:  121.08058758106259\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  7927.382552623749\n",
      "current PPL:  140.64835461847315\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7931.996333122253\n",
      "current PPL:  100.86474878779215\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  7936.373887062073\n",
      "current PPL:  79.64298341992287\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  7941.790771007538\n",
      "current PPL:  225.17636631994776\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  7946.522427558899\n",
      "current PPL:  113.48339780325806\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  7950.683786392212\n",
      "current PPL:  64.15864429778664\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7955.304974079132\n",
      "current PPL:  101.61464687608094\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7960.095093250275\n",
      "current PPL:  120.31570596905236\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7964.776505947113\n",
      "current PPL:  107.92242660188467\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7969.480316162109\n",
      "current PPL:  110.36689392414527\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  7974.303779125214\n",
      "current PPL:  124.39512147587827\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7979.243598937988\n",
      "current PPL:  139.74506701540395\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7983.753349781036\n",
      "current PPL:  90.89916752930978\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7988.304196357727\n",
      "current PPL:  94.7125558267067\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  7992.792588710785\n",
      "current PPL:  88.97828516548782\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  7997.421873092651\n",
      "current PPL:  102.44072943021574\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8002.126513004303\n",
      "current PPL:  110.45850296548937\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8007.057658672333\n",
      "current PPL:  138.53814017329378\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8012.540685176849\n",
      "current PPL:  240.57370409191586\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8017.28852891922\n",
      "current PPL:  115.33532354031239\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8021.501721382141\n",
      "current PPL:  67.57191667435995\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8025.990602016449\n",
      "current PPL:  89.02174220255606\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8030.635884284973\n",
      "current PPL:  104.09274374413718\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8035.417691230774\n",
      "current PPL:  119.3197597081651\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8040.571032524109\n",
      "current PPL:  173.0085981124888\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8045.063989162445\n",
      "current PPL:  89.38533568323848\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8050.4552845954895\n",
      "current PPL:  219.4875328702276\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8055.494941234589\n",
      "current PPL:  154.41698516708382\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8060.300007820129\n",
      "current PPL:  122.12762268425304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8064.875725269318\n",
      "current PPL:  97.0976768026042\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8069.34738445282\n",
      "current PPL:  87.50178415531953\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8073.717323303223\n",
      "current PPL:  79.03879836110718\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8078.319134712219\n",
      "current PPL:  99.66468573899544\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8083.1727476119995\n",
      "current PPL:  128.20273777788574\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8087.671619415283\n",
      "current PPL:  89.915631535194\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  8092.533148765564\n",
      "current PPL:  129.22167627219133\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8097.1005120277405\n",
      "current PPL:  96.28988357817326\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8101.823499679565\n",
      "current PPL:  112.50387346198521\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  8106.812481403351\n",
      "current PPL:  146.78687778293377\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8111.428981781006\n",
      "current PPL:  101.13946213923305\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8116.5711097717285\n",
      "current PPL:  171.07943669675166\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8121.368633747101\n",
      "current PPL:  121.20992689704607\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8126.252582550049\n",
      "current PPL:  132.1514750530132\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8130.670067310333\n",
      "current PPL:  82.88754091240462\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8135.327085494995\n",
      "current PPL:  105.32156401716807\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8139.851156711578\n",
      "current PPL:  92.21024270000875\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8144.223260402679\n",
      "current PPL:  79.21009011131846\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8149.1212430000305\n",
      "current PPL:  134.01913621789038\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8154.377320289612\n",
      "current PPL:  191.72792113100434\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8159.306277275085\n",
      "current PPL:  138.23525574237968\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8163.559619426727\n",
      "current PPL:  70.34010724016504\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8168.010106563568\n",
      "current PPL:  85.66866620257628\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8173.0733342170715\n",
      "current PPL:  158.09998565843213\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8177.632522583008\n",
      "current PPL:  95.50593249619313\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8181.97754240036\n",
      "current PPL:  77.09356525450617\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  8186.924385547638\n",
      "current PPL:  140.72999806768644\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8190.908933162689\n",
      "current PPL:  53.76096332527435\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8195.53852891922\n",
      "current PPL:  102.47263184449741\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  8200.6769156456\n",
      "current PPL:  170.44057911309898\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  8205.2788772583\n",
      "current PPL:  99.67965686836597\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8209.954747200012\n",
      "current PPL:  107.32589376347747\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8214.3610663414\n",
      "current PPL:  81.96719788074022\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8219.231727600098\n",
      "current PPL:  130.40712123476715\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8223.590275287628\n",
      "current PPL:  78.14356310142112\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8227.80609035492\n",
      "current PPL:  67.7493636632441\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8232.535382270813\n",
      "current PPL:  113.2153679571677\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8237.001842975616\n",
      "current PPL:  87.04808828018795\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8241.657677650452\n",
      "current PPL:  105.1969886438248\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8247.080953121185\n",
      "current PPL:  226.6201959768053\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8251.51879119873\n",
      "current PPL:  84.5918627962921\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8256.27666425705\n",
      "current PPL:  116.49787800832948\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8260.413498401642\n",
      "current PPL:  62.60431119048471\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8265.038251399994\n",
      "current PPL:  101.9775813409818\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  8269.327136993408\n",
      "current PPL:  72.88519947837895\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8273.796788215637\n",
      "current PPL:  87.32626024298425\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8278.239445209503\n",
      "current PPL:  85.00048767832928\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8282.771956443787\n",
      "current PPL:  92.99179228731484\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8287.61627960205\n",
      "current PPL:  127.01728229509713\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  8292.676082134247\n",
      "current PPL:  157.55940034248775\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8297.296661376953\n",
      "current PPL:  101.55283883742358\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  8301.98967409134\n",
      "current PPL:  109.18161784476129\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8306.898919582367\n",
      "current PPL:  135.53711185226592\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8311.94791316986\n",
      "current PPL:  155.86552051533735\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8317.539409160614\n",
      "current PPL:  268.1364494690836\n",
      "reps  torch.Size([64, 23, 1024])\n",
      "embs  torch.Size([64, 24, 512])\n",
      "val running loss:  8322.536449432373\n",
      "current PPL:  147.97454589238941\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8327.56208896637\n",
      "current PPL:  152.26760529045856\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8332.02394247055\n",
      "current PPL:  86.6479627108222\n",
      "reps  torch.Size([64, 23, 1024])\n",
      "embs  torch.Size([64, 24, 512])\n",
      "val running loss:  8337.057257175446\n",
      "current PPL:  153.44078158850834\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8341.382764339447\n",
      "current PPL:  75.60384668754837\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8345.815609931946\n",
      "current PPL:  84.170591656181\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8350.629159450531\n",
      "current PPL:  123.16802974308882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8355.404574394226\n",
      "current PPL:  118.5594999324375\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  8360.605324745178\n",
      "current PPL:  181.4083107177489\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8365.47215127945\n",
      "current PPL:  129.90800346279627\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8370.168060779572\n",
      "current PPL:  109.4983521321734\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8374.604787349701\n",
      "current PPL:  84.49789054858003\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8379.758862495422\n",
      "current PPL:  173.13560748245897\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8384.314571857452\n",
      "current PPL:  95.174244290798\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8388.56838607788\n",
      "current PPL:  70.37332044808329\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8392.99693107605\n",
      "current PPL:  83.80938534458585\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8397.493744373322\n",
      "current PPL:  89.73073004281872\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8402.476771354675\n",
      "current PPL:  145.91539703024827\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8407.014058589935\n",
      "current PPL:  93.43698344856104\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8411.78130197525\n",
      "current PPL:  117.59463166494237\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8416.504261016846\n",
      "current PPL:  112.500654746391\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8421.416547298431\n",
      "current PPL:  135.94987907350946\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8425.888662338257\n",
      "current PPL:  87.54168148995693\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8430.198850631714\n",
      "current PPL:  74.45450691705635\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8434.930322647095\n",
      "current PPL:  113.46245796534139\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8439.497990131378\n",
      "current PPL:  96.31918154575055\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8445.237460136414\n",
      "current PPL:  310.89959209035584\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8449.949938774109\n",
      "current PPL:  111.32775938992376\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8454.552523612976\n",
      "current PPL:  99.74179920107393\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8458.96988773346\n",
      "current PPL:  82.87754197910826\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8463.23940038681\n",
      "current PPL:  71.4867882818133\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8468.10363483429\n",
      "current PPL:  129.57170668635823\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8472.832662582397\n",
      "current PPL:  113.18546405411135\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8478.563302516937\n",
      "current PPL:  308.16641162209896\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8483.16924238205\n",
      "current PPL:  100.07699754031988\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  8488.106379032135\n",
      "current PPL:  139.37061085364198\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8492.902276039124\n",
      "current PPL:  121.01288251413892\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8497.054696559906\n",
      "current PPL:  63.58772959157772\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8501.96181678772\n",
      "current PPL:  135.24936569077173\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8506.854483127594\n",
      "current PPL:  133.30854649549076\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8511.520030975342\n",
      "current PPL:  106.22376373376137\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8516.265629291534\n",
      "current PPL:  115.07663712490395\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8520.33963727951\n",
      "current PPL:  58.7921291514387\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8525.272465229034\n",
      "current PPL:  138.7713964691039\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8529.805366039276\n",
      "current PPL:  93.02802671147673\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8534.446567058563\n",
      "current PPL:  103.66878105033928\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  8538.87999200821\n",
      "current PPL:  84.21937061889841\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8543.799810886383\n",
      "current PPL:  136.97780127003597\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  8548.81015586853\n",
      "current PPL:  149.95645952810958\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8553.519844532013\n",
      "current PPL:  111.01759069459985\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8558.12725353241\n",
      "current PPL:  100.2241322424927\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8562.92370223999\n",
      "current PPL:  121.07966381301375\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8567.806010246277\n",
      "current PPL:  131.93481914670107\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8572.585257530212\n",
      "current PPL:  119.01473201988371\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8577.011474609375\n",
      "current PPL:  83.61451079761818\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8581.726554870605\n",
      "current PPL:  111.61776939371806\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8586.526149272919\n",
      "current PPL:  121.46114316792799\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8591.568068027496\n",
      "current PPL:  154.76668960616365\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8596.069870471954\n",
      "current PPL:  90.17952849195264\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8601.245431423187\n",
      "current PPL:  176.89581637635388\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8605.766911506653\n",
      "current PPL:  91.97162296761255\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8610.65788936615\n",
      "current PPL:  133.08364755277785\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8615.317698001862\n",
      "current PPL:  105.61586911706426\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8620.048502922058\n",
      "current PPL:  113.38679294672168\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8624.618983745575\n",
      "current PPL:  96.59054161310218\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8629.701152324677\n",
      "current PPL:  161.12308549870048\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8635.390471935272\n",
      "current PPL:  295.69236622964934\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8640.362083435059\n",
      "current PPL:  144.25917378363326\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8645.274694442749\n",
      "current PPL:  135.9940327167127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8650.035170555115\n",
      "current PPL:  116.80152331221589\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  8655.055648803711\n",
      "current PPL:  151.48373335582738\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8659.833190441132\n",
      "current PPL:  118.81190797922397\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8664.048007011414\n",
      "current PPL:  67.68174988793967\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8668.852251052856\n",
      "current PPL:  122.02720863217795\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  8674.605808258057\n",
      "current PPL:  315.31029113402997\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  8679.631061553955\n",
      "current PPL:  152.20880509635072\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8684.216055870056\n",
      "current PPL:  98.00263010348168\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8688.972292423248\n",
      "current PPL:  116.30738454796611\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8694.005662441254\n",
      "current PPL:  153.44926911012624\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8698.520022392273\n",
      "current PPL:  91.31909861739308\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8703.038844585419\n",
      "current PPL:  91.72749705489505\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8708.510009765625\n",
      "current PPL:  237.73703793349205\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8713.363469600677\n",
      "current PPL:  128.18311596246895\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8718.050726890564\n",
      "current PPL:  108.55503613799524\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8723.422599315643\n",
      "current PPL:  215.26555921363357\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8728.56563282013\n",
      "current PPL:  171.23442164123014\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8733.234912872314\n",
      "current PPL:  106.62095327133859\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8738.89186000824\n",
      "current PPL:  286.27335353011136\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8743.605154037476\n",
      "current PPL:  111.41857212209145\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8748.048207759857\n",
      "current PPL:  85.03421648578076\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8752.580909252167\n",
      "current PPL:  93.00948640533169\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8757.077677726746\n",
      "current PPL:  89.7267081600014\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8761.64450931549\n",
      "current PPL:  96.23870241240114\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8766.291941165924\n",
      "current PPL:  104.31674028617192\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8770.89903640747\n",
      "current PPL:  100.19269096675546\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8775.447566509247\n",
      "current PPL:  94.49341048737726\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8779.764523506165\n",
      "current PPL:  74.96017682991591\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8785.557882785797\n",
      "current PPL:  328.1133997678738\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8790.293787956238\n",
      "current PPL:  113.9665712154667\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  8795.157060623169\n",
      "current PPL:  129.44714704840385\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8800.071527004242\n",
      "current PPL:  136.24658664367075\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8805.35406446457\n",
      "current PPL:  196.8687888388443\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8810.640709877014\n",
      "current PPL:  197.67917978087024\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8815.222975730896\n",
      "current PPL:  97.7355980889\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8820.404549121857\n",
      "current PPL:  177.96259556959498\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8824.844475746155\n",
      "current PPL:  84.76872148118709\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8829.397822380066\n",
      "current PPL:  94.9496388728737\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8834.026840686798\n",
      "current PPL:  102.41347612525131\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8838.781552314758\n",
      "current PPL:  116.13015964431554\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  8843.704154014587\n",
      "current PPL:  137.35951693867952\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8847.971097946167\n",
      "current PPL:  71.30339425735066\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8852.4010887146\n",
      "current PPL:  83.93064209531447\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  8857.890442848206\n",
      "current PPL:  242.1007915864508\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8862.998414039612\n",
      "current PPL:  165.33458215848918\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8867.700310230255\n",
      "current PPL:  110.1558510364492\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8872.328595161438\n",
      "current PPL:  102.3383961202256\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  8876.836998939514\n",
      "current PPL:  90.77680287982398\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8881.671298980713\n",
      "current PPL:  125.75053220265059\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8886.669559001923\n",
      "current PPL:  148.1551478856564\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8891.294199466705\n",
      "current PPL:  101.9661060854491\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8896.03968334198\n",
      "current PPL:  115.06346840244933\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  8901.219502925873\n",
      "current PPL:  177.65075704390395\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  8906.138922691345\n",
      "current PPL:  136.92314259794776\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8910.600311756134\n",
      "current PPL:  86.60772932740224\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8915.18714427948\n",
      "current PPL:  98.18294492538676\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8920.419958114624\n",
      "current PPL:  187.31914785117073\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8924.998439788818\n",
      "current PPL:  97.36644792965302\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8930.00095319748\n",
      "current PPL:  148.78665119456488\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8934.906165599823\n",
      "current PPL:  134.99157948984026\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8939.210576057434\n",
      "current PPL:  74.02556137985297\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8943.732038497925\n",
      "current PPL:  91.97000032889542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8948.400472164154\n",
      "current PPL:  106.53074897310515\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8953.601494312286\n",
      "current PPL:  181.45762368632174\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8958.376739501953\n",
      "current PPL:  118.53937568786245\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  8962.877357006073\n",
      "current PPL:  90.07273441576856\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  8967.863069534302\n",
      "current PPL:  146.30778632284526\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  8972.514125823975\n",
      "current PPL:  104.69551598310082\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  8977.343399524689\n",
      "current PPL:  125.12005304052009\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  8981.91719675064\n",
      "current PPL:  96.91140648496967\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  8986.455513954163\n",
      "current PPL:  93.53327015359687\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8990.779997825623\n",
      "current PPL:  75.52652140506387\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  8995.468241214752\n",
      "current PPL:  108.6621349733343\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9000.226907730103\n",
      "current PPL:  116.59035075048308\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9005.043651103973\n",
      "current PPL:  123.56203947600868\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  9010.138597488403\n",
      "current PPL:  163.19509459179176\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9014.900494098663\n",
      "current PPL:  116.9675575278384\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9020.02452135086\n",
      "current PPL:  168.01063016568972\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9024.5133228302\n",
      "current PPL:  89.0146959682533\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9029.5062789917\n",
      "current PPL:  147.37143395743394\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9033.923158168793\n",
      "current PPL:  82.83736080653941\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9039.302913188934\n",
      "current PPL:  216.96911585042295\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9043.828498840332\n",
      "current PPL:  92.34999489788946\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9048.286558151245\n",
      "current PPL:  86.31982649379839\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9053.243216514587\n",
      "current PPL:  142.11809449474023\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9057.887106895447\n",
      "current PPL:  103.94795912346373\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9062.313206195831\n",
      "current PPL:  83.60466336262782\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  9066.895651340485\n",
      "current PPL:  97.75312275064097\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9071.752656459808\n",
      "current PPL:  128.63836806955652\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9076.773781299591\n",
      "current PPL:  151.581713075715\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9081.890053272247\n",
      "current PPL:  166.7127001731088\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9086.309258460999\n",
      "current PPL:  83.03026573605392\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9090.934348583221\n",
      "current PPL:  102.01196621359837\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9095.543148994446\n",
      "current PPL:  100.36368224846571\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9099.934789180756\n",
      "current PPL:  80.77279282091078\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9105.457367897034\n",
      "current PPL:  250.27960584633013\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9110.099647045135\n",
      "current PPL:  103.78060962234498\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9114.321438789368\n",
      "current PPL:  68.15549216330172\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9118.688933372498\n",
      "current PPL:  78.84584232710647\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9124.190803527832\n",
      "current PPL:  245.1499723562086\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9129.018009662628\n",
      "current PPL:  124.8616263323869\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9134.602352142334\n",
      "current PPL:  266.2251767213752\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9139.792879581451\n",
      "current PPL:  179.56323663474683\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9144.148437976837\n",
      "current PPL:  77.91031795470701\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9149.359189987183\n",
      "current PPL:  183.23179860428755\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9153.79671049118\n",
      "current PPL:  84.5650029235641\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9158.514227867126\n",
      "current PPL:  111.89012644991604\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9163.33972978592\n",
      "current PPL:  124.64901636868763\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9167.895203113556\n",
      "current PPL:  95.15178254676438\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9172.885091781616\n",
      "current PPL:  146.9200656892449\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9177.262800216675\n",
      "current PPL:  79.65528883224087\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9181.927392959595\n",
      "current PPL:  106.12235733876109\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9186.609415054321\n",
      "current PPL:  107.98821434416315\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9191.509819507599\n",
      "current PPL:  134.3441046116824\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9195.76898431778\n",
      "current PPL:  70.75086836658419\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9200.754562854767\n",
      "current PPL:  146.28818367424225\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9205.25079536438\n",
      "current PPL:  89.67863067300448\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9209.767918586731\n",
      "current PPL:  91.57178702717943\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9214.467525959015\n",
      "current PPL:  109.9040126183438\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9220.252280712128\n",
      "current PPL:  325.3022509645613\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9225.01067829132\n",
      "current PPL:  116.55899960549974\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9229.454582214355\n",
      "current PPL:  85.10654337399785\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9234.208921909332\n",
      "current PPL:  116.08697503896387\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9238.97041606903\n",
      "current PPL:  116.92049333977099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  9243.536974906921\n",
      "current PPL:  96.21245680350178\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9248.713544845581\n",
      "current PPL:  177.0743921061067\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9253.244646549225\n",
      "current PPL:  92.86080984042219\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9257.728652954102\n",
      "current PPL:  88.58888558492015\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9262.401862621307\n",
      "current PPL:  107.04075686387932\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9266.850671768188\n",
      "current PPL:  85.52503557989854\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9271.515924930573\n",
      "current PPL:  106.19246575705884\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  9277.096562862396\n",
      "current PPL:  265.2407573469706\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9281.929120540619\n",
      "current PPL:  125.53161989884732\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9286.912233352661\n",
      "current PPL:  145.92792158672268\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9291.42507982254\n",
      "current PPL:  91.1809934200694\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9296.195345401764\n",
      "current PPL:  117.95056302032921\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9301.191756725311\n",
      "current PPL:  147.88150682782137\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9305.951966285706\n",
      "current PPL:  116.77039378491308\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9311.2142329216\n",
      "current PPL:  192.91827157843005\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9315.6919131279\n",
      "current PPL:  88.03022366919811\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9320.466251850128\n",
      "current PPL:  118.43197228990665\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9324.84665966034\n",
      "current PPL:  79.8705988101488\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9329.609407901764\n",
      "current PPL:  117.06721317397432\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9334.741335391998\n",
      "current PPL:  169.34321105895208\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9339.105696678162\n",
      "current PPL:  78.59918152109563\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9344.577360630035\n",
      "current PPL:  237.85564400854008\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9349.134282112122\n",
      "current PPL:  95.28967684605657\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9353.79561471939\n",
      "current PPL:  105.77694740582179\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9358.529767990112\n",
      "current PPL:  113.76708799966703\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9363.529663562775\n",
      "current PPL:  148.3976615206995\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9367.49153828621\n",
      "current PPL:  52.55576116794015\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9372.987913370132\n",
      "current PPL:  243.80655023240166\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  9377.60749745369\n",
      "current PPL:  101.45182787006078\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9382.164632558823\n",
      "current PPL:  95.31003509157796\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9386.922410726547\n",
      "current PPL:  116.48682397989928\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9391.321451425552\n",
      "current PPL:  81.3727702315662\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9396.193310022354\n",
      "current PPL:  130.56335616443897\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9401.264850378036\n",
      "current PPL:  159.41970135601917\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9406.135213136673\n",
      "current PPL:  130.36820051032743\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9410.73355603218\n",
      "current PPL:  99.31959625189518\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9415.311008691788\n",
      "current PPL:  97.26630796598783\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  9420.458122491837\n",
      "current PPL:  171.93453605757597\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9425.097068071365\n",
      "current PPL:  103.43522584372126\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  9430.047642946243\n",
      "current PPL:  141.25614519392923\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9434.65776181221\n",
      "current PPL:  100.49609449188799\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9439.378979444504\n",
      "current PPL:  112.30491554026396\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9443.809117078781\n",
      "current PPL:  83.94296954518275\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9448.440307855606\n",
      "current PPL:  102.63620819100515\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9453.195615530014\n",
      "current PPL:  116.19939924640816\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9457.69357085228\n",
      "current PPL:  89.83326331588462\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9463.052941083908\n",
      "current PPL:  212.59102118180155\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9467.717818975449\n",
      "current PPL:  106.15262229737218\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9472.05236363411\n",
      "current PPL:  76.29021289202413\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  9476.563987970352\n",
      "current PPL:  91.06962612772216\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  9481.726633310318\n",
      "current PPL:  174.62578972391148\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9485.912197828293\n",
      "current PPL:  65.73059654842655\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9490.46570801735\n",
      "current PPL:  94.96516964488652\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9495.367778539658\n",
      "current PPL:  134.568117722677\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9500.174962759018\n",
      "current PPL:  122.3865182946556\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9504.799165010452\n",
      "current PPL:  101.92143296557285\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  9509.434506177902\n",
      "current PPL:  103.06307376394649\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9514.22401022911\n",
      "current PPL:  120.24172013734047\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9518.571888685226\n",
      "current PPL:  77.31426320612141\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9524.31021285057\n",
      "current PPL:  310.5435550174323\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9528.958840608597\n",
      "current PPL:  104.44156809431797\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9533.807470560074\n",
      "current PPL:  127.56549914532873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9538.192026853561\n",
      "current PPL:  80.20262888801484\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9542.943457365036\n",
      "current PPL:  115.7497474926072\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9547.595989465714\n",
      "current PPL:  104.8501408481991\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9552.39994597435\n",
      "current PPL:  121.9921268502465\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9557.197908639908\n",
      "current PPL:  121.26311216744178\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9562.031550645828\n",
      "current PPL:  125.66781113586872\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9566.76725268364\n",
      "current PPL:  113.94342323732705\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9571.229412794113\n",
      "current PPL:  86.67453359463303\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9576.433076620102\n",
      "current PPL:  181.93760997814587\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  9581.18046927452\n",
      "current PPL:  115.28330889793376\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9585.984570264816\n",
      "current PPL:  122.00975374846199\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9590.981301546097\n",
      "current PPL:  147.92883022986194\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9595.76221203804\n",
      "current PPL:  119.21284297942513\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9600.471756219864\n",
      "current PPL:  111.00155184761277\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9605.240042924881\n",
      "current PPL:  117.71738448510831\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9609.787817716599\n",
      "current PPL:  94.42206561110847\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  9614.637516260147\n",
      "current PPL:  127.7018874850875\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9619.060892820358\n",
      "current PPL:  83.37733919976257\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9624.062661886215\n",
      "current PPL:  148.675944128539\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9628.67273926735\n",
      "current PPL:  100.49192551468984\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9633.47256731987\n",
      "current PPL:  121.48952590492179\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9638.396183252335\n",
      "current PPL:  137.4989021161045\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9643.933385133743\n",
      "current PPL:  253.9663762807967\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9648.397052049637\n",
      "current PPL:  86.80523369670458\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9652.84345459938\n",
      "current PPL:  85.31945874362451\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9657.546438455582\n",
      "current PPL:  110.27572894333555\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9662.36929821968\n",
      "current PPL:  124.32010908833458\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9667.695027589798\n",
      "current PPL:  205.55823383466117\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9672.216567754745\n",
      "current PPL:  91.97714892501848\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9676.672958612442\n",
      "current PPL:  86.1759259806513\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9681.021742105484\n",
      "current PPL:  77.38426714254568\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9685.448445558548\n",
      "current PPL:  83.65518860495577\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9689.966496229172\n",
      "current PPL:  91.65675451827225\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9694.37266945839\n",
      "current PPL:  81.9552387415082\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9698.75283408165\n",
      "current PPL:  79.85117768435278\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  9703.58112692833\n",
      "current PPL:  124.99738869944925\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9708.254168748856\n",
      "current PPL:  107.02279193596742\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9713.16207242012\n",
      "current PPL:  135.35536743832992\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9717.677336454391\n",
      "current PPL:  91.40169601687326\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  9722.039300203323\n",
      "current PPL:  78.41096277791955\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9726.460895776749\n",
      "current PPL:  83.2289774148104\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9731.258517026901\n",
      "current PPL:  121.2217181395379\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9735.55008149147\n",
      "current PPL:  73.08071129543414\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9739.96296954155\n",
      "current PPL:  82.50740526327478\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9745.000767469406\n",
      "current PPL:  154.1302351559839\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9749.764956712723\n",
      "current PPL:  117.2360288523037\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9754.530274629593\n",
      "current PPL:  117.36842475940726\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9759.037712812424\n",
      "current PPL:  90.68919153592988\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9763.887645483017\n",
      "current PPL:  127.73178945089701\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9768.073102712631\n",
      "current PPL:  65.72354479877399\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9772.970053434372\n",
      "current PPL:  133.88091646496704\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9777.873603105545\n",
      "current PPL:  134.76731128338446\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9782.179786920547\n",
      "current PPL:  74.15695162277157\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9786.80058169365\n",
      "current PPL:  101.57472891984747\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9791.209161043167\n",
      "current PPL:  82.15267033198727\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9795.904919862747\n",
      "current PPL:  109.48185410412398\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9800.48940873146\n",
      "current PPL:  97.95310744671167\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  9805.536155462265\n",
      "current PPL:  155.51570616643318\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9809.882903814316\n",
      "current PPL:  77.22693939478499\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  9814.550683259964\n",
      "current PPL:  106.46107715746462\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9818.923644781113\n",
      "current PPL:  79.27806805928422\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9823.453920125961\n",
      "current PPL:  92.78410519063026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9828.80946469307\n",
      "current PPL:  211.77927298292394\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9833.460803747177\n",
      "current PPL:  104.72512433740289\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9838.211146116257\n",
      "current PPL:  115.6238637872671\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  9843.000120401382\n",
      "current PPL:  120.17803702234512\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9848.499606847763\n",
      "current PPL:  244.56630209844613\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9852.956454515457\n",
      "current PPL:  86.21530099795419\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9857.515768289566\n",
      "current PPL:  95.51791047171295\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9862.24375128746\n",
      "current PPL:  113.06727526599289\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9866.841274023056\n",
      "current PPL:  99.23817169570518\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9871.719050645828\n",
      "current PPL:  131.33832437620214\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9876.893295526505\n",
      "current PPL:  176.66316212911096\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9881.829766988754\n",
      "current PPL:  139.27793404580885\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9886.377677202225\n",
      "current PPL:  94.4348532785934\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9890.79367518425\n",
      "current PPL:  82.76439708507793\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9895.357728242874\n",
      "current PPL:  95.9716714275691\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9900.7510035038\n",
      "current PPL:  219.9225108559944\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9905.758552312851\n",
      "current PPL:  149.5377409880239\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9910.578216314316\n",
      "current PPL:  123.92344568764815\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9915.17093205452\n",
      "current PPL:  98.76227898508105\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  9920.361378908157\n",
      "current PPL:  179.54876702820755\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  9924.587060689926\n",
      "current PPL:  68.42113593327674\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9929.487047433853\n",
      "current PPL:  134.28799954161198\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  9934.317921876907\n",
      "current PPL:  125.32049839489754\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9939.069095373154\n",
      "current PPL:  115.72000186753607\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9943.678717851639\n",
      "current PPL:  100.44622186772074\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9948.30434679985\n",
      "current PPL:  102.06694772356273\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  9953.271477937698\n",
      "current PPL:  143.6142862157637\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9957.882558107376\n",
      "current PPL:  100.59274820980343\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9963.115934610367\n",
      "current PPL:  187.42457597045896\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9967.691093683243\n",
      "current PPL:  97.04347489384179\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  9972.745430231094\n",
      "current PPL:  156.70053254422325\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9977.449219465256\n",
      "current PPL:  110.36457835885003\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  9982.08060002327\n",
      "current PPL:  102.65568846106243\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9986.560574293137\n",
      "current PPL:  88.2324024149905\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  9991.044808626175\n",
      "current PPL:  88.60907978807796\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9995.069050073624\n",
      "current PPL:  55.93786087711548\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  9999.72631764412\n",
      "current PPL:  105.3478329986411\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10004.486418008804\n",
      "current PPL:  116.75764365508925\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10010.015635728836\n",
      "current PPL:  251.94674102392543\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10015.115717172623\n",
      "current PPL:  164.0352664091219\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10020.01804947853\n",
      "current PPL:  134.60335006038284\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10024.483538389206\n",
      "current PPL:  86.96353654919923\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10029.275662660599\n",
      "current PPL:  120.55719304318885\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10034.764937639236\n",
      "current PPL:  242.08162886439897\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10039.802879095078\n",
      "current PPL:  154.15235874564385\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10044.493529081345\n",
      "current PPL:  108.92395587866524\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10049.460652589798\n",
      "current PPL:  143.61319052989356\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10054.230686426163\n",
      "current PPL:  117.92323198665584\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10059.157531023026\n",
      "current PPL:  137.94355736116975\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10063.68116736412\n",
      "current PPL:  92.17015144367421\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10068.849794149399\n",
      "current PPL:  175.6734344265214\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10073.46335721016\n",
      "current PPL:  100.84281936858055\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10077.86401963234\n",
      "current PPL:  81.50484140136162\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10082.548872232437\n",
      "current PPL:  108.29430856117902\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10087.652854204178\n",
      "current PPL:  164.67634000116178\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  10093.467171430588\n",
      "current PPL:  335.06254852447705\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10098.172977209091\n",
      "current PPL:  110.58735797189188\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10102.71901345253\n",
      "current PPL:  94.2580509065118\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10107.48830294609\n",
      "current PPL:  117.83548933686356\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10112.178046941757\n",
      "current PPL:  108.82531648838784\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10116.47574877739\n",
      "current PPL:  73.53061393572393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10121.194395303726\n",
      "current PPL:  112.01653858562916\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10125.92292189598\n",
      "current PPL:  113.12875470759276\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10130.454663991928\n",
      "current PPL:  92.92029623361893\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10135.001034498215\n",
      "current PPL:  94.28956313743596\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10139.577530145645\n",
      "current PPL:  97.17326745245313\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10143.686368227005\n",
      "current PPL:  60.875943567201645\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10148.43469119072\n",
      "current PPL:  115.39060793474226\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  10153.873351812363\n",
      "current PPL:  230.13374079441664\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10158.725212335587\n",
      "current PPL:  127.97827503480276\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10163.48577094078\n",
      "current PPL:  116.81115899766374\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10168.651688814163\n",
      "current PPL:  175.19819455232727\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10173.118685007095\n",
      "current PPL:  87.09471398072515\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10177.988372087479\n",
      "current PPL:  130.28014330485672\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  10182.702465772629\n",
      "current PPL:  111.50770427502948\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10187.53708910942\n",
      "current PPL:  125.79119336799566\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10192.023673295975\n",
      "current PPL:  88.81754297879053\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10196.81758236885\n",
      "current PPL:  120.77255583288034\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10202.417021036148\n",
      "current PPL:  270.27465083696075\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10206.892756700516\n",
      "current PPL:  87.85921153208685\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10211.513843297958\n",
      "current PPL:  101.60437522370465\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10215.876213788986\n",
      "current PPL:  78.4428623042654\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10220.139405488968\n",
      "current PPL:  71.03634873003\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10225.995570421219\n",
      "current PPL:  349.3816690530014\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10230.294181585312\n",
      "current PPL:  73.59750782535737\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10235.249900102615\n",
      "current PPL:  141.98458811413374\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10239.703479528427\n",
      "current PPL:  85.93398848939775\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10244.490649938583\n",
      "current PPL:  119.96144627952033\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10248.792494535446\n",
      "current PPL:  73.835865568131\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10253.47868180275\n",
      "current PPL:  108.43894192062236\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10258.112910985947\n",
      "current PPL:  102.9485329444588\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10262.785738229752\n",
      "current PPL:  106.99982979983909\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  10267.835552453995\n",
      "current PPL:  155.99348198717786\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10272.82367348671\n",
      "current PPL:  146.66059398141707\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10277.828426122665\n",
      "current PPL:  149.12019162208622\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10282.31522154808\n",
      "current PPL:  88.83630667715501\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10287.100951910019\n",
      "current PPL:  119.78882033727598\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10291.882109880447\n",
      "current PPL:  119.24234924414328\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10296.299221277237\n",
      "current PPL:  82.8565995070032\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10301.253409147263\n",
      "current PPL:  141.767426032516\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10305.665692090988\n",
      "current PPL:  82.45749461026728\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10310.016636610031\n",
      "current PPL:  77.55167737969396\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10314.812757253647\n",
      "current PPL:  121.03994845338669\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10319.016780614853\n",
      "current PPL:  66.95517470313247\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10323.620875120163\n",
      "current PPL:  99.89248976590405\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10329.076110601425\n",
      "current PPL:  233.97996247961402\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10334.394563913345\n",
      "current PPL:  204.06800822104876\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10338.924090623856\n",
      "current PPL:  92.71466981752403\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  10343.985243082047\n",
      "current PPL:  157.7722374976298\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  10348.763707876205\n",
      "current PPL:  118.92164063509037\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10352.90437912941\n",
      "current PPL:  62.84499219638254\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10357.187081575394\n",
      "current PPL:  72.43592992579451\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10362.076095342636\n",
      "current PPL:  132.82251551904935\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10366.603787183762\n",
      "current PPL:  92.54470648629898\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10370.848671674728\n",
      "current PPL:  69.7477031888231\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10375.48759007454\n",
      "current PPL:  103.4324145416551\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10380.446989297867\n",
      "current PPL:  142.50815459901335\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10384.780736207962\n",
      "current PPL:  76.22937675331212\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10389.320419073105\n",
      "current PPL:  93.6610922119147\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10393.900243520737\n",
      "current PPL:  97.49727682676316\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10398.726940870285\n",
      "current PPL:  124.79811473714376\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10403.40600657463\n",
      "current PPL:  107.66943048298764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10407.94863820076\n",
      "current PPL:  93.93768398766666\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10412.777714967728\n",
      "current PPL:  125.09541510583284\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10417.185703516006\n",
      "current PPL:  82.10414876727847\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10421.564593076706\n",
      "current PPL:  79.74942732005829\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10426.186033964157\n",
      "current PPL:  101.64037901618623\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10431.908327817917\n",
      "current PPL:  305.6051330435459\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10436.228521585464\n",
      "current PPL:  75.20319881973732\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10441.118757009506\n",
      "current PPL:  132.98487820378125\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10445.438120126724\n",
      "current PPL:  75.14075719501986\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10449.653447389603\n",
      "current PPL:  67.71632328395852\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10454.091116189957\n",
      "current PPL:  84.57754453527448\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10458.369668245316\n",
      "current PPL:  72.13591554042762\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10462.977790117264\n",
      "current PPL:  100.29560464743885\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10467.514297246933\n",
      "current PPL:  93.36412115921819\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10472.106801271439\n",
      "current PPL:  98.74137167350686\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10476.642898321152\n",
      "current PPL:  93.3258422537585\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10481.179508924484\n",
      "current PPL:  93.3737823866908\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10485.968628168106\n",
      "current PPL:  120.19545911256488\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  10490.669973611832\n",
      "current PPL:  110.09519974431072\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10495.183450937271\n",
      "current PPL:  91.23853360462674\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10499.825665712357\n",
      "current PPL:  103.77392916648704\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10504.458963632584\n",
      "current PPL:  102.85270541515514\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10509.199682474136\n",
      "current PPL:  114.51649131244041\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10514.055434942245\n",
      "current PPL:  128.47732994490883\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  10518.9628636837\n",
      "current PPL:  135.29109840229665\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10524.049523591995\n",
      "current PPL:  161.84836984245393\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10529.217336893082\n",
      "current PPL:  175.53058497544237\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10533.440190553665\n",
      "current PPL:  68.22790603679535\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10537.92626786232\n",
      "current PPL:  88.77253473700117\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10542.198227643967\n",
      "current PPL:  71.66193984596799\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10547.025957345963\n",
      "current PPL:  124.92701690112135\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10551.25430560112\n",
      "current PPL:  68.60382252769374\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10556.074180364609\n",
      "current PPL:  123.94956679644532\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10560.312443494797\n",
      "current PPL:  69.2874040675085\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10565.128065824509\n",
      "current PPL:  123.42359858706156\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10570.726103067398\n",
      "current PPL:  269.8961466288913\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10575.693932771683\n",
      "current PPL:  143.714645385647\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10580.129222631454\n",
      "current PPL:  84.37657871987538\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10585.122435808182\n",
      "current PPL:  147.40931552803494\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10589.551354169846\n",
      "current PPL:  83.84068255185504\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10594.028732538223\n",
      "current PPL:  88.00365681913118\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10598.454592943192\n",
      "current PPL:  83.58469297728428\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  10603.467639684677\n",
      "current PPL:  150.3621535900697\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10607.868216753006\n",
      "current PPL:  81.49788494613126\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10612.426179170609\n",
      "current PPL:  95.38891889835521\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10616.923063516617\n",
      "current PPL:  89.73710552430224\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10621.580235242844\n",
      "current PPL:  105.33773649647146\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10625.94791674614\n",
      "current PPL:  78.860581582533\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10630.386005163193\n",
      "current PPL:  84.61304213251182\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10635.626891851425\n",
      "current PPL:  188.83746815493362\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10640.290072202682\n",
      "current PPL:  105.97257680532807\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10645.088402986526\n",
      "current PPL:  121.30775955371946\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10649.478791952133\n",
      "current PPL:  80.67179143097601\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10654.143100976944\n",
      "current PPL:  106.09225277500732\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10658.858554124832\n",
      "current PPL:  111.6593979315697\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10663.897820711136\n",
      "current PPL:  154.3567661354249\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  10669.417120695114\n",
      "current PPL:  249.4603498131908\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10673.985816717148\n",
      "current PPL:  96.41830042505947\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10678.46203827858\n",
      "current PPL:  87.90191243831636\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10682.99713921547\n",
      "current PPL:  93.23292547100925\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10687.324886083603\n",
      "current PPL:  75.77336670185063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10692.33440899849\n",
      "current PPL:  149.83323588819428\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10697.059138536453\n",
      "current PPL:  112.70001317667476\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10701.448683977127\n",
      "current PPL:  80.6037714558311\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10706.646736860275\n",
      "current PPL:  180.91962704077906\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10711.30608868599\n",
      "current PPL:  105.56763375018845\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10716.176478624344\n",
      "current PPL:  130.37174392941012\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10720.792486906052\n",
      "current PPL:  101.08970406368347\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10725.013176679611\n",
      "current PPL:  68.08042817651273\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10730.109173059464\n",
      "current PPL:  163.3665386860711\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10734.52978348732\n",
      "current PPL:  83.14702513060328\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10739.238028287888\n",
      "current PPL:  110.85741217821628\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  10743.783107995987\n",
      "current PPL:  94.16793285722157\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10748.445670366287\n",
      "current PPL:  105.90710800221521\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10752.630793333054\n",
      "current PPL:  65.70157953080647\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  10757.76895737648\n",
      "current PPL:  170.40262912721562\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10763.313173532486\n",
      "current PPL:  255.75402839450797\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  10767.953368902206\n",
      "current PPL:  103.56457898976126\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10772.64743733406\n",
      "current PPL:  109.29694365095588\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10777.188703298569\n",
      "current PPL:  93.80948445638481\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10781.945756196976\n",
      "current PPL:  116.40237029009583\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10786.330707788467\n",
      "current PPL:  80.23433909421958\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10790.539150953293\n",
      "current PPL:  67.25175836458708\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10795.184335947037\n",
      "current PPL:  104.08261863782815\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10799.640945196152\n",
      "current PPL:  86.19474811858495\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  10804.352694749832\n",
      "current PPL:  111.24662168183589\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10809.029426336288\n",
      "current PPL:  107.41841040834406\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10813.811373472214\n",
      "current PPL:  119.33648833270188\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10818.47044301033\n",
      "current PPL:  105.53783752221753\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10823.055799245834\n",
      "current PPL:  98.03810557611233\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10827.784070253372\n",
      "current PPL:  113.09984442153025\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10832.285735845566\n",
      "current PPL:  90.16718806370264\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10836.685630083084\n",
      "current PPL:  81.44225467448888\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10841.6007874012\n",
      "current PPL:  136.34075698640382\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10846.372474908829\n",
      "current PPL:  118.11839957386611\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10850.978206396103\n",
      "current PPL:  100.05614588451235\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10855.655467748642\n",
      "current PPL:  107.47533211510633\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10860.203393697739\n",
      "current PPL:  94.43633928183836\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10865.805973291397\n",
      "current PPL:  271.1248981956748\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10870.870907068253\n",
      "current PPL:  158.36995397005668\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10875.348724126816\n",
      "current PPL:  88.04227162901974\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10880.50420832634\n",
      "current PPL:  173.37973682382508\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10884.757737398148\n",
      "current PPL:  70.35325645357622\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10889.836781740189\n",
      "current PPL:  160.62048431511613\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10895.196338415146\n",
      "current PPL:  212.630661054656\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10899.709549665451\n",
      "current PPL:  91.21426052892076\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  10905.112128019333\n",
      "current PPL:  221.97801687461188\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10910.170933485031\n",
      "current PPL:  157.40238143514662\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10914.931957483292\n",
      "current PPL:  116.8655347532085\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  10919.904567480087\n",
      "current PPL:  144.4032880740876\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10924.514895677567\n",
      "current PPL:  100.51713369335052\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10928.91285443306\n",
      "current PPL:  81.28477710114574\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10933.887330770493\n",
      "current PPL:  144.67304545004086\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10938.488351106644\n",
      "current PPL:  99.58587488912771\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10943.062828302383\n",
      "current PPL:  96.97732572245815\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10947.85835814476\n",
      "current PPL:  120.96845902197202\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  10952.351531267166\n",
      "current PPL:  89.40468827917859\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10956.938843488693\n",
      "current PPL:  98.23005440374983\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  10961.79055762291\n",
      "current PPL:  127.95954179333388\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10966.266518831253\n",
      "current PPL:  87.87902988283989\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10970.707815408707\n",
      "current PPL:  84.88493024077309\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10975.38983464241\n",
      "current PPL:  107.98790538784564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  10979.883877515793\n",
      "current PPL:  89.48248191976207\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10984.58855843544\n",
      "current PPL:  110.46303274017141\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  10989.341912031174\n",
      "current PPL:  115.97255818319569\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  10993.904724359512\n",
      "current PPL:  95.8526703076777\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  10998.619262456894\n",
      "current PPL:  111.5572706758513\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11003.504339933395\n",
      "current PPL:  132.3007151337802\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11007.739270925522\n",
      "current PPL:  69.05691309836106\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11012.006843328476\n",
      "current PPL:  71.34822048407165\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11016.611767053604\n",
      "current PPL:  99.97535695090652\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11021.279662370682\n",
      "current PPL:  106.47341366936577\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11025.912144422531\n",
      "current PPL:  102.76882536743956\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11030.609342813492\n",
      "current PPL:  109.639574545668\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11035.128787279129\n",
      "current PPL:  91.78459431620742\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11039.637375593185\n",
      "current PPL:  90.79355601185534\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11044.568725824356\n",
      "current PPL:  138.56648286921444\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11049.031866312027\n",
      "current PPL:  86.75954899772485\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  11053.890391111374\n",
      "current PPL:  128.8340058434855\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  11058.97156739235\n",
      "current PPL:  160.96328266200948\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11063.176378965378\n",
      "current PPL:  67.00797036776181\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11068.075408220291\n",
      "current PPL:  134.15948179436703\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11072.47965836525\n",
      "current PPL:  81.79778336044731\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11077.23328948021\n",
      "current PPL:  116.00474726412635\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11081.852329969406\n",
      "current PPL:  101.39669421511286\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11086.28871512413\n",
      "current PPL:  84.46904659119953\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11091.041944742203\n",
      "current PPL:  115.95818106791552\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11095.490400075912\n",
      "current PPL:  85.49478104836855\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11100.039057016373\n",
      "current PPL:  94.50539666735747\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11105.356162786484\n",
      "current PPL:  203.79320324525608\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11110.52510046959\n",
      "current PPL:  175.7280594065261\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11115.09171128273\n",
      "current PPL:  96.21745759997845\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11119.457431554794\n",
      "current PPL:  78.70606931365454\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11123.952763319016\n",
      "current PPL:  89.59788942878963\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11128.659769296646\n",
      "current PPL:  110.72016450360844\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11133.088029623032\n",
      "current PPL:  83.78553057294147\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11137.5630133152\n",
      "current PPL:  87.79316868193946\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11142.21733880043\n",
      "current PPL:  105.03834618289882\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11147.414945840836\n",
      "current PPL:  180.83898331655658\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11152.045784711838\n",
      "current PPL:  102.60009626608834\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11156.534470319748\n",
      "current PPL:  89.00438230573096\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  11161.27860713005\n",
      "current PPL:  114.90857478392257\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11166.146502256393\n",
      "current PPL:  130.0468963220127\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11170.670122861862\n",
      "current PPL:  92.16870110003346\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11174.963097333908\n",
      "current PPL:  73.1838283255787\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  11180.157181024551\n",
      "current PPL:  180.20294547759949\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11184.983333349228\n",
      "current PPL:  124.73011519305967\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  11189.985210180283\n",
      "current PPL:  148.69196708440225\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  11194.617540597916\n",
      "current PPL:  102.75324327856279\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11199.372999429703\n",
      "current PPL:  116.21696497061808\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11203.845173120499\n",
      "current PPL:  87.54681604510378\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11208.44455075264\n",
      "current PPL:  99.422419064633\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11214.213553190231\n",
      "current PPL:  320.21813569023703\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11218.600162267685\n",
      "current PPL:  80.36743665813245\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  11223.533588171005\n",
      "current PPL:  138.85440016616724\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11228.188190698624\n",
      "current PPL:  105.06745028860244\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  11232.831113576889\n",
      "current PPL:  103.84743783851454\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11237.390261411667\n",
      "current PPL:  95.50206160855677\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11241.743112802505\n",
      "current PPL:  77.69969957081297\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11246.323102235794\n",
      "current PPL:  97.51336380603455\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11250.813131093979\n",
      "current PPL:  89.12401779892505\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11255.386303186417\n",
      "current PPL:  96.85084284899948\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11259.674802541733\n",
      "current PPL:  72.85705387335192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11264.129418611526\n",
      "current PPL:  86.02311763102124\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11268.50743174553\n",
      "current PPL:  79.67956341267109\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11273.091217756271\n",
      "current PPL:  97.88428451354663\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  11278.28396487236\n",
      "current PPL:  179.96225169446328\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11283.60499739647\n",
      "current PPL:  204.59502226354533\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11288.394786119461\n",
      "current PPL:  120.2759544347948\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11293.513097047806\n",
      "current PPL:  167.05296675782864\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11298.63951086998\n",
      "current PPL:  168.4120781427277\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11303.243499994278\n",
      "current PPL:  99.88196354888647\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11307.610557794571\n",
      "current PPL:  78.81141133639625\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11312.520769834518\n",
      "current PPL:  135.6681784322299\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11316.91159081459\n",
      "current PPL:  80.70665034105299\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11321.565962553024\n",
      "current PPL:  105.04320465534803\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11326.161569833755\n",
      "current PPL:  99.04826739161061\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11330.517968416214\n",
      "current PPL:  77.9758047033942\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11335.452879667282\n",
      "current PPL:  139.06080048690464\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  11340.14744067192\n",
      "current PPL:  109.35079361224294\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11344.67630314827\n",
      "current PPL:  92.65310601522427\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11349.244852781296\n",
      "current PPL:  96.40418687880803\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11353.812123060226\n",
      "current PPL:  96.28093064849836\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  11358.988939523697\n",
      "current PPL:  177.11805071836105\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11363.497357606888\n",
      "current PPL:  90.77810146169361\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11368.064993619919\n",
      "current PPL:  96.31615030817184\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11372.675845861435\n",
      "current PPL:  100.5698229023924\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11377.19808793068\n",
      "current PPL:  92.04173074353976\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  11382.449502706528\n",
      "current PPL:  190.8360678205711\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11386.893069982529\n",
      "current PPL:  85.07789733069656\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11392.149659872055\n",
      "current PPL:  191.8262260462387\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11396.895886659622\n",
      "current PPL:  115.14898222824408\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11401.48497080803\n",
      "current PPL:  98.4042651763544\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11406.800350427628\n",
      "current PPL:  203.44172893903834\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11411.64273095131\n",
      "current PPL:  126.77077364557022\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11416.80594420433\n",
      "current PPL:  174.72499015565262\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11421.457485437393\n",
      "current PPL:  104.74629969414546\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11426.170731306076\n",
      "current PPL:  111.41320627125818\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  11431.767036676407\n",
      "current PPL:  269.42912542620843\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11436.497968912125\n",
      "current PPL:  113.40122976436344\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11441.040848016739\n",
      "current PPL:  93.96093442026668\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11445.721181631088\n",
      "current PPL:  107.80603221203498\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  11450.831504583359\n",
      "current PPL:  165.72386713147947\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11455.777420759201\n",
      "current PPL:  140.59960582363286\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11460.488942861557\n",
      "current PPL:  111.22132136779638\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11464.769531011581\n",
      "current PPL:  72.2829407210521\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11469.134767770767\n",
      "current PPL:  78.66802311418665\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11474.446191072464\n",
      "current PPL:  202.63843886813387\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11479.10822224617\n",
      "current PPL:  105.85086544638835\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11483.92284989357\n",
      "current PPL:  123.30089235363921\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11488.654591321945\n",
      "current PPL:  113.4930303440052\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11494.06932759285\n",
      "current PPL:  224.69327970846567\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11498.418755292892\n",
      "current PPL:  77.43413468997244\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11502.942420721054\n",
      "current PPL:  92.17283244200344\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11507.485909223557\n",
      "current PPL:  94.01821146575686\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11512.961147546768\n",
      "current PPL:  238.70734965437242\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11517.444068193436\n",
      "current PPL:  88.49275167368569\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11522.347319841385\n",
      "current PPL:  134.7271534790789\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11527.878893613815\n",
      "current PPL:  252.54104057298173\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11532.324208021164\n",
      "current PPL:  85.22666951654696\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11537.171264886856\n",
      "current PPL:  127.36498542596806\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11541.797116041183\n",
      "current PPL:  102.08963014355294\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11546.068844079971\n",
      "current PPL:  71.64533462729946\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11550.528927564621\n",
      "current PPL:  86.49472977712992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11555.403321504593\n",
      "current PPL:  130.89479906096452\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  11560.215672254562\n",
      "current PPL:  123.02046823829389\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11565.10557770729\n",
      "current PPL:  132.94100424781936\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11569.664159059525\n",
      "current PPL:  95.44797667827552\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11574.171726465225\n",
      "current PPL:  90.70091141074823\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  11579.586173295975\n",
      "current PPL:  224.62825386175234\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11584.89493393898\n",
      "current PPL:  202.09959955860705\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11589.093189001083\n",
      "current PPL:  66.57006899921895\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11593.83170390129\n",
      "current PPL:  114.26438160208397\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11598.201869249344\n",
      "current PPL:  79.05670249075148\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11603.24510216713\n",
      "current PPL:  154.97021199699756\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  11607.911394357681\n",
      "current PPL:  106.30286006164495\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11612.40567946434\n",
      "current PPL:  89.50416018002697\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11617.675090551376\n",
      "current PPL:  194.30150207163305\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11622.503777742386\n",
      "current PPL:  125.04669043121721\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11626.938794851303\n",
      "current PPL:  84.3535680741597\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11631.404344320297\n",
      "current PPL:  86.96880307425927\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11636.429185152054\n",
      "current PPL:  152.1460373677838\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11641.179201841354\n",
      "current PPL:  115.58621356414659\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11645.968482255936\n",
      "current PPL:  120.21483269122149\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11650.596578836441\n",
      "current PPL:  102.31912242914645\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11655.25836443901\n",
      "current PPL:  105.82487472048052\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11660.167223215103\n",
      "current PPL:  135.48470776020048\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11664.963685750961\n",
      "current PPL:  121.08133814779177\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11669.90617108345\n",
      "current PPL:  140.1180571319308\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11674.104433298111\n",
      "current PPL:  66.57054514715962\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11678.285777807236\n",
      "current PPL:  65.45379730767372\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11683.11421084404\n",
      "current PPL:  125.01491332729583\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11687.862736940384\n",
      "current PPL:  115.41404991317422\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  11692.554404973984\n",
      "current PPL:  109.03490208608461\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11697.309401273727\n",
      "current PPL:  116.1632233298994\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11701.595018148422\n",
      "current PPL:  72.6473472103294\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11706.169270277023\n",
      "current PPL:  96.95550176926122\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11710.497361898422\n",
      "current PPL:  75.79949432098222\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11715.231086969376\n",
      "current PPL:  113.71838338736801\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11719.767966508865\n",
      "current PPL:  93.39889734992107\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11724.391020536423\n",
      "current PPL:  101.80447150449\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11729.287740468979\n",
      "current PPL:  133.85002176264527\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11733.938900232315\n",
      "current PPL:  104.70634977217007\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11739.085589647293\n",
      "current PPL:  171.86158508806415\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  11743.946198701859\n",
      "current PPL:  129.10280882218197\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11749.014830827713\n",
      "current PPL:  158.95674574234488\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11753.871215105057\n",
      "current PPL:  128.55852875678573\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11758.510235071182\n",
      "current PPL:  103.44292032432813\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11762.969819784164\n",
      "current PPL:  86.45159941352654\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11767.770237207413\n",
      "current PPL:  121.56114937950917\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11772.322136640549\n",
      "current PPL:  94.81232706473996\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11776.935876607895\n",
      "current PPL:  100.8606607055252\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11781.440016508102\n",
      "current PPL:  90.39056569829309\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11786.03178191185\n",
      "current PPL:  98.66846617478173\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11790.262711286545\n",
      "current PPL:  68.78112591654205\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11794.73443865776\n",
      "current PPL:  87.50775090534621\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11799.651635885239\n",
      "current PPL:  136.61916363873618\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11804.684315443039\n",
      "current PPL:  153.3433550652317\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11809.180732011795\n",
      "current PPL:  89.69513836406665\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11813.719906568527\n",
      "current PPL:  93.61349558889997\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11818.37357878685\n",
      "current PPL:  104.96975051547822\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11822.960543870926\n",
      "current PPL:  98.19596099092823\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  11828.217039823532\n",
      "current PPL:  191.80820732768154\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  11832.891917943954\n",
      "current PPL:  107.21949842847619\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11837.843972921371\n",
      "current PPL:  141.46537357462125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11842.065881967545\n",
      "current PPL:  68.16348740373613\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11846.650685071945\n",
      "current PPL:  97.98389264539975\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11850.952740907669\n",
      "current PPL:  73.85146421974346\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11855.785944223404\n",
      "current PPL:  125.61269399104344\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11860.391162157059\n",
      "current PPL:  100.00477488066318\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11865.173139333725\n",
      "current PPL:  119.34007334308367\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  11869.734365224838\n",
      "current PPL:  95.70072661978195\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11874.435343503952\n",
      "current PPL:  110.0547841030844\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11879.08448958397\n",
      "current PPL:  104.49571648777157\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11883.525691270828\n",
      "current PPL:  84.87687584142937\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  11888.85502409935\n",
      "current PPL:  206.30029056230958\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11893.654833078384\n",
      "current PPL:  121.48720869820912\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11898.04848408699\n",
      "current PPL:  80.9353759617566\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11902.897858381271\n",
      "current PPL:  127.66048695401079\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  11907.619357824326\n",
      "current PPL:  112.33656873381582\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11912.060975790024\n",
      "current PPL:  84.91221564386767\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  11916.603070020676\n",
      "current PPL:  93.88721586302967\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11921.43458724022\n",
      "current PPL:  125.40107735924542\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11926.259996652603\n",
      "current PPL:  124.63748606915796\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  11931.27952170372\n",
      "current PPL:  151.33940823914187\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11936.177711725235\n",
      "current PPL:  134.04693790842757\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  11940.242007017136\n",
      "current PPL:  58.22386323377972\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11945.452117681503\n",
      "current PPL:  183.11432130307477\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11950.061146974564\n",
      "current PPL:  100.3866563013916\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11955.300258874893\n",
      "current PPL:  188.5026189319203\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11959.84455704689\n",
      "current PPL:  94.09436596934913\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11964.638284444809\n",
      "current PPL:  120.75061647693548\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11969.350020170212\n",
      "current PPL:  111.24508334330687\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11973.956285238266\n",
      "current PPL:  100.10954816682884\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11978.78242135048\n",
      "current PPL:  124.72809302702706\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11983.01130080223\n",
      "current PPL:  68.6402743252504\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  11988.061655759811\n",
      "current PPL:  156.07785567308233\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  11993.362374067307\n",
      "current PPL:  200.4807651027785\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  11997.837070703506\n",
      "current PPL:  87.76797074559302\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12002.72782444954\n",
      "current PPL:  133.05382505741196\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12007.302431821823\n",
      "current PPL:  96.9899507173067\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12012.626264333725\n",
      "current PPL:  205.16868858293918\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12018.034003019333\n",
      "current PPL:  223.12645769689934\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12022.909972906113\n",
      "current PPL:  131.1012449328391\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12028.476932287216\n",
      "current PPL:  261.63734907969774\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12032.882416963577\n",
      "current PPL:  81.89882765100955\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12037.483800649643\n",
      "current PPL:  99.62206598287638\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12042.315436601639\n",
      "current PPL:  125.41596742064222\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12047.247897863388\n",
      "current PPL:  138.7205200230019\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12052.295811414719\n",
      "current PPL:  155.697270990705\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12056.903265237808\n",
      "current PPL:  100.22862465867082\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12062.327765226364\n",
      "current PPL:  226.89786641716975\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12067.123074769974\n",
      "current PPL:  120.9418127547704\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12071.937484502792\n",
      "current PPL:  123.2740262186758\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12077.167053937912\n",
      "current PPL:  186.7123944109777\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12081.662265062332\n",
      "current PPL:  89.58708100921254\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12086.354316949844\n",
      "current PPL:  109.07676359367116\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12091.281546831131\n",
      "current PPL:  137.99671510495622\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  12096.287536382675\n",
      "current PPL:  149.30475483267057\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12100.908421754837\n",
      "current PPL:  101.58393191169823\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  12106.013227701187\n",
      "current PPL:  164.81208504164073\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12110.813901662827\n",
      "current PPL:  121.59233848162286\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12115.503558397293\n",
      "current PPL:  108.81582067500005\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12119.798928499222\n",
      "current PPL:  73.35935986200252\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12124.529040575027\n",
      "current PPL:  113.30826075166684\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12129.202285528183\n",
      "current PPL:  107.04453396528154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12134.012615919113\n",
      "current PPL:  122.77217362985566\n",
      "reps  torch.Size([64, 24, 1024])\n",
      "embs  torch.Size([64, 25, 512])\n",
      "val running loss:  12139.274705171585\n",
      "current PPL:  192.8840541099824\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12144.15040755272\n",
      "current PPL:  131.06617929999095\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12149.14997124672\n",
      "current PPL:  148.34841967494478\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12153.972973585129\n",
      "current PPL:  124.33783520575906\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12159.75374007225\n",
      "current PPL:  324.007442796163\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12164.119866609573\n",
      "current PPL:  78.73805135142806\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12169.056829690933\n",
      "current PPL:  139.34642257355716\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12174.165395498276\n",
      "current PPL:  165.4329219701708\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12178.49115395546\n",
      "current PPL:  75.62284780610791\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  12183.265668153763\n",
      "current PPL:  118.45275609094264\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12187.691488027573\n",
      "current PPL:  83.58130526150394\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12192.480157613754\n",
      "current PPL:  120.14142447954622\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12196.992845773697\n",
      "current PPL:  91.1665597053193\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  12202.120834589005\n",
      "current PPL:  168.6775350008985\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12206.81602883339\n",
      "current PPL:  109.42006081008186\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12211.403919935226\n",
      "current PPL:  98.2869343098406\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  12216.569273233414\n",
      "current PPL:  175.0993099139531\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12220.942679643631\n",
      "current PPL:  79.3133458519141\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12225.284034013748\n",
      "current PPL:  76.81150012213644\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12230.496465921402\n",
      "current PPL:  183.5398678995078\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12235.212308645248\n",
      "current PPL:  111.70290622285859\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12240.085919618607\n",
      "current PPL:  130.79235291457346\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12244.66176867485\n",
      "current PPL:  97.11045638288303\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12249.0723259449\n",
      "current PPL:  82.3153225890066\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12253.75948214531\n",
      "current PPL:  108.54406292075556\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12258.427762746811\n",
      "current PPL:  106.51444412089376\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12263.31741309166\n",
      "current PPL:  132.90709427564312\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12267.696996927261\n",
      "current PPL:  79.8048145706871\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12272.128723859787\n",
      "current PPL:  84.07648603029145\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12276.741696596146\n",
      "current PPL:  100.78330695909739\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12281.245938062668\n",
      "current PPL:  90.39974680117196\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12285.91541838646\n",
      "current PPL:  106.64230855928851\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12290.567520856857\n",
      "current PPL:  104.80510372822455\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12295.915190458298\n",
      "current PPL:  210.11806803000493\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12301.07484793663\n",
      "current PPL:  174.10481072077684\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12305.924000501633\n",
      "current PPL:  127.63218402424734\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12310.668210744858\n",
      "current PPL:  114.9170131661973\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12315.344336748123\n",
      "current PPL:  107.3533793174608\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  12320.241554021835\n",
      "current PPL:  133.91660744372743\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12325.044169187546\n",
      "current PPL:  121.82860326898228\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12329.47087597847\n",
      "current PPL:  83.6554678347386\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12334.11996626854\n",
      "current PPL:  104.48988683985311\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12338.433850049973\n",
      "current PPL:  74.73016167785035\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12344.078034162521\n",
      "current PPL:  282.6428573629405\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12348.691805124283\n",
      "current PPL:  100.86378687117544\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  12353.25882601738\n",
      "current PPL:  96.25692254210054\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12357.42879986763\n",
      "current PPL:  64.71375983665142\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12361.761091470718\n",
      "current PPL:  76.11852029185427\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12367.101607561111\n",
      "current PPL:  208.62034946909296\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12371.389683485031\n",
      "current PPL:  72.8262104397865\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12376.154407262802\n",
      "current PPL:  117.29871230075486\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12380.765677213669\n",
      "current PPL:  100.611840632794\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  12385.671699762344\n",
      "current PPL:  135.10098673474118\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12390.1816842556\n",
      "current PPL:  90.92040862006235\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12394.679967164993\n",
      "current PPL:  89.86269635726443\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12399.331570386887\n",
      "current PPL:  104.75279299602369\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12403.685120821\n",
      "current PPL:  77.75403401203424\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12408.0664331913\n",
      "current PPL:  79.94287925219894\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12412.892422437668\n",
      "current PPL:  124.70977607538373\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  12417.969601869583\n",
      "current PPL:  160.32122068413847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  12423.13512635231\n",
      "current PPL:  175.12928677445345\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12427.98614525795\n",
      "current PPL:  127.87061158021754\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12432.537885427475\n",
      "current PPL:  94.79722811356817\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12437.432416677475\n",
      "current PPL:  133.5573869140851\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12441.788351297379\n",
      "current PPL:  77.93963524110806\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12447.172747373581\n",
      "current PPL:  217.97842199208446\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12451.334790945053\n",
      "current PPL:  64.20259121412677\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12456.219125032425\n",
      "current PPL:  132.20240076774942\n",
      "reps  torch.Size([64, 23, 1024])\n",
      "embs  torch.Size([64, 24, 512])\n",
      "val running loss:  12461.167645215988\n",
      "current PPL:  140.96620538965507\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12466.852100610733\n",
      "current PPL:  294.25754719865745\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  12471.375004053116\n",
      "current PPL:  92.10262480649705\n",
      "reps  torch.Size([64, 25, 1024])\n",
      "embs  torch.Size([64, 26, 512])\n",
      "val running loss:  12476.801059484482\n",
      "current PPL:  227.2510676930872\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12481.246064424515\n",
      "current PPL:  85.20029872856679\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12485.966787576675\n",
      "current PPL:  112.24939671829318\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12490.835185289383\n",
      "current PPL:  130.11227254610498\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12495.390617609024\n",
      "current PPL:  95.14788064288902\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12500.281407117844\n",
      "current PPL:  133.05858351808646\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12504.93214392662\n",
      "current PPL:  104.66207310831201\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12509.637650251389\n",
      "current PPL:  110.55424713229426\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12514.376102209091\n",
      "current PPL:  114.25718974202627\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12519.383794546127\n",
      "current PPL:  149.55920537894593\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12524.200281381607\n",
      "current PPL:  123.53034513478029\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12528.496871232986\n",
      "current PPL:  73.44889449470551\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12533.124973535538\n",
      "current PPL:  102.31970790553633\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12537.90738749504\n",
      "current PPL:  119.39221042433824\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12542.3733856678\n",
      "current PPL:  87.00783505995643\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12547.356777906418\n",
      "current PPL:  145.96870342350488\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12552.246950864792\n",
      "current PPL:  132.9765714740124\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12556.756923437119\n",
      "current PPL:  90.91932477079088\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  12561.802483320236\n",
      "current PPL:  155.33124219728418\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12566.132131814957\n",
      "current PPL:  75.91759644264229\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12570.472338438034\n",
      "current PPL:  76.72339052368685\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  12575.151223897934\n",
      "current PPL:  107.65002541504094\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12579.507995843887\n",
      "current PPL:  78.00492345795553\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  12584.36361336708\n",
      "current PPL:  128.45999375218273\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12588.868897676468\n",
      "current PPL:  90.49406870503462\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12593.217022657394\n",
      "current PPL:  77.33332543978997\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12598.847215414047\n",
      "current PPL:  278.71583678730184\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12603.302379369736\n",
      "current PPL:  86.07026139731887\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12608.047989606857\n",
      "current PPL:  115.07800895349622\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  12612.902251958847\n",
      "current PPL:  128.28602637224935\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12617.517609834671\n",
      "current PPL:  101.02397610261333\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12621.659600019455\n",
      "current PPL:  62.92793512721099\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12626.82348036766\n",
      "current PPL:  174.8415872415202\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12631.681550741196\n",
      "current PPL:  128.77547364607472\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12636.6033847332\n",
      "current PPL:  137.2541054305248\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  12641.1418364048\n",
      "current PPL:  93.54584823837735\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12645.601780176163\n",
      "current PPL:  86.48264615823472\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12650.409742116928\n",
      "current PPL:  122.48173793199597\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12655.050073862076\n",
      "current PPL:  103.57870361657267\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12660.115438222885\n",
      "current PPL:  158.43816021421264\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  12664.98509478569\n",
      "current PPL:  130.2761675310711\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12669.292584657669\n",
      "current PPL:  74.2538681022265\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12673.975412130356\n",
      "current PPL:  108.07522070375713\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12678.606612920761\n",
      "current PPL:  102.63723595206562\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12682.9729783535\n",
      "current PPL:  78.75686375799052\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12687.926057577133\n",
      "current PPL:  141.61034317778467\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12692.407930135727\n",
      "current PPL:  88.40005206320879\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12697.356508493423\n",
      "current PPL:  140.97440621501394\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12701.796285390854\n",
      "current PPL:  84.75603027617372\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  12706.412164449692\n",
      "current PPL:  101.07664180599913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12711.28897023201\n",
      "current PPL:  131.21087769293194\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12715.939527750015\n",
      "current PPL:  104.64330984656937\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12720.38895535469\n",
      "current PPL:  85.57794556436095\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12724.93274140358\n",
      "current PPL:  94.0461904071743\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  12729.984923124313\n",
      "current PPL:  156.36323352835205\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12734.613052129745\n",
      "current PPL:  102.32244017298565\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12739.204850912094\n",
      "current PPL:  98.67175964511819\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  12743.890198469162\n",
      "current PPL:  108.34792285132474\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  12748.895469903946\n",
      "current PPL:  149.19757507423603\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  12753.777953863144\n",
      "current PPL:  131.9580355046749\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12758.278985261917\n",
      "current PPL:  90.11002275514302\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12762.996295690536\n",
      "current PPL:  111.86697348317249\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12767.715261220932\n",
      "current PPL:  112.0522780163036\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12772.293522119522\n",
      "current PPL:  97.3449541660145\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12776.72710776329\n",
      "current PPL:  84.23290526418174\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12781.542547941208\n",
      "current PPL:  123.401118804532\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12786.827674150467\n",
      "current PPL:  197.37909294528885\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12792.309549570084\n",
      "current PPL:  240.29694265233806\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12796.82259964943\n",
      "current PPL:  91.19956062366447\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  12801.581489801407\n",
      "current PPL:  116.6164275390425\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12806.190628767014\n",
      "current PPL:  100.39766656536223\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12810.919526815414\n",
      "current PPL:  113.17078488454591\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  12815.915838003159\n",
      "current PPL:  147.8666993357458\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12820.597711324692\n",
      "current PPL:  107.97214978768731\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12826.221912622452\n",
      "current PPL:  277.05091494435544\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12830.879659414291\n",
      "current PPL:  105.39833002741817\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12835.66949725151\n",
      "current PPL:  120.28186184042666\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12840.458991765976\n",
      "current PPL:  120.24057342840585\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12845.246612787247\n",
      "current PPL:  120.01551442146359\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  12850.988643407822\n",
      "current PPL:  311.6967065333771\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12855.40094256401\n",
      "current PPL:  82.45883146021575\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12860.212590456009\n",
      "current PPL:  122.9340327010844\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12864.788480520248\n",
      "current PPL:  97.11443876970593\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12869.081488847733\n",
      "current PPL:  73.18630603809997\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12874.192085504532\n",
      "current PPL:  165.7692327125443\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12878.666330099106\n",
      "current PPL:  87.72830493536263\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12883.0999314785\n",
      "current PPL:  84.23423073212297\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12888.141566514969\n",
      "current PPL:  154.72278572209012\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12893.363243341446\n",
      "current PPL:  185.2445467464993\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12897.769557714462\n",
      "current PPL:  81.96680703161503\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12902.347518205643\n",
      "current PPL:  97.31571541247824\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12907.00291800499\n",
      "current PPL:  105.15125099783398\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  12912.369586229324\n",
      "current PPL:  214.14818407423436\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12917.213618516922\n",
      "current PPL:  126.98034206621338\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12921.911818265915\n",
      "current PPL:  109.74941800142406\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12926.33429646492\n",
      "current PPL:  83.30246986764848\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12931.583163499832\n",
      "current PPL:  190.3504857897337\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12936.343518018723\n",
      "current PPL:  116.78732187248984\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12941.438138723373\n",
      "current PPL:  163.14195390333614\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12946.621345281601\n",
      "current PPL:  178.2534757187174\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12951.462176561356\n",
      "current PPL:  126.57452685070797\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12956.561051607132\n",
      "current PPL:  163.83749391027544\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12961.197719812393\n",
      "current PPL:  103.19993314848251\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  12965.898664712906\n",
      "current PPL:  110.05111068965655\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  12970.593893766403\n",
      "current PPL:  109.42386969158521\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12975.325355768204\n",
      "current PPL:  113.46132180559351\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12979.882871389389\n",
      "current PPL:  95.34630899083324\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  12984.570925951004\n",
      "current PPL:  108.6416185095483\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  12989.347607374191\n",
      "current PPL:  118.70974823081744\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  12994.299092054367\n",
      "current PPL:  141.38471926299647\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  12998.9127972126\n",
      "current PPL:  100.85714989653938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13003.772978544235\n",
      "current PPL:  129.04760039820022\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13008.536031961441\n",
      "current PPL:  117.10294470413496\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13013.384775400162\n",
      "current PPL:  127.57997702372359\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13018.346892118454\n",
      "current PPL:  142.89594646412453\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13022.951009988785\n",
      "current PPL:  99.89482378326747\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13027.623217821121\n",
      "current PPL:  106.93357340023817\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13033.108765363693\n",
      "current PPL:  241.1809646969853\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13037.827129602432\n",
      "current PPL:  111.9849221687252\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13042.38978934288\n",
      "current PPL:  95.83804546671988\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13047.110362291336\n",
      "current PPL:  112.23253770921522\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  13051.75600361824\n",
      "current PPL:  104.13012582686234\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13056.185457468033\n",
      "current PPL:  83.88559026476095\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13061.028311014175\n",
      "current PPL:  126.83075325362753\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13065.5735809803\n",
      "current PPL:  94.18585076671008\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13069.787006139755\n",
      "current PPL:  67.58764225468502\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13074.86263203621\n",
      "current PPL:  160.0723493478634\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13079.145218133926\n",
      "current PPL:  72.42750262116863\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13083.563521146774\n",
      "current PPL:  82.95539161095476\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13087.923776388168\n",
      "current PPL:  78.27711143253963\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13092.792457818985\n",
      "current PPL:  130.14919299129826\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  13097.264610052109\n",
      "current PPL:  87.54493751438453\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13101.816135644913\n",
      "current PPL:  94.77688901740784\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13106.62109208107\n",
      "current PPL:  122.11417114275366\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13111.228783369064\n",
      "current PPL:  100.25242826563093\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  13116.036616563797\n",
      "current PPL:  122.46596990921417\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13120.741482019424\n",
      "current PPL:  110.48341902514039\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13125.142277956009\n",
      "current PPL:  81.51572419819753\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13129.516038656235\n",
      "current PPL:  79.34145075624312\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13134.446955919266\n",
      "current PPL:  138.5065009829688\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13140.215062379837\n",
      "current PPL:  319.93135609233667\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13145.04078745842\n",
      "current PPL:  124.67683612101862\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13149.714945077896\n",
      "current PPL:  107.14227450172086\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13154.610041379929\n",
      "current PPL:  133.6328751123838\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13159.081659555435\n",
      "current PPL:  87.49819595611234\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13163.677081346512\n",
      "current PPL:  99.02989666655165\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13168.113513708115\n",
      "current PPL:  84.47303420535333\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13172.572012662888\n",
      "current PPL:  86.35778481896173\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13177.193785905838\n",
      "current PPL:  101.67416536932903\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13182.63791680336\n",
      "current PPL:  231.3960853843309\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13187.115329504013\n",
      "current PPL:  88.00667823677826\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13191.320234060287\n",
      "current PPL:  67.01420127602495\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13196.358803510666\n",
      "current PPL:  154.24919598830346\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13200.922530412674\n",
      "current PPL:  95.94037473605312\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13205.658058404922\n",
      "current PPL:  113.9235936157876\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13209.890435934067\n",
      "current PPL:  68.8808037671186\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13215.356338739395\n",
      "current PPL:  236.48926252800067\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13221.391906499863\n",
      "current PPL:  418.03608663769927\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13226.202693223953\n",
      "current PPL:  122.8282114288379\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13230.842730283737\n",
      "current PPL:  103.54818498553644\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13235.29187464714\n",
      "current PPL:  85.5537097906542\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  13240.36062169075\n",
      "current PPL:  158.97501374436666\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13244.948549985886\n",
      "current PPL:  98.29058999309434\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13249.77740931511\n",
      "current PPL:  125.06821759795943\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  13254.694568872452\n",
      "current PPL:  136.61401727326304\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13259.332894563675\n",
      "current PPL:  103.37112742580939\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13264.37264418602\n",
      "current PPL:  154.43134402713534\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13269.565070390701\n",
      "current PPL:  179.90450902061733\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13273.974930047989\n",
      "current PPL:  82.25791839470055\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13278.657160520554\n",
      "current PPL:  108.01071903947067\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13283.040988206863\n",
      "current PPL:  80.1442139602859\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13287.4139149189\n",
      "current PPL:  79.27530850811954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13292.101346731186\n",
      "current PPL:  108.57398307670806\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13296.518691301346\n",
      "current PPL:  82.87592171219124\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13301.200479745865\n",
      "current PPL:  107.96298582291136\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13306.087587118149\n",
      "current PPL:  132.56954455299146\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13310.829718351364\n",
      "current PPL:  114.67834772541754\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13315.27643942833\n",
      "current PPL:  85.34663964247162\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13320.058409452438\n",
      "current PPL:  119.33921975941485\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13324.499786615372\n",
      "current PPL:  84.89177100922853\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13328.74269413948\n",
      "current PPL:  69.60995050231737\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13333.307676076889\n",
      "current PPL:  96.06085889279987\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  13338.28816819191\n",
      "current PPL:  145.545989400135\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  13343.446645021439\n",
      "current PPL:  173.8993753816363\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13348.195046663284\n",
      "current PPL:  115.39968700927909\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13352.817230463028\n",
      "current PPL:  101.71591695872853\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13357.405746221542\n",
      "current PPL:  98.3483490792192\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13362.244961500168\n",
      "current PPL:  126.37014745553961\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13366.853984594345\n",
      "current PPL:  100.38603401817747\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  13373.670881986618\n",
      "current PPL:  913.1474720709067\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13378.089781045914\n",
      "current PPL:  83.00485161621242\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13382.7679169178\n",
      "current PPL:  107.56936248218418\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13387.48469042778\n",
      "current PPL:  111.80692614160472\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13391.625685930252\n",
      "current PPL:  62.86537294311571\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  13397.057133436203\n",
      "current PPL:  228.47973194735457\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13401.684161424637\n",
      "current PPL:  102.20984342389043\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13406.65393948555\n",
      "current PPL:  143.9949257219462\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13411.064894914627\n",
      "current PPL:  82.34810370337927\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13415.658551931381\n",
      "current PPL:  98.85528536783978\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13420.782995462418\n",
      "current PPL:  168.0805839949127\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13425.462627649307\n",
      "current PPL:  107.7304406148286\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13429.665078401566\n",
      "current PPL:  66.84996314629696\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13434.26017832756\n",
      "current PPL:  98.99802752981797\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13438.80341887474\n",
      "current PPL:  93.99490203980157\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13443.672928571701\n",
      "current PPL:  130.257035816611\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13448.10732293129\n",
      "current PPL:  84.30105329974282\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13452.438131570816\n",
      "current PPL:  76.00572295770722\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13457.707060575485\n",
      "current PPL:  194.20785531815167\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13463.29075217247\n",
      "current PPL:  266.05195173465705\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13468.065487623215\n",
      "current PPL:  118.47896695192063\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13472.78541970253\n",
      "current PPL:  112.16063438199609\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13476.835551977158\n",
      "current PPL:  57.40504977485864\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13481.235053300858\n",
      "current PPL:  81.41026117298495\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13485.719797372818\n",
      "current PPL:  88.65425879867092\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13490.055202245712\n",
      "current PPL:  76.35586705329635\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13494.444465398788\n",
      "current PPL:  80.5810212220303\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13499.48115992546\n",
      "current PPL:  153.9602614638417\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13503.95172905922\n",
      "current PPL:  87.40645482422761\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13509.447430849075\n",
      "current PPL:  243.64245197793088\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13514.48932671547\n",
      "current PPL:  154.76314731829615\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13519.061811208725\n",
      "current PPL:  96.78427117860394\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13523.53251338005\n",
      "current PPL:  87.41808393986712\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13527.95845913887\n",
      "current PPL:  83.59182755721876\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13532.37472319603\n",
      "current PPL:  82.78642156309877\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13536.984704256058\n",
      "current PPL:  100.48224648743931\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13541.654574155807\n",
      "current PPL:  106.68386193240772\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13546.76469540596\n",
      "current PPL:  165.69044364739622\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13551.456404447556\n",
      "current PPL:  109.03937348055103\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13555.846088647842\n",
      "current PPL:  80.61495677998532\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13560.800420999527\n",
      "current PPL:  141.78791030517743\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13565.697260141373\n",
      "current PPL:  133.86597887974534\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13570.39829659462\n",
      "current PPL:  110.06118663099414\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  13575.18513083458\n",
      "current PPL:  119.92112559423421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13579.7644469738\n",
      "current PPL:  97.44773073435172\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13584.105122327805\n",
      "current PPL:  76.75936157932681\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13589.218187093735\n",
      "current PPL:  166.17887458189017\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13593.637940645218\n",
      "current PPL:  83.07580892535873\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13598.574656248093\n",
      "current PPL:  139.3119415988192\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13604.230407953262\n",
      "current PPL:  285.93133802744364\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13609.596739053726\n",
      "current PPL:  214.07600177735515\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13613.93257689476\n",
      "current PPL:  76.38893386892792\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13618.54335141182\n",
      "current PPL:  100.56200647130599\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  13623.688942670822\n",
      "current PPL:  171.67295785148767\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  13629.448714017868\n",
      "current PPL:  317.2757745801622\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13633.6108648777\n",
      "current PPL:  64.20947977440869\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13638.327636480331\n",
      "current PPL:  111.80671288702038\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13642.987659692764\n",
      "current PPL:  105.63853425558378\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13648.076971769333\n",
      "current PPL:  162.27818867813113\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13652.925265550613\n",
      "current PPL:  127.52262263371665\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13657.437610387802\n",
      "current PPL:  91.13526552328688\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  13661.935896635056\n",
      "current PPL:  89.86299630687434\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  13666.479792833328\n",
      "current PPL:  94.05655010761923\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13671.647464990616\n",
      "current PPL:  175.50581167020874\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13676.266820669174\n",
      "current PPL:  101.42865841155077\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13680.719293832779\n",
      "current PPL:  85.83897552994544\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  13686.092993021011\n",
      "current PPL:  215.65915780157485\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13690.841474294662\n",
      "current PPL:  115.4088768605979\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13695.155462503433\n",
      "current PPL:  74.73796595715923\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13699.673226594925\n",
      "current PPL:  91.63049136852821\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13704.22727227211\n",
      "current PPL:  95.01603598381257\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13709.58991932869\n",
      "current PPL:  213.28878734883833\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13713.954369306564\n",
      "current PPL:  78.60615292616976\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13718.376032114029\n",
      "current PPL:  83.23457342326839\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13723.17179274559\n",
      "current PPL:  120.99638045584697\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13727.707623720169\n",
      "current PPL:  93.3010138710034\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13732.170019865036\n",
      "current PPL:  86.69499418019147\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13736.70768904686\n",
      "current PPL:  93.47267819962346\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13741.188511133194\n",
      "current PPL:  88.30723901807562\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  13745.536666154861\n",
      "current PPL:  77.33564862508254\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13749.873549222946\n",
      "current PPL:  76.46881939096946\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13754.969569921494\n",
      "current PPL:  163.37051159541755\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13759.53881907463\n",
      "current PPL:  96.47164713847577\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13764.389724969864\n",
      "current PPL:  127.85616168693375\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  13769.173216581345\n",
      "current PPL:  119.52094302801879\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13774.398722410202\n",
      "current PPL:  185.95520825097273\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13779.260122060776\n",
      "current PPL:  129.20491734547417\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13783.808179140091\n",
      "current PPL:  94.44872355160153\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13788.251548528671\n",
      "current PPL:  85.06106315073026\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13792.774208307266\n",
      "current PPL:  92.08018546600489\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13797.635995149612\n",
      "current PPL:  129.25495411271902\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  13802.056136369705\n",
      "current PPL:  83.10802105210958\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13806.69204545021\n",
      "current PPL:  103.1216212524367\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13811.27256655693\n",
      "current PPL:  97.56522285559412\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13816.147536993027\n",
      "current PPL:  130.9702811607884\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13820.924877405167\n",
      "current PPL:  118.78800242496462\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  13825.673043489456\n",
      "current PPL:  115.37250694238718\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13830.798268556595\n",
      "current PPL:  168.21199638447402\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13835.754992246628\n",
      "current PPL:  142.127378902795\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  13841.48013997078\n",
      "current PPL:  306.4785361812208\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13846.413482427597\n",
      "current PPL:  138.84281373552116\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13850.865315198898\n",
      "current PPL:  85.78402250830268\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13855.42518734932\n",
      "current PPL:  95.57126030357158\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13860.05919766426\n",
      "current PPL:  102.92600324424313\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13864.699344873428\n",
      "current PPL:  103.55959138247205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13869.133998155594\n",
      "current PPL:  84.32288357175212\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13873.845752477646\n",
      "current PPL:  111.24715214833004\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13878.245914697647\n",
      "current PPL:  81.46408269674352\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13882.687393903732\n",
      "current PPL:  84.90043407510467\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13887.236778974533\n",
      "current PPL:  94.57423397224298\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13892.040536642075\n",
      "current PPL:  121.96787221365497\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13896.724200487137\n",
      "current PPL:  108.1656496436908\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13901.2067964077\n",
      "current PPL:  88.46402043228181\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  13905.915617704391\n",
      "current PPL:  110.92133947183135\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13910.789386987686\n",
      "current PPL:  130.81306028270893\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13915.595265626907\n",
      "current PPL:  122.22683714801786\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13920.227657079697\n",
      "current PPL:  102.75951503021822\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13925.11868929863\n",
      "current PPL:  133.09088210143554\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13930.688537359238\n",
      "current PPL:  262.3942281918449\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13935.272064447403\n",
      "current PPL:  97.85894334320409\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13939.914899587631\n",
      "current PPL:  103.83832686785493\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13944.862652540207\n",
      "current PPL:  140.8580932274867\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13949.717237710953\n",
      "current PPL:  128.32744619289608\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  13955.202945947647\n",
      "current PPL:  241.21972417455294\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13959.826996564865\n",
      "current PPL:  101.90597936063732\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  13964.984656572342\n",
      "current PPL:  173.75738853388384\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13969.802521467209\n",
      "current PPL:  123.70069463540393\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  13974.028015375137\n",
      "current PPL:  68.4082825991495\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  13978.703713655472\n",
      "current PPL:  107.30747163400059\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  13983.13213467598\n",
      "current PPL:  83.79899549707764\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13987.769578695297\n",
      "current PPL:  103.28002817264374\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  13992.634872674942\n",
      "current PPL:  129.70906483217158\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  13997.000049352646\n",
      "current PPL:  78.66329676476164\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14001.609420061111\n",
      "current PPL:  100.42093570376183\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14006.203129529953\n",
      "current PPL:  98.86047066989684\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14010.655725240707\n",
      "current PPL:  85.849495496309\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14015.555466413498\n",
      "current PPL:  134.2550263337494\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14020.188430070877\n",
      "current PPL:  102.81833132223996\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  14024.860345602036\n",
      "current PPL:  106.90232115852388\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14029.45900940895\n",
      "current PPL:  99.35147415803608\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14033.752068281174\n",
      "current PPL:  73.19000531430886\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14038.79629778862\n",
      "current PPL:  155.12473069105923\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14043.308510541916\n",
      "current PPL:  91.12322881758814\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14047.532902002335\n",
      "current PPL:  68.33290761446698\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14052.087896585464\n",
      "current PPL:  95.10624005603295\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14056.857722997665\n",
      "current PPL:  117.89877439550163\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14061.245458841324\n",
      "current PPL:  80.45804300622729\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14066.41977238655\n",
      "current PPL:  176.67529304225522\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  14071.111844778061\n",
      "current PPL:  109.07900012632106\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14075.90563750267\n",
      "current PPL:  120.7585049727686\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14081.380250692368\n",
      "current PPL:  238.55817232270178\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14086.138085126877\n",
      "current PPL:  116.49337850334007\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14090.589914560318\n",
      "current PPL:  85.78373617371398\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14095.114356279373\n",
      "current PPL:  92.24441315259348\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14099.430953264236\n",
      "current PPL:  74.93319511981579\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14103.48013806343\n",
      "current PPL:  57.35068565884587\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14108.322103738785\n",
      "current PPL:  126.71819390919207\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14112.891595125198\n",
      "current PPL:  96.49501861219872\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14117.672431707382\n",
      "current PPL:  119.20403231246979\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14122.191221475601\n",
      "current PPL:  91.72452284574088\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14127.035484552383\n",
      "current PPL:  127.00965113779358\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14131.667322397232\n",
      "current PPL:  102.70264229077031\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14136.190025568008\n",
      "current PPL:  92.08418111280494\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14140.792754411697\n",
      "current PPL:  99.7561635353335\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14145.554440259933\n",
      "current PPL:  116.94290780638401\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14150.587974786758\n",
      "current PPL:  153.47451494477727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14155.379090547562\n",
      "current PPL:  120.43567112572264\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14159.992485761642\n",
      "current PPL:  100.82589465659728\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14164.584860563278\n",
      "current PPL:  98.72861285446737\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14169.290882825851\n",
      "current PPL:  110.6113009647615\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14174.067182302475\n",
      "current PPL:  118.66441610817586\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14178.843657255173\n",
      "current PPL:  118.68524070111945\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14183.544135332108\n",
      "current PPL:  109.99974822595195\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14188.478690862656\n",
      "current PPL:  139.01134250377237\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  14193.307814359665\n",
      "current PPL:  125.10126095636005\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14198.140254735947\n",
      "current PPL:  125.51689565979441\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  14202.752321958542\n",
      "current PPL:  100.69208759395046\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14207.211442232132\n",
      "current PPL:  86.4114572077821\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14211.71308875084\n",
      "current PPL:  90.16546827747507\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14217.039604902267\n",
      "current PPL:  205.72002685088623\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14221.601276159286\n",
      "current PPL:  95.74335795314155\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14226.241954565048\n",
      "current PPL:  103.61461649799824\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14230.878669977188\n",
      "current PPL:  103.20480501019638\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14235.105147123337\n",
      "current PPL:  68.47557731512715\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14239.852234125137\n",
      "current PPL:  115.24807763724817\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14244.500035047531\n",
      "current PPL:  104.35524777559722\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14249.01009106636\n",
      "current PPL:  90.92691198702846\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14253.96066069603\n",
      "current PPL:  141.255404277905\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14258.900266885757\n",
      "current PPL:  139.71521743679486\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14263.539557218552\n",
      "current PPL:  103.47089162318\n",
      "reps  torch.Size([64, 23, 1024])\n",
      "embs  torch.Size([64, 24, 512])\n",
      "val running loss:  14269.012065172195\n",
      "current PPL:  238.05647933385555\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14273.472084283829\n",
      "current PPL:  86.48916202968341\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14277.844200849533\n",
      "current PPL:  79.21110991636853\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14282.751343011856\n",
      "current PPL:  135.25233235177424\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14287.181941747665\n",
      "current PPL:  83.98168470216234\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14291.73881983757\n",
      "current PPL:  95.28554210882194\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14296.353108644485\n",
      "current PPL:  100.91603222073446\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14301.061384916306\n",
      "current PPL:  110.8609010547193\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14305.531236886978\n",
      "current PPL:  87.34379261355292\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14310.418329000473\n",
      "current PPL:  132.56752171770808\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14316.099889993668\n",
      "current PPL:  293.407079089704\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14320.880068063736\n",
      "current PPL:  119.1255608530172\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14325.211114645004\n",
      "current PPL:  76.02381004357647\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  14330.021217107773\n",
      "current PPL:  122.74419358286345\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14334.598325490952\n",
      "current PPL:  97.23282723253925\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  14339.231456041336\n",
      "current PPL:  102.83549241455488\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14343.523143529892\n",
      "current PPL:  73.08970252895445\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14347.89878821373\n",
      "current PPL:  79.49106964473728\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14352.462699651718\n",
      "current PPL:  95.95808082080276\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14357.07911992073\n",
      "current PPL:  101.13136031872725\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14361.579518556595\n",
      "current PPL:  90.05302251074232\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14366.081365346909\n",
      "current PPL:  90.1835276689842\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14370.633039712906\n",
      "current PPL:  94.79099032676604\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14374.93732380867\n",
      "current PPL:  74.01620796416734\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14379.470832586288\n",
      "current PPL:  93.08460191303273\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14383.774683237076\n",
      "current PPL:  73.98413296249933\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14389.246520757675\n",
      "current PPL:  237.89693189258313\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14393.814677476883\n",
      "current PPL:  96.36631578216146\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14398.477210760117\n",
      "current PPL:  105.90402751990732\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14402.935153722763\n",
      "current PPL:  86.30978391584208\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14407.393195390701\n",
      "current PPL:  86.31830356870469\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14412.641892671585\n",
      "current PPL:  190.31817577043375\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14417.208964586258\n",
      "current PPL:  96.2618338472728\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14421.762970685959\n",
      "current PPL:  95.01227556257074\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14426.156908273697\n",
      "current PPL:  80.95857367538585\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14430.883070230484\n",
      "current PPL:  112.86156247243218\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14435.468925714493\n",
      "current PPL:  98.08706317370562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14439.84202170372\n",
      "current PPL:  79.28872914554417\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14444.059179067612\n",
      "current PPL:  67.84036446513463\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14449.737145662308\n",
      "current PPL:  292.35435022210646\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14454.57416844368\n",
      "current PPL:  126.09338476591526\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14459.04456448555\n",
      "current PPL:  87.3913267852095\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  14464.172250032425\n",
      "current PPL:  168.6263881852404\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14468.605492830276\n",
      "current PPL:  84.20403130649817\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14473.134781122208\n",
      "current PPL:  92.69256755258426\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14477.416839838028\n",
      "current PPL:  72.38931573786384\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14481.809992551804\n",
      "current PPL:  80.8950563286913\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14487.161166906357\n",
      "current PPL:  210.8557719629454\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14491.622916460037\n",
      "current PPL:  86.63895607986213\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14496.584489107132\n",
      "current PPL:  142.81822204113973\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14501.126212358475\n",
      "current PPL:  93.85239210840275\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14505.699360609055\n",
      "current PPL:  96.84853377249223\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14510.467054605484\n",
      "current PPL:  117.64763305358693\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14515.212167024612\n",
      "current PPL:  115.02073530713034\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14519.899577856064\n",
      "current PPL:  108.5717051277848\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14524.681766748428\n",
      "current PPL:  119.36534218485063\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14529.333863019943\n",
      "current PPL:  104.80445405565642\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14533.782951593399\n",
      "current PPL:  85.54893688681697\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14538.15902543068\n",
      "current PPL:  79.5251908320028\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14542.949789762497\n",
      "current PPL:  120.39335397616138\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14547.62912774086\n",
      "current PPL:  107.69875006266804\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14552.335901498795\n",
      "current PPL:  110.69445608577739\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14557.356587648392\n",
      "current PPL:  151.51523024962816\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14562.033189058304\n",
      "current PPL:  107.40442796100785\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14566.280932664871\n",
      "current PPL:  69.94740528476488\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14570.90420460701\n",
      "current PPL:  101.82665860063032\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14575.476265192032\n",
      "current PPL:  96.74325222391481\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14579.901736974716\n",
      "current PPL:  83.55221641396425\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  14584.957536935806\n",
      "current PPL:  156.93001805314327\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14589.6449944973\n",
      "current PPL:  108.57677880661724\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14594.528322458267\n",
      "current PPL:  132.0694553328612\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14599.256175279617\n",
      "current PPL:  113.05255751681149\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14604.667872190475\n",
      "current PPL:  224.011392706406\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14609.24065232277\n",
      "current PPL:  96.81288861744464\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14613.434179067612\n",
      "current PPL:  66.25604757443013\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  14617.796472787857\n",
      "current PPL:  78.43684041550257\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14622.608415842056\n",
      "current PPL:  122.9703235363233\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14627.127762079239\n",
      "current PPL:  91.77557890014502\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14631.558013677597\n",
      "current PPL:  83.95253657368593\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14636.290397405624\n",
      "current PPL:  113.56595029363311\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14641.13662648201\n",
      "current PPL:  127.25959767843517\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14645.993788480759\n",
      "current PPL:  128.65855036583062\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14650.438421487808\n",
      "current PPL:  85.16861581959891\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14655.214215517044\n",
      "current PPL:  118.60445264450624\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14659.687577962875\n",
      "current PPL:  87.65094964591889\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14664.196839094162\n",
      "current PPL:  90.85466403569393\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  14668.979601621628\n",
      "current PPL:  119.43383397777889\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14673.38308930397\n",
      "current PPL:  81.73543937906389\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14678.080627679825\n",
      "current PPL:  109.67685668209853\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14682.781863451004\n",
      "current PPL:  110.08312598550185\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14687.099345445633\n",
      "current PPL:  74.99954108334872\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14692.838103532791\n",
      "current PPL:  310.678335880204\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14697.86591887474\n",
      "current PPL:  152.59927104666468\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  14702.375689268112\n",
      "current PPL:  90.90094465481124\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14707.41541838646\n",
      "current PPL:  154.42817759965905\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14712.273839235306\n",
      "current PPL:  128.82061418014527\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14717.261635065079\n",
      "current PPL:  146.61290727914252\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14722.260642766953\n",
      "current PPL:  148.26596204665222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14727.146026849747\n",
      "current PPL:  132.34128558483215\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14731.256891965866\n",
      "current PPL:  60.9994663710446\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14736.118423223495\n",
      "current PPL:  129.22192274321395\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14740.594132184982\n",
      "current PPL:  87.85686546935236\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14745.11766409874\n",
      "current PPL:  92.16052686269191\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14750.023166894913\n",
      "current PPL:  135.0307859039126\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14755.421218633652\n",
      "current PPL:  220.9754785864059\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14759.98699259758\n",
      "current PPL:  96.13697177828844\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14764.6577064991\n",
      "current PPL:  106.77394130894056\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14769.47573542595\n",
      "current PPL:  123.72098716983878\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14774.027897119522\n",
      "current PPL:  94.8371958479765\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14778.611971139908\n",
      "current PPL:  97.91248019155768\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14783.296161413193\n",
      "current PPL:  108.22260608480887\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14788.070257425308\n",
      "current PPL:  118.40323114049204\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14792.54206442833\n",
      "current PPL:  87.51471958299956\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14797.041863679886\n",
      "current PPL:  89.9990623152366\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14801.916024446487\n",
      "current PPL:  130.8642814375915\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14806.21109843254\n",
      "current PPL:  73.33764020687569\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14810.441188097\n",
      "current PPL:  68.72339394355076\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14815.419688463211\n",
      "current PPL:  145.25638685247813\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14819.908442258835\n",
      "current PPL:  89.01045151798331\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14824.35265469551\n",
      "current PPL:  85.13280395426284\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14829.210706472397\n",
      "current PPL:  128.77307887603703\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14833.509506464005\n",
      "current PPL:  73.61140637201706\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14838.26632475853\n",
      "current PPL:  116.37506504525433\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14843.020421266556\n",
      "current PPL:  116.05874763389747\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14847.67728304863\n",
      "current PPL:  105.30509274010385\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14852.405496835709\n",
      "current PPL:  113.09337298167254\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  14856.644279241562\n",
      "current PPL:  69.3233926735464\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14861.661596536636\n",
      "current PPL:  151.0056563031273\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14866.375208616257\n",
      "current PPL:  111.45401447772636\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14870.965297937393\n",
      "current PPL:  98.50322818930387\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14875.329890966415\n",
      "current PPL:  78.61739843086534\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14880.249687433243\n",
      "current PPL:  136.9747314474773\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14884.878497838974\n",
      "current PPL:  102.39218647419794\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  14889.483443498611\n",
      "current PPL:  99.97754988535145\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14894.594073057175\n",
      "current PPL:  165.7746869024293\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14898.95851635933\n",
      "current PPL:  78.6056281752372\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14903.625238656998\n",
      "current PPL:  106.34859151228913\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14908.2596514225\n",
      "current PPL:  102.96743420844234\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14913.431537866592\n",
      "current PPL:  176.24700419835835\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14918.447091817856\n",
      "current PPL:  150.73961604281217\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14923.515767335892\n",
      "current PPL:  158.96364337194083\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14928.464196920395\n",
      "current PPL:  140.95343456246795\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  14932.942806005478\n",
      "current PPL:  88.11203106502614\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14937.82961153984\n",
      "current PPL:  132.52953607559834\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  14942.59481883049\n",
      "current PPL:  117.3554414523066\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14947.154151201248\n",
      "current PPL:  95.51968680130028\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  14952.844942808151\n",
      "current PPL:  296.1279448072367\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14957.75337767601\n",
      "current PPL:  135.42728684850678\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14962.0597178936\n",
      "current PPL:  74.16855086896787\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  14966.967203855515\n",
      "current PPL:  135.29884004253174\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  14971.605274438858\n",
      "current PPL:  103.34476000008796\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  14977.218971014023\n",
      "current PPL:  274.1558047256877\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14981.825582265854\n",
      "current PPL:  100.14421046772948\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14986.303575277328\n",
      "current PPL:  88.0577642859862\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  14990.628497362137\n",
      "current PPL:  75.55962538767471\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  14995.35741353035\n",
      "current PPL:  113.1728355364719\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15000.432351827621\n",
      "current PPL:  159.96232156321275\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15005.0254175663\n",
      "current PPL:  98.79685168186919\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15009.567073583603\n",
      "current PPL:  93.8460822451039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15014.230768918991\n",
      "current PPL:  106.02716505552395\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15018.839279413223\n",
      "current PPL:  100.334589329053\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15023.600807905197\n",
      "current PPL:  116.92450755525532\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15027.969457387924\n",
      "current PPL:  78.936953960916\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15032.473751783371\n",
      "current PPL:  90.40453168917907\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15036.806701421738\n",
      "current PPL:  76.16862544721177\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15041.148419618607\n",
      "current PPL:  76.83945128510186\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15046.18788075447\n",
      "current PPL:  154.38679909779907\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15050.970628976822\n",
      "current PPL:  119.43212547529946\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15055.738820791245\n",
      "current PPL:  117.70621474247375\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15060.10091805458\n",
      "current PPL:  78.42143246981698\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15064.750725984573\n",
      "current PPL:  104.56489986716137\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15069.420595884323\n",
      "current PPL:  106.68386193240772\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15074.018899679184\n",
      "current PPL:  99.31571286734658\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15079.053614854813\n",
      "current PPL:  153.6558214558439\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15083.799445390701\n",
      "current PPL:  115.10336328964979\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15088.649067640305\n",
      "current PPL:  127.69214497591938\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  15093.750539064407\n",
      "current PPL:  164.26343073581313\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15098.025106191635\n",
      "current PPL:  71.84903108792558\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15102.754371404648\n",
      "current PPL:  113.21234482104909\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  15107.472242116928\n",
      "current PPL:  111.9296682824039\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15111.861955404282\n",
      "current PPL:  80.61730166670897\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15116.562823534012\n",
      "current PPL:  110.04266230407588\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15121.52430844307\n",
      "current PPL:  142.80569200036302\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15126.318666696548\n",
      "current PPL:  120.82681670789246\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15131.221637487411\n",
      "current PPL:  134.6893197165121\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15135.79504275322\n",
      "current PPL:  96.87342851953504\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15140.516561746597\n",
      "current PPL:  112.33876497154243\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15145.359566450119\n",
      "current PPL:  126.84992610690763\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15149.916252851486\n",
      "current PPL:  95.26727871309863\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15154.431313753128\n",
      "current PPL:  91.38313123565048\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15159.303159475327\n",
      "current PPL:  130.5616752238473\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15163.447556257248\n",
      "current PPL:  63.07955969219543\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15169.11904168129\n",
      "current PPL:  290.4656787989152\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15173.946694135666\n",
      "current PPL:  124.91736695916072\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15179.14179968834\n",
      "current PPL:  180.38718214147647\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15183.298426389694\n",
      "current PPL:  63.85575434954406\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15188.834153413773\n",
      "current PPL:  253.59208818769855\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15193.0744202137\n",
      "current PPL:  69.42637231906372\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15197.846081018448\n",
      "current PPL:  118.11524551442642\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15202.534133672714\n",
      "current PPL:  108.64141129230337\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  15207.326017141342\n",
      "current PPL:  120.5281660328088\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15212.077500104904\n",
      "current PPL:  115.75581896770886\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15217.339534044266\n",
      "current PPL:  192.87338538807518\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15221.938612222672\n",
      "current PPL:  99.39265110715188\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  15226.561970949173\n",
      "current PPL:  101.83549594577846\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15231.146830320358\n",
      "current PPL:  97.98940603909718\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15235.939339876175\n",
      "current PPL:  120.60365080099935\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15240.760619401932\n",
      "current PPL:  124.12380882668546\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15245.453199148178\n",
      "current PPL:  109.13435591499245\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15249.901438951492\n",
      "current PPL:  85.47635631001224\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15254.701961755753\n",
      "current PPL:  121.57396029144773\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15260.159844636917\n",
      "current PPL:  234.60022168424297\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15264.536134958267\n",
      "current PPL:  79.5424086325902\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15269.28109240532\n",
      "current PPL:  115.00291168606635\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15274.488208532333\n",
      "current PPL:  182.56679882537244\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15279.325470685959\n",
      "current PPL:  126.12357163637324\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15284.05476641655\n",
      "current PPL:  113.21579984034602\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15288.595378160477\n",
      "current PPL:  93.74813243202206\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15293.0022752285\n",
      "current PPL:  82.01458259877911\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15297.695320367813\n",
      "current PPL:  109.18515810811928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15301.761667013168\n",
      "current PPL:  58.34342354506637\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15306.550154924393\n",
      "current PPL:  120.11959977394815\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15311.048681020737\n",
      "current PPL:  89.8845524498223\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15315.611049413681\n",
      "current PPL:  95.81012735855033\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  15320.08610367775\n",
      "current PPL:  87.7993646312363\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15324.826094865799\n",
      "current PPL:  114.43319329605988\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15329.518670797348\n",
      "current PPL:  109.13393960125741\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15334.34367108345\n",
      "current PPL:  124.58650402767495\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15339.284986257553\n",
      "current PPL:  139.95419270468034\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15343.59870505333\n",
      "current PPL:  74.71783329007931\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15348.211359262466\n",
      "current PPL:  100.75120984451377\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15352.82913517952\n",
      "current PPL:  101.26855181988809\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15357.53548359871\n",
      "current PPL:  110.64738345635068\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15362.251785039902\n",
      "current PPL:  111.75415803771254\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15366.715250253677\n",
      "current PPL:  86.78772666288367\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15371.403528928757\n",
      "current PPL:  108.66596928761234\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15375.966988325119\n",
      "current PPL:  95.91471357656121\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15380.597861528397\n",
      "current PPL:  102.60361882131679\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15385.324308156967\n",
      "current PPL:  112.89369554817684\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15389.939355134964\n",
      "current PPL:  100.9925728498076\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15394.994483232498\n",
      "current PPL:  156.8246179044095\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15399.548231840134\n",
      "current PPL:  94.98781380498436\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15403.97828745842\n",
      "current PPL:  83.93608516164895\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15408.857133626938\n",
      "current PPL:  131.47887186989468\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15413.610289812088\n",
      "current PPL:  115.94966623244623\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15418.420930147171\n",
      "current PPL:  122.81023204488964\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15423.180848360062\n",
      "current PPL:  116.7363779776331\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15427.946236848831\n",
      "current PPL:  117.37670796435108\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  15433.22305893898\n",
      "current PPL:  195.7468201214993\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15438.088091611862\n",
      "current PPL:  129.67517540430924\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15442.512015104294\n",
      "current PPL:  83.42295342583498\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15447.249309778214\n",
      "current PPL:  114.12503823240013\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15451.966570615768\n",
      "current PPL:  111.86142601843378\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15456.514134168625\n",
      "current PPL:  94.40212210800318\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15461.31321310997\n",
      "current PPL:  121.39855082283542\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15466.287908792496\n",
      "current PPL:  144.70478225314568\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15470.890844106674\n",
      "current PPL:  99.7767623657016\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15475.723979234695\n",
      "current PPL:  125.60412904065367\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15480.663736104965\n",
      "current PPL:  139.73627138765332\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15485.136742830276\n",
      "current PPL:  87.61977594942113\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15489.525763750076\n",
      "current PPL:  80.56150418118048\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15494.260977983475\n",
      "current PPL:  113.8878546870515\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15498.794819116592\n",
      "current PPL:  93.1155442340161\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15503.240761995316\n",
      "current PPL:  85.28024887346558\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15507.970475912094\n",
      "current PPL:  113.26315502502561\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15513.013565778732\n",
      "current PPL:  154.9480449159001\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15517.697533369064\n",
      "current PPL:  108.19850943837321\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15523.024614095688\n",
      "current PPL:  205.83620406752672\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15527.73727107048\n",
      "current PPL:  111.34761502981354\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15532.375414609909\n",
      "current PPL:  103.35229990424163\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15537.464338064194\n",
      "current PPL:  162.21513601044353\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15542.721593618393\n",
      "current PPL:  191.95396049768334\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15547.359023809433\n",
      "current PPL:  103.27859999761951\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15552.57309126854\n",
      "current PPL:  183.84030241815174\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15557.465487241745\n",
      "current PPL:  133.2725091797294\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  15562.791450738907\n",
      "current PPL:  205.60636621078365\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15567.632292509079\n",
      "current PPL:  126.57585467730173\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15571.983457803726\n",
      "current PPL:  77.56880078827379\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15576.8440387249\n",
      "current PPL:  129.09917677330114\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15582.059691667557\n",
      "current PPL:  184.13200938084006\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  15586.765078783035\n",
      "current PPL:  110.54106882454076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15591.161374807358\n",
      "current PPL:  81.14973466930273\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15595.610003232956\n",
      "current PPL:  85.50958078229093\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15600.25159239769\n",
      "current PPL:  103.70902742589536\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15604.928580522537\n",
      "current PPL:  107.44597088953576\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15609.174878358841\n",
      "current PPL:  69.84635047480528\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15613.90480685234\n",
      "current PPL:  113.28746126914649\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15618.424084424973\n",
      "current PPL:  91.7692773875949\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15622.448292970657\n",
      "current PPL:  55.9360204530997\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15627.098206281662\n",
      "current PPL:  104.57591960275042\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15631.841252565384\n",
      "current PPL:  114.783332231336\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15636.647032022476\n",
      "current PPL:  122.21471503125865\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15641.257741689682\n",
      "current PPL:  100.55548525136946\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15645.857098340988\n",
      "current PPL:  99.42033312114968\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15650.466673612595\n",
      "current PPL:  100.44148022703287\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15655.92522740364\n",
      "current PPL:  234.75767010213835\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15660.562274694443\n",
      "current PPL:  103.2390621671017\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15664.861957788467\n",
      "current PPL:  73.67644149501297\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15669.134314775467\n",
      "current PPL:  71.69041000594129\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15673.84764790535\n",
      "current PPL:  111.42292874551903\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15678.464214086533\n",
      "current PPL:  101.14611769162185\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15683.658704042435\n",
      "current PPL:  180.27617054727227\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15689.392392873764\n",
      "current PPL:  309.1074129842126\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15694.00100159645\n",
      "current PPL:  100.3444455247762\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15698.758576631546\n",
      "current PPL:  116.46316410818176\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15703.18927025795\n",
      "current PPL:  83.9896541522563\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15707.998621702194\n",
      "current PPL:  122.65204502671594\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15712.876067876816\n",
      "current PPL:  131.2949310398233\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15717.400571107864\n",
      "current PPL:  92.25008746484461\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15721.925122499466\n",
      "current PPL:  92.25453038705517\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15727.015179872513\n",
      "current PPL:  162.39917912192854\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15731.572715520859\n",
      "current PPL:  95.34821852580147\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15736.331419706345\n",
      "current PPL:  116.59474280751779\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15740.755236387253\n",
      "current PPL:  83.41404336894675\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15745.415101766586\n",
      "current PPL:  105.62186231403653\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15750.70084452629\n",
      "current PPL:  197.5008246359957\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15754.987240076065\n",
      "current PPL:  72.70393791921062\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15760.06144118309\n",
      "current PPL:  159.84444235497546\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15765.323273897171\n",
      "current PPL:  192.8345782915644\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15769.728200674057\n",
      "current PPL:  81.85314908126178\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15774.229142427444\n",
      "current PPL:  90.10194516945846\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15778.660422086716\n",
      "current PPL:  84.03888927540486\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15783.220402002335\n",
      "current PPL:  95.58156011430839\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15787.476517915726\n",
      "current PPL:  70.53548477917383\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15792.653908491135\n",
      "current PPL:  177.21976550083983\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15797.461457014084\n",
      "current PPL:  122.4311122648778\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15802.59244608879\n",
      "current PPL:  169.18437130074835\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15807.552238702774\n",
      "current PPL:  142.56422700382456\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15811.79951262474\n",
      "current PPL:  69.91455977975238\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  15816.598753213882\n",
      "current PPL:  121.41817621724825\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15821.207439661026\n",
      "current PPL:  100.35224504539904\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15825.786426782608\n",
      "current PPL:  97.41567398595102\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15830.33615899086\n",
      "current PPL:  94.6070699297362\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15835.138071775436\n",
      "current PPL:  121.74306320084224\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15840.284843683243\n",
      "current PPL:  171.87576302108693\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15844.661401987076\n",
      "current PPL:  79.56372746116094\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15849.124812841415\n",
      "current PPL:  86.7830090592318\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15854.52875161171\n",
      "current PPL:  222.28020491612966\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15859.09195780754\n",
      "current PPL:  95.89043099446343\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15864.011284589767\n",
      "current PPL:  136.91041163160952\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  15868.866270780563\n",
      "current PPL:  128.3789183917931\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15873.09197306633\n",
      "current PPL:  68.42253885448027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15877.546579122543\n",
      "current PPL:  86.0222562359361\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15881.677446603775\n",
      "current PPL:  62.231884517878484\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15886.161823511124\n",
      "current PPL:  88.62171406715571\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15890.608811616898\n",
      "current PPL:  85.36943269703848\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15895.11326098442\n",
      "current PPL:  90.41854295282162\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15900.087789773941\n",
      "current PPL:  144.68063405228284\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15904.749952077866\n",
      "current PPL:  105.86474660360307\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  15909.740112543106\n",
      "current PPL:  146.96000357606712\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15915.060732126236\n",
      "current PPL:  204.51055403614905\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15920.231887102127\n",
      "current PPL:  176.11813225793074\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15925.087383508682\n",
      "current PPL:  128.44443605176556\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15929.43494772911\n",
      "current PPL:  77.28997212225075\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15934.084456682205\n",
      "current PPL:  104.53364205065454\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  15938.83699965477\n",
      "current PPL:  115.87858623363613\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15943.52129483223\n",
      "current PPL:  108.23395968350495\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15948.372041940689\n",
      "current PPL:  127.83586143127286\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  15952.92294049263\n",
      "current PPL:  94.71747866342879\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  15957.689393281937\n",
      "current PPL:  117.50169855966209\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15962.211324930191\n",
      "current PPL:  92.0131634925285\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15966.9848883152\n",
      "current PPL:  118.34018316220424\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  15971.347323179245\n",
      "current PPL:  78.44791207045624\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15975.42478108406\n",
      "current PPL:  58.99530738031313\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  15979.946598291397\n",
      "current PPL:  92.00263402414572\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  15985.575425863266\n",
      "current PPL:  278.33559777518997\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15990.274649858475\n",
      "current PPL:  109.86188601513689\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15994.75134730339\n",
      "current PPL:  87.94375346158415\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  15999.401185750961\n",
      "current PPL:  104.56809098335452\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16004.06110739708\n",
      "current PPL:  105.62780548381954\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16008.819351434708\n",
      "current PPL:  116.54110432816191\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16013.308409929276\n",
      "current PPL:  89.03757704092321\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16017.783319711685\n",
      "current PPL:  87.78668014974043\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16022.576133966446\n",
      "current PPL:  120.6404042051294\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16027.518651247025\n",
      "current PPL:  140.12253370768323\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16032.371175527573\n",
      "current PPL:  128.0632497503731\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16036.565617322922\n",
      "current PPL:  66.3167029514623\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16041.529819250107\n",
      "current PPL:  143.19422524114023\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16046.174173593521\n",
      "current PPL:  103.99619827387299\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16050.588715791702\n",
      "current PPL:  82.64399767196738\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16055.294504404068\n",
      "current PPL:  110.58545963037122\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16059.8676674366\n",
      "current PPL:  96.84996539344151\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16064.499239206314\n",
      "current PPL:  102.67531930657671\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16069.195464372635\n",
      "current PPL:  109.5329225168221\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16073.948711633682\n",
      "current PPL:  115.96022693323569\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16079.29011797905\n",
      "current PPL:  208.8061574689378\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16085.036604642868\n",
      "current PPL:  313.08873971315296\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16089.494978189468\n",
      "current PPL:  86.34695552603227\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16094.58628153801\n",
      "current PPL:  162.60165063049766\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16099.587239027023\n",
      "current PPL:  148.55533112511472\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16104.611056566238\n",
      "current PPL:  151.99042709352113\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16109.555755853653\n",
      "current PPL:  140.42861584932297\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16114.317533254623\n",
      "current PPL:  116.95361473947648\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16118.737569093704\n",
      "current PPL:  83.09926350619651\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16123.35251402855\n",
      "current PPL:  100.9822677751501\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  16128.115863084793\n",
      "current PPL:  117.13757002411027\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16132.592427968979\n",
      "current PPL:  87.932096346083\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16137.576621294022\n",
      "current PPL:  146.08568381985424\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16142.840562582016\n",
      "current PPL:  193.24161323380636\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16147.736023664474\n",
      "current PPL:  133.68163066149265\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16152.572781801224\n",
      "current PPL:  126.06001924486357\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16158.176929235458\n",
      "current PPL:  271.55031221581436\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16162.696877717972\n",
      "current PPL:  91.83086696083718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16167.255895853043\n",
      "current PPL:  95.48967582237904\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16171.718239068985\n",
      "current PPL:  86.69040562881935\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16176.06850028038\n",
      "current PPL:  77.49870382612635\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16180.511529684067\n",
      "current PPL:  85.03214858974404\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16185.515328168869\n",
      "current PPL:  148.97797627748727\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16189.994998216629\n",
      "current PPL:  88.20556425021651\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16194.625862836838\n",
      "current PPL:  102.60273817117177\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16199.218451738358\n",
      "current PPL:  98.74975290199039\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16203.685005426407\n",
      "current PPL:  87.05618267029675\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16208.259201288223\n",
      "current PPL:  96.95004654839609\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16213.203181505203\n",
      "current PPL:  140.32767407996852\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16218.318967580795\n",
      "current PPL:  166.63171463843847\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16222.985484838486\n",
      "current PPL:  106.32678803479088\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16227.75940823555\n",
      "current PPL:  118.38279472454548\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16232.55916762352\n",
      "current PPL:  121.481184167595\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16237.02888083458\n",
      "current PPL:  87.33167366351852\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16242.335397481918\n",
      "current PPL:  201.64659739053803\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16246.639630556107\n",
      "current PPL:  74.01243163693071\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16251.652451753616\n",
      "current PPL:  150.32824413631488\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16255.98943734169\n",
      "current PPL:  76.47665937536401\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16260.640793561935\n",
      "current PPL:  104.72692207873752\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16265.392976522446\n",
      "current PPL:  115.83687605427434\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16269.99114537239\n",
      "current PPL:  99.30231162107427\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16275.01548075676\n",
      "current PPL:  152.06915498228534\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16280.097000360489\n",
      "current PPL:  161.01855450698892\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16285.073620080948\n",
      "current PPL:  144.98346775810668\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16289.809372663498\n",
      "current PPL:  113.9491826234412\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16294.41834950447\n",
      "current PPL:  100.3813909498118\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16299.281231164932\n",
      "current PPL:  129.3965422704628\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16304.029519319534\n",
      "current PPL:  115.38659135999069\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16308.862631082535\n",
      "current PPL:  125.601194331857\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16313.385625600815\n",
      "current PPL:  92.11101351768622\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16317.887491464615\n",
      "current PPL:  90.1852477996706\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16322.529775857925\n",
      "current PPL:  103.78115397473326\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16327.115448236465\n",
      "current PPL:  98.06910454023706\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16331.925503969193\n",
      "current PPL:  122.73845787561892\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16336.40693640709\n",
      "current PPL:  88.36115393124237\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16341.634267091751\n",
      "current PPL:  186.2948595051413\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16346.564290761948\n",
      "current PPL:  138.38278784897972\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16351.016947984695\n",
      "current PPL:  85.85477643232886\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16355.297549009323\n",
      "current PPL:  72.28387134122785\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16360.811302900314\n",
      "current PPL:  248.08064902750124\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16365.402642965317\n",
      "current PPL:  98.62650757713752\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16370.045770406723\n",
      "current PPL:  103.86868336952217\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16374.6374604702\n",
      "current PPL:  98.66103274582315\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16379.794964551926\n",
      "current PPL:  173.73029739478937\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16385.66583800316\n",
      "current PPL:  354.5585346469842\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16389.88906121254\n",
      "current PPL:  68.25312423682527\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16394.32088780403\n",
      "current PPL:  84.08486542349345\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16399.08341193199\n",
      "current PPL:  117.04097977500624\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16404.057503461838\n",
      "current PPL:  144.61738487455776\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16408.514984369278\n",
      "current PPL:  86.26991324276462\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16414.08452296257\n",
      "current PPL:  262.31303831785215\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16418.46912932396\n",
      "current PPL:  80.20664456587441\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  16424.410996198654\n",
      "current PPL:  380.64488293459624\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16428.835533857346\n",
      "current PPL:  83.47420472591776\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16433.26669049263\n",
      "current PPL:  84.02855111213265\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16438.24724793434\n",
      "current PPL:  145.55549774853446\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16442.67127919197\n",
      "current PPL:  83.431944001335\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16448.372128725052\n",
      "current PPL:  299.12140658884334\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16452.82729077339\n",
      "current PPL:  86.07009723148003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16456.960257291794\n",
      "current PPL:  62.36264874814434\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16461.92577958107\n",
      "current PPL:  143.3834183420212\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16466.853803873062\n",
      "current PPL:  138.10638472836246\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16471.39855647087\n",
      "current PPL:  94.13713459483519\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16476.252370119095\n",
      "current PPL:  128.2284768614144\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16481.695328950882\n",
      "current PPL:  231.12503283820084\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16486.266612768173\n",
      "current PPL:  96.66813436576413\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16490.869998693466\n",
      "current PPL:  99.8217330151689\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16496.16997551918\n",
      "current PPL:  200.3321673660781\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  16501.1461622715\n",
      "current PPL:  144.92070812323328\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16506.540936231613\n",
      "current PPL:  220.2523556518135\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16511.957027196884\n",
      "current PPL:  224.99787669999833\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16516.57533764839\n",
      "current PPL:  101.32269782013962\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16521.38083577156\n",
      "current PPL:  122.1803367221081\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  16526.468235731125\n",
      "current PPL:  161.96819026518682\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16531.58043694496\n",
      "current PPL:  166.03543241065617\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16536.359862089157\n",
      "current PPL:  119.03590189364958\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16540.38487124443\n",
      "current PPL:  55.980821299024264\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16544.705485105515\n",
      "current PPL:  75.23479783428253\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16549.62737584114\n",
      "current PPL:  137.26189394654963\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16554.256281137466\n",
      "current PPL:  102.40190299063855\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16558.844135046005\n",
      "current PPL:  98.28327876255126\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16563.591562509537\n",
      "current PPL:  115.28732187745192\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16568.23984646797\n",
      "current PPL:  104.40566729761024\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16573.336818933487\n",
      "current PPL:  163.52607627077867\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16577.983154058456\n",
      "current PPL:  104.20239617430319\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16582.604728460312\n",
      "current PPL:  101.653950376809\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16587.250034570694\n",
      "current PPL:  104.09522553812819\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16592.230618715286\n",
      "current PPL:  145.55938455154345\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16597.01883149147\n",
      "current PPL:  120.08655520909284\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16602.014508008957\n",
      "current PPL:  147.77288251411494\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16607.11189723015\n",
      "current PPL:  163.59424089429288\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16611.84786105156\n",
      "current PPL:  113.97325566149108\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16616.68825984001\n",
      "current PPL:  126.51979630482386\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16621.418402910233\n",
      "current PPL:  113.31177272938116\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16626.14797282219\n",
      "current PPL:  113.24684575890696\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16630.60996365547\n",
      "current PPL:  86.65986281479009\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16635.206384420395\n",
      "current PPL:  99.12887437317568\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16640.08229327202\n",
      "current PPL:  131.0932433920602\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16644.67778468132\n",
      "current PPL:  99.03679119217871\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16649.462050676346\n",
      "current PPL:  119.6135339253799\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16654.302612543106\n",
      "current PPL:  126.5404306216061\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16658.662233114243\n",
      "current PPL:  78.22744703998853\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16663.29046845436\n",
      "current PPL:  102.33332117606454\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16668.182460546494\n",
      "current PPL:  133.21869380395816\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16672.891613721848\n",
      "current PPL:  110.95815800687977\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16677.65828537941\n",
      "current PPL:  117.52741876602335\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16682.877980470657\n",
      "current PPL:  184.8778046150662\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16687.790256261826\n",
      "current PPL:  135.94845291000212\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16692.835035562515\n",
      "current PPL:  155.21004066915455\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16697.27729344368\n",
      "current PPL:  84.96656967307389\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16701.945847272873\n",
      "current PPL:  106.54355079278164\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16706.758706331253\n",
      "current PPL:  123.08301647253086\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16711.263716459274\n",
      "current PPL:  90.46926031881921\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16716.51131415367\n",
      "current PPL:  190.10901948994493\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16720.987714529037\n",
      "current PPL:  87.9176319305045\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16725.389859437943\n",
      "current PPL:  81.62576085534701\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16730.326149225235\n",
      "current PPL:  139.2526330314416\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16734.94745850563\n",
      "current PPL:  101.6270033053556\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16739.587370157242\n",
      "current PPL:  103.53520001110856\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16744.151512384415\n",
      "current PPL:  95.98022946376364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16749.1047270298\n",
      "current PPL:  141.62952159724907\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16753.67607665062\n",
      "current PPL:  96.67449567933049\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16758.212126493454\n",
      "current PPL:  93.32143673603338\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16762.66259598732\n",
      "current PPL:  85.6671547657859\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  16767.443644285202\n",
      "current PPL:  119.22927234916584\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16772.489869356155\n",
      "current PPL:  155.43460102280252\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16777.199454545975\n",
      "current PPL:  111.00610389209761\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16781.772369146347\n",
      "current PPL:  96.82590773587035\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16786.6341483593\n",
      "current PPL:  129.25396797944077\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16791.989485502243\n",
      "current PPL:  211.7353493998751\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16796.44456601143\n",
      "current PPL:  86.06307943467903\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16800.908885240555\n",
      "current PPL:  86.8618763716631\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16805.698848485947\n",
      "current PPL:  120.29694711480646\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  16811.782789468765\n",
      "current PPL:  438.75491755446217\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16817.222301244736\n",
      "current PPL:  230.32970350919854\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  16821.637529611588\n",
      "current PPL:  82.70072485396932\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  16826.377665281296\n",
      "current PPL:  114.4497279881157\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16831.368860006332\n",
      "current PPL:  147.1120770275793\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16835.771082639694\n",
      "current PPL:  81.63210541983005\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16840.48913359642\n",
      "current PPL:  111.94984480173028\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16845.0727956295\n",
      "current PPL:  97.87214980112317\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  16849.685462236404\n",
      "current PPL:  100.75245894219204\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16854.434505701065\n",
      "current PPL:  115.47377693499772\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16859.105616807938\n",
      "current PPL:  106.81636091405562\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16863.768540143967\n",
      "current PPL:  105.94534373911621\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16868.64807152748\n",
      "current PPL:  131.56899403760576\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16873.161549329758\n",
      "current PPL:  91.2385771105602\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16877.614056825638\n",
      "current PPL:  85.8419226278826\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16882.312777280807\n",
      "current PPL:  109.80658008230571\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16887.093965291977\n",
      "current PPL:  119.24593142647463\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16892.06648182869\n",
      "current PPL:  144.38979276144394\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16897.038871526718\n",
      "current PPL:  144.37147971156134\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16901.50665783882\n",
      "current PPL:  87.16355637721365\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16905.894733190536\n",
      "current PPL:  80.4853637976014\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16910.328592061996\n",
      "current PPL:  84.25592317086964\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16915.696709394455\n",
      "current PPL:  214.45873290254005\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16920.48285508156\n",
      "current PPL:  119.83858198173944\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  16925.319495916367\n",
      "current PPL:  126.04523302717696\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16929.732157945633\n",
      "current PPL:  82.48875897976308\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16934.780595541\n",
      "current PPL:  155.77888459981872\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16939.582869291306\n",
      "current PPL:  121.78701620665913\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16944.479949235916\n",
      "current PPL:  133.89821805907062\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  16948.926198720932\n",
      "current PPL:  85.30640034331304\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  16953.648285150528\n",
      "current PPL:  112.40252814455806\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  16958.84130358696\n",
      "current PPL:  180.0110857388585\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16963.426386117935\n",
      "current PPL:  98.01127577450693\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16967.552634954453\n",
      "current PPL:  61.945120294186744\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16972.717090845108\n",
      "current PPL:  174.94224496061108\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  16977.106802225113\n",
      "current PPL:  80.6171479015555\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  16982.464380979538\n",
      "current PPL:  212.21051015389682\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  16987.279408216476\n",
      "current PPL:  123.35017194546957\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  16992.409965753555\n",
      "current PPL:  169.1113776293238\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  16996.939972639084\n",
      "current PPL:  92.75919977603255\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17001.681411504745\n",
      "current PPL:  114.59897563883872\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17005.861570596695\n",
      "current PPL:  65.3762532222829\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17010.368203878403\n",
      "current PPL:  90.61622507314769\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  17015.588683366776\n",
      "current PPL:  185.02287912410318\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  17020.39378809929\n",
      "current PPL:  122.13228157219682\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  17024.968829393387\n",
      "current PPL:  97.03204590500792\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17029.4485976696\n",
      "current PPL:  88.21422897203318\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17034.056076288223\n",
      "current PPL:  100.23110991157503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17039.258180379868\n",
      "current PPL:  181.65405683058626\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17044.18003678322\n",
      "current PPL:  137.25718151430075\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  17049.217475175858\n",
      "current PPL:  154.07482986906965\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17053.53339266777\n",
      "current PPL:  74.88229583678837\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17058.17686200142\n",
      "current PPL:  103.90420133791076\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17063.453876256943\n",
      "current PPL:  195.78443949700014\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17067.95869898796\n",
      "current PPL:  90.4523082389902\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17072.597766637802\n",
      "current PPL:  103.44785298474734\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17076.667172193527\n",
      "current PPL:  58.522164084635364\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17081.28394293785\n",
      "current PPL:  101.16681057557207\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17086.188239336014\n",
      "current PPL:  134.86798325461638\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17091.262253522873\n",
      "current PPL:  159.81456699751416\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17095.607107400894\n",
      "current PPL:  77.08077346121938\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17100.30481648445\n",
      "current PPL:  109.69558096447929\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17105.29129099846\n",
      "current PPL:  146.41931326092637\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17109.279230833054\n",
      "current PPL:  53.943641983623024\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17113.84037089348\n",
      "current PPL:  95.69251291302756\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17118.18640255928\n",
      "current PPL:  77.17161173793906\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17123.08384490013\n",
      "current PPL:  133.9467510634273\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17127.917313814163\n",
      "current PPL:  125.64606093957022\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17132.340688943863\n",
      "current PPL:  83.37721992760744\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17136.72253060341\n",
      "current PPL:  79.98520335830888\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  17141.441890001297\n",
      "current PPL:  112.09642045866038\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17146.02619242668\n",
      "current PPL:  97.9348464456612\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  17150.92608809471\n",
      "current PPL:  134.2757696984987\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17155.694483995438\n",
      "current PPL:  117.7302394202348\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17160.797140836716\n",
      "current PPL:  164.45826688612385\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17165.034551858902\n",
      "current PPL:  69.22838886331965\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17170.159312963486\n",
      "current PPL:  168.13397041882416\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17174.79190468788\n",
      "current PPL:  102.78009690428456\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17179.477289438248\n",
      "current PPL:  108.35195274288587\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17183.761959314346\n",
      "current PPL:  72.57858283952453\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17188.708525896072\n",
      "current PPL:  140.69108237973938\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17193.120764017105\n",
      "current PPL:  82.4537987261418\n",
      "reps  torch.Size([64, 22, 1024])\n",
      "embs  torch.Size([64, 23, 512])\n",
      "val running loss:  17198.363001585007\n",
      "current PPL:  189.09273723152867\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17203.41279911995\n",
      "current PPL:  155.99087858679965\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17207.94486641884\n",
      "current PPL:  92.95051910133219\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17212.369850873947\n",
      "current PPL:  83.51150903461611\n",
      "reps  torch.Size([64, 19, 1024])\n",
      "embs  torch.Size([64, 20, 512])\n",
      "val running loss:  17217.450500249863\n",
      "current PPL:  160.8784926340396\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17221.942047834396\n",
      "current PPL:  89.25947562872524\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17226.647146463394\n",
      "current PPL:  110.50918382003883\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17231.160134077072\n",
      "current PPL:  91.19386396013871\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17236.16160750389\n",
      "current PPL:  148.6319962121103\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17240.813603639603\n",
      "current PPL:  104.79395990289723\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17246.112021684647\n",
      "current PPL:  200.0201367128317\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17250.469849824905\n",
      "current PPL:  78.08735533828478\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17255.052963495255\n",
      "current PPL:  97.81849507414884\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17259.707401514053\n",
      "current PPL:  105.05016718802939\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17263.81726527214\n",
      "current PPL:  60.938414637855594\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17268.38809609413\n",
      "current PPL:  96.62435407209065\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17273.46052479744\n",
      "current PPL:  159.5613843917904\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  17278.10595679283\n",
      "current PPL:  104.1083303914466\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17282.402989149094\n",
      "current PPL:  73.4814031812524\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17287.799022436142\n",
      "current PPL:  220.52990009866102\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17293.04344201088\n",
      "current PPL:  189.5057893541879\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17297.25854563713\n",
      "current PPL:  67.70118112704665\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17301.794320821762\n",
      "current PPL:  93.29580875753479\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17306.955077409744\n",
      "current PPL:  174.29627619979487\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17311.58030819893\n",
      "current PPL:  102.02631693625223\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17316.48451447487\n",
      "current PPL:  134.85582919985083\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17320.741265535355\n",
      "current PPL:  70.58029941784366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  17325.7720181942\n",
      "current PPL:  153.04816240894783\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17329.822352170944\n",
      "current PPL:  57.41662966278223\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17334.87380051613\n",
      "current PPL:  156.24860259496995\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17339.747357606888\n",
      "current PPL:  130.78530567254876\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17343.81304192543\n",
      "current PPL:  58.30479392543377\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  17348.89185166359\n",
      "current PPL:  160.58280654584172\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17353.42791867256\n",
      "current PPL:  93.3230387184162\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17358.915570497513\n",
      "current PPL:  241.68901190110378\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17363.628764390945\n",
      "current PPL:  111.40741569246643\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17368.146592855453\n",
      "current PPL:  91.6363900895051\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17372.481412172318\n",
      "current PPL:  76.31116950263385\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17377.351061582565\n",
      "current PPL:  130.2752357266409\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17382.931450605392\n",
      "current PPL:  265.1747447521119\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  17388.305195569992\n",
      "current PPL:  215.66903012032745\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17392.694710969925\n",
      "current PPL:  80.60135009518176\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17398.05344223976\n",
      "current PPL:  212.4552270302031\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  17403.008479356766\n",
      "current PPL:  141.88787272801775\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17407.35832476616\n",
      "current PPL:  77.46648640842423\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17411.700475931168\n",
      "current PPL:  76.87272752263186\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17416.376096010208\n",
      "current PPL:  107.2990803789766\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17420.87796807289\n",
      "current PPL:  90.18580684920789\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17425.884774446487\n",
      "current PPL:  149.42676007038747\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17430.32666373253\n",
      "current PPL:  84.93525718102008\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17435.1025826931\n",
      "current PPL:  118.61927098278346\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17439.728677511215\n",
      "current PPL:  102.11450872041414\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17444.02073407173\n",
      "current PPL:  73.11668286729238\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17448.455729722977\n",
      "current PPL:  84.35175806237328\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17453.00184559822\n",
      "current PPL:  94.26555714414451\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17458.09172320366\n",
      "current PPL:  162.3699876337729\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17462.556237459183\n",
      "current PPL:  86.87881838252574\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17467.487114191055\n",
      "current PPL:  138.50088726779742\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17472.072584867477\n",
      "current PPL:  98.04932578892387\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17476.948519468307\n",
      "current PPL:  131.09661898251989\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17481.959188699722\n",
      "current PPL:  150.00509068416247\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17486.474406957626\n",
      "current PPL:  91.39751207503839\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17491.144644021988\n",
      "current PPL:  106.72303966305921\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17495.616156339645\n",
      "current PPL:  87.48893407551648\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17500.066789388657\n",
      "current PPL:  85.68116721560084\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17505.516694784164\n",
      "current PPL:  232.73614698113497\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17510.749437570572\n",
      "current PPL:  187.30583953515523\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17516.412327051163\n",
      "current PPL:  287.97955285688136\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17521.190299272537\n",
      "current PPL:  118.86307749592284\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17526.0888774395\n",
      "current PPL:  134.09897771588498\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17530.525882959366\n",
      "current PPL:  84.52146450079302\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  17535.276193857193\n",
      "current PPL:  115.62022501672023\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17539.724145650864\n",
      "current PPL:  85.45174183987156\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17544.154032945633\n",
      "current PPL:  83.92195793360999\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17548.796715021133\n",
      "current PPL:  103.82243409896164\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17553.666358232498\n",
      "current PPL:  130.27442816819243\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17558.182986974716\n",
      "current PPL:  91.52651779103735\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17562.791402578354\n",
      "current PPL:  100.32506897192773\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17567.624847650528\n",
      "current PPL:  125.6430653397488\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17572.05710196495\n",
      "current PPL:  84.12083814120712\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17576.347987413406\n",
      "current PPL:  73.0311051584836\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17580.762743234634\n",
      "current PPL:  82.66165422041169\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17585.601024389267\n",
      "current PPL:  126.25215718616307\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17590.068228006363\n",
      "current PPL:  87.11278140269076\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17594.465064764023\n",
      "current PPL:  81.19362690208705\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17599.098425149918\n",
      "current PPL:  102.85913037874391\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17603.398169755936\n",
      "current PPL:  73.68097361918511\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17608.000932455063\n",
      "current PPL:  99.75954088113681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17613.020497083664\n",
      "current PPL:  151.3453979906987\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17617.26417374611\n",
      "current PPL:  69.66351077881897\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17621.93263888359\n",
      "current PPL:  106.53410168195555\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17626.98002552986\n",
      "current PPL:  155.6152549200595\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17631.5751349926\n",
      "current PPL:  98.99897165308221\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  17636.492737531662\n",
      "current PPL:  136.67454819166218\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  17641.66557908058\n",
      "current PPL:  176.41541897704917\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17646.568078279495\n",
      "current PPL:  134.6258162926838\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17651.116082906723\n",
      "current PPL:  94.44376964882117\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17656.203003168106\n",
      "current PPL:  161.89051305121075\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  17661.2277905941\n",
      "current PPL:  152.13791210973542\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17667.18955397606\n",
      "current PPL:  388.29423193191775\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  17672.71257376671\n",
      "current PPL:  250.3900221152406\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17676.948874235153\n",
      "current PPL:  69.15154969196453\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17681.343861818314\n",
      "current PPL:  81.04362445079452\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17685.92780327797\n",
      "current PPL:  97.89950170194732\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17690.381193876266\n",
      "current PPL:  85.9177633198549\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  17695.257932424545\n",
      "current PPL:  131.20205615218092\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17700.019125699997\n",
      "current PPL:  116.88531909714702\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  17704.661026716232\n",
      "current PPL:  103.74137428525977\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17709.374591588974\n",
      "current PPL:  111.4487532057736\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17714.803256750107\n",
      "current PPL:  227.8449061108537\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17719.7263982296\n",
      "current PPL:  137.43368082673288\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17724.38352036476\n",
      "current PPL:  105.33251281551654\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17728.70890212059\n",
      "current PPL:  75.59436594178712\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17733.640293836594\n",
      "current PPL:  138.5722313958204\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17738.50241112709\n",
      "current PPL:  129.29767323110406\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17743.369065999985\n",
      "current PPL:  129.88570518997548\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17747.938054800034\n",
      "current PPL:  96.44653371652261\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17752.56505036354\n",
      "current PPL:  102.20652933093339\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17757.114745378494\n",
      "current PPL:  94.60355124619537\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17761.659639120102\n",
      "current PPL:  94.15042240534667\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17766.232765436172\n",
      "current PPL:  96.84640947072755\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17770.9914124012\n",
      "current PPL:  116.58807139369168\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17775.969424962997\n",
      "current PPL:  145.18554742527533\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17780.562017679214\n",
      "current PPL:  98.75012960312127\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17785.993223428726\n",
      "current PPL:  228.4245021772728\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17790.56506419182\n",
      "current PPL:  96.7219882727301\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17795.308277845383\n",
      "current PPL:  114.80254510735972\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17799.640312433243\n",
      "current PPL:  76.09895918684438\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17804.249197244644\n",
      "current PPL:  100.37215331848692\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17809.06908583641\n",
      "current PPL:  123.95128081731283\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17813.34573674202\n",
      "current PPL:  71.99890464303351\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17817.846388578415\n",
      "current PPL:  90.07582687077692\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17822.666567087173\n",
      "current PPL:  123.98722160949663\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17827.195463895798\n",
      "current PPL:  92.65628706178175\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17831.90704035759\n",
      "current PPL:  111.22736746043063\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  17836.517390966415\n",
      "current PPL:  100.5193864428999\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17841.21833062172\n",
      "current PPL:  110.05053345012276\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17845.526178121567\n",
      "current PPL:  74.28042810383039\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17849.717178106308\n",
      "current PPL:  66.0888457653366\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17854.490466833115\n",
      "current PPL:  118.3076845233526\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17858.925028562546\n",
      "current PPL:  84.31516393457308\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17863.65861392021\n",
      "current PPL:  113.70249652802094\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17868.03099179268\n",
      "current PPL:  79.23181101962163\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17873.092435598373\n",
      "current PPL:  157.81821074194167\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17878.52220416069\n",
      "current PPL:  228.09644920099421\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17883.17653107643\n",
      "current PPL:  105.03849644156578\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17887.26074385643\n",
      "current PPL:  59.39516228264263\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17891.907668828964\n",
      "current PPL:  104.26387783454344\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17896.306245088577\n",
      "current PPL:  81.3349862864826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17900.734007120132\n",
      "current PPL:  83.74379107635251\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17905.129561662674\n",
      "current PPL:  81.08958592186796\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17910.041127443314\n",
      "current PPL:  135.85196233580928\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17914.55228447914\n",
      "current PPL:  91.02707919550902\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17918.759226083755\n",
      "current PPL:  67.1508515778622\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17923.488488435745\n",
      "current PPL:  113.21202091839577\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17927.904425382614\n",
      "current PPL:  82.75934570132748\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17932.86508011818\n",
      "current PPL:  142.68718769666776\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17937.300563097\n",
      "current PPL:  84.39287501803389\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17941.91018462181\n",
      "current PPL:  100.44612607478444\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  17946.42385983467\n",
      "current PPL:  91.25659034924843\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17950.869074106216\n",
      "current PPL:  85.2181357028162\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17955.075453042984\n",
      "current PPL:  67.11307858062425\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17959.666702985764\n",
      "current PPL:  98.61761953754872\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17964.20422911644\n",
      "current PPL:  93.45930778210034\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  17969.455404520035\n",
      "current PPL:  190.7903924279124\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  17974.320558786392\n",
      "current PPL:  129.69094401821306\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17978.747178316116\n",
      "current PPL:  83.64816827672159\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  17983.383157491684\n",
      "current PPL:  103.12884982223888\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  17988.10792040825\n",
      "current PPL:  112.70377500823763\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  17993.225816965103\n",
      "current PPL:  166.98375911083252\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  17997.59196639061\n",
      "current PPL:  78.73985354302758\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18002.5945956707\n",
      "current PPL:  148.80389231537825\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18007.318372488022\n",
      "current PPL:  112.59269267910192\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18011.407682180405\n",
      "current PPL:  59.698667032341405\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18015.858295679092\n",
      "current PPL:  85.6794921374393\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18020.154133081436\n",
      "current PPL:  73.39364873229073\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18025.157395601273\n",
      "current PPL:  148.89815069529234\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18029.62039208412\n",
      "current PPL:  86.74705610387402\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18034.472692728043\n",
      "current PPL:  128.0346133193278\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18039.25049805641\n",
      "current PPL:  118.84324173496282\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18043.698813676834\n",
      "current PPL:  85.48283712583847\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18048.53583407402\n",
      "current PPL:  126.09308413621734\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18052.77052140236\n",
      "current PPL:  69.04008847919732\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18057.43096280098\n",
      "current PPL:  105.68272006980766\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18061.963883161545\n",
      "current PPL:  93.02984545727071\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  18067.124716997147\n",
      "current PPL:  174.3097406922848\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18071.89919114113\n",
      "current PPL:  118.4480116412111\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18076.678960561752\n",
      "current PPL:  119.07689020403349\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18081.724160909653\n",
      "current PPL:  155.2754051836575\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18086.08293223381\n",
      "current PPL:  78.1610408185663\n",
      "reps  torch.Size([64, 26, 1024])\n",
      "embs  torch.Size([64, 27, 512])\n",
      "val running loss:  18091.833137750626\n",
      "current PPL:  314.25523838527255\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18096.821266412735\n",
      "current PPL:  146.66171291721915\n",
      "reps  torch.Size([64, 20, 1024])\n",
      "embs  torch.Size([64, 21, 512])\n",
      "val running loss:  18101.475336313248\n",
      "current PPL:  105.01150341738328\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18106.0971057415\n",
      "current PPL:  101.67377751390819\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18110.816702127457\n",
      "current PPL:  112.12298912083638\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18115.436594724655\n",
      "current PPL:  101.48313197152221\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18120.84482359886\n",
      "current PPL:  223.23585855385147\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18125.954578638077\n",
      "current PPL:  165.62977710374724\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18130.451521635056\n",
      "current PPL:  89.7423688469754\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18134.81009554863\n",
      "current PPL:  78.14561252479601\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18139.18021416664\n",
      "current PPL:  79.05300825407951\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18144.529713392258\n",
      "current PPL:  210.50285702937947\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18149.09374642372\n",
      "current PPL:  95.96974940673448\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18153.860452890396\n",
      "current PPL:  117.53150986237405\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18158.70855641365\n",
      "current PPL:  127.49836273914133\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18163.33483195305\n",
      "current PPL:  102.1329646530785\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18167.897492170334\n",
      "current PPL:  95.83809116587202\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18172.652634382248\n",
      "current PPL:  116.18017419457595\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18178.020797491074\n",
      "current PPL:  214.46855026894394\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18182.84639954567\n",
      "current PPL:  124.66149882302248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  18187.821687459946\n",
      "current PPL:  144.79050640141912\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18192.115560770035\n",
      "current PPL:  73.2496383064522\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18196.70174574852\n",
      "current PPL:  98.11938764429446\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18201.590759038925\n",
      "current PPL:  132.82245218435358\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18207.150103330612\n",
      "current PPL:  259.65252417291816\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18212.23193669319\n",
      "current PPL:  161.06908343002928\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18217.38068461418\n",
      "current PPL:  172.21572757135388\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18222.25708603859\n",
      "current PPL:  131.1578322620308\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18226.80763745308\n",
      "current PPL:  94.68460438558078\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18232.41104054451\n",
      "current PPL:  271.3482609020543\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18237.309504270554\n",
      "current PPL:  134.08363218387163\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18242.119480848312\n",
      "current PPL:  122.7287429013806\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18246.749284029007\n",
      "current PPL:  102.49388934905586\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18251.584780454636\n",
      "current PPL:  125.90106821294727\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18256.086391210556\n",
      "current PPL:  90.16224376670955\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18260.48114132881\n",
      "current PPL:  81.02438171905803\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18265.441690683365\n",
      "current PPL:  142.67215196868818\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18270.22163081169\n",
      "current PPL:  119.09721928151303\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18274.787097215652\n",
      "current PPL:  96.10740844089946\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18279.267935037613\n",
      "current PPL:  88.30862859871432\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18283.598271608353\n",
      "current PPL:  75.96985149585922\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18288.590722322464\n",
      "current PPL:  147.29696427295843\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18292.976944208145\n",
      "current PPL:  80.33632507134853\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18297.171305418015\n",
      "current PPL:  66.31135900346563\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18302.080381155014\n",
      "current PPL:  135.51410583427946\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18306.741112470627\n",
      "current PPL:  105.71336372798046\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18311.47657942772\n",
      "current PPL:  113.91664048364561\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18316.351334810257\n",
      "current PPL:  130.94211856412858\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18321.023281812668\n",
      "current PPL:  106.90568556140033\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18325.50586628914\n",
      "current PPL:  88.4630080477042\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18329.99640917778\n",
      "current PPL:  89.16984203500067\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18334.451154470444\n",
      "current PPL:  86.03423450341855\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18338.97900032997\n",
      "current PPL:  92.55896117182854\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18343.550183057785\n",
      "current PPL:  96.6583627284796\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18347.898704767227\n",
      "current PPL:  77.36401186188691\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18352.641592741013\n",
      "current PPL:  114.76516232757261\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18357.17899441719\n",
      "current PPL:  93.44767707460164\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18361.759459733963\n",
      "current PPL:  97.55977984876617\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18366.485119104385\n",
      "current PPL:  112.80485404166531\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18371.60871386528\n",
      "current PPL:  167.93798274023936\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18376.201680898666\n",
      "current PPL:  98.78710039106006\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18380.798738718033\n",
      "current PPL:  99.19204498248257\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18385.44091296196\n",
      "current PPL:  103.76972317415874\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18389.875666856766\n",
      "current PPL:  84.33136794652332\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18395.27640938759\n",
      "current PPL:  221.57087834412184\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18400.230065107346\n",
      "current PPL:  141.69200452824722\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18405.166323423386\n",
      "current PPL:  139.2482506456343\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18409.599206209183\n",
      "current PPL:  84.17372229632696\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18414.611653089523\n",
      "current PPL:  150.27198422370307\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18418.879143953323\n",
      "current PPL:  71.34240304770785\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18423.18632054329\n",
      "current PPL:  74.23060934442435\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18428.30907034874\n",
      "current PPL:  167.79614256016728\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18432.98458647728\n",
      "current PPL:  107.28792716557037\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  18437.920613527298\n",
      "current PPL:  139.2160509801626\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18442.016090154648\n",
      "current PPL:  60.0679623693211\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18446.58541035652\n",
      "current PPL:  96.4785015706165\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18451.1144220829\n",
      "current PPL:  92.66693552612638\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18455.364730119705\n",
      "current PPL:  70.1270107202404\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18459.69153189659\n",
      "current PPL:  75.70178778581403\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18464.292174100876\n",
      "current PPL:  99.54822541506488\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  18469.10142636299\n",
      "current PPL:  122.63988073902543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18474.007217645645\n",
      "current PPL:  135.06974607959768\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18479.131121873856\n",
      "current PPL:  167.98996209949922\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18483.6966650486\n",
      "current PPL:  96.1147869650706\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18488.15305161476\n",
      "current PPL:  86.175556154492\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18492.846558332443\n",
      "current PPL:  109.23556724832257\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18497.72778391838\n",
      "current PPL:  131.79208747546753\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18502.508878469467\n",
      "current PPL:  119.23478721260285\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18506.96058821678\n",
      "current PPL:  85.7734696649883\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18511.42878985405\n",
      "current PPL:  87.1997651143095\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18516.436280965805\n",
      "current PPL:  149.52911331359675\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18521.585146665573\n",
      "current PPL:  172.2360121238342\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18526.003843545914\n",
      "current PPL:  82.98807147839877\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18530.747446775436\n",
      "current PPL:  114.84727813176934\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18535.60796236992\n",
      "current PPL:  129.09074342677812\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18540.746475934982\n",
      "current PPL:  170.46219894295425\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18545.246868371964\n",
      "current PPL:  90.05246428431707\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18549.852670431137\n",
      "current PPL:  100.06320728594079\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18554.497195005417\n",
      "current PPL:  104.01390314362652\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18559.18068099022\n",
      "current PPL:  108.14641298389041\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18563.87393784523\n",
      "current PPL:  109.208276767311\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18568.70031094551\n",
      "current PPL:  124.75765559962244\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18573.665543317795\n",
      "current PPL:  143.34185507788533\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18578.130187749863\n",
      "current PPL:  86.89012870301929\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18583.09717106819\n",
      "current PPL:  143.59305879000019\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18587.707921743393\n",
      "current PPL:  100.55960891481776\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18592.243315935135\n",
      "current PPL:  93.26027048813079\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18597.08901000023\n",
      "current PPL:  127.19153056668526\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18601.70887875557\n",
      "current PPL:  101.48071245395248\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18606.267640829086\n",
      "current PPL:  95.4652277178447\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18610.88561463356\n",
      "current PPL:  101.28859357534137\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18615.322703123093\n",
      "current PPL:  84.52847750936199\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18620.075846910477\n",
      "current PPL:  115.94822872451432\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18624.733736753464\n",
      "current PPL:  105.41340845793674\n",
      "reps  torch.Size([64, 18, 1024])\n",
      "embs  torch.Size([64, 19, 512])\n",
      "val running loss:  18629.839324235916\n",
      "current PPL:  164.94094198281226\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18634.506631612778\n",
      "current PPL:  106.41083206645119\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18639.21464753151\n",
      "current PPL:  110.83204183370592\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18643.663795232773\n",
      "current PPL:  85.55399535744574\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18648.403444051743\n",
      "current PPL:  114.39402161496541\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18652.793289899826\n",
      "current PPL:  80.62798906341587\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18657.19683623314\n",
      "current PPL:  81.74023338248946\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18662.086179494858\n",
      "current PPL:  132.86628701508064\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18667.378680944443\n",
      "current PPL:  198.8401925484952\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18672.17915701866\n",
      "current PPL:  121.56827926797578\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18676.826548814774\n",
      "current PPL:  104.31256203361977\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18681.250223875046\n",
      "current PPL:  83.40223105552806\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18685.79773926735\n",
      "current PPL:  94.39757575907832\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18690.974603891373\n",
      "current PPL:  177.12658102703665\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18696.03465437889\n",
      "current PPL:  157.59847287829706\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18701.21696305275\n",
      "current PPL:  178.09349654131734\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18706.179052591324\n",
      "current PPL:  142.89206264537455\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18710.950087308884\n",
      "current PPL:  118.04131821729892\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18715.435683965683\n",
      "current PPL:  88.72987630621338\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18719.850850343704\n",
      "current PPL:  82.69559849163888\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18724.396249055862\n",
      "current PPL:  94.19797760195837\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18729.572026014328\n",
      "current PPL:  176.93403127931865\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18734.529721021652\n",
      "current PPL:  142.26549675075265\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18739.02384829521\n",
      "current PPL:  89.49003457579295\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18743.599971055984\n",
      "current PPL:  97.13703959239616\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  18749.17760491371\n",
      "current PPL:  264.4451500883464\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18753.758692502975\n",
      "current PPL:  97.62050750865498\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18758.09852385521\n",
      "current PPL:  76.69460387394139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18763.218492269516\n",
      "current PPL:  167.33008430090175\n",
      "reps  torch.Size([64, 25, 1024])\n",
      "embs  torch.Size([64, 26, 512])\n",
      "val running loss:  18768.523015737534\n",
      "current PPL:  201.24507984357464\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18773.150203466415\n",
      "current PPL:  102.22617177418306\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18777.862875699997\n",
      "current PPL:  111.34931407254652\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18782.175761938095\n",
      "current PPL:  74.65565227250706\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  18786.72891688347\n",
      "current PPL:  94.93143985977957\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18791.20730614662\n",
      "current PPL:  88.09266423701197\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18795.832154989243\n",
      "current PPL:  101.98735577610361\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18800.68949484825\n",
      "current PPL:  128.68143564418162\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18805.9870865345\n",
      "current PPL:  199.85491658860212\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18810.810686826706\n",
      "current PPL:  124.41220571920437\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18815.455751657486\n",
      "current PPL:  104.07011251328711\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18820.35344338417\n",
      "current PPL:  133.98015965125916\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18825.200532197952\n",
      "current PPL:  127.36905455893447\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18829.599442243576\n",
      "current PPL:  81.36213929848462\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18834.458343744278\n",
      "current PPL:  128.88254693022685\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  18839.025446653366\n",
      "current PPL:  96.2648174727646\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18843.72225213051\n",
      "current PPL:  109.59650410382994\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18848.358646154404\n",
      "current PPL:  103.17164152853893\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18853.166877508163\n",
      "current PPL:  122.51474054923702\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18857.942074537277\n",
      "current PPL:  118.5336669034498\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18862.599277734756\n",
      "current PPL:  105.34105165913424\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18867.506764650345\n",
      "current PPL:  135.29896907362206\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18871.85534977913\n",
      "current PPL:  77.36891839219966\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18876.329855680466\n",
      "current PPL:  87.75123193008098\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18880.880727529526\n",
      "current PPL:  94.7149494676493\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18885.72968840599\n",
      "current PPL:  127.60772074228161\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18890.18595814705\n",
      "current PPL:  86.16548927424631\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18894.847891569138\n",
      "current PPL:  105.8405188587905\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18899.149299383163\n",
      "current PPL:  73.80362237145222\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18903.682438135147\n",
      "current PPL:  93.05016459586095\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18908.4787709713\n",
      "current PPL:  121.06563495207901\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18913.100707769394\n",
      "current PPL:  101.6907960621962\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18917.7709543705\n",
      "current PPL:  106.72405745813138\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18922.512989759445\n",
      "current PPL:  114.66735698974067\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  18927.6198990345\n",
      "current PPL:  165.15910385038913\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18932.02969479561\n",
      "current PPL:  82.25266259592077\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18936.521409749985\n",
      "current PPL:  89.27441622337307\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18940.963157892227\n",
      "current PPL:  84.92326994214922\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18945.938645124435\n",
      "current PPL:  144.81936862203045\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18950.699932336807\n",
      "current PPL:  116.89629945975828\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18955.718423128128\n",
      "current PPL:  151.18296488910732\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18959.89103770256\n",
      "current PPL:  64.88487686416552\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  18964.43217253685\n",
      "current PPL:  93.7971840046882\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18969.282382249832\n",
      "current PPL:  127.76718147330585\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  18974.039667367935\n",
      "current PPL:  116.42940435194284\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  18978.39489388466\n",
      "current PPL:  77.88446547280053\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  18983.04744410515\n",
      "current PPL:  104.85204073025338\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  18987.640177488327\n",
      "current PPL:  98.76402146085685\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18992.241859197617\n",
      "current PPL:  99.65176009669787\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  18997.06733393669\n",
      "current PPL:  124.64562848961256\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19001.97646164894\n",
      "current PPL:  135.5211493968857\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19006.55347800255\n",
      "current PPL:  97.22387934885136\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19011.04060959816\n",
      "current PPL:  88.86617581610581\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19015.513518571854\n",
      "current PPL:  87.6112113932095\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19019.787678956985\n",
      "current PPL:  71.81981300494408\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  19024.244774580002\n",
      "current PPL:  86.23668119125418\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19029.168522119522\n",
      "current PPL:  137.51699913259043\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  19034.349504232407\n",
      "current PPL:  177.8574012910561\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19039.137334108353\n",
      "current PPL:  120.04058284049533\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19043.38300871849\n",
      "current PPL:  69.80283396332855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19047.846525907516\n",
      "current PPL:  86.79223759392247\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19052.890820741653\n",
      "current PPL:  155.13486480736748\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  19057.00328564644\n",
      "current PPL:  61.097130726297834\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19061.967720270157\n",
      "current PPL:  143.22754991804658\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  19066.89712691307\n",
      "current PPL:  138.2974282307336\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19071.710928678513\n",
      "current PPL:  123.19910241026271\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19076.212844610214\n",
      "current PPL:  90.18976329882408\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  19080.49928689003\n",
      "current PPL:  72.70733545662999\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19085.409735441208\n",
      "current PPL:  135.7002692748191\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19090.210792779922\n",
      "current PPL:  121.63896313355637\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19094.638129472733\n",
      "current PPL:  83.70817917144309\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19098.835436582565\n",
      "current PPL:  66.5069936520959\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19103.441126585007\n",
      "current PPL:  100.05199515813004\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19108.13034749031\n",
      "current PPL:  108.76840590011923\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  19114.018713712692\n",
      "current PPL:  360.81531058172266\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19118.869180440903\n",
      "current PPL:  127.80002380492671\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19123.748328447342\n",
      "current PPL:  131.51856316912233\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19128.32588982582\n",
      "current PPL:  97.27688322413499\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19133.350583791733\n",
      "current PPL:  152.12369395226645\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19137.99817967415\n",
      "current PPL:  104.33385297135632\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19142.524861574173\n",
      "current PPL:  92.45128896456933\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19146.832690000534\n",
      "current PPL:  74.27901133061195\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19151.439385652542\n",
      "current PPL:  100.15266301351184\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19156.421994447708\n",
      "current PPL:  145.8543899836722\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  19161.258040189743\n",
      "current PPL:  125.97024673398978\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19165.71244120598\n",
      "current PPL:  86.00462004253176\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  19170.473173379898\n",
      "current PPL:  116.83143552129947\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  19175.03830075264\n",
      "current PPL:  96.07483055178723\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19179.662442922592\n",
      "current PPL:  101.915309558793\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19184.089534521103\n",
      "current PPL:  83.68766528794265\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  19188.396181344986\n",
      "current PPL:  74.19129489993989\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19192.781231164932\n",
      "current PPL:  80.24222077645022\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19197.483617544174\n",
      "current PPL:  110.20986141525442\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  19201.925378084183\n",
      "current PPL:  84.92432280751412\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  19207.179292440414\n",
      "current PPL:  191.31367457168466\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  19211.852592229843\n",
      "current PPL:  107.05040404953522\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19216.363695383072\n",
      "current PPL:  91.02217455205243\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  19220.607444047928\n",
      "current PPL:  69.66852690013027\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19225.356922388077\n",
      "current PPL:  115.52400457071823\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19230.04723572731\n",
      "current PPL:  108.88729312357087\n",
      "reps  torch.Size([64, 8, 1024])\n",
      "embs  torch.Size([64, 9, 512])\n",
      "val running loss:  19235.305752038956\n",
      "current PPL:  192.19612050316422\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19240.070832014084\n",
      "current PPL:  117.34050123418872\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19244.614844560623\n",
      "current PPL:  94.06749406082942\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19249.199934244156\n",
      "current PPL:  98.0119768082872\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19254.377159833908\n",
      "current PPL:  177.19052919329368\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19259.19885134697\n",
      "current PPL:  124.17495679556498\n",
      "reps  torch.Size([64, 15, 1024])\n",
      "embs  torch.Size([64, 16, 512])\n",
      "val running loss:  19263.900706529617\n",
      "current PPL:  110.15133385841483\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19268.117172956467\n",
      "current PPL:  67.79350723392933\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19272.38495182991\n",
      "current PPL:  71.36295330697432\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19277.029118299484\n",
      "current PPL:  103.97666194396348\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19282.11511015892\n",
      "current PPL:  161.74028333126256\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19286.757140398026\n",
      "current PPL:  103.75478090957205\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19291.987437963486\n",
      "current PPL:  186.84839487733427\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  19296.575434446335\n",
      "current PPL:  98.29729243220604\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19300.993960618973\n",
      "current PPL:  82.97390598448429\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19305.695560216904\n",
      "current PPL:  110.12318445837728\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19310.949478387833\n",
      "current PPL:  191.31440437682792\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19315.112167596817\n",
      "current PPL:  64.24405619963015\n",
      "reps  torch.Size([64, 16, 1024])\n",
      "embs  torch.Size([64, 17, 512])\n",
      "val running loss:  19319.878340005875\n",
      "current PPL:  117.46875802231308\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19324.383949041367\n",
      "current PPL:  90.52345926314942\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19329.196907281876\n",
      "current PPL:  123.09522471354647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19333.88366484642\n",
      "current PPL:  108.5008019876757\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19338.273131608963\n",
      "current PPL:  80.5974299512052\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19342.8873026371\n",
      "current PPL:  100.9041471536893\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19347.735355615616\n",
      "current PPL:  127.49191853056493\n",
      "reps  torch.Size([64, 21, 1024])\n",
      "embs  torch.Size([64, 22, 512])\n",
      "val running loss:  19352.584175348282\n",
      "current PPL:  127.58971097482966\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  19358.174288988113\n",
      "current PPL:  267.7660468732054\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19362.651074171066\n",
      "current PPL:  87.95146981239269\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19367.322777032852\n",
      "current PPL:  106.87958872628977\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  19371.729518175125\n",
      "current PPL:  82.00179541036827\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19376.418247938156\n",
      "current PPL:  108.7149982544702\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19381.329653978348\n",
      "current PPL:  135.83026301566005\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19386.385154008865\n",
      "current PPL:  156.88295700086158\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19390.896713018417\n",
      "current PPL:  91.0636770447454\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  19396.564846754074\n",
      "current PPL:  289.4937580546404\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19400.94662642479\n",
      "current PPL:  79.98024532276308\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19405.53931069374\n",
      "current PPL:  98.75917086137595\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19409.998970270157\n",
      "current PPL:  86.45807171938591\n",
      "reps  torch.Size([64, 17, 1024])\n",
      "embs  torch.Size([64, 18, 512])\n",
      "val running loss:  19414.675368070602\n",
      "current PPL:  107.38256162889697\n",
      "reps  torch.Size([64, 24, 1024])\n",
      "embs  torch.Size([64, 25, 512])\n",
      "val running loss:  19419.89253306389\n",
      "current PPL:  184.4106368977518\n",
      "reps  torch.Size([64, 13, 1024])\n",
      "embs  torch.Size([64, 14, 512])\n",
      "val running loss:  19424.87987112999\n",
      "current PPL:  146.54580857520838\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19429.848306894302\n",
      "current PPL:  143.8017714868212\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  19435.034059286118\n",
      "current PPL:  178.7078575491654\n",
      "reps  torch.Size([64, 11, 1024])\n",
      "embs  torch.Size([64, 12, 512])\n",
      "val running loss:  19439.58314871788\n",
      "current PPL:  94.54627826928589\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19443.98651242256\n",
      "current PPL:  81.72530663858772\n",
      "reps  torch.Size([64, 12, 1024])\n",
      "embs  torch.Size([64, 13, 512])\n",
      "val running loss:  19448.560984373093\n",
      "current PPL:  96.97681705747569\n",
      "reps  torch.Size([64, 9, 1024])\n",
      "embs  torch.Size([64, 10, 512])\n",
      "val running loss:  19454.30169224739\n",
      "current PPL:  311.28468343638565\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19458.701399564743\n",
      "current PPL:  81.42703289739731\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19463.30420565605\n",
      "current PPL:  99.76386975914981\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19468.121821165085\n",
      "current PPL:  123.66984928089514\n",
      "reps  torch.Size([64, 10, 1024])\n",
      "embs  torch.Size([64, 11, 512])\n",
      "val running loss:  19472.862161397934\n",
      "current PPL:  114.473142578744\n",
      "reps  torch.Size([64, 14, 1024])\n",
      "embs  torch.Size([64, 15, 512])\n",
      "val running loss:  19477.394936323166\n",
      "current PPL:  93.01631661450398\n",
      "FINAL VAL LOSS  4.720648312245071\n",
      "FINAL AVG PPL  119.00895866134093\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "val_running_loss = 0.0\n",
    "val_running_ppl = 0.0\n",
    "losses_list = []\n",
    "ppl_list = []\n",
    "counter = 0\n",
    "total = 0\n",
    "\n",
    "total_steps = math.ceil(len(data_loader_val.dataset.ids) / data_loader_val.batch_sampler.batch_size)\n",
    "print(\"Val total steps: \", total_steps+1)\n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "decoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "        print(\"Validating the model...\")\n",
    "        for i in range(1, total_steps+1): \n",
    "            \n",
    "            hidden = decoder.init_hidden(batch_size=64)\n",
    "             # get val indices\n",
    "            indices = data_loader_val.dataset.get_func_train_indices()\n",
    "            # create separate lists for retrieving the image emebddings\n",
    "            target_inds = [x[0] for x in indices]\n",
    "            distractor_inds = [x[1] for x in indices]\n",
    "\n",
    "            new_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices=indices)\n",
    "            data_loader_val.batch_sampler.sampler = new_sampler\n",
    "\n",
    "            counter += 1\n",
    "            # print(\"Counter: \", counter)\n",
    "            # Obtain the batch.\n",
    "            targets, distractors, target_captions = next(iter(data_loader_val))\n",
    "\n",
    "            # Move batch of images and captions to GPU if CUDA is available.\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            targets = targets.to(device)\n",
    "            distractors = distractors.to(device)\n",
    "            target_captions = target_captions.to(device)\n",
    "\n",
    "            # Pass the inputs through the CNN-RNN model.\n",
    "            # after retrieving the resnet embeddings\n",
    "            # target_features = torch.index_select(embedded_imgs, 0, target_inds)\n",
    "            # distractor_features = torch.index_select(embedded_imgs, 0, distractor_inds)\n",
    "\n",
    "            # compute val predictions and loss\n",
    "#             target_features = encoder(targets)#encoder(target_features)\n",
    "#             distractor_features = encoder(distractors) #encoder(distractor_features)\n",
    "            test_targets = [str(data_loader_val.dataset.ids[i]) for i in target_inds]\n",
    "            test_dists = [str(data_loader_val.dataset.ids[i]) for i in distractor_inds]\n",
    "            target_features = [embedded_imgs[i] for i in test_targets]\n",
    "            target_features_arr = torch.stack(target_features)\n",
    "            \n",
    "            distractor_features = [embedded_imgs[i] for i in test_dists]\n",
    "            distractor_features_arr = torch.stack(distractor_features)\n",
    "            \n",
    "            both_images = torch.cat((target_features_arr.unsqueeze(1), distractor_features_arr.unsqueeze(1)), dim=1)\n",
    "            outputs, hidden = decoder(both_images, target_captions, hidden)\n",
    "            \n",
    "            # The size of the vocabulary.\n",
    "            vocab_size = len(data_loader_val.dataset.vocab)\n",
    "\n",
    "            # Calculate the batch loss.\n",
    "            loss = criterion(outputs.transpose(1,2), target_captions[:, 1:]) \n",
    "            losses_list.append(loss)\n",
    "            ppl = np.exp(loss.item())\n",
    "            ppl_list.append(ppl)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "            val_running_ppl += ppl\n",
    "            \n",
    "            print(\"val running loss: \", val_running_loss)\n",
    "            print(\"current PPL: \", ppl)\n",
    "            \n",
    "        \n",
    "        val_loss = val_running_loss / counter\n",
    "        ppl_avg = val_running_ppl / counter\n",
    "        print(\"FINAL VAL LOSS \", val_loss)\n",
    "        print(\"FINAL AVG PPL \", ppl_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3188070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the train and val losses and perplexities\n",
    "# train_losses_1 = pd.read_csv('../../../data/pretraining_losses_epoch_1.csv')\n",
    "# train_losses_2 = pd.read_csv('../../../data/pretraining_losses_epoch_2.csv')\n",
    "# train_losses_3 = pd.read_csv('../../../data/pretraining_losses_epoch_3.csv')\n",
    "# val_losses = pd.read_csv('../../../data/pretraining_2imgs_token0_1024dim_val_losses_6000vocab_epoch_8.csv')\n",
    "# val_losses_1 = pd.read_csv('../../../data/pretrain_val_losses_epoch_1.csv')\n",
    "# val_losses_2 = pd.read_csv('../../../data/pretrain_val_losses_epoch_2.csv')\n",
    "# val_losses_3 = pd.read_csv('../../../data/pretrain_val_losses_epoch_3.csv')\n",
    "# train_losses = pd.read_csv('../../../data/pretraining_2imgs_token0_1024dim_losses_6000vocab_epoch_8.csv')\n",
    "# train_losses = pd.read_csv(\"../functional_training_losses_token0_noEnc_vocab4000_metrics_epoch_5.csv\")\n",
    "train_losses = pd.read_csv(\"../../../data/pretrain_noEnc_prepend_512dim_losses_4000vocab_rs1234_leon_DSfix_cont_epoch_7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4ef7265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ppl_list)\n",
    "csv_val = pd.DataFrame({\"losses\":losses_list, \"ppl\": ppl_list})\n",
    "csv_val.to_csv(\"val_results_leon_df_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc374c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>losses</th>\n",
       "      <th>perplexities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.991168</td>\n",
       "      <td>19.908918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.039926</td>\n",
       "      <td>20.903687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.974365</td>\n",
       "      <td>19.577179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.008687</td>\n",
       "      <td>20.260777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.990944</td>\n",
       "      <td>19.904457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   steps    losses  perplexities\n",
       "0      1  2.991168     19.908918\n",
       "1      2  3.039926     20.903687\n",
       "2      3  2.974365     19.577179\n",
       "3      4  3.008687     20.260777\n",
       "4      5  2.990944     19.904457"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(val_losses)\n",
    "# val_steps = [i*1000 for i in range(1, len(val_losses)+1)]\n",
    "# # val_losses.head()\n",
    "# train_losses[\"speaker\"] = train_losses[\"speaker_s\"] + train_losses[\"speaker_f\"]\n",
    "# train_losses[\"plot_steps\"] = list(range(0, len(train_losses[\"listener\"])))\n",
    "train_losses.head()\n",
    "# len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24d71cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>speaker_s</th>\n",
       "      <th>speaker_f</th>\n",
       "      <th>listener</th>\n",
       "      <th>perplexities</th>\n",
       "      <th>accuracies</th>\n",
       "      <th>speaker</th>\n",
       "      <th>plot_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.210864</td>\n",
       "      <td>-19.303410</td>\n",
       "      <td>0.749412</td>\n",
       "      <td>1354.061157</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>-12.092546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>7.471138</td>\n",
       "      <td>-23.065058</td>\n",
       "      <td>0.702742</td>\n",
       "      <td>1756.605347</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>-15.593919</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>7.537291</td>\n",
       "      <td>-23.859810</td>\n",
       "      <td>0.728382</td>\n",
       "      <td>1876.738281</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>-16.322519</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>7.237387</td>\n",
       "      <td>6.465183</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>1390.456177</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>13.702570</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>7.376411</td>\n",
       "      <td>-32.573551</td>\n",
       "      <td>0.682326</td>\n",
       "      <td>1597.844727</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>-25.197140</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    steps  speaker_s  speaker_f  listener  perplexities  accuracies  \\\n",
       "0       1   7.210864 -19.303410  0.749412   1354.061157    0.453125   \n",
       "20     21   7.471138 -23.065058  0.702742   1756.605347    0.421875   \n",
       "40     41   7.537291 -23.859810  0.728382   1876.738281    0.437500   \n",
       "60     61   7.237387   6.465183  0.726273   1390.456177    0.578125   \n",
       "80     81   7.376411 -32.573551  0.682326   1597.844727    0.406250   \n",
       "\n",
       "      speaker  plot_steps  \n",
       "0  -12.092546           0  \n",
       "20 -15.593919          20  \n",
       "40 -16.322519          40  \n",
       "60  13.702570          60  \n",
       "80 -25.197140          80  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds2keep = list(np.arange(0, len(train_losses), 20))\n",
    "train_losses_plot = train_losses[train_losses.index.isin(inds2keep)]\n",
    "len(train_losses_plot)\n",
    "train_losses_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b47abbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(0, len(train_losses[\"steps\"]))), train_losses['losses'], label=\"PPL\")\n",
    "# plt.plot(val_steps, val_losses[\"val_losses\"], label=\"Val\")\n",
    "# plt.plot(list(range(0, len(train_losses[\"perplexities\"][200:]))), train_losses['perplexities'][200:], label=\"PPL\")\n",
    "# plt.plot(list(range(0, len(train_losses[\"perplexities\"]))), train_losses['perplexities'], label=\"PPL\")\n",
    "# plt.plot(list(range(0, len(train_losses[\"listener\"]))), train_losses['speaker_f'], label=\"S F\")\n",
    "# plt.plot(list(range(0, len(train_losses[\"listener\"]))), train_losses['listener'], label=\"Listener\")\n",
    "# plt.plot(list(range(0, len(train_losses[\"listener\"]))), train_losses['accuracies'], label=\"Acc\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07fb050e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "columns = 3\n",
    "rows = 3\n",
    "\n",
    "fig.add_subplot(2,3, 1)\n",
    "plt.plot(train_losses_plot[\"plot_steps\"], train_losses_plot['speaker_s'], label=\"S_s\")\n",
    "plt.title(\"Structural speaker loss\")\n",
    "fig.add_subplot(2,3, 2)\n",
    "plt.plot(train_losses_plot[\"plot_steps\"], train_losses_plot['perplexities'], label=\"PPL\")\n",
    "plt.title(\"Perplexities\")\n",
    "fig.add_subplot(2,3,3)\n",
    "plt.plot(train_losses_plot[\"plot_steps\"], train_losses_plot['speaker_f'], label=\"S_f\")\n",
    "plt.title(\"Functional speaker loss\")\n",
    "\n",
    "fig.add_subplot(2,3, 4)\n",
    "plt.plot(train_losses_plot[\"plot_steps\"], train_losses_plot['speaker'], label=\"Speaker loss\")\n",
    "plt.title(\"Total speaker loss\")\n",
    "fig.add_subplot(2,3,5)\n",
    "plt.plot(train_losses_plot[\"plot_steps\"], train_losses_plot['listener'], label=\"Listener loss\")\n",
    "plt.title(\"Listener loss\")\n",
    "fig.add_subplot(2,3,6)\n",
    "plt.plot(train_losses_plot[\"plot_steps\"], train_losses_plot['accuracies'], label=\"Acc\")\n",
    "plt.title(\"Listener accuracy\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e110e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot drift metric\n",
    "train_metrics = pd.read_csv(\"../functional_language_drift_metrics_train_epoch_5.csv\")\n",
    "\n",
    "train_metrics[\"drift_num\"] = train_metrics[\"semantic_drifts\"].apply(lambda s: float(re.sub(\"[^0-9\\.-]\", \"\", s)))\n",
    "train_metrics.head()\n",
    "metrics_tensor = torch.tensor(train_metrics[\"drift_num\"]).view(-1, 64)\n",
    "# metrics_tensor.shape # len(train_metrics)\n",
    "metrics_mean = metrics_tensor.mean(dim=1)\n",
    "metrics_mean_list = metrics_mean.tolist()\n",
    "metrics_steps = list(range(0, len(metrics_mean_list)))\n",
    "# train_metrics.iloc[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0897629b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(metrics_steps, metrics_mean_list, label=\"Semantic drift\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Leanguage drift\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c1c1bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_perplexities = [np.exp(x) for x in val_losses[\"val_losses\"]]\n",
    "\n",
    "plt.plot(list(range(0, len(train_losses[\"perplexities\"][500:]))), train_losses['perplexities'][500:], label=\"Train\")\n",
    "plt.plot(val_steps, val_perplexities, label=\"Val\")\n",
    "plt.legend()\n",
    "plt.title(\"Perplexities\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e812213",
   "metadata": {},
   "source": [
    "Ideally, the pretrained speaker model should be evaluated in order to estimate the quality of the base performance, since it is critical for any kinds of changes that could follow from functional training. The evaluation should contain some standard methods like BLEU, and maybe one or two language drift explorations. Some examples should be inspected manually, too.  \n",
    "In case the performance is bad, the following aspects could be tweaked: train longer (larger early stopping delta), different NN weight initialization, more data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a61475",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "The code was created with the help of [this](https://medium.com/@deepeshrishu09/automatic-image-captioning-with-pytorch-cf576c98d319) and [this](https://medium.com/@thechrisyoon/deriving-policy-gradients-and-implementing-reinforce-f887949bd63) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba38294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "## create a test corpus\n",
    "\n",
    "# data_loader_val = get_loader(transform=transform_test,\n",
    "#                          mode='val',\n",
    "#                          batch_size=1,\n",
    "#                          vocab_threshold=11,\n",
    "#                          vocab_from_file=True,\n",
    "#                          download_dir=\"../../../data/val\", \n",
    "#                               vocab_file=\"vocab.pkl\"\n",
    "# #                          vocab_file='../../../data/vocab.pkl'\n",
    "#                         )\n",
    "train_coco = COCO(\"../../../data/train/annotations/captions_train2014.json\") #.anns.keys()\n",
    "used_val_ids = torch.load(\"../pretrain_val_img_IDs_2imgs_main.pt\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bc52c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3700"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ids)\n",
    "len(used_val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3de9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 7000 test images and captions which were not used before\n",
    "possible_test_ids = [x for x in val_ids if x not in used_val_ids]\n",
    "test_ds = list(np.random.choice(possible_test_ids, 7000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cddcf9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "980c6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(test_ds, \"testset_IDs_fromVal_ds.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "853baa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n",
      "VOCAB:  6039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecoderRNN_token0(\n",
       "  (embed): Embedding(6039, 2048)\n",
       "  (lstm): LSTM(2048, 512, batch_first=True)\n",
       "  (linear): Linear(in_features=512, out_features=6039, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a loop iterating over the test images to compute the BLEU score for two models\n",
    "\n",
    "torch.manual_seed(42)\n",
    "transform_test = transforms.Compose([transforms.Resize((224, 224)), \\\n",
    "                                     transforms.ToTensor(), \\\n",
    "                                     transforms.Normalize((0.485, 0.456, 0.406), \\\n",
    "                                                          (0.229, 0.224, 0.225))])\n",
    "data_loader_test = get_loader(transform=transform_test,\n",
    "                         mode='val',\n",
    "                         batch_size=1,\n",
    "                         vocab_threshold=11,\n",
    "                         vocab_from_file=True,\n",
    "                         download_dir=\"../../../data/val\", \n",
    "                              vocab_file=\"vocab.pkl\"\n",
    "#                          vocab_file='../../../data/vocab.pkl'\n",
    "                        )\n",
    "encoder_file_prepend = 'encoder-byImage-prepend-1024dim-6000vocab-wResNet-1.pkl' \n",
    "decoder_file_prepend = 'decoder-byImage-prepend-1024dim-6000vocab-wResNet-1.pkl'\n",
    "\n",
    "encoder_file_token0 = 'encoder-byImage-1024dim-6000vocab-wResNet-2.pkl' \n",
    "decoder_file_token0 = 'decoder-byImage-1024dim-6000vocab-wResNet-2.pkl'\n",
    "\n",
    "\n",
    "embed_size = 2048 #512\n",
    "visual_embed_size = 1024\n",
    "hidden_size = 512\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader_test.dataset.vocab)\n",
    "print(\"VOCAB: \", vocab_size)\n",
    "# Initialize the encoder and decoder, and set each to inference mode.\n",
    "encoder_prepend = EncoderCNN(visual_embed_size)\n",
    "encoder_prepend.eval()\n",
    "decoder_prepend = DecoderRNN(embed_size, hidden_size, vocab_size, 1024)\n",
    "decoder_prepend.eval()\n",
    "\n",
    "# Load the trained weights.\n",
    "encoder_prepend.load_state_dict(torch.load(os.path.join('./../models', encoder_file_prepend)))\n",
    "decoder_prepend.load_state_dict(torch.load(os.path.join('./../models', decoder_file_prepend)))\n",
    "\n",
    "# Move models to GPU if CUDA is available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder_prepend.to(device)\n",
    "decoder_prepend.to(device)\n",
    "\n",
    "## second model\n",
    "encoder_token0 = EncoderCNN(visual_embed_size)\n",
    "encoder_token0.eval()\n",
    "decoder_token0 = DecoderRNN_token0(embed_size, hidden_size, vocab_size, 1024)\n",
    "decoder_token0.eval()\n",
    "\n",
    "# Load the trained weights.\n",
    "encoder_token0.load_state_dict(torch.load(os.path.join('./../models', encoder_file_token0)))\n",
    "decoder_token0.load_state_dict(torch.load(os.path.join('./../models', decoder_file_token0)))\n",
    "\n",
    "# Move models to GPU if CUDA is available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder_token0.to(device)\n",
    "decoder_token0.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a43dab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1848, 1785)]\n",
      "Ann_id in getitem:  42557\n",
      "Test inds:  [(995, 1005)]\n",
      "Ann_id in getitem:  23655\n",
      "Test inds:  [(337, 1525)]\n",
      "Ann_id in getitem:  8226\n",
      "Test inds:  [(48, 426)]\n",
      "Ann_id in getitem:  974\n",
      "Test inds:  [(492, 2181)]\n",
      "Ann_id in getitem:  11821\n",
      "Test inds:  [(2177, 1697)]\n",
      "Ann_id in getitem:  49079\n",
      "Test inds:  [(865, 1777)]\n",
      "Ann_id in getitem:  20910\n",
      "Test inds:  [(3419, 1826)]\n",
      "Ann_id in getitem:  78749\n",
      "Test inds:  [(2198, 1367)]\n",
      "Ann_id in getitem:  49494\n",
      "Test inds:  [(2820, 3557)]\n",
      "Ann_id in getitem:  64986\n",
      "Test inds:  [(3571, 3646)]\n",
      "Ann_id in getitem:  82346\n",
      "Test inds:  [(1831, 1280)]\n",
      "Ann_id in getitem:  42080\n",
      "Test inds:  [(2739, 2219)]\n",
      "Ann_id in getitem:  63066\n",
      "Test inds:  [(1980, 2835)]\n",
      "Ann_id in getitem:  45155\n",
      "Test inds:  [(2078, 1303)]\n",
      "Ann_id in getitem:  47189\n",
      "Test inds:  [(595, 617)]\n",
      "Ann_id in getitem:  14427\n",
      "Test inds:  [(2211, 588)]\n",
      "Ann_id in getitem:  49740\n",
      "Test inds:  [(1574, 305)]\n",
      "Ann_id in getitem:  37275\n",
      "Test inds:  [(2543, 4)]\n",
      "Ann_id in getitem:  57767\n",
      "Test inds:  [(1481, 462)]\n",
      "Ann_id in getitem:  35089\n",
      "Test inds:  [(2472, 2969)]\n",
      "Ann_id in getitem:  56252\n",
      "Test inds:  [(1589, 651)]\n",
      "Ann_id in getitem:  37453\n",
      "Test inds:  [(564, 1509)]\n",
      "Ann_id in getitem:  13573\n",
      "Test inds:  [(54, 584)]\n",
      "Ann_id in getitem:  1132\n",
      "Test inds:  [(882, 2088)]\n",
      "Ann_id in getitem:  21117\n",
      "Test inds:  [(803, 1270)]\n",
      "Ann_id in getitem:  19394\n",
      "Test inds:  [(2141, 298)]\n",
      "Ann_id in getitem:  48465\n",
      "Test inds:  [(1144, 3097)]\n",
      "Ann_id in getitem:  26728\n",
      "Test inds:  [(1846, 3664)]\n",
      "Ann_id in getitem:  42505\n",
      "Test inds:  [(3109, 2202)]\n",
      "Ann_id in getitem:  71745\n",
      "Test inds:  [(2149, 1732)]\n",
      "Ann_id in getitem:  48563\n",
      "Test inds:  [(1641, 2557)]\n",
      "Ann_id in getitem:  38500\n",
      "Test inds:  [(2084, 3107)]\n",
      "Ann_id in getitem:  47299\n",
      "Test inds:  [(2172, 1689)]\n",
      "Ann_id in getitem:  48955\n",
      "Test inds:  [(2903, 2249)]\n",
      "Ann_id in getitem:  66924\n",
      "Test inds:  [(2242, 1137)]\n",
      "Ann_id in getitem:  50649\n",
      "Test inds:  [(3381, 2329)]\n",
      "Ann_id in getitem:  77762\n",
      "Test inds:  [(3435, 823)]\n",
      "Ann_id in getitem:  79158\n",
      "Test inds:  [(3549, 959)]\n",
      "Ann_id in getitem:  81851\n",
      "Test inds:  [(1355, 833)]\n",
      "Ann_id in getitem:  31978\n",
      "Test inds:  [(453, 495)]\n",
      "Ann_id in getitem:  10960\n",
      "Test inds:  [(103, 3292)]\n",
      "Ann_id in getitem:  2258\n",
      "Test inds:  [(2021, 2105)]\n",
      "Ann_id in getitem:  45944\n",
      "Test inds:  [(335, 1431)]\n",
      "Ann_id in getitem:  8198\n",
      "Test inds:  [(3498, 2703)]\n",
      "Ann_id in getitem:  80556\n",
      "Test inds:  [(1587, 996)]\n",
      "Ann_id in getitem:  37446\n",
      "Test inds:  [(1527, 464)]\n",
      "Ann_id in getitem:  36178\n",
      "Test inds:  [(2164, 2547)]\n",
      "Ann_id in getitem:  48818\n",
      "Test inds:  [(1262, 2286)]\n",
      "Ann_id in getitem:  29544\n",
      "Test inds:  [(1108, 2675)]\n",
      "Ann_id in getitem:  25733\n",
      "Test inds:  [(804, 2361)]\n",
      "Ann_id in getitem:  19396\n",
      "Test inds:  [(1097, 782)]\n",
      "Ann_id in getitem:  25511\n",
      "Test inds:  [(3122, 2484)]\n",
      "Ann_id in getitem:  72009\n",
      "Test inds:  [(2247, 1276)]\n",
      "Ann_id in getitem:  50758\n",
      "Test inds:  [(1782, 552)]\n",
      "Ann_id in getitem:  41096\n",
      "Test inds:  [(3175, 2892)]\n",
      "Ann_id in getitem:  73078\n",
      "Test inds:  [(3028, 3187)]\n",
      "Ann_id in getitem:  69831\n",
      "Test inds:  [(1200, 1055)]\n",
      "Ann_id in getitem:  27886\n",
      "Test inds:  [(3086, 3626)]\n",
      "Ann_id in getitem:  71201\n",
      "Test inds:  [(1798, 2464)]\n",
      "Ann_id in getitem:  41571\n",
      "Test inds:  [(2137, 881)]\n",
      "Ann_id in getitem:  48404\n",
      "Test inds:  [(1727, 1194)]\n",
      "Ann_id in getitem:  40272\n",
      "Test inds:  [(2574, 3409)]\n",
      "Ann_id in getitem:  58663\n",
      "Test inds:  [(1253, 311)]\n",
      "Ann_id in getitem:  29400\n",
      "Test inds:  [(1139, 1429)]\n",
      "Ann_id in getitem:  26548\n",
      "Test inds:  [(2955, 795)]\n",
      "Ann_id in getitem:  68049\n",
      "Test inds:  [(499, 593)]\n",
      "Ann_id in getitem:  11933\n",
      "Test inds:  [(674, 3528)]\n",
      "Ann_id in getitem:  16395\n",
      "Test inds:  [(2281, 1973)]\n",
      "Ann_id in getitem:  51602\n",
      "Test inds:  [(3615, 1680)]\n",
      "Ann_id in getitem:  83445\n",
      "Test inds:  [(3682, 2829)]\n",
      "Ann_id in getitem:  84878\n",
      "Test inds:  [(2248, 1228)]\n",
      "Ann_id in getitem:  50804\n",
      "Test inds:  [(1630, 3412)]\n",
      "Ann_id in getitem:  38253\n",
      "Test inds:  [(1862, 2293)]\n",
      "Ann_id in getitem:  42919\n",
      "Test inds:  [(907, 544)]\n",
      "Ann_id in getitem:  21617\n",
      "Test inds:  [(3675, 2897)]\n",
      "Ann_id in getitem:  84758\n",
      "Test inds:  [(1381, 1368)]\n",
      "Ann_id in getitem:  32820\n",
      "Test inds:  [(1658, 1417)]\n",
      "Ann_id in getitem:  38806\n",
      "Test inds:  [(1577, 882)]\n",
      "Ann_id in getitem:  37319\n",
      "Test inds:  [(269, 899)]\n",
      "Ann_id in getitem:  6394\n",
      "Test inds:  [(1591, 2673)]\n",
      "Ann_id in getitem:  37519\n",
      "Test inds:  [(602, 968)]\n",
      "Ann_id in getitem:  14565\n",
      "Test inds:  [(651, 2482)]\n",
      "Ann_id in getitem:  15894\n",
      "Test inds:  [(2556, 1099)]\n",
      "Ann_id in getitem:  58084\n",
      "Test inds:  [(3235, 652)]\n",
      "Ann_id in getitem:  74370\n",
      "Test inds:  [(365, 356)]\n",
      "Ann_id in getitem:  8845\n",
      "Test inds:  [(2061, 2444)]\n",
      "Ann_id in getitem:  46879\n",
      "Test inds:  [(1818, 2468)]\n",
      "Ann_id in getitem:  41866\n",
      "Test inds:  [(2515, 1740)]\n",
      "Ann_id in getitem:  57200\n",
      "Test inds:  [(1370, 1872)]\n",
      "Ann_id in getitem:  32353\n",
      "Test inds:  [(2394, 564)]\n",
      "Ann_id in getitem:  54152\n",
      "Test inds:  [(1286, 3648)]\n",
      "Ann_id in getitem:  30110\n",
      "Test inds:  [(904, 1312)]\n",
      "Ann_id in getitem:  21602\n",
      "Test inds:  [(61, 697)]\n",
      "Ann_id in getitem:  1327\n",
      "Test inds:  [(3654, 2554)]\n",
      "Ann_id in getitem:  84412\n",
      "Test inds:  [(1594, 2922)]\n",
      "Ann_id in getitem:  37627\n",
      "Test inds:  [(1572, 3669)]\n",
      "Ann_id in getitem:  37199\n",
      "Test inds:  [(2815, 2784)]\n",
      "Ann_id in getitem:  64875\n",
      "Test inds:  [(902, 178)]\n",
      "Ann_id in getitem:  21581\n",
      "Test inds:  [(504, 1556)]\n",
      "Ann_id in getitem:  12014\n",
      "Test inds:  [(1413, 2319)]\n",
      "Ann_id in getitem:  33452\n",
      "Test inds:  [(2781, 1679)]\n",
      "Ann_id in getitem:  64155\n",
      "Test inds:  [(854, 1696)]\n",
      "Ann_id in getitem:  20773\n",
      "Test inds:  [(874, 3546)]\n",
      "Ann_id in getitem:  21004\n",
      "Test inds:  [(2240, 3365)]\n",
      "Ann_id in getitem:  50606\n",
      "Test inds:  [(3600, 1862)]\n",
      "Ann_id in getitem:  83059\n",
      "Test inds:  [(3488, 1061)]\n",
      "Ann_id in getitem:  80387\n",
      "Test inds:  [(1201, 911)]\n",
      "Ann_id in getitem:  27913\n",
      "Test inds:  [(820, 2282)]\n",
      "Ann_id in getitem:  19711\n",
      "Test inds:  [(845, 3535)]\n",
      "Ann_id in getitem:  20472\n",
      "Test inds:  [(192, 964)]\n",
      "Ann_id in getitem:  4852\n",
      "Test inds:  [(2021, 1324)]\n",
      "Ann_id in getitem:  45944\n",
      "Test inds:  [(3181, 2231)]\n",
      "Ann_id in getitem:  73268\n",
      "Test inds:  [(3385, 844)]\n",
      "Ann_id in getitem:  77829\n",
      "Test inds:  [(1717, 2227)]\n",
      "Ann_id in getitem:  40080\n",
      "Test inds:  [(2601, 2859)]\n",
      "Ann_id in getitem:  59583\n",
      "Test inds:  [(2214, 1725)]\n",
      "Ann_id in getitem:  49833\n",
      "Test inds:  [(380, 1089)]\n",
      "Ann_id in getitem:  9264\n",
      "Test inds:  [(425, 2365)]\n",
      "Ann_id in getitem:  10359\n",
      "Test inds:  [(1763, 2020)]\n",
      "Ann_id in getitem:  40781\n",
      "Test inds:  [(906, 1009)]\n",
      "Ann_id in getitem:  21608\n",
      "Test inds:  [(2799, 1028)]\n",
      "Ann_id in getitem:  64555\n",
      "Test inds:  [(1706, 1624)]\n",
      "Ann_id in getitem:  39906\n",
      "Test inds:  [(1846, 2848)]\n",
      "Ann_id in getitem:  42505\n",
      "Test inds:  [(235, 2676)]\n",
      "Ann_id in getitem:  5749\n",
      "Test inds:  [(3479, 3042)]\n",
      "Ann_id in getitem:  80249\n",
      "Test inds:  [(337, 1264)]\n",
      "Ann_id in getitem:  8226\n",
      "Test inds:  [(2681, 3169)]\n",
      "Ann_id in getitem:  61586\n",
      "Test inds:  [(1607, 2259)]\n",
      "Ann_id in getitem:  37779\n",
      "Test inds:  [(237, 2432)]\n",
      "Ann_id in getitem:  5786\n",
      "Test inds:  [(967, 3261)]\n",
      "Ann_id in getitem:  22855\n",
      "Test inds:  [(3601, 99)]\n",
      "Ann_id in getitem:  83060\n",
      "Test inds:  [(203, 253)]\n",
      "Ann_id in getitem:  5024\n",
      "Test inds:  [(1751, 2920)]\n",
      "Ann_id in getitem:  40566\n",
      "Test inds:  [(3344, 1868)]\n",
      "Ann_id in getitem:  76854\n",
      "Test inds:  [(997, 2712)]\n",
      "Ann_id in getitem:  23663\n",
      "Test inds:  [(674, 1402)]\n",
      "Ann_id in getitem:  16395\n",
      "Test inds:  [(387, 880)]\n",
      "Ann_id in getitem:  9595\n",
      "Test inds:  [(2868, 2777)]\n",
      "Ann_id in getitem:  65951\n",
      "Test inds:  [(2018, 1894)]\n",
      "Ann_id in getitem:  45873\n",
      "Test inds:  [(2897, 1694)]\n",
      "Ann_id in getitem:  66631\n",
      "Test inds:  [(1575, 1523)]\n",
      "Ann_id in getitem:  37304\n",
      "Test inds:  [(1899, 3478)]\n",
      "Ann_id in getitem:  43557\n",
      "Test inds:  [(3152, 1369)]\n",
      "Ann_id in getitem:  72637\n",
      "Test inds:  [(2, 1108)]\n",
      "Ann_id in getitem:  49\n",
      "Test inds:  [(1304, 491)]\n",
      "Ann_id in getitem:  30493\n",
      "Test inds:  [(1405, 656)]\n",
      "Ann_id in getitem:  33265\n",
      "Test inds:  [(405, 2075)]\n",
      "Ann_id in getitem:  9977\n",
      "Test inds:  [(248, 1054)]\n",
      "Ann_id in getitem:  6023\n",
      "Test inds:  [(3218, 1786)]\n",
      "Ann_id in getitem:  74015\n",
      "Test inds:  [(128, 1903)]\n",
      "Ann_id in getitem:  3043\n",
      "Test inds:  [(486, 336)]\n",
      "Ann_id in getitem:  11702\n",
      "Test inds:  [(2110, 687)]\n",
      "Ann_id in getitem:  47851\n",
      "Test inds:  [(773, 3609)]\n",
      "Ann_id in getitem:  18756\n",
      "Test inds:  [(2475, 906)]\n",
      "Ann_id in getitem:  56352\n",
      "Test inds:  [(1005, 794)]\n",
      "Ann_id in getitem:  23874\n",
      "Test inds:  [(759, 3642)]\n",
      "Ann_id in getitem:  18345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3546, 611)]\n",
      "Ann_id in getitem:  81822\n",
      "Test inds:  [(2136, 3583)]\n",
      "Ann_id in getitem:  48396\n",
      "Test inds:  [(3697, 115)]\n",
      "Ann_id in getitem:  85435\n",
      "Test inds:  [(235, 2673)]\n",
      "Ann_id in getitem:  5749\n",
      "Test inds:  [(1886, 2478)]\n",
      "Ann_id in getitem:  43376\n",
      "Test inds:  [(1037, 1390)]\n",
      "Ann_id in getitem:  24537\n",
      "Test inds:  [(3301, 2375)]\n",
      "Ann_id in getitem:  75728\n",
      "Test inds:  [(2910, 282)]\n",
      "Ann_id in getitem:  67092\n",
      "Test inds:  [(3124, 3120)]\n",
      "Ann_id in getitem:  72017\n",
      "Test inds:  [(2907, 1060)]\n",
      "Ann_id in getitem:  67051\n",
      "Test inds:  [(2877, 2738)]\n",
      "Ann_id in getitem:  66124\n",
      "Test inds:  [(402, 1295)]\n",
      "Ann_id in getitem:  9897\n",
      "Test inds:  [(1212, 2074)]\n",
      "Ann_id in getitem:  28241\n",
      "Test inds:  [(1921, 2782)]\n",
      "Ann_id in getitem:  43968\n",
      "Test inds:  [(176, 1849)]\n",
      "Ann_id in getitem:  4451\n",
      "Test inds:  [(972, 2369)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(2738, 795)]\n",
      "Ann_id in getitem:  63062\n",
      "Test inds:  [(3397, 561)]\n",
      "Ann_id in getitem:  78099\n",
      "Test inds:  [(2849, 3046)]\n",
      "Ann_id in getitem:  65577\n",
      "Test inds:  [(2222, 1916)]\n",
      "Ann_id in getitem:  49994\n",
      "Test inds:  [(471, 2637)]\n",
      "Ann_id in getitem:  11319\n",
      "Test inds:  [(976, 289)]\n",
      "Ann_id in getitem:  23051\n",
      "Test inds:  [(3465, 3261)]\n",
      "Ann_id in getitem:  80003\n",
      "Test inds:  [(1189, 2928)]\n",
      "Ann_id in getitem:  27717\n",
      "Test inds:  [(1674, 660)]\n",
      "Ann_id in getitem:  39208\n",
      "Test inds:  [(1666, 704)]\n",
      "Ann_id in getitem:  38967\n",
      "Test inds:  [(1682, 945)]\n",
      "Ann_id in getitem:  39476\n",
      "Test inds:  [(3539, 778)]\n",
      "Ann_id in getitem:  81612\n",
      "Test inds:  [(3438, 585)]\n",
      "Ann_id in getitem:  79233\n",
      "Test inds:  [(2726, 1875)]\n",
      "Ann_id in getitem:  62715\n",
      "Test inds:  [(263, 1112)]\n",
      "Ann_id in getitem:  6282\n",
      "Test inds:  [(1498, 2720)]\n",
      "Ann_id in getitem:  35589\n",
      "Test inds:  [(1559, 3565)]\n",
      "Ann_id in getitem:  36827\n",
      "Test inds:  [(1675, 762)]\n",
      "Ann_id in getitem:  39223\n",
      "Test inds:  [(2777, 904)]\n",
      "Ann_id in getitem:  63977\n",
      "Test inds:  [(1929, 2588)]\n",
      "Ann_id in getitem:  44065\n",
      "Test inds:  [(3240, 2947)]\n",
      "Ann_id in getitem:  74511\n",
      "Test inds:  [(3388, 1931)]\n",
      "Ann_id in getitem:  77853\n",
      "Test inds:  [(1106, 1048)]\n",
      "Ann_id in getitem:  25701\n",
      "Test inds:  [(2952, 3453)]\n",
      "Ann_id in getitem:  68018\n",
      "Test inds:  [(90, 106)]\n",
      "Ann_id in getitem:  2076\n",
      "Test inds:  [(1511, 1506)]\n",
      "Ann_id in getitem:  35841\n",
      "Test inds:  [(1260, 148)]\n",
      "Ann_id in getitem:  29512\n",
      "Test inds:  [(3545, 913)]\n",
      "Ann_id in getitem:  81789\n",
      "Test inds:  [(1961, 3116)]\n",
      "Ann_id in getitem:  44615\n",
      "Test inds:  [(216, 2316)]\n",
      "Ann_id in getitem:  5384\n",
      "Test inds:  [(476, 2879)]\n",
      "Ann_id in getitem:  11512\n",
      "Test inds:  [(1337, 3303)]\n",
      "Ann_id in getitem:  31421\n",
      "Test inds:  [(41, 777)]\n",
      "Ann_id in getitem:  891\n",
      "Test inds:  [(3057, 576)]\n",
      "Ann_id in getitem:  70527\n",
      "Test inds:  [(1272, 2969)]\n",
      "Ann_id in getitem:  29682\n",
      "Test inds:  [(879, 1149)]\n",
      "Ann_id in getitem:  21078\n",
      "Test inds:  [(2287, 724)]\n",
      "Ann_id in getitem:  51686\n",
      "Test inds:  [(349, 1276)]\n",
      "Ann_id in getitem:  8469\n",
      "Test inds:  [(2765, 672)]\n",
      "Ann_id in getitem:  63589\n",
      "Test inds:  [(440, 2903)]\n",
      "Ann_id in getitem:  10730\n",
      "Test inds:  [(1256, 693)]\n",
      "Ann_id in getitem:  29448\n",
      "Test inds:  [(1873, 1729)]\n",
      "Ann_id in getitem:  43075\n",
      "Test inds:  [(3450, 781)]\n",
      "Ann_id in getitem:  79560\n",
      "Test inds:  [(2703, 686)]\n",
      "Ann_id in getitem:  62141\n",
      "Test inds:  [(1200, 3619)]\n",
      "Ann_id in getitem:  27886\n",
      "Test inds:  [(2124, 857)]\n",
      "Ann_id in getitem:  48193\n",
      "Test inds:  [(1465, 2967)]\n",
      "Ann_id in getitem:  34694\n",
      "Test inds:  [(2480, 3003)]\n",
      "Ann_id in getitem:  56445\n",
      "Test inds:  [(1999, 1589)]\n",
      "Ann_id in getitem:  45551\n",
      "Test inds:  [(2409, 600)]\n",
      "Ann_id in getitem:  54511\n",
      "Test inds:  [(1532, 3227)]\n",
      "Ann_id in getitem:  36246\n",
      "Test inds:  [(690, 3327)]\n",
      "Ann_id in getitem:  16819\n",
      "Test inds:  [(2352, 2921)]\n",
      "Ann_id in getitem:  53192\n",
      "Test inds:  [(2588, 1264)]\n",
      "Ann_id in getitem:  59353\n",
      "Test inds:  [(843, 2330)]\n",
      "Ann_id in getitem:  20421\n",
      "Test inds:  [(939, 2543)]\n",
      "Ann_id in getitem:  22341\n",
      "Test inds:  [(2551, 552)]\n",
      "Ann_id in getitem:  57956\n",
      "Test inds:  [(3331, 485)]\n",
      "Ann_id in getitem:  76562\n",
      "Test inds:  [(3568, 337)]\n",
      "Ann_id in getitem:  82290\n",
      "Test inds:  [(2815, 1984)]\n",
      "Ann_id in getitem:  64875\n",
      "Test inds:  [(3695, 822)]\n",
      "Ann_id in getitem:  85421\n",
      "Test inds:  [(3278, 2584)]\n",
      "Ann_id in getitem:  75082\n",
      "Test inds:  [(1447, 2223)]\n",
      "Ann_id in getitem:  34266\n",
      "Test inds:  [(1913, 647)]\n",
      "Ann_id in getitem:  43827\n",
      "Test inds:  [(3075, 705)]\n",
      "Ann_id in getitem:  70904\n",
      "Test inds:  [(2539, 1294)]\n",
      "Ann_id in getitem:  57623\n",
      "Test inds:  [(2600, 2359)]\n",
      "Ann_id in getitem:  59568\n",
      "Test inds:  [(581, 2983)]\n",
      "Ann_id in getitem:  14119\n",
      "Test inds:  [(1850, 2587)]\n",
      "Ann_id in getitem:  42614\n",
      "Test inds:  [(2753, 339)]\n",
      "Ann_id in getitem:  63365\n",
      "Test inds:  [(1698, 177)]\n",
      "Ann_id in getitem:  39801\n",
      "Test inds:  [(394, 888)]\n",
      "Ann_id in getitem:  9709\n",
      "Test inds:  [(1647, 150)]\n",
      "Ann_id in getitem:  38577\n",
      "Test inds:  [(259, 3135)]\n",
      "Ann_id in getitem:  6216\n",
      "Test inds:  [(321, 2059)]\n",
      "Ann_id in getitem:  7911\n",
      "Test inds:  [(2836, 2423)]\n",
      "Ann_id in getitem:  65379\n",
      "Test inds:  [(1822, 1750)]\n",
      "Ann_id in getitem:  41928\n",
      "Test inds:  [(1329, 905)]\n",
      "Ann_id in getitem:  31225\n",
      "Test inds:  [(356, 2548)]\n",
      "Ann_id in getitem:  8549\n",
      "Test inds:  [(862, 3651)]\n",
      "Ann_id in getitem:  20877\n",
      "Test inds:  [(1180, 1183)]\n",
      "Ann_id in getitem:  27482\n",
      "Test inds:  [(2352, 842)]\n",
      "Ann_id in getitem:  53192\n",
      "Test inds:  [(3533, 2177)]\n",
      "Ann_id in getitem:  81544\n",
      "Test inds:  [(1378, 3331)]\n",
      "Ann_id in getitem:  32598\n",
      "Test inds:  [(1215, 479)]\n",
      "Ann_id in getitem:  28350\n",
      "Test inds:  [(2505, 266)]\n",
      "Ann_id in getitem:  57045\n",
      "Test inds:  [(1107, 3215)]\n",
      "Ann_id in getitem:  25712\n",
      "Test inds:  [(3496, 828)]\n",
      "Ann_id in getitem:  80522\n",
      "Test inds:  [(3334, 1386)]\n",
      "Ann_id in getitem:  76616\n",
      "Test inds:  [(1805, 2430)]\n",
      "Ann_id in getitem:  41643\n",
      "Test inds:  [(1807, 1232)]\n",
      "Ann_id in getitem:  41695\n",
      "Test inds:  [(374, 2886)]\n",
      "Ann_id in getitem:  9123\n",
      "Test inds:  [(3277, 3111)]\n",
      "Ann_id in getitem:  75070\n",
      "Test inds:  [(2858, 2077)]\n",
      "Ann_id in getitem:  65708\n",
      "Test inds:  [(1800, 3651)]\n",
      "Ann_id in getitem:  41577\n",
      "Test inds:  [(2566, 2435)]\n",
      "Ann_id in getitem:  58337\n",
      "Test inds:  [(871, 905)]\n",
      "Ann_id in getitem:  20979\n",
      "Test inds:  [(330, 3479)]\n",
      "Ann_id in getitem:  8089\n",
      "Test inds:  [(1983, 543)]\n",
      "Ann_id in getitem:  45234\n",
      "Test inds:  [(2482, 292)]\n",
      "Ann_id in getitem:  56501\n",
      "Test inds:  [(907, 1723)]\n",
      "Ann_id in getitem:  21617\n",
      "Test inds:  [(3359, 2356)]\n",
      "Ann_id in getitem:  77075\n",
      "Test inds:  [(3123, 1873)]\n",
      "Ann_id in getitem:  72016\n",
      "Test inds:  [(1137, 686)]\n",
      "Ann_id in getitem:  26499\n",
      "Test inds:  [(2520, 2185)]\n",
      "Ann_id in getitem:  57279\n",
      "Test inds:  [(1024, 3613)]\n",
      "Ann_id in getitem:  24200\n",
      "Test inds:  [(2367, 2723)]\n",
      "Ann_id in getitem:  53536\n",
      "Test inds:  [(1310, 3289)]\n",
      "Ann_id in getitem:  30641\n",
      "Test inds:  [(3520, 3466)]\n",
      "Ann_id in getitem:  81210\n",
      "Test inds:  [(153, 409)]\n",
      "Ann_id in getitem:  3762\n",
      "Test inds:  [(479, 578)]\n",
      "Ann_id in getitem:  11523\n",
      "Test inds:  [(2496, 693)]\n",
      "Ann_id in getitem:  56792\n",
      "Test inds:  [(1242, 545)]\n",
      "Ann_id in getitem:  29101\n",
      "Test inds:  [(3544, 2560)]\n",
      "Ann_id in getitem:  81777\n",
      "Test inds:  [(206, 952)]\n",
      "Ann_id in getitem:  5173\n",
      "Test inds:  [(10, 2853)]\n",
      "Ann_id in getitem:  182\n",
      "Test inds:  [(2958, 78)]\n",
      "Ann_id in getitem:  68104\n",
      "Test inds:  [(1294, 3106)]\n",
      "Ann_id in getitem:  30367\n",
      "Test inds:  [(3086, 1762)]\n",
      "Ann_id in getitem:  71201\n",
      "Test inds:  [(2552, 1343)]\n",
      "Ann_id in getitem:  57974\n",
      "Test inds:  [(826, 787)]\n",
      "Ann_id in getitem:  19812\n",
      "Test inds:  [(2725, 2806)]\n",
      "Ann_id in getitem:  62664\n",
      "Test inds:  [(2089, 3285)]\n",
      "Ann_id in getitem:  47397\n",
      "Test inds:  [(2690, 2384)]\n",
      "Ann_id in getitem:  61838\n",
      "Test inds:  [(3562, 1466)]\n",
      "Ann_id in getitem:  82145\n",
      "Test inds:  [(2831, 713)]\n",
      "Ann_id in getitem:  65285\n",
      "Test inds:  [(2444, 902)]\n",
      "Ann_id in getitem:  55553\n",
      "Test inds:  [(1237, 3020)]\n",
      "Ann_id in getitem:  28905\n",
      "Test inds:  [(2339, 3250)]\n",
      "Ann_id in getitem:  52740\n",
      "Test inds:  [(2224, 2989)]\n",
      "Ann_id in getitem:  50042\n",
      "Test inds:  [(981, 1500)]\n",
      "Ann_id in getitem:  23182\n",
      "Test inds:  [(3523, 2484)]\n",
      "Ann_id in getitem:  81287\n",
      "Test inds:  [(3048, 2167)]\n",
      "Ann_id in getitem:  70269\n",
      "Test inds:  [(2249, 681)]\n",
      "Ann_id in getitem:  50819\n",
      "Test inds:  [(1496, 1910)]\n",
      "Ann_id in getitem:  35562\n",
      "Test inds:  [(1721, 217)]\n",
      "Ann_id in getitem:  40158\n",
      "Test inds:  [(1082, 2449)]\n",
      "Ann_id in getitem:  25259\n",
      "Test inds:  [(468, 463)]\n",
      "Ann_id in getitem:  11279\n",
      "Test inds:  [(2638, 1412)]\n",
      "Ann_id in getitem:  60373\n",
      "Test inds:  [(3277, 942)]\n",
      "Ann_id in getitem:  75070\n",
      "Test inds:  [(70, 2239)]\n",
      "Ann_id in getitem:  1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2140, 811)]\n",
      "Ann_id in getitem:  48460\n",
      "Test inds:  [(468, 706)]\n",
      "Ann_id in getitem:  11279\n",
      "Test inds:  [(1947, 1682)]\n",
      "Ann_id in getitem:  44320\n",
      "Test inds:  [(2089, 228)]\n",
      "Ann_id in getitem:  47397\n",
      "Test inds:  [(2518, 2206)]\n",
      "Ann_id in getitem:  57251\n",
      "Test inds:  [(3067, 2359)]\n",
      "Ann_id in getitem:  70680\n",
      "Test inds:  [(198, 2472)]\n",
      "Ann_id in getitem:  4985\n",
      "Test inds:  [(1236, 1468)]\n",
      "Ann_id in getitem:  28894\n",
      "Test inds:  [(1001, 119)]\n",
      "Ann_id in getitem:  23725\n",
      "Test inds:  [(2919, 1852)]\n",
      "Ann_id in getitem:  67228\n",
      "Test inds:  [(1287, 1488)]\n",
      "Ann_id in getitem:  30176\n",
      "Test inds:  [(1730, 112)]\n",
      "Ann_id in getitem:  40309\n",
      "Test inds:  [(702, 2227)]\n",
      "Ann_id in getitem:  17065\n",
      "Test inds:  [(602, 3304)]\n",
      "Ann_id in getitem:  14565\n",
      "Test inds:  [(20, 3215)]\n",
      "Ann_id in getitem:  452\n",
      "Test inds:  [(2390, 1677)]\n",
      "Ann_id in getitem:  54109\n",
      "Test inds:  [(867, 2853)]\n",
      "Ann_id in getitem:  20919\n",
      "Test inds:  [(3402, 1442)]\n",
      "Ann_id in getitem:  78308\n",
      "Test inds:  [(1110, 372)]\n",
      "Ann_id in getitem:  25767\n",
      "Test inds:  [(3050, 2186)]\n",
      "Ann_id in getitem:  70297\n",
      "Test inds:  [(3039, 914)]\n",
      "Ann_id in getitem:  70044\n",
      "Test inds:  [(790, 2636)]\n",
      "Ann_id in getitem:  19135\n",
      "Test inds:  [(1501, 3009)]\n",
      "Ann_id in getitem:  35694\n",
      "Test inds:  [(1714, 1498)]\n",
      "Ann_id in getitem:  40069\n",
      "Test inds:  [(281, 28)]\n",
      "Ann_id in getitem:  6637\n",
      "Test inds:  [(3495, 2083)]\n",
      "Ann_id in getitem:  80518\n",
      "Test inds:  [(3142, 1247)]\n",
      "Ann_id in getitem:  72472\n",
      "Test inds:  [(1378, 1540)]\n",
      "Ann_id in getitem:  32598\n",
      "Test inds:  [(3024, 3337)]\n",
      "Ann_id in getitem:  69795\n",
      "Test inds:  [(12, 2339)]\n",
      "Ann_id in getitem:  221\n",
      "Test inds:  [(2798, 788)]\n",
      "Ann_id in getitem:  64523\n",
      "Test inds:  [(2641, 704)]\n",
      "Ann_id in getitem:  60472\n",
      "Test inds:  [(1381, 2168)]\n",
      "Ann_id in getitem:  32820\n",
      "Test inds:  [(3606, 895)]\n",
      "Ann_id in getitem:  83291\n",
      "Test inds:  [(1048, 3277)]\n",
      "Ann_id in getitem:  24744\n",
      "Test inds:  [(253, 1647)]\n",
      "Ann_id in getitem:  6106\n",
      "Test inds:  [(3498, 1279)]\n",
      "Ann_id in getitem:  80556\n",
      "Test inds:  [(2689, 1149)]\n",
      "Ann_id in getitem:  61729\n",
      "Test inds:  [(693, 763)]\n",
      "Ann_id in getitem:  16873\n",
      "Test inds:  [(3240, 2250)]\n",
      "Ann_id in getitem:  74511\n",
      "Test inds:  [(233, 45)]\n",
      "Ann_id in getitem:  5653\n",
      "Test inds:  [(2302, 366)]\n",
      "Ann_id in getitem:  51919\n",
      "Test inds:  [(3646, 1621)]\n",
      "Ann_id in getitem:  84149\n",
      "Test inds:  [(238, 486)]\n",
      "Ann_id in getitem:  5795\n",
      "Test inds:  [(3476, 669)]\n",
      "Ann_id in getitem:  80194\n",
      "Test inds:  [(2061, 3618)]\n",
      "Ann_id in getitem:  46879\n",
      "Test inds:  [(839, 1605)]\n",
      "Ann_id in getitem:  20148\n",
      "Test inds:  [(2498, 844)]\n",
      "Ann_id in getitem:  56850\n",
      "Test inds:  [(2431, 601)]\n",
      "Ann_id in getitem:  54983\n",
      "Test inds:  [(3331, 965)]\n",
      "Ann_id in getitem:  76562\n",
      "Test inds:  [(1534, 34)]\n",
      "Ann_id in getitem:  36322\n",
      "Test inds:  [(3500, 2839)]\n",
      "Ann_id in getitem:  80593\n",
      "Test inds:  [(705, 1903)]\n",
      "Ann_id in getitem:  17127\n",
      "Test inds:  [(2348, 3158)]\n",
      "Ann_id in getitem:  52982\n",
      "Test inds:  [(2840, 3298)]\n",
      "Ann_id in getitem:  65399\n",
      "Test inds:  [(166, 1827)]\n",
      "Ann_id in getitem:  4193\n",
      "Test inds:  [(2577, 3482)]\n",
      "Ann_id in getitem:  58761\n",
      "Test inds:  [(847, 2529)]\n",
      "Ann_id in getitem:  20639\n",
      "Test inds:  [(57, 2872)]\n",
      "Ann_id in getitem:  1221\n",
      "Test inds:  [(1839, 2155)]\n",
      "Ann_id in getitem:  42229\n",
      "Test inds:  [(2429, 307)]\n",
      "Ann_id in getitem:  54907\n",
      "Test inds:  [(2347, 3377)]\n",
      "Ann_id in getitem:  52955\n",
      "Test inds:  [(3565, 1517)]\n",
      "Ann_id in getitem:  82226\n",
      "Test inds:  [(3220, 235)]\n",
      "Ann_id in getitem:  74051\n",
      "Test inds:  [(3469, 455)]\n",
      "Ann_id in getitem:  80073\n",
      "Test inds:  [(1785, 2707)]\n",
      "Ann_id in getitem:  41113\n",
      "Test inds:  [(2447, 1420)]\n",
      "Ann_id in getitem:  55608\n",
      "Test inds:  [(2229, 1683)]\n",
      "Ann_id in getitem:  50207\n",
      "Test inds:  [(970, 3162)]\n",
      "Ann_id in getitem:  22898\n",
      "Test inds:  [(787, 2775)]\n",
      "Ann_id in getitem:  19043\n",
      "Test inds:  [(3271, 3211)]\n",
      "Ann_id in getitem:  74953\n",
      "Test inds:  [(2384, 787)]\n",
      "Ann_id in getitem:  53904\n",
      "Test inds:  [(2432, 2486)]\n",
      "Ann_id in getitem:  55017\n",
      "Test inds:  [(54, 3270)]\n",
      "Ann_id in getitem:  1132\n",
      "Test inds:  [(1943, 3318)]\n",
      "Ann_id in getitem:  44244\n",
      "Test inds:  [(538, 122)]\n",
      "Ann_id in getitem:  12762\n",
      "Test inds:  [(440, 689)]\n",
      "Ann_id in getitem:  10730\n",
      "Test inds:  [(377, 3245)]\n",
      "Ann_id in getitem:  9180\n",
      "Test inds:  [(240, 823)]\n",
      "Ann_id in getitem:  5835\n",
      "Test inds:  [(71, 1823)]\n",
      "Ann_id in getitem:  1614\n",
      "Test inds:  [(189, 5)]\n",
      "Ann_id in getitem:  4781\n",
      "Test inds:  [(2383, 2842)]\n",
      "Ann_id in getitem:  53894\n",
      "Test inds:  [(984, 2805)]\n",
      "Ann_id in getitem:  23330\n",
      "Test inds:  [(2358, 2642)]\n",
      "Ann_id in getitem:  53318\n",
      "Test inds:  [(2364, 3582)]\n",
      "Ann_id in getitem:  53431\n",
      "Test inds:  [(2184, 3091)]\n",
      "Ann_id in getitem:  49226\n",
      "Test inds:  [(665, 685)]\n",
      "Ann_id in getitem:  16182\n",
      "Test inds:  [(1590, 57)]\n",
      "Ann_id in getitem:  37511\n",
      "Test inds:  [(3340, 3077)]\n",
      "Ann_id in getitem:  76767\n",
      "Test inds:  [(16, 1158)]\n",
      "Ann_id in getitem:  401\n",
      "Test inds:  [(3300, 108)]\n",
      "Ann_id in getitem:  75726\n",
      "Test inds:  [(3513, 2670)]\n",
      "Ann_id in getitem:  81072\n",
      "Test inds:  [(1985, 3355)]\n",
      "Ann_id in getitem:  45252\n",
      "Test inds:  [(401, 1128)]\n",
      "Ann_id in getitem:  9891\n",
      "Test inds:  [(40, 1510)]\n",
      "Ann_id in getitem:  882\n",
      "Test inds:  [(3527, 2247)]\n",
      "Ann_id in getitem:  81427\n",
      "Test inds:  [(2328, 2271)]\n",
      "Ann_id in getitem:  52512\n",
      "Test inds:  [(2018, 1697)]\n",
      "Ann_id in getitem:  45873\n",
      "Test inds:  [(3374, 1131)]\n",
      "Ann_id in getitem:  77630\n",
      "Test inds:  [(3609, 2225)]\n",
      "Ann_id in getitem:  83357\n",
      "Test inds:  [(787, 987)]\n",
      "Ann_id in getitem:  19043\n",
      "Test inds:  [(796, 547)]\n",
      "Ann_id in getitem:  19268\n",
      "Test inds:  [(829, 20)]\n",
      "Ann_id in getitem:  19937\n",
      "Test inds:  [(2103, 1043)]\n",
      "Ann_id in getitem:  47624\n",
      "Test inds:  [(196, 1739)]\n",
      "Ann_id in getitem:  4949\n",
      "Test inds:  [(2541, 1458)]\n",
      "Ann_id in getitem:  57734\n",
      "Test inds:  [(3372, 3532)]\n",
      "Ann_id in getitem:  77585\n",
      "Test inds:  [(951, 2703)]\n",
      "Ann_id in getitem:  22560\n",
      "Test inds:  [(1524, 2483)]\n",
      "Ann_id in getitem:  36083\n",
      "Test inds:  [(1893, 3680)]\n",
      "Ann_id in getitem:  43442\n",
      "Test inds:  [(2714, 2954)]\n",
      "Ann_id in getitem:  62433\n",
      "Test inds:  [(1021, 2574)]\n",
      "Ann_id in getitem:  24152\n",
      "Test inds:  [(700, 2821)]\n",
      "Ann_id in getitem:  17004\n",
      "Test inds:  [(2690, 725)]\n",
      "Ann_id in getitem:  61838\n",
      "Test inds:  [(2980, 647)]\n",
      "Ann_id in getitem:  68758\n",
      "Test inds:  [(2646, 3371)]\n",
      "Ann_id in getitem:  60603\n",
      "Test inds:  [(3347, 1849)]\n",
      "Ann_id in getitem:  76882\n",
      "Test inds:  [(2641, 3572)]\n",
      "Ann_id in getitem:  60472\n",
      "Test inds:  [(3019, 3486)]\n",
      "Ann_id in getitem:  69543\n",
      "Test inds:  [(1681, 454)]\n",
      "Ann_id in getitem:  39449\n",
      "Test inds:  [(2383, 129)]\n",
      "Ann_id in getitem:  53894\n",
      "Test inds:  [(828, 2313)]\n",
      "Ann_id in getitem:  19865\n",
      "Test inds:  [(2287, 3205)]\n",
      "Ann_id in getitem:  51686\n",
      "Test inds:  [(2384, 692)]\n",
      "Ann_id in getitem:  53904\n",
      "Test inds:  [(1012, 2847)]\n",
      "Ann_id in getitem:  24045\n",
      "Test inds:  [(2674, 1460)]\n",
      "Ann_id in getitem:  61341\n",
      "Test inds:  [(1817, 901)]\n",
      "Ann_id in getitem:  41838\n",
      "Test inds:  [(1973, 3395)]\n",
      "Ann_id in getitem:  44991\n",
      "Test inds:  [(736, 3180)]\n",
      "Ann_id in getitem:  17866\n",
      "Test inds:  [(3476, 992)]\n",
      "Ann_id in getitem:  80194\n",
      "Test inds:  [(2862, 2356)]\n",
      "Ann_id in getitem:  65761\n",
      "Test inds:  [(74, 2200)]\n",
      "Ann_id in getitem:  1638\n",
      "Test inds:  [(13, 2744)]\n",
      "Ann_id in getitem:  250\n",
      "Test inds:  [(3361, 600)]\n",
      "Ann_id in getitem:  77144\n",
      "Test inds:  [(1377, 3417)]\n",
      "Ann_id in getitem:  32557\n",
      "Test inds:  [(46, 2361)]\n",
      "Ann_id in getitem:  957\n",
      "Test inds:  [(3122, 2258)]\n",
      "Ann_id in getitem:  72009\n",
      "Test inds:  [(3568, 1261)]\n",
      "Ann_id in getitem:  82290\n",
      "Test inds:  [(2960, 949)]\n",
      "Ann_id in getitem:  68134\n",
      "Test inds:  [(387, 1057)]\n",
      "Ann_id in getitem:  9595\n",
      "Test inds:  [(3376, 2478)]\n",
      "Ann_id in getitem:  77651\n",
      "Test inds:  [(982, 3194)]\n",
      "Ann_id in getitem:  23306\n",
      "Test inds:  [(3688, 1314)]\n",
      "Ann_id in getitem:  85200\n",
      "Test inds:  [(2699, 892)]\n",
      "Ann_id in getitem:  62015\n",
      "Test inds:  [(3618, 54)]\n",
      "Ann_id in getitem:  83536\n",
      "Test inds:  [(3175, 689)]\n",
      "Ann_id in getitem:  73078\n",
      "Test inds:  [(2817, 2789)]\n",
      "Ann_id in getitem:  64933\n",
      "Test inds:  [(3330, 1171)]\n",
      "Ann_id in getitem:  76518\n",
      "Test inds:  [(2689, 3559)]\n",
      "Ann_id in getitem:  61729\n",
      "Test inds:  [(843, 3597)]\n",
      "Ann_id in getitem:  20421\n",
      "Test inds:  [(2818, 2380)]\n",
      "Ann_id in getitem:  64942\n",
      "Test inds:  [(1824, 3694)]\n",
      "Ann_id in getitem:  41983\n",
      "Test inds:  [(132, 3022)]\n",
      "Ann_id in getitem:  3200\n",
      "Test inds:  [(585, 3685)]\n",
      "Ann_id in getitem:  14218\n",
      "Test inds:  [(592, 608)]\n",
      "Ann_id in getitem:  14358\n",
      "Test inds:  [(1397, 3193)]\n",
      "Ann_id in getitem:  33147\n",
      "Test inds:  [(608, 684)]\n",
      "Ann_id in getitem:  14850\n",
      "Test inds:  [(2751, 1940)]\n",
      "Ann_id in getitem:  63321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2507, 2111)]\n",
      "Ann_id in getitem:  57060\n",
      "Test inds:  [(1724, 1222)]\n",
      "Ann_id in getitem:  40226\n",
      "Test inds:  [(2436, 733)]\n",
      "Ann_id in getitem:  55096\n",
      "Test inds:  [(1004, 3684)]\n",
      "Ann_id in getitem:  23799\n",
      "Test inds:  [(1325, 1491)]\n",
      "Ann_id in getitem:  31012\n",
      "Test inds:  [(3315, 760)]\n",
      "Ann_id in getitem:  76162\n",
      "Test inds:  [(283, 3050)]\n",
      "Ann_id in getitem:  6647\n",
      "Test inds:  [(1900, 2653)]\n",
      "Ann_id in getitem:  43579\n",
      "Test inds:  [(2143, 913)]\n",
      "Ann_id in getitem:  48494\n",
      "Test inds:  [(2334, 845)]\n",
      "Ann_id in getitem:  52637\n",
      "Test inds:  [(2831, 2226)]\n",
      "Ann_id in getitem:  65285\n",
      "Test inds:  [(940, 130)]\n",
      "Ann_id in getitem:  22343\n",
      "Test inds:  [(1091, 1202)]\n",
      "Ann_id in getitem:  25434\n",
      "Test inds:  [(2804, 198)]\n",
      "Ann_id in getitem:  64707\n",
      "Test inds:  [(2271, 3566)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(51, 1230)]\n",
      "Ann_id in getitem:  1037\n",
      "Test inds:  [(1783, 1501)]\n",
      "Ann_id in getitem:  41100\n",
      "Test inds:  [(3431, 2644)]\n",
      "Ann_id in getitem:  79085\n",
      "Test inds:  [(760, 2006)]\n",
      "Ann_id in getitem:  18463\n",
      "Test inds:  [(3500, 1677)]\n",
      "Ann_id in getitem:  80593\n",
      "Test inds:  [(3275, 1394)]\n",
      "Ann_id in getitem:  75029\n",
      "Test inds:  [(2281, 2069)]\n",
      "Ann_id in getitem:  51602\n",
      "Test inds:  [(604, 321)]\n",
      "Ann_id in getitem:  14618\n",
      "Test inds:  [(1885, 3051)]\n",
      "Ann_id in getitem:  43370\n",
      "Test inds:  [(1511, 1760)]\n",
      "Ann_id in getitem:  35841\n",
      "Test inds:  [(260, 3427)]\n",
      "Ann_id in getitem:  6241\n",
      "Test inds:  [(1603, 1387)]\n",
      "Ann_id in getitem:  37765\n",
      "Test inds:  [(3089, 344)]\n",
      "Ann_id in getitem:  71229\n",
      "Test inds:  [(881, 1344)]\n",
      "Ann_id in getitem:  21112\n",
      "Test inds:  [(2255, 915)]\n",
      "Ann_id in getitem:  50948\n",
      "Test inds:  [(1336, 1934)]\n",
      "Ann_id in getitem:  31415\n",
      "Test inds:  [(316, 2120)]\n",
      "Ann_id in getitem:  7717\n",
      "Test inds:  [(1388, 874)]\n",
      "Ann_id in getitem:  32955\n",
      "Test inds:  [(1165, 1794)]\n",
      "Ann_id in getitem:  27148\n",
      "Test inds:  [(2458, 1107)]\n",
      "Ann_id in getitem:  55898\n",
      "Test inds:  [(3235, 1914)]\n",
      "Ann_id in getitem:  74370\n",
      "Test inds:  [(2458, 373)]\n",
      "Ann_id in getitem:  55898\n",
      "Test inds:  [(523, 2816)]\n",
      "Ann_id in getitem:  12496\n",
      "Test inds:  [(1468, 201)]\n",
      "Ann_id in getitem:  34778\n",
      "Test inds:  [(1080, 2857)]\n",
      "Ann_id in getitem:  25255\n",
      "Test inds:  [(3203, 1455)]\n",
      "Ann_id in getitem:  73697\n",
      "Test inds:  [(2304, 1762)]\n",
      "Ann_id in getitem:  51975\n",
      "Test inds:  [(2418, 834)]\n",
      "Ann_id in getitem:  54672\n",
      "Test inds:  [(1688, 3075)]\n",
      "Ann_id in getitem:  39530\n",
      "Test inds:  [(3623, 3027)]\n",
      "Ann_id in getitem:  83592\n",
      "Test inds:  [(941, 2444)]\n",
      "Ann_id in getitem:  22353\n",
      "Test inds:  [(1144, 2241)]\n",
      "Ann_id in getitem:  26728\n",
      "Test inds:  [(1545, 294)]\n",
      "Ann_id in getitem:  36558\n",
      "Test inds:  [(3490, 2196)]\n",
      "Ann_id in getitem:  80401\n",
      "Test inds:  [(712, 724)]\n",
      "Ann_id in getitem:  17320\n",
      "Test inds:  [(1561, 2655)]\n",
      "Ann_id in getitem:  36877\n",
      "Test inds:  [(302, 395)]\n",
      "Ann_id in getitem:  7096\n",
      "Test inds:  [(1709, 1114)]\n",
      "Ann_id in getitem:  39985\n",
      "Test inds:  [(3252, 655)]\n",
      "Ann_id in getitem:  74681\n",
      "Test inds:  [(3116, 2892)]\n",
      "Ann_id in getitem:  71909\n",
      "Test inds:  [(340, 3656)]\n",
      "Ann_id in getitem:  8272\n",
      "Test inds:  [(403, 1705)]\n",
      "Ann_id in getitem:  9914\n",
      "Test inds:  [(3047, 2248)]\n",
      "Ann_id in getitem:  70257\n",
      "Test inds:  [(3592, 2401)]\n",
      "Ann_id in getitem:  82841\n",
      "Test inds:  [(141, 1430)]\n",
      "Ann_id in getitem:  3446\n",
      "Test inds:  [(1189, 2752)]\n",
      "Ann_id in getitem:  27717\n",
      "Test inds:  [(319, 2893)]\n",
      "Ann_id in getitem:  7777\n",
      "Test inds:  [(2933, 3637)]\n",
      "Ann_id in getitem:  67558\n",
      "Test inds:  [(3275, 3529)]\n",
      "Ann_id in getitem:  75029\n",
      "Test inds:  [(2734, 3612)]\n",
      "Ann_id in getitem:  62919\n",
      "Test inds:  [(1515, 469)]\n",
      "Ann_id in getitem:  35923\n",
      "Test inds:  [(335, 2111)]\n",
      "Ann_id in getitem:  8198\n",
      "Test inds:  [(500, 1229)]\n",
      "Ann_id in getitem:  11969\n",
      "Test inds:  [(2990, 479)]\n",
      "Ann_id in getitem:  68939\n",
      "Test inds:  [(2331, 1809)]\n",
      "Ann_id in getitem:  52569\n",
      "Test inds:  [(2519, 31)]\n",
      "Ann_id in getitem:  57269\n",
      "Test inds:  [(1155, 147)]\n",
      "Ann_id in getitem:  26857\n",
      "Test inds:  [(15, 2484)]\n",
      "Ann_id in getitem:  391\n",
      "Test inds:  [(789, 582)]\n",
      "Ann_id in getitem:  19065\n",
      "Test inds:  [(1469, 2609)]\n",
      "Ann_id in getitem:  34786\n",
      "Test inds:  [(3250, 2398)]\n",
      "Ann_id in getitem:  74658\n",
      "Test inds:  [(3671, 3198)]\n",
      "Ann_id in getitem:  84679\n",
      "Test inds:  [(2940, 869)]\n",
      "Ann_id in getitem:  67716\n",
      "Test inds:  [(2265, 2822)]\n",
      "Ann_id in getitem:  51180\n",
      "Test inds:  [(1206, 648)]\n",
      "Ann_id in getitem:  28119\n",
      "Test inds:  [(143, 635)]\n",
      "Ann_id in getitem:  3464\n",
      "Test inds:  [(1957, 2214)]\n",
      "Ann_id in getitem:  44503\n",
      "Test inds:  [(1927, 150)]\n",
      "Ann_id in getitem:  44037\n",
      "Test inds:  [(3089, 373)]\n",
      "Ann_id in getitem:  71229\n",
      "Test inds:  [(1578, 198)]\n",
      "Ann_id in getitem:  37339\n",
      "Test inds:  [(1271, 3653)]\n",
      "Ann_id in getitem:  29649\n",
      "Test inds:  [(3022, 3653)]\n",
      "Ann_id in getitem:  69562\n",
      "Test inds:  [(2696, 3604)]\n",
      "Ann_id in getitem:  61994\n",
      "Test inds:  [(921, 2863)]\n",
      "Ann_id in getitem:  22052\n",
      "Test inds:  [(19, 471)]\n",
      "Ann_id in getitem:  447\n",
      "Test inds:  [(171, 2915)]\n",
      "Ann_id in getitem:  4347\n",
      "Test inds:  [(411, 848)]\n",
      "Ann_id in getitem:  10045\n",
      "Test inds:  [(2605, 812)]\n",
      "Ann_id in getitem:  59675\n",
      "Test inds:  [(3655, 1277)]\n",
      "Ann_id in getitem:  84414\n",
      "Test inds:  [(1725, 3405)]\n",
      "Ann_id in getitem:  40232\n",
      "Test inds:  [(2154, 1860)]\n",
      "Ann_id in getitem:  48648\n",
      "Test inds:  [(1394, 2524)]\n",
      "Ann_id in getitem:  33100\n",
      "Test inds:  [(784, 2750)]\n",
      "Ann_id in getitem:  19000\n",
      "Test inds:  [(2555, 2379)]\n",
      "Ann_id in getitem:  58051\n",
      "Test inds:  [(2316, 2211)]\n",
      "Ann_id in getitem:  52188\n",
      "Test inds:  [(2769, 2946)]\n",
      "Ann_id in getitem:  63753\n",
      "Test inds:  [(634, 2910)]\n",
      "Ann_id in getitem:  15425\n",
      "Test inds:  [(2484, 3074)]\n",
      "Ann_id in getitem:  56556\n",
      "Test inds:  [(2824, 432)]\n",
      "Ann_id in getitem:  65096\n",
      "Test inds:  [(597, 3502)]\n",
      "Ann_id in getitem:  14439\n",
      "Test inds:  [(972, 139)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(938, 2901)]\n",
      "Ann_id in getitem:  22337\n",
      "Test inds:  [(2639, 617)]\n",
      "Ann_id in getitem:  60410\n",
      "Test inds:  [(704, 45)]\n",
      "Ann_id in getitem:  17085\n",
      "Test inds:  [(448, 990)]\n",
      "Ann_id in getitem:  10935\n",
      "Test inds:  [(371, 2499)]\n",
      "Ann_id in getitem:  9108\n",
      "Test inds:  [(454, 754)]\n",
      "Ann_id in getitem:  10973\n",
      "Test inds:  [(597, 2127)]\n",
      "Ann_id in getitem:  14439\n",
      "Test inds:  [(3265, 2380)]\n",
      "Ann_id in getitem:  74882\n",
      "Test inds:  [(517, 62)]\n",
      "Ann_id in getitem:  12356\n",
      "Test inds:  [(3523, 2023)]\n",
      "Ann_id in getitem:  81287\n",
      "Test inds:  [(1319, 1451)]\n",
      "Ann_id in getitem:  30873\n",
      "Test inds:  [(1852, 552)]\n",
      "Ann_id in getitem:  42644\n",
      "Test inds:  [(508, 408)]\n",
      "Ann_id in getitem:  12169\n",
      "Test inds:  [(1527, 104)]\n",
      "Ann_id in getitem:  36178\n",
      "Test inds:  [(2750, 1667)]\n",
      "Ann_id in getitem:  63316\n",
      "Test inds:  [(1598, 126)]\n",
      "Ann_id in getitem:  37711\n",
      "Test inds:  [(96, 1208)]\n",
      "Ann_id in getitem:  2154\n",
      "Test inds:  [(1853, 2039)]\n",
      "Ann_id in getitem:  42659\n",
      "Test inds:  [(1156, 1572)]\n",
      "Ann_id in getitem:  26881\n",
      "Test inds:  [(2148, 1596)]\n",
      "Ann_id in getitem:  48554\n",
      "Test inds:  [(306, 2495)]\n",
      "Ann_id in getitem:  7423\n",
      "Test inds:  [(2564, 2787)]\n",
      "Ann_id in getitem:  58323\n",
      "Test inds:  [(2524, 3428)]\n",
      "Ann_id in getitem:  57326\n",
      "Test inds:  [(113, 73)]\n",
      "Ann_id in getitem:  2655\n",
      "Test inds:  [(1515, 362)]\n",
      "Ann_id in getitem:  35923\n",
      "Test inds:  [(1995, 504)]\n",
      "Ann_id in getitem:  45494\n",
      "Test inds:  [(2597, 3427)]\n",
      "Ann_id in getitem:  59499\n",
      "Test inds:  [(2161, 486)]\n",
      "Ann_id in getitem:  48766\n",
      "Test inds:  [(1621, 1617)]\n",
      "Ann_id in getitem:  38030\n",
      "Test inds:  [(480, 2142)]\n",
      "Ann_id in getitem:  11542\n",
      "Test inds:  [(248, 832)]\n",
      "Ann_id in getitem:  6023\n",
      "Test inds:  [(2950, 1502)]\n",
      "Ann_id in getitem:  67958\n",
      "Test inds:  [(3316, 3594)]\n",
      "Ann_id in getitem:  76172\n",
      "Test inds:  [(1787, 3382)]\n",
      "Ann_id in getitem:  41205\n",
      "Test inds:  [(3191, 3045)]\n",
      "Ann_id in getitem:  73435\n",
      "Test inds:  [(3211, 2200)]\n",
      "Ann_id in getitem:  73815\n",
      "Test inds:  [(943, 567)]\n",
      "Ann_id in getitem:  22384\n",
      "Test inds:  [(1662, 2316)]\n",
      "Ann_id in getitem:  38868\n",
      "Test inds:  [(1594, 927)]\n",
      "Ann_id in getitem:  37627\n",
      "Test inds:  [(2803, 3389)]\n",
      "Ann_id in getitem:  64675\n",
      "Test inds:  [(272, 1469)]\n",
      "Ann_id in getitem:  6444\n",
      "Test inds:  [(2068, 3137)]\n",
      "Ann_id in getitem:  47000\n",
      "Test inds:  [(1540, 425)]\n",
      "Ann_id in getitem:  36496\n",
      "Test inds:  [(1209, 3338)]\n",
      "Ann_id in getitem:  28210\n",
      "Test inds:  [(2520, 3483)]\n",
      "Ann_id in getitem:  57279\n",
      "Test inds:  [(2860, 2966)]\n",
      "Ann_id in getitem:  65733\n",
      "Test inds:  [(1486, 574)]\n",
      "Ann_id in getitem:  35288\n",
      "Test inds:  [(29, 846)]\n",
      "Ann_id in getitem:  626\n",
      "Test inds:  [(2272, 2947)]\n",
      "Ann_id in getitem:  51390\n",
      "Test inds:  [(486, 2975)]\n",
      "Ann_id in getitem:  11702\n",
      "Test inds:  [(2737, 125)]\n",
      "Ann_id in getitem:  63040\n",
      "Test inds:  [(2006, 543)]\n",
      "Ann_id in getitem:  45673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(580, 3649)]\n",
      "Ann_id in getitem:  14091\n",
      "Test inds:  [(1645, 1429)]\n",
      "Ann_id in getitem:  38521\n",
      "Test inds:  [(2683, 1260)]\n",
      "Ann_id in getitem:  61622\n",
      "Test inds:  [(1688, 3397)]\n",
      "Ann_id in getitem:  39530\n",
      "Test inds:  [(2781, 1680)]\n",
      "Ann_id in getitem:  64155\n",
      "Test inds:  [(2962, 2422)]\n",
      "Ann_id in getitem:  68179\n",
      "Test inds:  [(2571, 2417)]\n",
      "Ann_id in getitem:  58628\n",
      "Test inds:  [(2370, 2253)]\n",
      "Ann_id in getitem:  53599\n",
      "Test inds:  [(3302, 1136)]\n",
      "Ann_id in getitem:  75751\n",
      "Test inds:  [(3186, 1261)]\n",
      "Ann_id in getitem:  73364\n",
      "Test inds:  [(2574, 1125)]\n",
      "Ann_id in getitem:  58663\n",
      "Test inds:  [(1270, 643)]\n",
      "Ann_id in getitem:  29641\n",
      "Test inds:  [(2143, 3257)]\n",
      "Ann_id in getitem:  48494\n",
      "Test inds:  [(2862, 1068)]\n",
      "Ann_id in getitem:  65761\n",
      "Test inds:  [(2562, 2551)]\n",
      "Ann_id in getitem:  58233\n",
      "Test inds:  [(2990, 2698)]\n",
      "Ann_id in getitem:  68939\n",
      "Test inds:  [(1873, 523)]\n",
      "Ann_id in getitem:  43075\n",
      "Test inds:  [(2543, 1195)]\n",
      "Ann_id in getitem:  57767\n",
      "Test inds:  [(1968, 568)]\n",
      "Ann_id in getitem:  44930\n",
      "Test inds:  [(52, 459)]\n",
      "Ann_id in getitem:  1104\n",
      "Test inds:  [(337, 339)]\n",
      "Ann_id in getitem:  8226\n",
      "Test inds:  [(649, 564)]\n",
      "Ann_id in getitem:  15827\n",
      "Test inds:  [(1480, 2433)]\n",
      "Ann_id in getitem:  35073\n",
      "Test inds:  [(2215, 3312)]\n",
      "Ann_id in getitem:  49836\n",
      "Test inds:  [(1944, 2983)]\n",
      "Ann_id in getitem:  44247\n",
      "Test inds:  [(3469, 2312)]\n",
      "Ann_id in getitem:  80073\n",
      "Test inds:  [(1244, 298)]\n",
      "Ann_id in getitem:  29129\n",
      "Test inds:  [(1038, 3338)]\n",
      "Ann_id in getitem:  24539\n",
      "Test inds:  [(193, 3130)]\n",
      "Ann_id in getitem:  4855\n",
      "Test inds:  [(1088, 628)]\n",
      "Ann_id in getitem:  25388\n",
      "Test inds:  [(2093, 1676)]\n",
      "Ann_id in getitem:  47425\n",
      "Test inds:  [(3169, 2158)]\n",
      "Ann_id in getitem:  73030\n",
      "Test inds:  [(3054, 2979)]\n",
      "Ann_id in getitem:  70504\n",
      "Test inds:  [(3387, 1442)]\n",
      "Ann_id in getitem:  77849\n",
      "Test inds:  [(2218, 1328)]\n",
      "Ann_id in getitem:  49948\n",
      "Test inds:  [(2800, 1024)]\n",
      "Ann_id in getitem:  64625\n",
      "Test inds:  [(2611, 1263)]\n",
      "Ann_id in getitem:  59841\n",
      "Test inds:  [(1614, 252)]\n",
      "Ann_id in getitem:  37855\n",
      "Test inds:  [(2555, 2245)]\n",
      "Ann_id in getitem:  58051\n",
      "Test inds:  [(66, 2491)]\n",
      "Ann_id in getitem:  1437\n",
      "Test inds:  [(1093, 2939)]\n",
      "Ann_id in getitem:  25491\n",
      "Test inds:  [(2406, 570)]\n",
      "Ann_id in getitem:  54420\n",
      "Test inds:  [(2411, 3397)]\n",
      "Ann_id in getitem:  54530\n",
      "Test inds:  [(3440, 999)]\n",
      "Ann_id in getitem:  79259\n",
      "Test inds:  [(1504, 2872)]\n",
      "Ann_id in getitem:  35719\n",
      "Test inds:  [(2939, 2366)]\n",
      "Ann_id in getitem:  67698\n",
      "Test inds:  [(2273, 3369)]\n",
      "Ann_id in getitem:  51405\n",
      "Test inds:  [(1446, 69)]\n",
      "Ann_id in getitem:  34252\n",
      "Test inds:  [(1069, 3523)]\n",
      "Ann_id in getitem:  25099\n",
      "Test inds:  [(3266, 2358)]\n",
      "Ann_id in getitem:  74900\n",
      "Test inds:  [(779, 2010)]\n",
      "Ann_id in getitem:  18903\n",
      "Test inds:  [(2450, 1567)]\n",
      "Ann_id in getitem:  55676\n",
      "Test inds:  [(2570, 2066)]\n",
      "Ann_id in getitem:  58607\n",
      "Test inds:  [(1586, 1870)]\n",
      "Ann_id in getitem:  37444\n",
      "Test inds:  [(1173, 1195)]\n",
      "Ann_id in getitem:  27289\n",
      "Test inds:  [(385, 903)]\n",
      "Ann_id in getitem:  9564\n",
      "Test inds:  [(3356, 656)]\n",
      "Ann_id in getitem:  77006\n",
      "Test inds:  [(352, 2176)]\n",
      "Ann_id in getitem:  8503\n",
      "Test inds:  [(908, 1086)]\n",
      "Ann_id in getitem:  21641\n",
      "Test inds:  [(489, 3486)]\n",
      "Ann_id in getitem:  11740\n",
      "Test inds:  [(472, 2541)]\n",
      "Ann_id in getitem:  11329\n",
      "Test inds:  [(2758, 1332)]\n",
      "Ann_id in getitem:  63437\n",
      "Test inds:  [(88, 2128)]\n",
      "Ann_id in getitem:  2045\n",
      "Test inds:  [(2208, 2318)]\n",
      "Ann_id in getitem:  49698\n",
      "Test inds:  [(3386, 1369)]\n",
      "Ann_id in getitem:  77842\n",
      "Test inds:  [(2607, 2860)]\n",
      "Ann_id in getitem:  59730\n",
      "Test inds:  [(2510, 2041)]\n",
      "Ann_id in getitem:  57133\n",
      "Test inds:  [(131, 2607)]\n",
      "Ann_id in getitem:  3192\n",
      "Test inds:  [(1989, 758)]\n",
      "Ann_id in getitem:  45321\n",
      "Test inds:  [(2625, 574)]\n",
      "Ann_id in getitem:  60008\n",
      "Test inds:  [(1238, 3239)]\n",
      "Ann_id in getitem:  28960\n",
      "Test inds:  [(40, 1401)]\n",
      "Ann_id in getitem:  882\n",
      "Test inds:  [(1328, 1377)]\n",
      "Ann_id in getitem:  31105\n",
      "Test inds:  [(1861, 1536)]\n",
      "Ann_id in getitem:  42816\n",
      "Test inds:  [(1229, 737)]\n",
      "Ann_id in getitem:  28738\n",
      "Test inds:  [(2075, 1977)]\n",
      "Ann_id in getitem:  47137\n",
      "Test inds:  [(542, 3578)]\n",
      "Ann_id in getitem:  12941\n",
      "Test inds:  [(3378, 974)]\n",
      "Ann_id in getitem:  77700\n",
      "Test inds:  [(1780, 3646)]\n",
      "Ann_id in getitem:  41085\n",
      "Test inds:  [(753, 1779)]\n",
      "Ann_id in getitem:  18251\n",
      "Test inds:  [(3420, 2789)]\n",
      "Ann_id in getitem:  78757\n",
      "Test inds:  [(482, 43)]\n",
      "Ann_id in getitem:  11605\n",
      "Test inds:  [(2895, 1110)]\n",
      "Ann_id in getitem:  66611\n",
      "Test inds:  [(2740, 2764)]\n",
      "Ann_id in getitem:  63078\n",
      "Test inds:  [(1101, 3210)]\n",
      "Ann_id in getitem:  25609\n",
      "Test inds:  [(988, 1101)]\n",
      "Ann_id in getitem:  23520\n",
      "Test inds:  [(2121, 3196)]\n",
      "Ann_id in getitem:  48055\n",
      "Test inds:  [(1615, 3036)]\n",
      "Ann_id in getitem:  37868\n",
      "Test inds:  [(1291, 1168)]\n",
      "Ann_id in getitem:  30308\n",
      "Test inds:  [(28, 2249)]\n",
      "Ann_id in getitem:  589\n",
      "Test inds:  [(584, 5)]\n",
      "Ann_id in getitem:  14209\n",
      "Test inds:  [(855, 1830)]\n",
      "Ann_id in getitem:  20777\n",
      "Test inds:  [(3599, 148)]\n",
      "Ann_id in getitem:  83057\n",
      "Test inds:  [(2167, 3515)]\n",
      "Ann_id in getitem:  48894\n",
      "Test inds:  [(1280, 3636)]\n",
      "Ann_id in getitem:  29993\n",
      "Test inds:  [(3525, 1178)]\n",
      "Ann_id in getitem:  81315\n",
      "Test inds:  [(2394, 3225)]\n",
      "Ann_id in getitem:  54152\n",
      "Test inds:  [(3311, 50)]\n",
      "Ann_id in getitem:  76008\n",
      "Test inds:  [(2849, 2009)]\n",
      "Ann_id in getitem:  65577\n",
      "Test inds:  [(3092, 939)]\n",
      "Ann_id in getitem:  71268\n",
      "Test inds:  [(1034, 317)]\n",
      "Ann_id in getitem:  24392\n",
      "Test inds:  [(943, 3238)]\n",
      "Ann_id in getitem:  22384\n",
      "Test inds:  [(3207, 12)]\n",
      "Ann_id in getitem:  73741\n",
      "Test inds:  [(3170, 1728)]\n",
      "Ann_id in getitem:  73044\n",
      "Test inds:  [(3483, 1413)]\n",
      "Ann_id in getitem:  80266\n",
      "Test inds:  [(288, 2701)]\n",
      "Ann_id in getitem:  6725\n",
      "Test inds:  [(2247, 372)]\n",
      "Ann_id in getitem:  50758\n",
      "Test inds:  [(2383, 2662)]\n",
      "Ann_id in getitem:  53894\n",
      "Test inds:  [(3122, 690)]\n",
      "Ann_id in getitem:  72009\n",
      "Test inds:  [(3541, 1013)]\n",
      "Ann_id in getitem:  81674\n",
      "Test inds:  [(1739, 2129)]\n",
      "Ann_id in getitem:  40433\n",
      "Test inds:  [(2056, 2960)]\n",
      "Ann_id in getitem:  46804\n",
      "Test inds:  [(1253, 2210)]\n",
      "Ann_id in getitem:  29400\n",
      "Test inds:  [(2398, 3111)]\n",
      "Ann_id in getitem:  54288\n",
      "Test inds:  [(1098, 2452)]\n",
      "Ann_id in getitem:  25514\n",
      "Test inds:  [(227, 63)]\n",
      "Ann_id in getitem:  5535\n",
      "Test inds:  [(2517, 1849)]\n",
      "Ann_id in getitem:  57225\n",
      "Test inds:  [(2486, 2212)]\n",
      "Ann_id in getitem:  56577\n",
      "Test inds:  [(763, 443)]\n",
      "Ann_id in getitem:  18513\n",
      "Test inds:  [(3299, 2865)]\n",
      "Ann_id in getitem:  75613\n",
      "Test inds:  [(916, 2418)]\n",
      "Ann_id in getitem:  21901\n",
      "Test inds:  [(3390, 2546)]\n",
      "Ann_id in getitem:  77905\n",
      "Test inds:  [(3255, 2640)]\n",
      "Ann_id in getitem:  74768\n",
      "Test inds:  [(413, 1448)]\n",
      "Ann_id in getitem:  10096\n",
      "Test inds:  [(237, 1972)]\n",
      "Ann_id in getitem:  5786\n",
      "Test inds:  [(3239, 361)]\n",
      "Ann_id in getitem:  74424\n",
      "Test inds:  [(3441, 2524)]\n",
      "Ann_id in getitem:  79336\n",
      "Test inds:  [(267, 135)]\n",
      "Ann_id in getitem:  6343\n",
      "Test inds:  [(2958, 1777)]\n",
      "Ann_id in getitem:  68104\n",
      "Test inds:  [(2705, 2796)]\n",
      "Ann_id in getitem:  62152\n",
      "Test inds:  [(233, 1641)]\n",
      "Ann_id in getitem:  5653\n",
      "Test inds:  [(1248, 40)]\n",
      "Ann_id in getitem:  29247\n",
      "Test inds:  [(2294, 3481)]\n",
      "Ann_id in getitem:  51776\n",
      "Test inds:  [(1838, 3405)]\n",
      "Ann_id in getitem:  42220\n",
      "Test inds:  [(3453, 263)]\n",
      "Ann_id in getitem:  79645\n",
      "Test inds:  [(365, 1633)]\n",
      "Ann_id in getitem:  8845\n",
      "Test inds:  [(276, 990)]\n",
      "Ann_id in getitem:  6566\n",
      "Test inds:  [(2342, 3393)]\n",
      "Ann_id in getitem:  52873\n",
      "Test inds:  [(1999, 970)]\n",
      "Ann_id in getitem:  45551\n",
      "Test inds:  [(323, 2124)]\n",
      "Ann_id in getitem:  7979\n",
      "Test inds:  [(1793, 1518)]\n",
      "Ann_id in getitem:  41441\n",
      "Test inds:  [(1204, 1964)]\n",
      "Ann_id in getitem:  27981\n",
      "Test inds:  [(3380, 453)]\n",
      "Ann_id in getitem:  77732\n",
      "Test inds:  [(2002, 1873)]\n",
      "Ann_id in getitem:  45579\n",
      "Test inds:  [(2920, 757)]\n",
      "Ann_id in getitem:  67248\n",
      "Test inds:  [(1628, 264)]\n",
      "Ann_id in getitem:  38203\n",
      "Test inds:  [(2250, 2858)]\n",
      "Ann_id in getitem:  50843\n",
      "Test inds:  [(205, 176)]\n",
      "Ann_id in getitem:  5098\n",
      "Test inds:  [(2054, 2298)]\n",
      "Ann_id in getitem:  46791\n",
      "Test inds:  [(399, 2738)]\n",
      "Ann_id in getitem:  9861\n",
      "Test inds:  [(2356, 351)]\n",
      "Ann_id in getitem:  53294\n",
      "Test inds:  [(841, 3479)]\n",
      "Ann_id in getitem:  20304\n",
      "Test inds:  [(1465, 3001)]\n",
      "Ann_id in getitem:  34694\n",
      "Test inds:  [(225, 1032)]\n",
      "Ann_id in getitem:  5509\n",
      "Test inds:  [(1723, 3106)]\n",
      "Ann_id in getitem:  40192\n",
      "Test inds:  [(358, 3116)]\n",
      "Ann_id in getitem:  8648\n",
      "Test inds:  [(325, 914)]\n",
      "Ann_id in getitem:  7993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1017, 2972)]\n",
      "Ann_id in getitem:  24110\n",
      "Test inds:  [(768, 348)]\n",
      "Ann_id in getitem:  18562\n",
      "Test inds:  [(845, 1356)]\n",
      "Ann_id in getitem:  20472\n",
      "Test inds:  [(629, 25)]\n",
      "Ann_id in getitem:  15332\n",
      "Test inds:  [(1835, 991)]\n",
      "Ann_id in getitem:  42156\n",
      "Test inds:  [(1223, 1953)]\n",
      "Ann_id in getitem:  28576\n",
      "Test inds:  [(1429, 292)]\n",
      "Ann_id in getitem:  33892\n",
      "Test inds:  [(2611, 3596)]\n",
      "Ann_id in getitem:  59841\n",
      "Test inds:  [(2916, 1487)]\n",
      "Ann_id in getitem:  67135\n",
      "Test inds:  [(2034, 776)]\n",
      "Ann_id in getitem:  46308\n",
      "Test inds:  [(1290, 3632)]\n",
      "Ann_id in getitem:  30285\n",
      "Test inds:  [(1566, 1677)]\n",
      "Ann_id in getitem:  36993\n",
      "Test inds:  [(1592, 3174)]\n",
      "Ann_id in getitem:  37549\n",
      "Test inds:  [(2842, 3607)]\n",
      "Ann_id in getitem:  65439\n",
      "Test inds:  [(3606, 32)]\n",
      "Ann_id in getitem:  83291\n",
      "Test inds:  [(939, 937)]\n",
      "Ann_id in getitem:  22341\n",
      "Test inds:  [(2572, 170)]\n",
      "Ann_id in getitem:  58645\n",
      "Test inds:  [(3131, 2447)]\n",
      "Ann_id in getitem:  72184\n",
      "Test inds:  [(2380, 1870)]\n",
      "Ann_id in getitem:  53783\n",
      "Test inds:  [(20, 1833)]\n",
      "Ann_id in getitem:  452\n",
      "Test inds:  [(1946, 95)]\n",
      "Ann_id in getitem:  44309\n",
      "Test inds:  [(110, 660)]\n",
      "Ann_id in getitem:  2599\n",
      "Test inds:  [(16, 766)]\n",
      "Ann_id in getitem:  401\n",
      "Test inds:  [(239, 2856)]\n",
      "Ann_id in getitem:  5812\n",
      "Test inds:  [(160, 158)]\n",
      "Ann_id in getitem:  4052\n",
      "Test inds:  [(446, 3214)]\n",
      "Ann_id in getitem:  10865\n",
      "Test inds:  [(794, 1154)]\n",
      "Ann_id in getitem:  19244\n",
      "Test inds:  [(1554, 109)]\n",
      "Ann_id in getitem:  36772\n",
      "Test inds:  [(1063, 2478)]\n",
      "Ann_id in getitem:  24998\n",
      "Test inds:  [(1608, 2989)]\n",
      "Ann_id in getitem:  37789\n",
      "Test inds:  [(1613, 3508)]\n",
      "Ann_id in getitem:  37849\n",
      "Test inds:  [(538, 2599)]\n",
      "Ann_id in getitem:  12762\n",
      "Test inds:  [(3463, 251)]\n",
      "Ann_id in getitem:  79929\n",
      "Test inds:  [(3325, 1577)]\n",
      "Ann_id in getitem:  76389\n",
      "Test inds:  [(1644, 1544)]\n",
      "Ann_id in getitem:  38515\n",
      "Test inds:  [(98, 260)]\n",
      "Ann_id in getitem:  2158\n",
      "Test inds:  [(1757, 2479)]\n",
      "Ann_id in getitem:  40650\n",
      "Test inds:  [(732, 966)]\n",
      "Ann_id in getitem:  17778\n",
      "Test inds:  [(2408, 1932)]\n",
      "Ann_id in getitem:  54458\n",
      "Test inds:  [(2027, 828)]\n",
      "Ann_id in getitem:  46113\n",
      "Test inds:  [(2453, 1713)]\n",
      "Ann_id in getitem:  55705\n",
      "Test inds:  [(2658, 208)]\n",
      "Ann_id in getitem:  61013\n",
      "Test inds:  [(952, 2225)]\n",
      "Ann_id in getitem:  22575\n",
      "Test inds:  [(803, 1170)]\n",
      "Ann_id in getitem:  19394\n",
      "Test inds:  [(632, 118)]\n",
      "Ann_id in getitem:  15404\n",
      "Test inds:  [(1564, 466)]\n",
      "Ann_id in getitem:  36955\n",
      "Test inds:  [(3385, 2218)]\n",
      "Ann_id in getitem:  77829\n",
      "Test inds:  [(865, 2068)]\n",
      "Ann_id in getitem:  20910\n",
      "Test inds:  [(2338, 2107)]\n",
      "Ann_id in getitem:  52711\n",
      "Test inds:  [(2735, 1925)]\n",
      "Ann_id in getitem:  62956\n",
      "Test inds:  [(262, 692)]\n",
      "Ann_id in getitem:  6271\n",
      "Test inds:  [(1960, 2183)]\n",
      "Ann_id in getitem:  44552\n",
      "Test inds:  [(975, 2960)]\n",
      "Ann_id in getitem:  22991\n",
      "Test inds:  [(3311, 1866)]\n",
      "Ann_id in getitem:  76008\n",
      "Test inds:  [(3420, 1993)]\n",
      "Ann_id in getitem:  78757\n",
      "Test inds:  [(996, 3247)]\n",
      "Ann_id in getitem:  23661\n",
      "Test inds:  [(3375, 1612)]\n",
      "Ann_id in getitem:  77639\n",
      "Test inds:  [(1143, 2002)]\n",
      "Ann_id in getitem:  26709\n",
      "Test inds:  [(412, 737)]\n",
      "Ann_id in getitem:  10069\n",
      "Test inds:  [(1758, 3610)]\n",
      "Ann_id in getitem:  40670\n",
      "Test inds:  [(1651, 2337)]\n",
      "Ann_id in getitem:  38642\n",
      "Test inds:  [(2114, 2115)]\n",
      "Ann_id in getitem:  47929\n",
      "Test inds:  [(1909, 3340)]\n",
      "Ann_id in getitem:  43728\n",
      "Test inds:  [(3054, 44)]\n",
      "Ann_id in getitem:  70504\n",
      "Test inds:  [(631, 3646)]\n",
      "Ann_id in getitem:  15384\n",
      "Test inds:  [(2722, 585)]\n",
      "Ann_id in getitem:  62553\n",
      "Test inds:  [(326, 1383)]\n",
      "Ann_id in getitem:  7996\n",
      "Test inds:  [(2998, 558)]\n",
      "Ann_id in getitem:  69104\n",
      "Test inds:  [(168, 1023)]\n",
      "Ann_id in getitem:  4220\n",
      "Test inds:  [(2910, 1677)]\n",
      "Ann_id in getitem:  67092\n",
      "Test inds:  [(465, 30)]\n",
      "Ann_id in getitem:  11221\n",
      "Test inds:  [(1951, 2191)]\n",
      "Ann_id in getitem:  44378\n",
      "Test inds:  [(234, 1268)]\n",
      "Ann_id in getitem:  5689\n",
      "Test inds:  [(332, 2443)]\n",
      "Ann_id in getitem:  8109\n",
      "Test inds:  [(2894, 1323)]\n",
      "Ann_id in getitem:  66573\n",
      "Test inds:  [(1036, 1185)]\n",
      "Ann_id in getitem:  24474\n",
      "Test inds:  [(920, 3695)]\n",
      "Ann_id in getitem:  22004\n",
      "Test inds:  [(1181, 384)]\n",
      "Ann_id in getitem:  27484\n",
      "Test inds:  [(971, 750)]\n",
      "Ann_id in getitem:  22910\n",
      "Test inds:  [(3129, 1583)]\n",
      "Ann_id in getitem:  72149\n",
      "Test inds:  [(2666, 1176)]\n",
      "Ann_id in getitem:  61166\n",
      "Test inds:  [(618, 2413)]\n",
      "Ann_id in getitem:  15170\n",
      "Test inds:  [(1178, 1376)]\n",
      "Ann_id in getitem:  27434\n",
      "Test inds:  [(2712, 1058)]\n",
      "Ann_id in getitem:  62387\n",
      "Test inds:  [(693, 2396)]\n",
      "Ann_id in getitem:  16873\n",
      "Test inds:  [(1929, 2675)]\n",
      "Ann_id in getitem:  44065\n",
      "Test inds:  [(1826, 350)]\n",
      "Ann_id in getitem:  42020\n",
      "Test inds:  [(2232, 632)]\n",
      "Ann_id in getitem:  50228\n",
      "Test inds:  [(1648, 949)]\n",
      "Ann_id in getitem:  38600\n",
      "Test inds:  [(2084, 2914)]\n",
      "Ann_id in getitem:  47299\n",
      "Test inds:  [(1243, 3589)]\n",
      "Ann_id in getitem:  29124\n",
      "Test inds:  [(1169, 2617)]\n",
      "Ann_id in getitem:  27212\n",
      "Test inds:  [(315, 1479)]\n",
      "Ann_id in getitem:  7679\n",
      "Test inds:  [(484, 913)]\n",
      "Ann_id in getitem:  11616\n",
      "Test inds:  [(488, 3148)]\n",
      "Ann_id in getitem:  11734\n",
      "Test inds:  [(791, 360)]\n",
      "Ann_id in getitem:  19137\n",
      "Test inds:  [(3382, 1650)]\n",
      "Ann_id in getitem:  77773\n",
      "Test inds:  [(93, 3218)]\n",
      "Ann_id in getitem:  2121\n",
      "Test inds:  [(101, 2857)]\n",
      "Ann_id in getitem:  2219\n",
      "Test inds:  [(3416, 3614)]\n",
      "Ann_id in getitem:  78692\n",
      "Test inds:  [(1526, 766)]\n",
      "Ann_id in getitem:  36114\n",
      "Test inds:  [(3393, 1095)]\n",
      "Ann_id in getitem:  78005\n",
      "Test inds:  [(812, 1452)]\n",
      "Ann_id in getitem:  19553\n",
      "Test inds:  [(130, 1646)]\n",
      "Ann_id in getitem:  3125\n",
      "Test inds:  [(2501, 1421)]\n",
      "Ann_id in getitem:  56987\n",
      "Test inds:  [(1907, 1883)]\n",
      "Ann_id in getitem:  43705\n",
      "Test inds:  [(781, 840)]\n",
      "Ann_id in getitem:  18927\n",
      "Test inds:  [(2868, 2971)]\n",
      "Ann_id in getitem:  65951\n",
      "Test inds:  [(189, 1338)]\n",
      "Ann_id in getitem:  4781\n",
      "Test inds:  [(2117, 1170)]\n",
      "Ann_id in getitem:  47986\n",
      "Test inds:  [(1571, 1202)]\n",
      "Ann_id in getitem:  37186\n",
      "Test inds:  [(1564, 2646)]\n",
      "Ann_id in getitem:  36955\n",
      "Test inds:  [(3534, 1756)]\n",
      "Ann_id in getitem:  81549\n",
      "Test inds:  [(2608, 1420)]\n",
      "Ann_id in getitem:  59777\n",
      "Test inds:  [(2959, 1213)]\n",
      "Ann_id in getitem:  68107\n",
      "Test inds:  [(1156, 2510)]\n",
      "Ann_id in getitem:  26881\n",
      "Test inds:  [(3180, 1166)]\n",
      "Ann_id in getitem:  73252\n",
      "Test inds:  [(1633, 1621)]\n",
      "Ann_id in getitem:  38308\n",
      "Test inds:  [(3570, 3513)]\n",
      "Ann_id in getitem:  82292\n",
      "Test inds:  [(783, 1231)]\n",
      "Ann_id in getitem:  18954\n",
      "Test inds:  [(2225, 17)]\n",
      "Ann_id in getitem:  50142\n",
      "Test inds:  [(2445, 2368)]\n",
      "Ann_id in getitem:  55577\n",
      "Test inds:  [(388, 3583)]\n",
      "Ann_id in getitem:  9616\n",
      "Test inds:  [(32, 837)]\n",
      "Ann_id in getitem:  701\n",
      "Test inds:  [(921, 359)]\n",
      "Ann_id in getitem:  22052\n",
      "Test inds:  [(2198, 2702)]\n",
      "Ann_id in getitem:  49494\n",
      "Test inds:  [(3633, 2111)]\n",
      "Ann_id in getitem:  83855\n",
      "Test inds:  [(2290, 301)]\n",
      "Ann_id in getitem:  51723\n",
      "Test inds:  [(1993, 2627)]\n",
      "Ann_id in getitem:  45422\n",
      "Test inds:  [(2582, 3002)]\n",
      "Ann_id in getitem:  58999\n",
      "Test inds:  [(1294, 75)]\n",
      "Ann_id in getitem:  30367\n",
      "Test inds:  [(2473, 327)]\n",
      "Ann_id in getitem:  56274\n",
      "Test inds:  [(3609, 662)]\n",
      "Ann_id in getitem:  83357\n",
      "Test inds:  [(2312, 2816)]\n",
      "Ann_id in getitem:  52100\n",
      "Test inds:  [(3459, 1942)]\n",
      "Ann_id in getitem:  79802\n",
      "Test inds:  [(2689, 1828)]\n",
      "Ann_id in getitem:  61729\n",
      "Test inds:  [(2221, 3189)]\n",
      "Ann_id in getitem:  49983\n",
      "Test inds:  [(1205, 3247)]\n",
      "Ann_id in getitem:  28095\n",
      "Test inds:  [(3066, 714)]\n",
      "Ann_id in getitem:  70643\n",
      "Test inds:  [(279, 1439)]\n",
      "Ann_id in getitem:  6614\n",
      "Test inds:  [(605, 3301)]\n",
      "Ann_id in getitem:  14706\n",
      "Test inds:  [(401, 997)]\n",
      "Ann_id in getitem:  9891\n",
      "Test inds:  [(201, 2877)]\n",
      "Ann_id in getitem:  5010\n",
      "Test inds:  [(539, 3606)]\n",
      "Ann_id in getitem:  12831\n",
      "Test inds:  [(2592, 169)]\n",
      "Ann_id in getitem:  59430\n",
      "Test inds:  [(2879, 1052)]\n",
      "Ann_id in getitem:  66209\n",
      "Test inds:  [(1642, 3519)]\n",
      "Ann_id in getitem:  38504\n",
      "Test inds:  [(1635, 3011)]\n",
      "Ann_id in getitem:  38338\n",
      "Test inds:  [(3572, 154)]\n",
      "Ann_id in getitem:  82352\n",
      "Test inds:  [(2884, 2950)]\n",
      "Ann_id in getitem:  66357\n",
      "Test inds:  [(2352, 1759)]\n",
      "Ann_id in getitem:  53192\n",
      "Test inds:  [(3419, 2049)]\n",
      "Ann_id in getitem:  78749\n",
      "Test inds:  [(2115, 3231)]\n",
      "Ann_id in getitem:  47933\n",
      "Test inds:  [(3121, 70)]\n",
      "Ann_id in getitem:  71994\n",
      "Test inds:  [(916, 1387)]\n",
      "Ann_id in getitem:  21901\n",
      "Test inds:  [(678, 1244)]\n",
      "Ann_id in getitem:  16429\n",
      "Test inds:  [(394, 1356)]\n",
      "Ann_id in getitem:  9709\n",
      "Test inds:  [(2200, 649)]\n",
      "Ann_id in getitem:  49558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2611, 1933)]\n",
      "Ann_id in getitem:  59841\n",
      "Test inds:  [(3430, 2388)]\n",
      "Ann_id in getitem:  79058\n",
      "Test inds:  [(1429, 3110)]\n",
      "Ann_id in getitem:  33892\n",
      "Test inds:  [(468, 2304)]\n",
      "Ann_id in getitem:  11279\n",
      "Test inds:  [(2875, 3226)]\n",
      "Ann_id in getitem:  66059\n",
      "Test inds:  [(2859, 2344)]\n",
      "Ann_id in getitem:  65727\n",
      "Test inds:  [(1449, 956)]\n",
      "Ann_id in getitem:  34312\n",
      "Test inds:  [(1042, 3197)]\n",
      "Ann_id in getitem:  24664\n",
      "Test inds:  [(3098, 3058)]\n",
      "Ann_id in getitem:  71418\n",
      "Test inds:  [(2177, 3345)]\n",
      "Ann_id in getitem:  49079\n",
      "Test inds:  [(1171, 2745)]\n",
      "Ann_id in getitem:  27251\n",
      "Test inds:  [(2505, 1751)]\n",
      "Ann_id in getitem:  57045\n",
      "Test inds:  [(2550, 68)]\n",
      "Ann_id in getitem:  57948\n",
      "Test inds:  [(3603, 1620)]\n",
      "Ann_id in getitem:  83130\n",
      "Test inds:  [(2165, 3484)]\n",
      "Ann_id in getitem:  48865\n",
      "Test inds:  [(397, 102)]\n",
      "Ann_id in getitem:  9769\n",
      "Test inds:  [(2745, 1590)]\n",
      "Ann_id in getitem:  63173\n",
      "Test inds:  [(3218, 1829)]\n",
      "Ann_id in getitem:  74015\n",
      "Test inds:  [(3558, 3606)]\n",
      "Ann_id in getitem:  82054\n",
      "Test inds:  [(1946, 753)]\n",
      "Ann_id in getitem:  44309\n",
      "Test inds:  [(2269, 3329)]\n",
      "Ann_id in getitem:  51256\n",
      "Test inds:  [(1487, 451)]\n",
      "Ann_id in getitem:  35350\n",
      "Test inds:  [(2975, 382)]\n",
      "Ann_id in getitem:  68531\n",
      "Test inds:  [(1039, 1638)]\n",
      "Ann_id in getitem:  24546\n",
      "Test inds:  [(769, 1229)]\n",
      "Ann_id in getitem:  18639\n",
      "Test inds:  [(981, 975)]\n",
      "Ann_id in getitem:  23182\n",
      "Test inds:  [(190, 933)]\n",
      "Ann_id in getitem:  4840\n",
      "Test inds:  [(3060, 2320)]\n",
      "Ann_id in getitem:  70600\n",
      "Test inds:  [(983, 1926)]\n",
      "Ann_id in getitem:  23321\n",
      "Test inds:  [(89, 971)]\n",
      "Ann_id in getitem:  2049\n",
      "Test inds:  [(943, 3622)]\n",
      "Ann_id in getitem:  22384\n",
      "Test inds:  [(840, 156)]\n",
      "Ann_id in getitem:  20226\n",
      "Test inds:  [(2366, 2726)]\n",
      "Ann_id in getitem:  53509\n",
      "Test inds:  [(2637, 1175)]\n",
      "Ann_id in getitem:  60348\n",
      "Test inds:  [(3040, 859)]\n",
      "Ann_id in getitem:  70076\n",
      "Test inds:  [(3539, 2885)]\n",
      "Ann_id in getitem:  81612\n",
      "Test inds:  [(1298, 1792)]\n",
      "Ann_id in getitem:  30473\n",
      "Test inds:  [(889, 3518)]\n",
      "Ann_id in getitem:  21210\n",
      "Test inds:  [(7, 2983)]\n",
      "Ann_id in getitem:  121\n",
      "Test inds:  [(448, 1957)]\n",
      "Ann_id in getitem:  10935\n",
      "Test inds:  [(866, 17)]\n",
      "Ann_id in getitem:  20914\n",
      "Test inds:  [(1728, 365)]\n",
      "Ann_id in getitem:  40298\n",
      "Test inds:  [(3611, 3187)]\n",
      "Ann_id in getitem:  83382\n",
      "Test inds:  [(2677, 55)]\n",
      "Ann_id in getitem:  61404\n",
      "Test inds:  [(2445, 3698)]\n",
      "Ann_id in getitem:  55577\n",
      "Test inds:  [(3360, 2050)]\n",
      "Ann_id in getitem:  77096\n",
      "Test inds:  [(115, 377)]\n",
      "Ann_id in getitem:  2686\n",
      "Test inds:  [(3181, 990)]\n",
      "Ann_id in getitem:  73268\n",
      "Test inds:  [(945, 2891)]\n",
      "Ann_id in getitem:  22472\n",
      "Test inds:  [(1616, 1490)]\n",
      "Ann_id in getitem:  37888\n",
      "Test inds:  [(286, 2657)]\n",
      "Ann_id in getitem:  6676\n",
      "Test inds:  [(1780, 454)]\n",
      "Ann_id in getitem:  41085\n",
      "Test inds:  [(906, 2143)]\n",
      "Ann_id in getitem:  21608\n",
      "Test inds:  [(2921, 1475)]\n",
      "Ann_id in getitem:  67274\n",
      "Test inds:  [(1768, 432)]\n",
      "Ann_id in getitem:  40851\n",
      "Test inds:  [(47, 1300)]\n",
      "Ann_id in getitem:  961\n",
      "Test inds:  [(531, 3549)]\n",
      "Ann_id in getitem:  12627\n",
      "Test inds:  [(2924, 2076)]\n",
      "Ann_id in getitem:  67297\n",
      "Test inds:  [(1761, 2037)]\n",
      "Ann_id in getitem:  40756\n",
      "Test inds:  [(1903, 3409)]\n",
      "Ann_id in getitem:  43648\n",
      "Test inds:  [(824, 238)]\n",
      "Ann_id in getitem:  19788\n",
      "Test inds:  [(462, 1611)]\n",
      "Ann_id in getitem:  11142\n",
      "Test inds:  [(2476, 965)]\n",
      "Ann_id in getitem:  56395\n",
      "Test inds:  [(382, 70)]\n",
      "Ann_id in getitem:  9345\n",
      "Test inds:  [(2253, 327)]\n",
      "Ann_id in getitem:  50937\n",
      "Test inds:  [(3423, 1685)]\n",
      "Ann_id in getitem:  78901\n",
      "Test inds:  [(2166, 1497)]\n",
      "Ann_id in getitem:  48868\n",
      "Test inds:  [(1103, 602)]\n",
      "Ann_id in getitem:  25651\n",
      "Test inds:  [(345, 3187)]\n",
      "Ann_id in getitem:  8357\n",
      "Test inds:  [(1372, 583)]\n",
      "Ann_id in getitem:  32365\n",
      "Test inds:  [(1, 3397)]\n",
      "Ann_id in getitem:  38\n",
      "Test inds:  [(2738, 3017)]\n",
      "Ann_id in getitem:  63062\n",
      "Test inds:  [(2394, 1072)]\n",
      "Ann_id in getitem:  54152\n",
      "Test inds:  [(1950, 2002)]\n",
      "Ann_id in getitem:  44354\n",
      "Test inds:  [(3065, 2183)]\n",
      "Ann_id in getitem:  70637\n",
      "Test inds:  [(2996, 965)]\n",
      "Ann_id in getitem:  69040\n",
      "Test inds:  [(2265, 2064)]\n",
      "Ann_id in getitem:  51180\n",
      "Test inds:  [(2403, 2517)]\n",
      "Ann_id in getitem:  54351\n",
      "Test inds:  [(3220, 3643)]\n",
      "Ann_id in getitem:  74051\n",
      "Test inds:  [(3069, 2908)]\n",
      "Ann_id in getitem:  70739\n",
      "Test inds:  [(2590, 2815)]\n",
      "Ann_id in getitem:  59384\n",
      "Test inds:  [(527, 1465)]\n",
      "Ann_id in getitem:  12564\n",
      "Test inds:  [(225, 3319)]\n",
      "Ann_id in getitem:  5509\n",
      "Test inds:  [(3411, 670)]\n",
      "Ann_id in getitem:  78612\n",
      "Test inds:  [(2402, 3176)]\n",
      "Ann_id in getitem:  54342\n",
      "Test inds:  [(1218, 888)]\n",
      "Ann_id in getitem:  28460\n",
      "Test inds:  [(2408, 1554)]\n",
      "Ann_id in getitem:  54458\n",
      "Test inds:  [(467, 1460)]\n",
      "Ann_id in getitem:  11252\n",
      "Test inds:  [(2859, 1484)]\n",
      "Ann_id in getitem:  65727\n",
      "Test inds:  [(104, 1017)]\n",
      "Ann_id in getitem:  2376\n",
      "Test inds:  [(3498, 3344)]\n",
      "Ann_id in getitem:  80556\n",
      "Test inds:  [(2828, 1774)]\n",
      "Ann_id in getitem:  65139\n",
      "Test inds:  [(2239, 2877)]\n",
      "Ann_id in getitem:  50558\n",
      "Test inds:  [(397, 1278)]\n",
      "Ann_id in getitem:  9769\n",
      "Test inds:  [(7, 1828)]\n",
      "Ann_id in getitem:  121\n",
      "Test inds:  [(1148, 742)]\n",
      "Ann_id in getitem:  26760\n",
      "Test inds:  [(686, 3060)]\n",
      "Ann_id in getitem:  16703\n",
      "Test inds:  [(2883, 3184)]\n",
      "Ann_id in getitem:  66318\n",
      "Test inds:  [(1036, 2783)]\n",
      "Ann_id in getitem:  24474\n",
      "Test inds:  [(1616, 213)]\n",
      "Ann_id in getitem:  37888\n",
      "Test inds:  [(3186, 1595)]\n",
      "Ann_id in getitem:  73364\n",
      "Test inds:  [(326, 2269)]\n",
      "Ann_id in getitem:  7996\n",
      "Test inds:  [(1667, 167)]\n",
      "Ann_id in getitem:  38983\n",
      "Test inds:  [(3327, 2926)]\n",
      "Ann_id in getitem:  76414\n",
      "Test inds:  [(2405, 617)]\n",
      "Ann_id in getitem:  54377\n",
      "Test inds:  [(1477, 1745)]\n",
      "Ann_id in getitem:  35022\n",
      "Test inds:  [(1595, 2461)]\n",
      "Ann_id in getitem:  37651\n",
      "Test inds:  [(1498, 1620)]\n",
      "Ann_id in getitem:  35589\n",
      "Test inds:  [(1050, 414)]\n",
      "Ann_id in getitem:  24781\n",
      "Test inds:  [(1381, 2004)]\n",
      "Ann_id in getitem:  32820\n",
      "Test inds:  [(3233, 3322)]\n",
      "Ann_id in getitem:  74320\n",
      "Test inds:  [(1485, 747)]\n",
      "Ann_id in getitem:  35264\n",
      "Test inds:  [(3692, 2232)]\n",
      "Ann_id in getitem:  85388\n",
      "Test inds:  [(433, 207)]\n",
      "Ann_id in getitem:  10657\n",
      "Test inds:  [(2445, 3600)]\n",
      "Ann_id in getitem:  55577\n",
      "Test inds:  [(93, 1365)]\n",
      "Ann_id in getitem:  2121\n",
      "Test inds:  [(2227, 2065)]\n",
      "Ann_id in getitem:  50158\n",
      "Test inds:  [(2192, 2265)]\n",
      "Ann_id in getitem:  49357\n",
      "Test inds:  [(461, 3426)]\n",
      "Ann_id in getitem:  11138\n",
      "Test inds:  [(271, 2208)]\n",
      "Ann_id in getitem:  6443\n",
      "Test inds:  [(3137, 1935)]\n",
      "Ann_id in getitem:  72344\n",
      "Test inds:  [(3009, 3168)]\n",
      "Ann_id in getitem:  69329\n",
      "Test inds:  [(3191, 1839)]\n",
      "Ann_id in getitem:  73435\n",
      "Test inds:  [(733, 3400)]\n",
      "Ann_id in getitem:  17818\n",
      "Test inds:  [(116, 3603)]\n",
      "Ann_id in getitem:  2688\n",
      "Test inds:  [(1735, 1362)]\n",
      "Ann_id in getitem:  40385\n",
      "Test inds:  [(1499, 913)]\n",
      "Ann_id in getitem:  35667\n",
      "Test inds:  [(1092, 907)]\n",
      "Ann_id in getitem:  25487\n",
      "Test inds:  [(175, 697)]\n",
      "Ann_id in getitem:  4397\n",
      "Test inds:  [(3521, 3196)]\n",
      "Ann_id in getitem:  81243\n",
      "Test inds:  [(1557, 73)]\n",
      "Ann_id in getitem:  36794\n",
      "Test inds:  [(735, 68)]\n",
      "Ann_id in getitem:  17852\n",
      "Test inds:  [(3056, 788)]\n",
      "Ann_id in getitem:  70525\n",
      "Test inds:  [(3605, 587)]\n",
      "Ann_id in getitem:  83236\n",
      "Test inds:  [(3690, 3012)]\n",
      "Ann_id in getitem:  85287\n",
      "Test inds:  [(2719, 1794)]\n",
      "Ann_id in getitem:  62513\n",
      "Test inds:  [(2182, 233)]\n",
      "Ann_id in getitem:  49148\n",
      "Test inds:  [(3550, 399)]\n",
      "Ann_id in getitem:  81878\n",
      "Test inds:  [(3328, 1050)]\n",
      "Ann_id in getitem:  76474\n",
      "Test inds:  [(2078, 546)]\n",
      "Ann_id in getitem:  47189\n",
      "Test inds:  [(3280, 234)]\n",
      "Ann_id in getitem:  75098\n",
      "Test inds:  [(3438, 903)]\n",
      "Ann_id in getitem:  79233\n",
      "Test inds:  [(259, 1222)]\n",
      "Ann_id in getitem:  6216\n",
      "Test inds:  [(2685, 3497)]\n",
      "Ann_id in getitem:  61647\n",
      "Test inds:  [(917, 399)]\n",
      "Ann_id in getitem:  21924\n",
      "Test inds:  [(3590, 280)]\n",
      "Ann_id in getitem:  82793\n",
      "Test inds:  [(1342, 3170)]\n",
      "Ann_id in getitem:  31597\n",
      "Test inds:  [(3595, 2013)]\n",
      "Ann_id in getitem:  82901\n",
      "Test inds:  [(2950, 3100)]\n",
      "Ann_id in getitem:  67958\n",
      "Test inds:  [(1750, 3411)]\n",
      "Ann_id in getitem:  40556\n",
      "Test inds:  [(2264, 2048)]\n",
      "Ann_id in getitem:  51172\n",
      "Test inds:  [(221, 3508)]\n",
      "Ann_id in getitem:  5433\n",
      "Test inds:  [(2365, 2546)]\n",
      "Ann_id in getitem:  53465\n",
      "Test inds:  [(1651, 2928)]\n",
      "Ann_id in getitem:  38642\n",
      "Test inds:  [(2687, 1160)]\n",
      "Ann_id in getitem:  61673\n",
      "Test inds:  [(1082, 516)]\n",
      "Ann_id in getitem:  25259\n",
      "Test inds:  [(1111, 2888)]\n",
      "Ann_id in getitem:  25778\n",
      "Test inds:  [(126, 2129)]\n",
      "Ann_id in getitem:  2970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1228, 1048)]\n",
      "Ann_id in getitem:  28712\n",
      "Test inds:  [(904, 2000)]\n",
      "Ann_id in getitem:  21602\n",
      "Test inds:  [(1359, 3150)]\n",
      "Ann_id in getitem:  32039\n",
      "Test inds:  [(2407, 3324)]\n",
      "Ann_id in getitem:  54427\n",
      "Test inds:  [(1865, 1261)]\n",
      "Ann_id in getitem:  42971\n",
      "Test inds:  [(3517, 114)]\n",
      "Ann_id in getitem:  81156\n",
      "Test inds:  [(3010, 1153)]\n",
      "Ann_id in getitem:  69388\n",
      "Test inds:  [(476, 2261)]\n",
      "Ann_id in getitem:  11512\n",
      "Test inds:  [(650, 499)]\n",
      "Ann_id in getitem:  15861\n",
      "Test inds:  [(3501, 259)]\n",
      "Ann_id in getitem:  80649\n",
      "Test inds:  [(2613, 3325)]\n",
      "Ann_id in getitem:  59857\n",
      "Test inds:  [(2473, 1964)]\n",
      "Ann_id in getitem:  56274\n",
      "Test inds:  [(419, 2483)]\n",
      "Ann_id in getitem:  10187\n",
      "Test inds:  [(704, 1225)]\n",
      "Ann_id in getitem:  17085\n",
      "Test inds:  [(909, 1161)]\n",
      "Ann_id in getitem:  21647\n",
      "Test inds:  [(1641, 2007)]\n",
      "Ann_id in getitem:  38500\n",
      "Test inds:  [(3523, 2315)]\n",
      "Ann_id in getitem:  81287\n",
      "Test inds:  [(3676, 2923)]\n",
      "Ann_id in getitem:  84764\n",
      "Test inds:  [(1653, 56)]\n",
      "Ann_id in getitem:  38727\n",
      "Test inds:  [(2493, 1048)]\n",
      "Ann_id in getitem:  56700\n",
      "Test inds:  [(499, 3423)]\n",
      "Ann_id in getitem:  11933\n",
      "Test inds:  [(1951, 223)]\n",
      "Ann_id in getitem:  44378\n",
      "Test inds:  [(1423, 3598)]\n",
      "Ann_id in getitem:  33746\n",
      "Test inds:  [(1247, 1028)]\n",
      "Ann_id in getitem:  29227\n",
      "Test inds:  [(1444, 1128)]\n",
      "Ann_id in getitem:  34207\n",
      "Test inds:  [(961, 3112)]\n",
      "Ann_id in getitem:  22727\n",
      "Test inds:  [(620, 704)]\n",
      "Ann_id in getitem:  15185\n",
      "Test inds:  [(927, 811)]\n",
      "Ann_id in getitem:  22157\n",
      "Test inds:  [(1711, 1117)]\n",
      "Ann_id in getitem:  39995\n",
      "Test inds:  [(421, 1469)]\n",
      "Ann_id in getitem:  10216\n",
      "Test inds:  [(2955, 981)]\n",
      "Ann_id in getitem:  68049\n",
      "Test inds:  [(499, 3327)]\n",
      "Ann_id in getitem:  11933\n",
      "Test inds:  [(935, 1579)]\n",
      "Ann_id in getitem:  22304\n",
      "Test inds:  [(2023, 3039)]\n",
      "Ann_id in getitem:  45981\n",
      "Test inds:  [(3360, 3635)]\n",
      "Ann_id in getitem:  77096\n",
      "Test inds:  [(1071, 2155)]\n",
      "Ann_id in getitem:  25148\n",
      "Test inds:  [(3696, 2653)]\n",
      "Ann_id in getitem:  85427\n",
      "Test inds:  [(3174, 2060)]\n",
      "Ann_id in getitem:  73075\n",
      "Test inds:  [(3234, 1074)]\n",
      "Ann_id in getitem:  74355\n",
      "Test inds:  [(2743, 2642)]\n",
      "Ann_id in getitem:  63111\n",
      "Test inds:  [(2674, 2637)]\n",
      "Ann_id in getitem:  61341\n",
      "Test inds:  [(1336, 2909)]\n",
      "Ann_id in getitem:  31415\n",
      "Test inds:  [(3440, 2118)]\n",
      "Ann_id in getitem:  79259\n",
      "Test inds:  [(2399, 1574)]\n",
      "Ann_id in getitem:  54291\n",
      "Test inds:  [(3464, 1120)]\n",
      "Ann_id in getitem:  79958\n",
      "Test inds:  [(313, 1064)]\n",
      "Ann_id in getitem:  7637\n",
      "Test inds:  [(1845, 1621)]\n",
      "Ann_id in getitem:  42475\n",
      "Test inds:  [(999, 2038)]\n",
      "Ann_id in getitem:  23697\n",
      "Test inds:  [(2822, 2089)]\n",
      "Ann_id in getitem:  65049\n",
      "Test inds:  [(626, 3363)]\n",
      "Ann_id in getitem:  15274\n",
      "Test inds:  [(898, 2627)]\n",
      "Ann_id in getitem:  21512\n",
      "Test inds:  [(3628, 1315)]\n",
      "Ann_id in getitem:  83699\n",
      "Test inds:  [(2602, 2482)]\n",
      "Ann_id in getitem:  59628\n",
      "Test inds:  [(1205, 1274)]\n",
      "Ann_id in getitem:  28095\n",
      "Test inds:  [(3637, 1339)]\n",
      "Ann_id in getitem:  83957\n",
      "Test inds:  [(3331, 3114)]\n",
      "Ann_id in getitem:  76562\n",
      "Test inds:  [(3422, 2923)]\n",
      "Ann_id in getitem:  78853\n",
      "Test inds:  [(2594, 2290)]\n",
      "Ann_id in getitem:  59476\n",
      "Test inds:  [(2207, 2210)]\n",
      "Ann_id in getitem:  49688\n",
      "Test inds:  [(3107, 2927)]\n",
      "Ann_id in getitem:  71706\n",
      "Test inds:  [(2297, 3178)]\n",
      "Ann_id in getitem:  51834\n",
      "Test inds:  [(940, 1775)]\n",
      "Ann_id in getitem:  22343\n",
      "Test inds:  [(3557, 940)]\n",
      "Ann_id in getitem:  82025\n",
      "Test inds:  [(3112, 1112)]\n",
      "Ann_id in getitem:  71790\n",
      "Test inds:  [(749, 1746)]\n",
      "Ann_id in getitem:  18138\n",
      "Test inds:  [(1832, 175)]\n",
      "Ann_id in getitem:  42118\n",
      "Test inds:  [(701, 3121)]\n",
      "Ann_id in getitem:  17058\n",
      "Test inds:  [(1676, 189)]\n",
      "Ann_id in getitem:  39279\n",
      "Test inds:  [(2025, 3430)]\n",
      "Ann_id in getitem:  45991\n",
      "Test inds:  [(3650, 685)]\n",
      "Ann_id in getitem:  84238\n",
      "Test inds:  [(2784, 2549)]\n",
      "Ann_id in getitem:  64236\n",
      "Test inds:  [(2824, 1690)]\n",
      "Ann_id in getitem:  65096\n",
      "Test inds:  [(225, 3369)]\n",
      "Ann_id in getitem:  5509\n",
      "Test inds:  [(2972, 1087)]\n",
      "Ann_id in getitem:  68369\n",
      "Test inds:  [(3377, 384)]\n",
      "Ann_id in getitem:  77676\n",
      "Test inds:  [(1372, 2456)]\n",
      "Ann_id in getitem:  32365\n",
      "Test inds:  [(1121, 3398)]\n",
      "Ann_id in getitem:  26049\n",
      "Test inds:  [(725, 1831)]\n",
      "Ann_id in getitem:  17548\n",
      "Test inds:  [(1649, 1021)]\n",
      "Ann_id in getitem:  38628\n",
      "Test inds:  [(531, 1478)]\n",
      "Ann_id in getitem:  12627\n",
      "Test inds:  [(705, 1501)]\n",
      "Ann_id in getitem:  17127\n",
      "Test inds:  [(2605, 2718)]\n",
      "Ann_id in getitem:  59675\n",
      "Test inds:  [(588, 393)]\n",
      "Ann_id in getitem:  14305\n",
      "Test inds:  [(1595, 1352)]\n",
      "Ann_id in getitem:  37651\n",
      "Test inds:  [(276, 1925)]\n",
      "Ann_id in getitem:  6566\n",
      "Test inds:  [(3432, 314)]\n",
      "Ann_id in getitem:  79088\n",
      "Test inds:  [(1944, 1413)]\n",
      "Ann_id in getitem:  44247\n",
      "Test inds:  [(3354, 662)]\n",
      "Ann_id in getitem:  76925\n",
      "Test inds:  [(3482, 3213)]\n",
      "Ann_id in getitem:  80262\n",
      "Test inds:  [(2106, 2227)]\n",
      "Ann_id in getitem:  47683\n",
      "Test inds:  [(2601, 2775)]\n",
      "Ann_id in getitem:  59583\n",
      "Test inds:  [(3282, 1163)]\n",
      "Ann_id in getitem:  75150\n",
      "Test inds:  [(114, 1106)]\n",
      "Ann_id in getitem:  2666\n",
      "Test inds:  [(2402, 2175)]\n",
      "Ann_id in getitem:  54342\n",
      "Test inds:  [(2121, 1150)]\n",
      "Ann_id in getitem:  48055\n",
      "Test inds:  [(172, 2493)]\n",
      "Ann_id in getitem:  4355\n",
      "Test inds:  [(1894, 3030)]\n",
      "Ann_id in getitem:  43476\n",
      "Test inds:  [(717, 2680)]\n",
      "Ann_id in getitem:  17358\n",
      "Test inds:  [(2597, 1980)]\n",
      "Ann_id in getitem:  59499\n",
      "Test inds:  [(870, 798)]\n",
      "Ann_id in getitem:  20955\n",
      "Test inds:  [(1157, 816)]\n",
      "Ann_id in getitem:  26920\n",
      "Test inds:  [(244, 3669)]\n",
      "Ann_id in getitem:  5922\n",
      "Test inds:  [(155, 2025)]\n",
      "Ann_id in getitem:  3840\n",
      "Test inds:  [(1228, 2792)]\n",
      "Ann_id in getitem:  28712\n",
      "Test inds:  [(1307, 2447)]\n",
      "Ann_id in getitem:  30530\n",
      "Test inds:  [(3436, 1057)]\n",
      "Ann_id in getitem:  79222\n",
      "Test inds:  [(2872, 320)]\n",
      "Ann_id in getitem:  66028\n",
      "Test inds:  [(3117, 3345)]\n",
      "Ann_id in getitem:  71924\n",
      "Test inds:  [(2034, 2690)]\n",
      "Ann_id in getitem:  46308\n",
      "Test inds:  [(291, 2672)]\n",
      "Ann_id in getitem:  6785\n",
      "Test inds:  [(927, 2226)]\n",
      "Ann_id in getitem:  22157\n",
      "Test inds:  [(2617, 3590)]\n",
      "Ann_id in getitem:  59921\n",
      "Test inds:  [(3535, 132)]\n",
      "Ann_id in getitem:  81561\n",
      "Test inds:  [(773, 1452)]\n",
      "Ann_id in getitem:  18756\n",
      "Test inds:  [(532, 1225)]\n",
      "Ann_id in getitem:  12639\n",
      "Test inds:  [(3572, 1079)]\n",
      "Ann_id in getitem:  82352\n",
      "Test inds:  [(1793, 848)]\n",
      "Ann_id in getitem:  41441\n",
      "Test inds:  [(425, 3597)]\n",
      "Ann_id in getitem:  10359\n",
      "Test inds:  [(3485, 3036)]\n",
      "Ann_id in getitem:  80284\n",
      "Test inds:  [(375, 2445)]\n",
      "Ann_id in getitem:  9174\n",
      "Test inds:  [(788, 1015)]\n",
      "Ann_id in getitem:  19055\n",
      "Test inds:  [(2029, 2886)]\n",
      "Ann_id in getitem:  46188\n",
      "Test inds:  [(2554, 1039)]\n",
      "Ann_id in getitem:  58015\n",
      "Test inds:  [(324, 2)]\n",
      "Ann_id in getitem:  7990\n",
      "Test inds:  [(3571, 1450)]\n",
      "Ann_id in getitem:  82346\n",
      "Test inds:  [(1666, 3641)]\n",
      "Ann_id in getitem:  38967\n",
      "Test inds:  [(1083, 2484)]\n",
      "Ann_id in getitem:  25262\n",
      "Test inds:  [(3476, 2392)]\n",
      "Ann_id in getitem:  80194\n",
      "Test inds:  [(3445, 347)]\n",
      "Ann_id in getitem:  79380\n",
      "Test inds:  [(2158, 544)]\n",
      "Ann_id in getitem:  48679\n",
      "Test inds:  [(2458, 3310)]\n",
      "Ann_id in getitem:  55898\n",
      "Test inds:  [(865, 603)]\n",
      "Ann_id in getitem:  20910\n",
      "Test inds:  [(3090, 1930)]\n",
      "Ann_id in getitem:  71238\n",
      "Test inds:  [(3358, 1151)]\n",
      "Ann_id in getitem:  77016\n",
      "Test inds:  [(1360, 1083)]\n",
      "Ann_id in getitem:  32054\n",
      "Test inds:  [(2144, 2619)]\n",
      "Ann_id in getitem:  48510\n",
      "Test inds:  [(422, 1617)]\n",
      "Ann_id in getitem:  10243\n",
      "Test inds:  [(2281, 407)]\n",
      "Ann_id in getitem:  51602\n",
      "Test inds:  [(465, 2594)]\n",
      "Ann_id in getitem:  11221\n",
      "Test inds:  [(1366, 2776)]\n",
      "Ann_id in getitem:  32215\n",
      "Test inds:  [(972, 2257)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(607, 362)]\n",
      "Ann_id in getitem:  14791\n",
      "Test inds:  [(1851, 668)]\n",
      "Ann_id in getitem:  42630\n",
      "Test inds:  [(427, 417)]\n",
      "Ann_id in getitem:  10533\n",
      "Test inds:  [(688, 986)]\n",
      "Ann_id in getitem:  16752\n",
      "Test inds:  [(935, 2137)]\n",
      "Ann_id in getitem:  22304\n",
      "Test inds:  [(698, 1347)]\n",
      "Ann_id in getitem:  16993\n",
      "Test inds:  [(89, 2815)]\n",
      "Ann_id in getitem:  2049\n",
      "Test inds:  [(2797, 2340)]\n",
      "Ann_id in getitem:  64518\n",
      "Test inds:  [(2531, 2016)]\n",
      "Ann_id in getitem:  57476\n",
      "Test inds:  [(2606, 2434)]\n",
      "Ann_id in getitem:  59688\n",
      "Test inds:  [(1440, 287)]\n",
      "Ann_id in getitem:  34155\n",
      "Test inds:  [(505, 1992)]\n",
      "Ann_id in getitem:  12029\n",
      "Test inds:  [(391, 2284)]\n",
      "Ann_id in getitem:  9687\n",
      "Test inds:  [(2271, 1083)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(2573, 3199)]\n",
      "Ann_id in getitem:  58650\n",
      "Test inds:  [(1332, 3356)]\n",
      "Ann_id in getitem:  31315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(914, 3286)]\n",
      "Ann_id in getitem:  21788\n",
      "Test inds:  [(2582, 3457)]\n",
      "Ann_id in getitem:  58999\n",
      "Test inds:  [(2776, 3064)]\n",
      "Ann_id in getitem:  63953\n",
      "Test inds:  [(32, 1365)]\n",
      "Ann_id in getitem:  701\n",
      "Test inds:  [(3591, 860)]\n",
      "Ann_id in getitem:  82805\n",
      "Test inds:  [(3292, 2720)]\n",
      "Ann_id in getitem:  75467\n",
      "Test inds:  [(985, 850)]\n",
      "Ann_id in getitem:  23419\n",
      "Test inds:  [(414, 3137)]\n",
      "Ann_id in getitem:  10100\n",
      "Test inds:  [(3330, 1343)]\n",
      "Ann_id in getitem:  76518\n",
      "Test inds:  [(2275, 1777)]\n",
      "Ann_id in getitem:  51424\n",
      "Test inds:  [(2660, 2613)]\n",
      "Ann_id in getitem:  61028\n",
      "Test inds:  [(214, 3514)]\n",
      "Ann_id in getitem:  5369\n",
      "Test inds:  [(2822, 469)]\n",
      "Ann_id in getitem:  65049\n",
      "Test inds:  [(2799, 1333)]\n",
      "Ann_id in getitem:  64555\n",
      "Test inds:  [(953, 72)]\n",
      "Ann_id in getitem:  22578\n",
      "Test inds:  [(594, 2172)]\n",
      "Ann_id in getitem:  14398\n",
      "Test inds:  [(2179, 2091)]\n",
      "Ann_id in getitem:  49124\n",
      "Test inds:  [(1957, 2022)]\n",
      "Ann_id in getitem:  44503\n",
      "Test inds:  [(1997, 3568)]\n",
      "Ann_id in getitem:  45522\n",
      "Test inds:  [(1804, 2091)]\n",
      "Ann_id in getitem:  41620\n",
      "Test inds:  [(2004, 2911)]\n",
      "Ann_id in getitem:  45648\n",
      "Test inds:  [(98, 1646)]\n",
      "Ann_id in getitem:  2158\n",
      "Test inds:  [(1507, 2298)]\n",
      "Ann_id in getitem:  35763\n",
      "Test inds:  [(3327, 2926)]\n",
      "Ann_id in getitem:  76414\n",
      "Test inds:  [(2338, 2849)]\n",
      "Ann_id in getitem:  52711\n",
      "Test inds:  [(1543, 2553)]\n",
      "Ann_id in getitem:  36520\n",
      "Test inds:  [(1777, 1669)]\n",
      "Ann_id in getitem:  41029\n",
      "Test inds:  [(2430, 3252)]\n",
      "Ann_id in getitem:  54979\n",
      "Test inds:  [(3178, 768)]\n",
      "Ann_id in getitem:  73240\n",
      "Test inds:  [(2304, 2063)]\n",
      "Ann_id in getitem:  51975\n",
      "Test inds:  [(3601, 1107)]\n",
      "Ann_id in getitem:  83060\n",
      "Test inds:  [(1751, 3506)]\n",
      "Ann_id in getitem:  40566\n",
      "Test inds:  [(3091, 3508)]\n",
      "Ann_id in getitem:  71255\n",
      "Test inds:  [(1513, 407)]\n",
      "Ann_id in getitem:  35905\n",
      "Test inds:  [(40, 2704)]\n",
      "Ann_id in getitem:  882\n",
      "Test inds:  [(3138, 540)]\n",
      "Ann_id in getitem:  72386\n",
      "Test inds:  [(3054, 2779)]\n",
      "Ann_id in getitem:  70504\n",
      "Test inds:  [(348, 3059)]\n",
      "Ann_id in getitem:  8433\n",
      "Test inds:  [(3675, 160)]\n",
      "Ann_id in getitem:  84758\n",
      "Test inds:  [(2696, 1417)]\n",
      "Ann_id in getitem:  61994\n",
      "Test inds:  [(140, 2863)]\n",
      "Ann_id in getitem:  3417\n",
      "Test inds:  [(1722, 2990)]\n",
      "Ann_id in getitem:  40179\n",
      "Test inds:  [(1826, 960)]\n",
      "Ann_id in getitem:  42020\n",
      "Test inds:  [(2826, 3495)]\n",
      "Ann_id in getitem:  65109\n",
      "Test inds:  [(727, 2780)]\n",
      "Ann_id in getitem:  17571\n",
      "Test inds:  [(2667, 767)]\n",
      "Ann_id in getitem:  61205\n",
      "Test inds:  [(2450, 2592)]\n",
      "Ann_id in getitem:  55676\n",
      "Test inds:  [(568, 3348)]\n",
      "Ann_id in getitem:  13737\n",
      "Test inds:  [(2624, 50)]\n",
      "Ann_id in getitem:  59987\n",
      "Test inds:  [(2462, 450)]\n",
      "Ann_id in getitem:  55979\n",
      "Test inds:  [(520, 2360)]\n",
      "Ann_id in getitem:  12426\n",
      "Test inds:  [(3352, 2523)]\n",
      "Ann_id in getitem:  76904\n",
      "Test inds:  [(1447, 112)]\n",
      "Ann_id in getitem:  34266\n",
      "Test inds:  [(1833, 3169)]\n",
      "Ann_id in getitem:  42135\n",
      "Test inds:  [(2215, 1889)]\n",
      "Ann_id in getitem:  49836\n",
      "Test inds:  [(50, 780)]\n",
      "Ann_id in getitem:  1034\n",
      "Test inds:  [(1549, 1366)]\n",
      "Ann_id in getitem:  36600\n",
      "Test inds:  [(1173, 1959)]\n",
      "Ann_id in getitem:  27289\n",
      "Test inds:  [(1991, 1458)]\n",
      "Ann_id in getitem:  45378\n",
      "Test inds:  [(3118, 230)]\n",
      "Ann_id in getitem:  71929\n",
      "Test inds:  [(1913, 1602)]\n",
      "Ann_id in getitem:  43827\n",
      "Test inds:  [(679, 2932)]\n",
      "Ann_id in getitem:  16437\n",
      "Test inds:  [(2233, 2743)]\n",
      "Ann_id in getitem:  50232\n",
      "Test inds:  [(2256, 1346)]\n",
      "Ann_id in getitem:  50949\n",
      "Test inds:  [(1756, 2440)]\n",
      "Ann_id in getitem:  40646\n",
      "Test inds:  [(1647, 1868)]\n",
      "Ann_id in getitem:  38577\n",
      "Test inds:  [(1655, 137)]\n",
      "Ann_id in getitem:  38742\n",
      "Test inds:  [(508, 949)]\n",
      "Ann_id in getitem:  12169\n",
      "Test inds:  [(364, 7)]\n",
      "Ann_id in getitem:  8833\n",
      "Test inds:  [(137, 3669)]\n",
      "Ann_id in getitem:  3362\n",
      "Test inds:  [(99, 2066)]\n",
      "Ann_id in getitem:  2167\n",
      "Test inds:  [(930, 1494)]\n",
      "Ann_id in getitem:  22185\n",
      "Test inds:  [(1680, 2287)]\n",
      "Ann_id in getitem:  39407\n",
      "Test inds:  [(1039, 2689)]\n",
      "Ann_id in getitem:  24546\n",
      "Test inds:  [(3305, 1916)]\n",
      "Ann_id in getitem:  75853\n",
      "Test inds:  [(1478, 366)]\n",
      "Ann_id in getitem:  35037\n",
      "Test inds:  [(1550, 2250)]\n",
      "Ann_id in getitem:  36685\n",
      "Test inds:  [(663, 2646)]\n",
      "Ann_id in getitem:  16179\n",
      "Test inds:  [(1610, 450)]\n",
      "Ann_id in getitem:  37817\n",
      "Test inds:  [(3302, 1393)]\n",
      "Ann_id in getitem:  75751\n",
      "Test inds:  [(3244, 2955)]\n",
      "Ann_id in getitem:  74557\n",
      "Test inds:  [(2974, 2797)]\n",
      "Ann_id in getitem:  68523\n",
      "Test inds:  [(1223, 3075)]\n",
      "Ann_id in getitem:  28576\n",
      "Test inds:  [(460, 2929)]\n",
      "Ann_id in getitem:  11127\n",
      "Test inds:  [(760, 2467)]\n",
      "Ann_id in getitem:  18463\n",
      "Test inds:  [(630, 1029)]\n",
      "Ann_id in getitem:  15378\n",
      "Test inds:  [(1752, 632)]\n",
      "Ann_id in getitem:  40571\n",
      "Test inds:  [(2240, 2713)]\n",
      "Ann_id in getitem:  50606\n",
      "Test inds:  [(978, 1903)]\n",
      "Ann_id in getitem:  23081\n",
      "Test inds:  [(129, 2594)]\n",
      "Ann_id in getitem:  3106\n",
      "Test inds:  [(73, 3073)]\n",
      "Ann_id in getitem:  1637\n",
      "Test inds:  [(92, 1355)]\n",
      "Ann_id in getitem:  2099\n",
      "Test inds:  [(1073, 605)]\n",
      "Ann_id in getitem:  25160\n",
      "Test inds:  [(535, 3317)]\n",
      "Ann_id in getitem:  12731\n",
      "Test inds:  [(2562, 669)]\n",
      "Ann_id in getitem:  58233\n",
      "Test inds:  [(309, 1276)]\n",
      "Ann_id in getitem:  7481\n",
      "Test inds:  [(2787, 3097)]\n",
      "Ann_id in getitem:  64330\n",
      "Test inds:  [(100, 2680)]\n",
      "Ann_id in getitem:  2192\n",
      "Test inds:  [(213, 3579)]\n",
      "Ann_id in getitem:  5338\n",
      "Test inds:  [(1320, 2554)]\n",
      "Ann_id in getitem:  30875\n",
      "Test inds:  [(3362, 2077)]\n",
      "Ann_id in getitem:  77176\n",
      "Test inds:  [(1197, 48)]\n",
      "Ann_id in getitem:  27858\n",
      "Test inds:  [(629, 1831)]\n",
      "Ann_id in getitem:  15332\n",
      "Test inds:  [(885, 531)]\n",
      "Ann_id in getitem:  21147\n",
      "Test inds:  [(1936, 2168)]\n",
      "Ann_id in getitem:  44151\n",
      "Test inds:  [(1595, 1969)]\n",
      "Ann_id in getitem:  37651\n",
      "Test inds:  [(1300, 2665)]\n",
      "Ann_id in getitem:  30486\n",
      "Test inds:  [(3516, 3557)]\n",
      "Ann_id in getitem:  81120\n",
      "Test inds:  [(3687, 2435)]\n",
      "Ann_id in getitem:  85147\n",
      "Test inds:  [(1497, 1886)]\n",
      "Ann_id in getitem:  35575\n",
      "Test inds:  [(3646, 753)]\n",
      "Ann_id in getitem:  84149\n",
      "Test inds:  [(3158, 764)]\n",
      "Ann_id in getitem:  72775\n",
      "Test inds:  [(3647, 505)]\n",
      "Ann_id in getitem:  84161\n",
      "Test inds:  [(640, 2934)]\n",
      "Ann_id in getitem:  15491\n",
      "Test inds:  [(2496, 2508)]\n",
      "Ann_id in getitem:  56792\n",
      "Test inds:  [(2364, 2214)]\n",
      "Ann_id in getitem:  53431\n",
      "Test inds:  [(1633, 1534)]\n",
      "Ann_id in getitem:  38308\n",
      "Test inds:  [(137, 3503)]\n",
      "Ann_id in getitem:  3362\n",
      "Test inds:  [(3109, 2123)]\n",
      "Ann_id in getitem:  71745\n",
      "Test inds:  [(3514, 1889)]\n",
      "Ann_id in getitem:  81076\n",
      "Test inds:  [(3297, 3449)]\n",
      "Ann_id in getitem:  75592\n",
      "Test inds:  [(3662, 1030)]\n",
      "Ann_id in getitem:  84554\n",
      "Test inds:  [(1540, 3576)]\n",
      "Ann_id in getitem:  36496\n",
      "Test inds:  [(1133, 1246)]\n",
      "Ann_id in getitem:  26455\n",
      "Test inds:  [(2719, 512)]\n",
      "Ann_id in getitem:  62513\n",
      "Test inds:  [(914, 1501)]\n",
      "Ann_id in getitem:  21788\n",
      "Test inds:  [(1656, 255)]\n",
      "Ann_id in getitem:  38775\n",
      "Test inds:  [(1494, 1181)]\n",
      "Ann_id in getitem:  35494\n",
      "Test inds:  [(1103, 2915)]\n",
      "Ann_id in getitem:  25651\n",
      "Test inds:  [(1589, 1844)]\n",
      "Ann_id in getitem:  37453\n",
      "Test inds:  [(1814, 1102)]\n",
      "Ann_id in getitem:  41772\n",
      "Test inds:  [(1652, 218)]\n",
      "Ann_id in getitem:  38696\n",
      "Test inds:  [(2749, 1250)]\n",
      "Ann_id in getitem:  63297\n",
      "Test inds:  [(808, 1618)]\n",
      "Ann_id in getitem:  19468\n",
      "Test inds:  [(2249, 3485)]\n",
      "Ann_id in getitem:  50819\n",
      "Test inds:  [(320, 3451)]\n",
      "Ann_id in getitem:  7799\n",
      "Test inds:  [(2155, 1435)]\n",
      "Ann_id in getitem:  48653\n",
      "Test inds:  [(2647, 1337)]\n",
      "Ann_id in getitem:  60662\n",
      "Test inds:  [(3534, 2659)]\n",
      "Ann_id in getitem:  81549\n",
      "Test inds:  [(3058, 3390)]\n",
      "Ann_id in getitem:  70591\n",
      "Test inds:  [(1030, 940)]\n",
      "Ann_id in getitem:  24314\n",
      "Test inds:  [(2873, 1123)]\n",
      "Ann_id in getitem:  66049\n",
      "Test inds:  [(2861, 2152)]\n",
      "Ann_id in getitem:  65734\n",
      "Test inds:  [(766, 2109)]\n",
      "Ann_id in getitem:  18542\n",
      "Test inds:  [(1101, 2877)]\n",
      "Ann_id in getitem:  25609\n",
      "Test inds:  [(3257, 774)]\n",
      "Ann_id in getitem:  74789\n",
      "Test inds:  [(2254, 172)]\n",
      "Ann_id in getitem:  50941\n",
      "Test inds:  [(2332, 3607)]\n",
      "Ann_id in getitem:  52604\n",
      "Test inds:  [(2967, 67)]\n",
      "Ann_id in getitem:  68295\n",
      "Test inds:  [(251, 955)]\n",
      "Ann_id in getitem:  6079\n",
      "Test inds:  [(1222, 270)]\n",
      "Ann_id in getitem:  28538\n",
      "Test inds:  [(605, 534)]\n",
      "Ann_id in getitem:  14706\n",
      "Test inds:  [(672, 1545)]\n",
      "Ann_id in getitem:  16341\n",
      "Test inds:  [(1480, 3566)]\n",
      "Ann_id in getitem:  35073\n",
      "Test inds:  [(2653, 2535)]\n",
      "Ann_id in getitem:  60801\n",
      "Test inds:  [(722, 1120)]\n",
      "Ann_id in getitem:  17477\n",
      "Test inds:  [(3469, 1181)]\n",
      "Ann_id in getitem:  80073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1914, 3157)]\n",
      "Ann_id in getitem:  43829\n",
      "Test inds:  [(397, 1721)]\n",
      "Ann_id in getitem:  9769\n",
      "Test inds:  [(2271, 3649)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(3312, 147)]\n",
      "Ann_id in getitem:  76011\n",
      "Test inds:  [(2633, 599)]\n",
      "Ann_id in getitem:  60290\n",
      "Test inds:  [(773, 2130)]\n",
      "Ann_id in getitem:  18756\n",
      "Test inds:  [(202, 1885)]\n",
      "Ann_id in getitem:  5018\n",
      "Test inds:  [(2612, 1923)]\n",
      "Ann_id in getitem:  59845\n",
      "Test inds:  [(518, 2488)]\n",
      "Ann_id in getitem:  12357\n",
      "Test inds:  [(2093, 2067)]\n",
      "Ann_id in getitem:  47425\n",
      "Test inds:  [(1153, 2160)]\n",
      "Ann_id in getitem:  26813\n",
      "Test inds:  [(1399, 843)]\n",
      "Ann_id in getitem:  33180\n",
      "Test inds:  [(923, 1976)]\n",
      "Ann_id in getitem:  22116\n",
      "Test inds:  [(2888, 1885)]\n",
      "Ann_id in getitem:  66440\n",
      "Test inds:  [(2435, 2681)]\n",
      "Ann_id in getitem:  55095\n",
      "Test inds:  [(2678, 3696)]\n",
      "Ann_id in getitem:  61409\n",
      "Test inds:  [(1106, 1006)]\n",
      "Ann_id in getitem:  25701\n",
      "Test inds:  [(3589, 1354)]\n",
      "Ann_id in getitem:  82774\n",
      "Test inds:  [(1616, 3674)]\n",
      "Ann_id in getitem:  37888\n",
      "Test inds:  [(2907, 997)]\n",
      "Ann_id in getitem:  67051\n",
      "Test inds:  [(1347, 333)]\n",
      "Ann_id in getitem:  31739\n",
      "Test inds:  [(2000, 3415)]\n",
      "Ann_id in getitem:  45563\n",
      "Test inds:  [(880, 1160)]\n",
      "Ann_id in getitem:  21096\n",
      "Test inds:  [(1093, 441)]\n",
      "Ann_id in getitem:  25491\n",
      "Test inds:  [(572, 2104)]\n",
      "Ann_id in getitem:  13805\n",
      "Test inds:  [(3618, 2570)]\n",
      "Ann_id in getitem:  83536\n",
      "Test inds:  [(1964, 993)]\n",
      "Ann_id in getitem:  44738\n",
      "Test inds:  [(3640, 1528)]\n",
      "Ann_id in getitem:  83982\n",
      "Test inds:  [(754, 1963)]\n",
      "Ann_id in getitem:  18267\n",
      "Test inds:  [(92, 348)]\n",
      "Ann_id in getitem:  2099\n",
      "Test inds:  [(256, 3688)]\n",
      "Ann_id in getitem:  6151\n",
      "Test inds:  [(30, 2083)]\n",
      "Ann_id in getitem:  644\n",
      "Test inds:  [(2227, 2053)]\n",
      "Ann_id in getitem:  50158\n",
      "Test inds:  [(2745, 2474)]\n",
      "Ann_id in getitem:  63173\n",
      "Test inds:  [(3173, 395)]\n",
      "Ann_id in getitem:  73071\n",
      "Test inds:  [(2457, 3546)]\n",
      "Ann_id in getitem:  55877\n",
      "Test inds:  [(2875, 508)]\n",
      "Ann_id in getitem:  66059\n",
      "Test inds:  [(2219, 2460)]\n",
      "Ann_id in getitem:  49971\n",
      "Test inds:  [(1784, 1363)]\n",
      "Ann_id in getitem:  41111\n",
      "Test inds:  [(325, 2902)]\n",
      "Ann_id in getitem:  7993\n",
      "Test inds:  [(141, 2651)]\n",
      "Ann_id in getitem:  3446\n",
      "Test inds:  [(3622, 1363)]\n",
      "Ann_id in getitem:  83583\n",
      "Test inds:  [(2330, 414)]\n",
      "Ann_id in getitem:  52542\n",
      "Test inds:  [(2082, 2470)]\n",
      "Ann_id in getitem:  47256\n",
      "Test inds:  [(751, 455)]\n",
      "Ann_id in getitem:  18232\n",
      "Test inds:  [(3064, 609)]\n",
      "Ann_id in getitem:  70629\n",
      "Test inds:  [(3235, 1968)]\n",
      "Ann_id in getitem:  74370\n",
      "Test inds:  [(47, 138)]\n",
      "Ann_id in getitem:  961\n",
      "Test inds:  [(1836, 3526)]\n",
      "Ann_id in getitem:  42166\n",
      "Test inds:  [(2758, 677)]\n",
      "Ann_id in getitem:  63437\n",
      "Test inds:  [(3374, 603)]\n",
      "Ann_id in getitem:  77630\n",
      "Test inds:  [(1808, 366)]\n",
      "Ann_id in getitem:  41703\n",
      "Test inds:  [(2639, 123)]\n",
      "Ann_id in getitem:  60410\n",
      "Test inds:  [(1795, 728)]\n",
      "Ann_id in getitem:  41460\n",
      "Test inds:  [(435, 2971)]\n",
      "Ann_id in getitem:  10668\n",
      "Test inds:  [(2512, 2444)]\n",
      "Ann_id in getitem:  57154\n",
      "Test inds:  [(1431, 2262)]\n",
      "Ann_id in getitem:  33918\n",
      "Test inds:  [(352, 2718)]\n",
      "Ann_id in getitem:  8503\n",
      "Test inds:  [(3427, 1250)]\n",
      "Ann_id in getitem:  79018\n",
      "Test inds:  [(3468, 1413)]\n",
      "Ann_id in getitem:  80052\n",
      "Test inds:  [(2868, 2685)]\n",
      "Ann_id in getitem:  65951\n",
      "Test inds:  [(2244, 1081)]\n",
      "Ann_id in getitem:  50687\n",
      "Test inds:  [(1960, 249)]\n",
      "Ann_id in getitem:  44552\n",
      "Test inds:  [(407, 1748)]\n",
      "Ann_id in getitem:  9990\n",
      "Test inds:  [(1222, 3239)]\n",
      "Ann_id in getitem:  28538\n",
      "Test inds:  [(2236, 1748)]\n",
      "Ann_id in getitem:  50350\n",
      "Test inds:  [(409, 3487)]\n",
      "Ann_id in getitem:  10030\n",
      "Test inds:  [(1166, 889)]\n",
      "Ann_id in getitem:  27152\n",
      "Test inds:  [(727, 576)]\n",
      "Ann_id in getitem:  17571\n",
      "Test inds:  [(3522, 1017)]\n",
      "Ann_id in getitem:  81276\n",
      "Test inds:  [(1357, 2774)]\n",
      "Ann_id in getitem:  32031\n",
      "Test inds:  [(1680, 861)]\n",
      "Ann_id in getitem:  39407\n",
      "Test inds:  [(46, 2945)]\n",
      "Ann_id in getitem:  957\n",
      "Test inds:  [(2285, 2458)]\n",
      "Ann_id in getitem:  51632\n",
      "Test inds:  [(3409, 2540)]\n",
      "Ann_id in getitem:  78446\n",
      "Test inds:  [(243, 462)]\n",
      "Ann_id in getitem:  5884\n",
      "Test inds:  [(2213, 3257)]\n",
      "Ann_id in getitem:  49805\n",
      "Test inds:  [(471, 2516)]\n",
      "Ann_id in getitem:  11319\n",
      "Test inds:  [(838, 3490)]\n",
      "Ann_id in getitem:  20143\n",
      "Test inds:  [(2837, 1924)]\n",
      "Ann_id in getitem:  65387\n",
      "Test inds:  [(536, 1747)]\n",
      "Ann_id in getitem:  12740\n",
      "Test inds:  [(2228, 1487)]\n",
      "Ann_id in getitem:  50166\n",
      "Test inds:  [(1826, 1048)]\n",
      "Ann_id in getitem:  42020\n",
      "Test inds:  [(705, 75)]\n",
      "Ann_id in getitem:  17127\n",
      "Test inds:  [(1596, 1727)]\n",
      "Ann_id in getitem:  37674\n",
      "Test inds:  [(284, 1558)]\n",
      "Ann_id in getitem:  6666\n",
      "Test inds:  [(350, 2814)]\n",
      "Ann_id in getitem:  8479\n",
      "Test inds:  [(3220, 1638)]\n",
      "Ann_id in getitem:  74051\n",
      "Test inds:  [(1470, 1683)]\n",
      "Ann_id in getitem:  34905\n",
      "Test inds:  [(490, 1361)]\n",
      "Ann_id in getitem:  11777\n",
      "Test inds:  [(3696, 2196)]\n",
      "Ann_id in getitem:  85427\n",
      "Test inds:  [(1517, 3525)]\n",
      "Ann_id in getitem:  35944\n",
      "Test inds:  [(1242, 1330)]\n",
      "Ann_id in getitem:  29101\n",
      "Test inds:  [(3654, 3355)]\n",
      "Ann_id in getitem:  84412\n",
      "Test inds:  [(3000, 1021)]\n",
      "Ann_id in getitem:  69126\n",
      "Test inds:  [(3423, 225)]\n",
      "Ann_id in getitem:  78901\n",
      "Test inds:  [(2644, 2303)]\n",
      "Ann_id in getitem:  60548\n",
      "Test inds:  [(199, 3348)]\n",
      "Ann_id in getitem:  5006\n",
      "Test inds:  [(734, 601)]\n",
      "Ann_id in getitem:  17848\n",
      "Test inds:  [(605, 1838)]\n",
      "Ann_id in getitem:  14706\n",
      "Test inds:  [(3404, 495)]\n",
      "Ann_id in getitem:  78362\n",
      "Test inds:  [(3343, 1025)]\n",
      "Ann_id in getitem:  76833\n",
      "Test inds:  [(158, 2142)]\n",
      "Ann_id in getitem:  4036\n",
      "Test inds:  [(2287, 2613)]\n",
      "Ann_id in getitem:  51686\n",
      "Test inds:  [(1930, 3314)]\n",
      "Ann_id in getitem:  44078\n",
      "Test inds:  [(3077, 2643)]\n",
      "Ann_id in getitem:  70935\n",
      "Test inds:  [(686, 91)]\n",
      "Ann_id in getitem:  16703\n",
      "Test inds:  [(2025, 3010)]\n",
      "Ann_id in getitem:  45991\n",
      "Test inds:  [(746, 3119)]\n",
      "Ann_id in getitem:  18027\n",
      "Test inds:  [(2409, 3668)]\n",
      "Ann_id in getitem:  54511\n",
      "Test inds:  [(605, 1040)]\n",
      "Ann_id in getitem:  14706\n",
      "Test inds:  [(2169, 2485)]\n",
      "Ann_id in getitem:  48920\n",
      "Test inds:  [(1821, 3417)]\n",
      "Ann_id in getitem:  41926\n",
      "Test inds:  [(1780, 480)]\n",
      "Ann_id in getitem:  41085\n",
      "Test inds:  [(2889, 2225)]\n",
      "Ann_id in getitem:  66466\n",
      "Test inds:  [(3117, 309)]\n",
      "Ann_id in getitem:  71924\n",
      "Test inds:  [(3655, 720)]\n",
      "Ann_id in getitem:  84414\n",
      "Test inds:  [(3126, 2600)]\n",
      "Ann_id in getitem:  72096\n",
      "Test inds:  [(2132, 147)]\n",
      "Ann_id in getitem:  48304\n",
      "Test inds:  [(303, 2669)]\n",
      "Ann_id in getitem:  7237\n",
      "Test inds:  [(1186, 598)]\n",
      "Ann_id in getitem:  27671\n",
      "Test inds:  [(3036, 1967)]\n",
      "Ann_id in getitem:  70015\n",
      "Test inds:  [(1413, 1971)]\n",
      "Ann_id in getitem:  33452\n",
      "Test inds:  [(3186, 1487)]\n",
      "Ann_id in getitem:  73364\n",
      "Test inds:  [(1749, 2963)]\n",
      "Ann_id in getitem:  40552\n",
      "Test inds:  [(1978, 36)]\n",
      "Ann_id in getitem:  45078\n",
      "Test inds:  [(3349, 776)]\n",
      "Ann_id in getitem:  76888\n",
      "Test inds:  [(257, 1196)]\n",
      "Ann_id in getitem:  6165\n",
      "Test inds:  [(3084, 3621)]\n",
      "Ann_id in getitem:  71134\n",
      "Test inds:  [(432, 3499)]\n",
      "Ann_id in getitem:  10625\n",
      "Test inds:  [(1294, 78)]\n",
      "Ann_id in getitem:  30367\n",
      "Test inds:  [(3297, 2813)]\n",
      "Ann_id in getitem:  75592\n",
      "Test inds:  [(1113, 3286)]\n",
      "Ann_id in getitem:  25802\n",
      "Test inds:  [(3498, 2135)]\n",
      "Ann_id in getitem:  80556\n",
      "Test inds:  [(352, 2997)]\n",
      "Ann_id in getitem:  8503\n",
      "Test inds:  [(1323, 1170)]\n",
      "Ann_id in getitem:  30918\n",
      "Test inds:  [(379, 2154)]\n",
      "Ann_id in getitem:  9250\n",
      "Test inds:  [(357, 1498)]\n",
      "Ann_id in getitem:  8612\n",
      "Test inds:  [(421, 141)]\n",
      "Ann_id in getitem:  10216\n",
      "Test inds:  [(2750, 1269)]\n",
      "Ann_id in getitem:  63316\n",
      "Test inds:  [(405, 1403)]\n",
      "Ann_id in getitem:  9977\n",
      "Test inds:  [(3371, 1015)]\n",
      "Ann_id in getitem:  77508\n",
      "Test inds:  [(325, 1810)]\n",
      "Ann_id in getitem:  7993\n",
      "Test inds:  [(2091, 1763)]\n",
      "Ann_id in getitem:  47403\n",
      "Test inds:  [(2759, 3623)]\n",
      "Ann_id in getitem:  63453\n",
      "Test inds:  [(1751, 3467)]\n",
      "Ann_id in getitem:  40566\n",
      "Test inds:  [(2537, 706)]\n",
      "Ann_id in getitem:  57575\n",
      "Test inds:  [(3090, 1831)]\n",
      "Ann_id in getitem:  71238\n",
      "Test inds:  [(1534, 3209)]\n",
      "Ann_id in getitem:  36322\n",
      "Test inds:  [(1876, 347)]\n",
      "Ann_id in getitem:  43156\n",
      "Test inds:  [(2775, 2679)]\n",
      "Ann_id in getitem:  63945\n",
      "Test inds:  [(686, 1908)]\n",
      "Ann_id in getitem:  16703\n",
      "Test inds:  [(2698, 336)]\n",
      "Ann_id in getitem:  62010\n",
      "Test inds:  [(1086, 434)]\n",
      "Ann_id in getitem:  25327\n",
      "Test inds:  [(214, 2926)]\n",
      "Ann_id in getitem:  5369\n",
      "Test inds:  [(227, 3365)]\n",
      "Ann_id in getitem:  5535\n",
      "Test inds:  [(805, 3045)]\n",
      "Ann_id in getitem:  19433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3010, 416)]\n",
      "Ann_id in getitem:  69388\n",
      "Test inds:  [(886, 3394)]\n",
      "Ann_id in getitem:  21159\n",
      "Test inds:  [(1421, 2230)]\n",
      "Ann_id in getitem:  33710\n",
      "Test inds:  [(2433, 304)]\n",
      "Ann_id in getitem:  55019\n",
      "Test inds:  [(867, 804)]\n",
      "Ann_id in getitem:  20919\n",
      "Test inds:  [(2013, 1626)]\n",
      "Ann_id in getitem:  45826\n",
      "Test inds:  [(1483, 2083)]\n",
      "Ann_id in getitem:  35229\n",
      "Test inds:  [(360, 1842)]\n",
      "Ann_id in getitem:  8724\n",
      "Test inds:  [(242, 522)]\n",
      "Ann_id in getitem:  5871\n",
      "Test inds:  [(1749, 1325)]\n",
      "Ann_id in getitem:  40552\n",
      "Test inds:  [(1810, 116)]\n",
      "Ann_id in getitem:  41711\n",
      "Test inds:  [(1375, 2759)]\n",
      "Ann_id in getitem:  32506\n",
      "Test inds:  [(3086, 454)]\n",
      "Ann_id in getitem:  71201\n",
      "Test inds:  [(3487, 3309)]\n",
      "Ann_id in getitem:  80344\n",
      "Test inds:  [(963, 2496)]\n",
      "Ann_id in getitem:  22776\n",
      "Test inds:  [(143, 806)]\n",
      "Ann_id in getitem:  3464\n",
      "Test inds:  [(1220, 3462)]\n",
      "Ann_id in getitem:  28505\n",
      "Test inds:  [(3468, 3102)]\n",
      "Ann_id in getitem:  80052\n",
      "Test inds:  [(434, 555)]\n",
      "Ann_id in getitem:  10667\n",
      "Test inds:  [(2992, 2659)]\n",
      "Ann_id in getitem:  68965\n",
      "Test inds:  [(1348, 3110)]\n",
      "Ann_id in getitem:  31781\n",
      "Test inds:  [(2271, 1653)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(1310, 33)]\n",
      "Ann_id in getitem:  30641\n",
      "Test inds:  [(2234, 1215)]\n",
      "Ann_id in getitem:  50316\n",
      "Test inds:  [(1776, 2077)]\n",
      "Ann_id in getitem:  41018\n",
      "Test inds:  [(185, 3649)]\n",
      "Ann_id in getitem:  4731\n",
      "Test inds:  [(218, 2567)]\n",
      "Ann_id in getitem:  5387\n",
      "Test inds:  [(454, 429)]\n",
      "Ann_id in getitem:  10973\n",
      "Test inds:  [(2278, 264)]\n",
      "Ann_id in getitem:  51538\n",
      "Test inds:  [(3557, 252)]\n",
      "Ann_id in getitem:  82025\n",
      "Test inds:  [(1656, 2578)]\n",
      "Ann_id in getitem:  38775\n",
      "Test inds:  [(3216, 1994)]\n",
      "Ann_id in getitem:  73985\n",
      "Test inds:  [(3600, 2617)]\n",
      "Ann_id in getitem:  83059\n",
      "Test inds:  [(2428, 1491)]\n",
      "Ann_id in getitem:  54859\n",
      "Test inds:  [(3234, 3608)]\n",
      "Ann_id in getitem:  74355\n",
      "Test inds:  [(846, 1735)]\n",
      "Ann_id in getitem:  20513\n",
      "Test inds:  [(3076, 538)]\n",
      "Ann_id in getitem:  70908\n",
      "Test inds:  [(689, 21)]\n",
      "Ann_id in getitem:  16759\n",
      "Test inds:  [(3327, 917)]\n",
      "Ann_id in getitem:  76414\n",
      "Test inds:  [(2506, 3168)]\n",
      "Ann_id in getitem:  57054\n",
      "Test inds:  [(731, 3063)]\n",
      "Ann_id in getitem:  17755\n",
      "Test inds:  [(3116, 772)]\n",
      "Ann_id in getitem:  71909\n",
      "Test inds:  [(2521, 1401)]\n",
      "Ann_id in getitem:  57302\n",
      "Test inds:  [(1443, 1655)]\n",
      "Ann_id in getitem:  34196\n",
      "Test inds:  [(2633, 1023)]\n",
      "Ann_id in getitem:  60290\n",
      "Test inds:  [(2671, 606)]\n",
      "Ann_id in getitem:  61303\n",
      "Test inds:  [(178, 3331)]\n",
      "Ann_id in getitem:  4571\n",
      "Test inds:  [(826, 3461)]\n",
      "Ann_id in getitem:  19812\n",
      "Test inds:  [(3496, 2104)]\n",
      "Ann_id in getitem:  80522\n",
      "Test inds:  [(3015, 2791)]\n",
      "Ann_id in getitem:  69504\n",
      "Test inds:  [(710, 184)]\n",
      "Ann_id in getitem:  17246\n",
      "Test inds:  [(3249, 116)]\n",
      "Ann_id in getitem:  74646\n",
      "Test inds:  [(494, 3117)]\n",
      "Ann_id in getitem:  11860\n",
      "Test inds:  [(2969, 1476)]\n",
      "Ann_id in getitem:  68311\n",
      "Test inds:  [(2657, 3144)]\n",
      "Ann_id in getitem:  60988\n",
      "Test inds:  [(1565, 1325)]\n",
      "Ann_id in getitem:  36992\n",
      "Test inds:  [(1642, 2266)]\n",
      "Ann_id in getitem:  38504\n",
      "Test inds:  [(2971, 3248)]\n",
      "Ann_id in getitem:  68358\n",
      "Test inds:  [(1165, 3383)]\n",
      "Ann_id in getitem:  27148\n",
      "Test inds:  [(3041, 2014)]\n",
      "Ann_id in getitem:  70092\n",
      "Test inds:  [(958, 1248)]\n",
      "Ann_id in getitem:  22623\n",
      "Test inds:  [(2103, 3636)]\n",
      "Ann_id in getitem:  47624\n",
      "Test inds:  [(292, 658)]\n",
      "Ann_id in getitem:  6802\n",
      "Test inds:  [(1185, 1215)]\n",
      "Ann_id in getitem:  27587\n",
      "Test inds:  [(3439, 3268)]\n",
      "Ann_id in getitem:  79244\n",
      "Test inds:  [(1501, 3388)]\n",
      "Ann_id in getitem:  35694\n",
      "Test inds:  [(1264, 2263)]\n",
      "Ann_id in getitem:  29570\n",
      "Test inds:  [(3237, 3183)]\n",
      "Ann_id in getitem:  74376\n",
      "Test inds:  [(2312, 1767)]\n",
      "Ann_id in getitem:  52100\n",
      "Test inds:  [(1261, 1837)]\n",
      "Ann_id in getitem:  29543\n",
      "Test inds:  [(3489, 1075)]\n",
      "Ann_id in getitem:  80394\n",
      "Test inds:  [(3395, 2472)]\n",
      "Ann_id in getitem:  78052\n",
      "Test inds:  [(2387, 1666)]\n",
      "Ann_id in getitem:  54051\n",
      "Test inds:  [(2798, 2598)]\n",
      "Ann_id in getitem:  64523\n",
      "Test inds:  [(2732, 672)]\n",
      "Ann_id in getitem:  62823\n",
      "Test inds:  [(179, 1141)]\n",
      "Ann_id in getitem:  4594\n",
      "Test inds:  [(1056, 752)]\n",
      "Ann_id in getitem:  24948\n",
      "Test inds:  [(3426, 2164)]\n",
      "Ann_id in getitem:  79010\n",
      "Test inds:  [(2941, 3159)]\n",
      "Ann_id in getitem:  67736\n",
      "Test inds:  [(1529, 2702)]\n",
      "Ann_id in getitem:  36191\n",
      "Test inds:  [(1609, 3358)]\n",
      "Ann_id in getitem:  37795\n",
      "Test inds:  [(1026, 2293)]\n",
      "Ann_id in getitem:  24205\n",
      "Test inds:  [(543, 131)]\n",
      "Ann_id in getitem:  12949\n",
      "Test inds:  [(2637, 2867)]\n",
      "Ann_id in getitem:  60348\n",
      "Test inds:  [(1049, 1902)]\n",
      "Ann_id in getitem:  24779\n",
      "Test inds:  [(1822, 2678)]\n",
      "Ann_id in getitem:  41928\n",
      "Test inds:  [(3623, 1112)]\n",
      "Ann_id in getitem:  83592\n",
      "Test inds:  [(2999, 1448)]\n",
      "Ann_id in getitem:  69118\n",
      "Test inds:  [(2668, 2243)]\n",
      "Ann_id in getitem:  61233\n",
      "Test inds:  [(2546, 2890)]\n",
      "Ann_id in getitem:  57849\n",
      "Test inds:  [(1872, 1820)]\n",
      "Ann_id in getitem:  43071\n",
      "Test inds:  [(610, 83)]\n",
      "Ann_id in getitem:  14943\n",
      "Test inds:  [(2879, 342)]\n",
      "Ann_id in getitem:  66209\n",
      "Test inds:  [(361, 3563)]\n",
      "Ann_id in getitem:  8733\n",
      "Test inds:  [(3018, 2321)]\n",
      "Ann_id in getitem:  69534\n",
      "Test inds:  [(2167, 2394)]\n",
      "Ann_id in getitem:  48894\n",
      "Test inds:  [(2550, 2735)]\n",
      "Ann_id in getitem:  57948\n",
      "Test inds:  [(1708, 1057)]\n",
      "Ann_id in getitem:  39966\n",
      "Test inds:  [(1151, 1627)]\n",
      "Ann_id in getitem:  26781\n",
      "Test inds:  [(1353, 1706)]\n",
      "Ann_id in getitem:  31912\n",
      "Test inds:  [(2997, 2308)]\n",
      "Ann_id in getitem:  69090\n",
      "Test inds:  [(2991, 3112)]\n",
      "Ann_id in getitem:  68948\n",
      "Test inds:  [(2271, 1051)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(3058, 1486)]\n",
      "Ann_id in getitem:  70591\n",
      "Test inds:  [(233, 2857)]\n",
      "Ann_id in getitem:  5653\n",
      "Test inds:  [(2076, 2249)]\n",
      "Ann_id in getitem:  47142\n",
      "Test inds:  [(1446, 2613)]\n",
      "Ann_id in getitem:  34252\n",
      "Test inds:  [(2280, 630)]\n",
      "Ann_id in getitem:  51553\n",
      "Test inds:  [(2625, 240)]\n",
      "Ann_id in getitem:  60008\n",
      "Test inds:  [(1733, 2052)]\n",
      "Ann_id in getitem:  40354\n",
      "Test inds:  [(3497, 436)]\n",
      "Ann_id in getitem:  80554\n",
      "Test inds:  [(464, 386)]\n",
      "Ann_id in getitem:  11208\n",
      "Test inds:  [(2065, 192)]\n",
      "Ann_id in getitem:  46987\n",
      "Test inds:  [(2305, 1522)]\n",
      "Ann_id in getitem:  51996\n",
      "Test inds:  [(1782, 3496)]\n",
      "Ann_id in getitem:  41096\n",
      "Test inds:  [(1332, 1440)]\n",
      "Ann_id in getitem:  31315\n",
      "Test inds:  [(1643, 1196)]\n",
      "Ann_id in getitem:  38509\n",
      "Test inds:  [(3217, 2851)]\n",
      "Ann_id in getitem:  73990\n",
      "Test inds:  [(687, 1848)]\n",
      "Ann_id in getitem:  16726\n",
      "Test inds:  [(150, 3182)]\n",
      "Ann_id in getitem:  3728\n",
      "Test inds:  [(804, 2945)]\n",
      "Ann_id in getitem:  19396\n",
      "Test inds:  [(3460, 2706)]\n",
      "Ann_id in getitem:  79849\n",
      "Test inds:  [(1108, 61)]\n",
      "Ann_id in getitem:  25733\n",
      "Test inds:  [(3507, 1180)]\n",
      "Ann_id in getitem:  80940\n",
      "Test inds:  [(1114, 999)]\n",
      "Ann_id in getitem:  25816\n",
      "Test inds:  [(2267, 1865)]\n",
      "Ann_id in getitem:  51199\n",
      "Test inds:  [(3675, 2064)]\n",
      "Ann_id in getitem:  84758\n",
      "Test inds:  [(3687, 1003)]\n",
      "Ann_id in getitem:  85147\n",
      "Test inds:  [(534, 1550)]\n",
      "Ann_id in getitem:  12713\n",
      "Test inds:  [(1693, 2982)]\n",
      "Ann_id in getitem:  39688\n",
      "Test inds:  [(2413, 3182)]\n",
      "Ann_id in getitem:  54599\n",
      "Test inds:  [(341, 1087)]\n",
      "Ann_id in getitem:  8278\n",
      "Test inds:  [(1839, 46)]\n",
      "Ann_id in getitem:  42229\n",
      "Test inds:  [(334, 3233)]\n",
      "Ann_id in getitem:  8173\n",
      "Test inds:  [(3078, 3444)]\n",
      "Ann_id in getitem:  71032\n",
      "Test inds:  [(2052, 1929)]\n",
      "Ann_id in getitem:  46731\n",
      "Test inds:  [(3490, 1179)]\n",
      "Ann_id in getitem:  80401\n",
      "Test inds:  [(1170, 611)]\n",
      "Ann_id in getitem:  27224\n",
      "Test inds:  [(2999, 1560)]\n",
      "Ann_id in getitem:  69118\n",
      "Test inds:  [(963, 1960)]\n",
      "Ann_id in getitem:  22776\n",
      "Test inds:  [(1115, 368)]\n",
      "Ann_id in getitem:  25844\n",
      "Test inds:  [(600, 3550)]\n",
      "Ann_id in getitem:  14472\n",
      "Test inds:  [(3292, 2124)]\n",
      "Ann_id in getitem:  75467\n",
      "Test inds:  [(2491, 2707)]\n",
      "Ann_id in getitem:  56679\n",
      "Test inds:  [(445, 2793)]\n",
      "Ann_id in getitem:  10845\n",
      "Test inds:  [(2948, 2686)]\n",
      "Ann_id in getitem:  67914\n",
      "Test inds:  [(724, 2264)]\n",
      "Ann_id in getitem:  17539\n",
      "Test inds:  [(1973, 2182)]\n",
      "Ann_id in getitem:  44991\n",
      "Test inds:  [(1231, 357)]\n",
      "Ann_id in getitem:  28779\n",
      "Test inds:  [(207, 657)]\n",
      "Ann_id in getitem:  5174\n",
      "Test inds:  [(758, 59)]\n",
      "Ann_id in getitem:  18333\n",
      "Test inds:  [(722, 1094)]\n",
      "Ann_id in getitem:  17477\n",
      "Test inds:  [(3167, 2118)]\n",
      "Ann_id in getitem:  72946\n",
      "Test inds:  [(2853, 307)]\n",
      "Ann_id in getitem:  65665\n",
      "Test inds:  [(3372, 2976)]\n",
      "Ann_id in getitem:  77585\n",
      "Test inds:  [(736, 2885)]\n",
      "Ann_id in getitem:  17866\n",
      "Test inds:  [(3644, 3514)]\n",
      "Ann_id in getitem:  84119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(974, 1935)]\n",
      "Ann_id in getitem:  22963\n",
      "Test inds:  [(3580, 1938)]\n",
      "Ann_id in getitem:  82483\n",
      "Test inds:  [(478, 1705)]\n",
      "Ann_id in getitem:  11519\n",
      "Test inds:  [(841, 1012)]\n",
      "Ann_id in getitem:  20304\n",
      "Test inds:  [(238, 1658)]\n",
      "Ann_id in getitem:  5795\n",
      "Test inds:  [(2004, 161)]\n",
      "Ann_id in getitem:  45648\n",
      "Test inds:  [(2762, 405)]\n",
      "Ann_id in getitem:  63517\n",
      "Test inds:  [(1239, 3454)]\n",
      "Ann_id in getitem:  28966\n",
      "Test inds:  [(1530, 866)]\n",
      "Ann_id in getitem:  36222\n",
      "Test inds:  [(648, 676)]\n",
      "Ann_id in getitem:  15817\n",
      "Test inds:  [(3273, 2610)]\n",
      "Ann_id in getitem:  74988\n",
      "Test inds:  [(1966, 908)]\n",
      "Ann_id in getitem:  44888\n",
      "Test inds:  [(3542, 1931)]\n",
      "Ann_id in getitem:  81710\n",
      "Test inds:  [(1421, 3142)]\n",
      "Ann_id in getitem:  33710\n",
      "Test inds:  [(3344, 1816)]\n",
      "Ann_id in getitem:  76854\n",
      "Test inds:  [(2576, 2686)]\n",
      "Ann_id in getitem:  58713\n",
      "Test inds:  [(4, 2073)]\n",
      "Ann_id in getitem:  98\n",
      "Test inds:  [(70, 1554)]\n",
      "Ann_id in getitem:  1562\n",
      "Test inds:  [(1568, 2436)]\n",
      "Ann_id in getitem:  37096\n",
      "Test inds:  [(690, 2548)]\n",
      "Ann_id in getitem:  16819\n",
      "Test inds:  [(3276, 2385)]\n",
      "Ann_id in getitem:  75053\n",
      "Test inds:  [(1034, 3297)]\n",
      "Ann_id in getitem:  24392\n",
      "Test inds:  [(290, 101)]\n",
      "Ann_id in getitem:  6752\n",
      "Test inds:  [(1804, 2692)]\n",
      "Ann_id in getitem:  41620\n",
      "Test inds:  [(2258, 757)]\n",
      "Ann_id in getitem:  50978\n",
      "Test inds:  [(2704, 1542)]\n",
      "Ann_id in getitem:  62146\n",
      "Test inds:  [(614, 2142)]\n",
      "Ann_id in getitem:  15059\n",
      "Test inds:  [(2406, 133)]\n",
      "Ann_id in getitem:  54420\n",
      "Test inds:  [(896, 228)]\n",
      "Ann_id in getitem:  21497\n",
      "Test inds:  [(531, 3599)]\n",
      "Ann_id in getitem:  12627\n",
      "Test inds:  [(1954, 1407)]\n",
      "Ann_id in getitem:  44460\n",
      "Test inds:  [(1459, 2728)]\n",
      "Ann_id in getitem:  34552\n",
      "Test inds:  [(2697, 525)]\n",
      "Ann_id in getitem:  62007\n",
      "Test inds:  [(2293, 2338)]\n",
      "Ann_id in getitem:  51751\n",
      "Test inds:  [(3086, 238)]\n",
      "Ann_id in getitem:  71201\n",
      "Test inds:  [(1643, 872)]\n",
      "Ann_id in getitem:  38509\n",
      "Test inds:  [(2740, 2591)]\n",
      "Ann_id in getitem:  63078\n",
      "Test inds:  [(1422, 1146)]\n",
      "Ann_id in getitem:  33737\n",
      "Test inds:  [(3251, 1178)]\n",
      "Ann_id in getitem:  74669\n",
      "Test inds:  [(1278, 1062)]\n",
      "Ann_id in getitem:  29873\n",
      "Test inds:  [(1048, 1565)]\n",
      "Ann_id in getitem:  24744\n",
      "Test inds:  [(149, 883)]\n",
      "Ann_id in getitem:  3710\n",
      "Test inds:  [(1831, 3231)]\n",
      "Ann_id in getitem:  42080\n",
      "Test inds:  [(1892, 1701)]\n",
      "Ann_id in getitem:  43427\n",
      "Test inds:  [(651, 547)]\n",
      "Ann_id in getitem:  15894\n",
      "Test inds:  [(3296, 2379)]\n",
      "Ann_id in getitem:  75584\n",
      "Test inds:  [(1354, 3691)]\n",
      "Ann_id in getitem:  31963\n",
      "Test inds:  [(3441, 289)]\n",
      "Ann_id in getitem:  79336\n",
      "Test inds:  [(2172, 2924)]\n",
      "Ann_id in getitem:  48955\n",
      "Test inds:  [(2402, 2286)]\n",
      "Ann_id in getitem:  54342\n",
      "Test inds:  [(869, 44)]\n",
      "Ann_id in getitem:  20939\n",
      "Test inds:  [(355, 679)]\n",
      "Ann_id in getitem:  8523\n",
      "Test inds:  [(1265, 498)]\n",
      "Ann_id in getitem:  29575\n",
      "Test inds:  [(606, 1166)]\n",
      "Ann_id in getitem:  14749\n",
      "Test inds:  [(3095, 1141)]\n",
      "Ann_id in getitem:  71296\n",
      "Test inds:  [(457, 2123)]\n",
      "Ann_id in getitem:  11053\n",
      "Test inds:  [(1558, 891)]\n",
      "Ann_id in getitem:  36808\n",
      "Test inds:  [(1065, 1798)]\n",
      "Ann_id in getitem:  25040\n",
      "Test inds:  [(2088, 3295)]\n",
      "Ann_id in getitem:  47370\n",
      "Test inds:  [(3460, 3607)]\n",
      "Ann_id in getitem:  79849\n",
      "Test inds:  [(2445, 40)]\n",
      "Ann_id in getitem:  55577\n",
      "Test inds:  [(884, 1041)]\n",
      "Ann_id in getitem:  21144\n",
      "Test inds:  [(272, 2860)]\n",
      "Ann_id in getitem:  6444\n",
      "Test inds:  [(1125, 2714)]\n",
      "Ann_id in getitem:  26216\n",
      "Test inds:  [(2764, 1234)]\n",
      "Ann_id in getitem:  63573\n",
      "Test inds:  [(787, 1105)]\n",
      "Ann_id in getitem:  19043\n",
      "Test inds:  [(1409, 1338)]\n",
      "Ann_id in getitem:  33336\n",
      "Test inds:  [(720, 2843)]\n",
      "Ann_id in getitem:  17402\n",
      "Test inds:  [(3038, 1054)]\n",
      "Ann_id in getitem:  70026\n",
      "Test inds:  [(1356, 2723)]\n",
      "Ann_id in getitem:  31991\n",
      "Test inds:  [(253, 2647)]\n",
      "Ann_id in getitem:  6106\n",
      "Test inds:  [(2800, 934)]\n",
      "Ann_id in getitem:  64625\n",
      "Test inds:  [(2787, 2366)]\n",
      "Ann_id in getitem:  64330\n",
      "Test inds:  [(855, 816)]\n",
      "Ann_id in getitem:  20777\n",
      "Test inds:  [(3250, 1184)]\n",
      "Ann_id in getitem:  74658\n",
      "Test inds:  [(1774, 2452)]\n",
      "Ann_id in getitem:  41007\n",
      "Test inds:  [(2927, 1013)]\n",
      "Ann_id in getitem:  67357\n",
      "Test inds:  [(1208, 2693)]\n",
      "Ann_id in getitem:  28145\n",
      "Test inds:  [(1497, 74)]\n",
      "Ann_id in getitem:  35575\n",
      "Test inds:  [(3688, 891)]\n",
      "Ann_id in getitem:  85200\n",
      "Test inds:  [(2828, 1808)]\n",
      "Ann_id in getitem:  65139\n",
      "Test inds:  [(2291, 3124)]\n",
      "Ann_id in getitem:  51732\n",
      "Test inds:  [(614, 719)]\n",
      "Ann_id in getitem:  15059\n",
      "Test inds:  [(1277, 1200)]\n",
      "Ann_id in getitem:  29852\n",
      "Test inds:  [(2885, 378)]\n",
      "Ann_id in getitem:  66392\n",
      "Test inds:  [(2315, 3551)]\n",
      "Ann_id in getitem:  52174\n",
      "Test inds:  [(1464, 2918)]\n",
      "Ann_id in getitem:  34664\n",
      "Test inds:  [(3402, 1526)]\n",
      "Ann_id in getitem:  78308\n",
      "Test inds:  [(3196, 2531)]\n",
      "Ann_id in getitem:  73530\n",
      "Test inds:  [(2689, 1906)]\n",
      "Ann_id in getitem:  61729\n",
      "Test inds:  [(1526, 944)]\n",
      "Ann_id in getitem:  36114\n",
      "Test inds:  [(1849, 1131)]\n",
      "Ann_id in getitem:  42562\n",
      "Test inds:  [(1256, 1448)]\n",
      "Ann_id in getitem:  29448\n",
      "Test inds:  [(2108, 3553)]\n",
      "Ann_id in getitem:  47790\n",
      "Test inds:  [(3003, 2381)]\n",
      "Ann_id in getitem:  69224\n",
      "Test inds:  [(1366, 1165)]\n",
      "Ann_id in getitem:  32215\n",
      "Test inds:  [(3124, 780)]\n",
      "Ann_id in getitem:  72017\n",
      "Test inds:  [(2325, 2345)]\n",
      "Ann_id in getitem:  52356\n",
      "Test inds:  [(2874, 3446)]\n",
      "Ann_id in getitem:  66053\n",
      "Test inds:  [(3505, 1959)]\n",
      "Ann_id in getitem:  80866\n",
      "Test inds:  [(2771, 2754)]\n",
      "Ann_id in getitem:  63770\n",
      "Test inds:  [(323, 2890)]\n",
      "Ann_id in getitem:  7979\n",
      "Test inds:  [(2044, 789)]\n",
      "Ann_id in getitem:  46557\n",
      "Test inds:  [(1644, 674)]\n",
      "Ann_id in getitem:  38515\n",
      "Test inds:  [(3262, 1312)]\n",
      "Ann_id in getitem:  74853\n",
      "Test inds:  [(1734, 818)]\n",
      "Ann_id in getitem:  40357\n",
      "Test inds:  [(3139, 536)]\n",
      "Ann_id in getitem:  72402\n",
      "Test inds:  [(2282, 3454)]\n",
      "Ann_id in getitem:  51611\n",
      "Test inds:  [(104, 2657)]\n",
      "Ann_id in getitem:  2376\n",
      "Test inds:  [(2001, 3065)]\n",
      "Ann_id in getitem:  45576\n",
      "Test inds:  [(1940, 3073)]\n",
      "Ann_id in getitem:  44209\n",
      "Test inds:  [(313, 3314)]\n",
      "Ann_id in getitem:  7637\n",
      "Test inds:  [(921, 3420)]\n",
      "Ann_id in getitem:  22052\n",
      "Test inds:  [(746, 1732)]\n",
      "Ann_id in getitem:  18027\n",
      "Test inds:  [(924, 2182)]\n",
      "Ann_id in getitem:  22119\n",
      "Test inds:  [(2524, 1379)]\n",
      "Ann_id in getitem:  57326\n",
      "Test inds:  [(3014, 2714)]\n",
      "Ann_id in getitem:  69501\n",
      "Test inds:  [(3492, 474)]\n",
      "Ann_id in getitem:  80478\n",
      "Test inds:  [(3188, 2580)]\n",
      "Ann_id in getitem:  73388\n",
      "Test inds:  [(3547, 3406)]\n",
      "Ann_id in getitem:  81836\n",
      "Test inds:  [(1386, 91)]\n",
      "Ann_id in getitem:  32931\n",
      "Test inds:  [(2524, 2291)]\n",
      "Ann_id in getitem:  57326\n",
      "Test inds:  [(765, 416)]\n",
      "Ann_id in getitem:  18533\n",
      "Test inds:  [(2875, 702)]\n",
      "Ann_id in getitem:  66059\n",
      "Test inds:  [(2615, 2457)]\n",
      "Ann_id in getitem:  59876\n",
      "Test inds:  [(2608, 923)]\n",
      "Ann_id in getitem:  59777\n",
      "Test inds:  [(288, 1741)]\n",
      "Ann_id in getitem:  6725\n",
      "Test inds:  [(1042, 2029)]\n",
      "Ann_id in getitem:  24664\n",
      "Test inds:  [(383, 688)]\n",
      "Ann_id in getitem:  9434\n",
      "Test inds:  [(832, 3557)]\n",
      "Ann_id in getitem:  19992\n",
      "Test inds:  [(696, 3650)]\n",
      "Ann_id in getitem:  16928\n",
      "Test inds:  [(1484, 605)]\n",
      "Ann_id in getitem:  35252\n",
      "Test inds:  [(580, 528)]\n",
      "Ann_id in getitem:  14091\n",
      "Test inds:  [(3126, 2755)]\n",
      "Ann_id in getitem:  72096\n",
      "Test inds:  [(36, 17)]\n",
      "Ann_id in getitem:  827\n",
      "Test inds:  [(1188, 1099)]\n",
      "Ann_id in getitem:  27692\n",
      "Test inds:  [(2969, 1923)]\n",
      "Ann_id in getitem:  68311\n",
      "Test inds:  [(2065, 3362)]\n",
      "Ann_id in getitem:  46987\n",
      "Test inds:  [(107, 1205)]\n",
      "Ann_id in getitem:  2450\n",
      "Test inds:  [(593, 3484)]\n",
      "Ann_id in getitem:  14370\n",
      "Test inds:  [(1259, 3243)]\n",
      "Ann_id in getitem:  29503\n",
      "Test inds:  [(3616, 2252)]\n",
      "Ann_id in getitem:  83499\n",
      "Test inds:  [(1034, 1329)]\n",
      "Ann_id in getitem:  24392\n",
      "Test inds:  [(3030, 1249)]\n",
      "Ann_id in getitem:  69883\n",
      "Test inds:  [(684, 375)]\n",
      "Ann_id in getitem:  16638\n",
      "Test inds:  [(1374, 562)]\n",
      "Ann_id in getitem:  32396\n",
      "Test inds:  [(1217, 3145)]\n",
      "Ann_id in getitem:  28419\n",
      "Test inds:  [(384, 2015)]\n",
      "Ann_id in getitem:  9509\n",
      "Test inds:  [(3429, 2838)]\n",
      "Ann_id in getitem:  79028\n",
      "Test inds:  [(1384, 1525)]\n",
      "Ann_id in getitem:  32866\n",
      "Test inds:  [(1173, 1683)]\n",
      "Ann_id in getitem:  27289\n",
      "Test inds:  [(2479, 3329)]\n",
      "Ann_id in getitem:  56419\n",
      "Test inds:  [(2816, 860)]\n",
      "Ann_id in getitem:  64887\n",
      "Test inds:  [(403, 3304)]\n",
      "Ann_id in getitem:  9914\n",
      "Test inds:  [(2297, 1294)]\n",
      "Ann_id in getitem:  51834\n",
      "Test inds:  [(3353, 1080)]\n",
      "Ann_id in getitem:  76922\n",
      "Test inds:  [(3039, 178)]\n",
      "Ann_id in getitem:  70044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2281, 2405)]\n",
      "Ann_id in getitem:  51602\n",
      "Test inds:  [(3670, 337)]\n",
      "Ann_id in getitem:  84666\n",
      "Test inds:  [(1651, 2467)]\n",
      "Ann_id in getitem:  38642\n",
      "Test inds:  [(3384, 2607)]\n",
      "Ann_id in getitem:  77826\n",
      "Test inds:  [(2106, 3630)]\n",
      "Ann_id in getitem:  47683\n",
      "Test inds:  [(1594, 3456)]\n",
      "Ann_id in getitem:  37627\n",
      "Test inds:  [(2228, 3321)]\n",
      "Ann_id in getitem:  50166\n",
      "Test inds:  [(154, 747)]\n",
      "Ann_id in getitem:  3765\n",
      "Test inds:  [(1549, 1589)]\n",
      "Ann_id in getitem:  36600\n",
      "Test inds:  [(2133, 3128)]\n",
      "Ann_id in getitem:  48316\n",
      "Test inds:  [(1055, 3265)]\n",
      "Ann_id in getitem:  24930\n",
      "Test inds:  [(746, 1212)]\n",
      "Ann_id in getitem:  18027\n",
      "Test inds:  [(1991, 1986)]\n",
      "Ann_id in getitem:  45378\n",
      "Test inds:  [(2867, 3293)]\n",
      "Ann_id in getitem:  65912\n",
      "Test inds:  [(3254, 435)]\n",
      "Ann_id in getitem:  74750\n",
      "Test inds:  [(1297, 3362)]\n",
      "Ann_id in getitem:  30406\n",
      "Test inds:  [(3058, 3170)]\n",
      "Ann_id in getitem:  70591\n",
      "Test inds:  [(619, 3572)]\n",
      "Ann_id in getitem:  15172\n",
      "Test inds:  [(108, 2882)]\n",
      "Ann_id in getitem:  2473\n",
      "Test inds:  [(239, 1526)]\n",
      "Ann_id in getitem:  5812\n",
      "Test inds:  [(2498, 845)]\n",
      "Ann_id in getitem:  56850\n",
      "Test inds:  [(1075, 2442)]\n",
      "Ann_id in getitem:  25173\n",
      "Test inds:  [(491, 3192)]\n",
      "Ann_id in getitem:  11805\n",
      "Test inds:  [(1569, 1872)]\n",
      "Ann_id in getitem:  37150\n",
      "Test inds:  [(1579, 727)]\n",
      "Ann_id in getitem:  37354\n",
      "Test inds:  [(1766, 252)]\n",
      "Ann_id in getitem:  40811\n",
      "Test inds:  [(1973, 1268)]\n",
      "Ann_id in getitem:  44991\n",
      "Test inds:  [(3486, 1316)]\n",
      "Ann_id in getitem:  80301\n",
      "Test inds:  [(36, 1658)]\n",
      "Ann_id in getitem:  827\n",
      "Test inds:  [(2017, 200)]\n",
      "Ann_id in getitem:  45867\n",
      "Test inds:  [(2365, 451)]\n",
      "Ann_id in getitem:  53465\n",
      "Test inds:  [(3482, 1568)]\n",
      "Ann_id in getitem:  80262\n",
      "Test inds:  [(354, 3412)]\n",
      "Ann_id in getitem:  8522\n",
      "Test inds:  [(2838, 664)]\n",
      "Ann_id in getitem:  65391\n",
      "Test inds:  [(1610, 1010)]\n",
      "Ann_id in getitem:  37817\n",
      "Test inds:  [(1403, 1336)]\n",
      "Ann_id in getitem:  33214\n",
      "Test inds:  [(100, 3693)]\n",
      "Ann_id in getitem:  2192\n",
      "Test inds:  [(1426, 2274)]\n",
      "Ann_id in getitem:  33809\n",
      "Test inds:  [(3224, 1259)]\n",
      "Ann_id in getitem:  74118\n",
      "Test inds:  [(1469, 2500)]\n",
      "Ann_id in getitem:  34786\n",
      "Test inds:  [(1895, 1117)]\n",
      "Ann_id in getitem:  43488\n",
      "Test inds:  [(2973, 1620)]\n",
      "Ann_id in getitem:  68413\n",
      "Test inds:  [(1826, 2027)]\n",
      "Ann_id in getitem:  42020\n",
      "Test inds:  [(1562, 1223)]\n",
      "Ann_id in getitem:  36886\n",
      "Test inds:  [(940, 1379)]\n",
      "Ann_id in getitem:  22343\n",
      "Test inds:  [(388, 3126)]\n",
      "Ann_id in getitem:  9616\n",
      "Test inds:  [(536, 1372)]\n",
      "Ann_id in getitem:  12740\n",
      "Test inds:  [(3505, 1623)]\n",
      "Ann_id in getitem:  80866\n",
      "Test inds:  [(1544, 2468)]\n",
      "Ann_id in getitem:  36524\n",
      "Test inds:  [(2751, 1511)]\n",
      "Ann_id in getitem:  63321\n",
      "Test inds:  [(2407, 975)]\n",
      "Ann_id in getitem:  54427\n",
      "Test inds:  [(3510, 3616)]\n",
      "Ann_id in getitem:  81014\n",
      "Test inds:  [(649, 1567)]\n",
      "Ann_id in getitem:  15827\n",
      "Test inds:  [(3325, 191)]\n",
      "Ann_id in getitem:  76389\n",
      "Test inds:  [(1736, 3373)]\n",
      "Ann_id in getitem:  40402\n",
      "Test inds:  [(254, 1684)]\n",
      "Ann_id in getitem:  6108\n",
      "Test inds:  [(239, 2337)]\n",
      "Ann_id in getitem:  5812\n",
      "Test inds:  [(1746, 2052)]\n",
      "Ann_id in getitem:  40540\n",
      "Test inds:  [(644, 3440)]\n",
      "Ann_id in getitem:  15620\n",
      "Test inds:  [(889, 2449)]\n",
      "Ann_id in getitem:  21210\n",
      "Test inds:  [(1234, 1359)]\n",
      "Ann_id in getitem:  28883\n",
      "Test inds:  [(2177, 2364)]\n",
      "Ann_id in getitem:  49079\n",
      "Test inds:  [(297, 831)]\n",
      "Ann_id in getitem:  6928\n",
      "Test inds:  [(486, 3567)]\n",
      "Ann_id in getitem:  11702\n",
      "Test inds:  [(3652, 1555)]\n",
      "Ann_id in getitem:  84310\n",
      "Test inds:  [(2102, 208)]\n",
      "Ann_id in getitem:  47580\n",
      "Test inds:  [(2420, 608)]\n",
      "Ann_id in getitem:  54679\n",
      "Test inds:  [(328, 502)]\n",
      "Ann_id in getitem:  8051\n",
      "Test inds:  [(2610, 660)]\n",
      "Ann_id in getitem:  59833\n",
      "Test inds:  [(3484, 509)]\n",
      "Ann_id in getitem:  80271\n",
      "Test inds:  [(2455, 3337)]\n",
      "Ann_id in getitem:  55771\n",
      "Test inds:  [(528, 2336)]\n",
      "Ann_id in getitem:  12570\n",
      "Test inds:  [(1240, 1597)]\n",
      "Ann_id in getitem:  28968\n",
      "Test inds:  [(2407, 2640)]\n",
      "Ann_id in getitem:  54427\n",
      "Test inds:  [(2044, 1109)]\n",
      "Ann_id in getitem:  46557\n",
      "Test inds:  [(153, 57)]\n",
      "Ann_id in getitem:  3762\n",
      "Test inds:  [(3105, 2022)]\n",
      "Ann_id in getitem:  71652\n",
      "Test inds:  [(548, 1773)]\n",
      "Ann_id in getitem:  13138\n",
      "Test inds:  [(2025, 3469)]\n",
      "Ann_id in getitem:  45991\n",
      "Test inds:  [(1136, 1270)]\n",
      "Ann_id in getitem:  26492\n",
      "Test inds:  [(2267, 659)]\n",
      "Ann_id in getitem:  51199\n",
      "Test inds:  [(3603, 1861)]\n",
      "Ann_id in getitem:  83130\n",
      "Test inds:  [(818, 799)]\n",
      "Ann_id in getitem:  19702\n",
      "Test inds:  [(992, 597)]\n",
      "Ann_id in getitem:  23597\n",
      "Test inds:  [(1, 898)]\n",
      "Ann_id in getitem:  38\n",
      "Test inds:  [(2611, 259)]\n",
      "Ann_id in getitem:  59841\n",
      "Test inds:  [(1032, 1333)]\n",
      "Ann_id in getitem:  24365\n",
      "Test inds:  [(409, 1083)]\n",
      "Ann_id in getitem:  10030\n",
      "Test inds:  [(1066, 1230)]\n",
      "Ann_id in getitem:  25051\n",
      "Test inds:  [(2524, 3667)]\n",
      "Ann_id in getitem:  57326\n",
      "Test inds:  [(798, 1507)]\n",
      "Ann_id in getitem:  19322\n",
      "Test inds:  [(1402, 2000)]\n",
      "Ann_id in getitem:  33201\n",
      "Test inds:  [(3394, 470)]\n",
      "Ann_id in getitem:  78013\n",
      "Test inds:  [(1633, 1833)]\n",
      "Ann_id in getitem:  38308\n",
      "Test inds:  [(3692, 1271)]\n",
      "Ann_id in getitem:  85388\n",
      "Test inds:  [(762, 2502)]\n",
      "Ann_id in getitem:  18511\n",
      "Test inds:  [(2127, 172)]\n",
      "Ann_id in getitem:  48216\n",
      "Test inds:  [(2363, 601)]\n",
      "Ann_id in getitem:  53396\n",
      "Test inds:  [(2091, 2823)]\n",
      "Ann_id in getitem:  47403\n",
      "Test inds:  [(2271, 2467)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(1404, 2646)]\n",
      "Ann_id in getitem:  33262\n",
      "Test inds:  [(2978, 887)]\n",
      "Ann_id in getitem:  68624\n",
      "Test inds:  [(2112, 1039)]\n",
      "Ann_id in getitem:  47884\n",
      "Test inds:  [(2568, 1353)]\n",
      "Ann_id in getitem:  58448\n",
      "Test inds:  [(303, 775)]\n",
      "Ann_id in getitem:  7237\n",
      "Test inds:  [(1071, 1952)]\n",
      "Ann_id in getitem:  25148\n",
      "Test inds:  [(3418, 115)]\n",
      "Ann_id in getitem:  78740\n",
      "Test inds:  [(646, 1445)]\n",
      "Ann_id in getitem:  15748\n",
      "Test inds:  [(836, 1727)]\n",
      "Ann_id in getitem:  20033\n",
      "Test inds:  [(2643, 1204)]\n",
      "Ann_id in getitem:  60524\n",
      "Test inds:  [(44, 457)]\n",
      "Ann_id in getitem:  939\n",
      "Test inds:  [(431, 258)]\n",
      "Ann_id in getitem:  10614\n",
      "Test inds:  [(454, 2486)]\n",
      "Ann_id in getitem:  10973\n",
      "Test inds:  [(2236, 594)]\n",
      "Ann_id in getitem:  50350\n",
      "Test inds:  [(2588, 1280)]\n",
      "Ann_id in getitem:  59353\n",
      "Test inds:  [(454, 401)]\n",
      "Ann_id in getitem:  10973\n",
      "Test inds:  [(2606, 1194)]\n",
      "Ann_id in getitem:  59688\n",
      "Test inds:  [(1056, 384)]\n",
      "Ann_id in getitem:  24948\n",
      "Test inds:  [(1231, 770)]\n",
      "Ann_id in getitem:  28779\n",
      "Test inds:  [(3044, 1874)]\n",
      "Ann_id in getitem:  70219\n",
      "Test inds:  [(1066, 3261)]\n",
      "Ann_id in getitem:  25051\n",
      "Test inds:  [(2494, 923)]\n",
      "Ann_id in getitem:  56718\n",
      "Test inds:  [(2009, 3280)]\n",
      "Ann_id in getitem:  45716\n",
      "Test inds:  [(546, 717)]\n",
      "Ann_id in getitem:  13014\n",
      "Test inds:  [(2404, 2175)]\n",
      "Ann_id in getitem:  54376\n",
      "Test inds:  [(2887, 3473)]\n",
      "Ann_id in getitem:  66414\n",
      "Test inds:  [(773, 36)]\n",
      "Ann_id in getitem:  18756\n",
      "Test inds:  [(2924, 3001)]\n",
      "Ann_id in getitem:  67297\n",
      "Test inds:  [(1808, 428)]\n",
      "Ann_id in getitem:  41703\n",
      "Test inds:  [(2267, 272)]\n",
      "Ann_id in getitem:  51199\n",
      "Test inds:  [(500, 650)]\n",
      "Ann_id in getitem:  11969\n",
      "Test inds:  [(2452, 1024)]\n",
      "Ann_id in getitem:  55702\n",
      "Test inds:  [(2219, 1495)]\n",
      "Ann_id in getitem:  49971\n",
      "Test inds:  [(1840, 1639)]\n",
      "Ann_id in getitem:  42233\n",
      "Test inds:  [(2273, 2116)]\n",
      "Ann_id in getitem:  51405\n",
      "Test inds:  [(1536, 797)]\n",
      "Ann_id in getitem:  36374\n",
      "Test inds:  [(594, 503)]\n",
      "Ann_id in getitem:  14398\n",
      "Test inds:  [(3455, 3557)]\n",
      "Ann_id in getitem:  79727\n",
      "Test inds:  [(2594, 3501)]\n",
      "Ann_id in getitem:  59476\n",
      "Test inds:  [(421, 547)]\n",
      "Ann_id in getitem:  10216\n",
      "Test inds:  [(2745, 3277)]\n",
      "Ann_id in getitem:  63173\n",
      "Test inds:  [(1038, 511)]\n",
      "Ann_id in getitem:  24539\n",
      "Test inds:  [(1372, 3126)]\n",
      "Ann_id in getitem:  32365\n",
      "Test inds:  [(2200, 998)]\n",
      "Ann_id in getitem:  49558\n",
      "Test inds:  [(1501, 2889)]\n",
      "Ann_id in getitem:  35694\n",
      "Test inds:  [(2393, 3627)]\n",
      "Ann_id in getitem:  54145\n",
      "Test inds:  [(618, 1589)]\n",
      "Ann_id in getitem:  15170\n",
      "Test inds:  [(1510, 2907)]\n",
      "Ann_id in getitem:  35827\n",
      "Test inds:  [(693, 196)]\n",
      "Ann_id in getitem:  16873\n",
      "Test inds:  [(1939, 82)]\n",
      "Ann_id in getitem:  44192\n",
      "Test inds:  [(1421, 771)]\n",
      "Ann_id in getitem:  33710\n",
      "Test inds:  [(2481, 482)]\n",
      "Ann_id in getitem:  56453\n",
      "Test inds:  [(440, 600)]\n",
      "Ann_id in getitem:  10730\n",
      "Test inds:  [(1070, 479)]\n",
      "Ann_id in getitem:  25125\n",
      "Test inds:  [(1589, 366)]\n",
      "Ann_id in getitem:  37453\n",
      "Test inds:  [(1482, 2332)]\n",
      "Ann_id in getitem:  35136\n",
      "Test inds:  [(2947, 3104)]\n",
      "Ann_id in getitem:  67910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3381, 2337)]\n",
      "Ann_id in getitem:  77762\n",
      "Test inds:  [(3420, 1702)]\n",
      "Ann_id in getitem:  78757\n",
      "Test inds:  [(1351, 1628)]\n",
      "Ann_id in getitem:  31835\n",
      "Test inds:  [(2345, 1280)]\n",
      "Ann_id in getitem:  52927\n",
      "Test inds:  [(122, 2081)]\n",
      "Ann_id in getitem:  2919\n",
      "Test inds:  [(1671, 3183)]\n",
      "Ann_id in getitem:  39137\n",
      "Test inds:  [(1745, 2100)]\n",
      "Ann_id in getitem:  40508\n",
      "Test inds:  [(2673, 1248)]\n",
      "Ann_id in getitem:  61322\n",
      "Test inds:  [(1991, 3359)]\n",
      "Ann_id in getitem:  45378\n",
      "Test inds:  [(1736, 1141)]\n",
      "Ann_id in getitem:  40402\n",
      "Test inds:  [(2521, 1791)]\n",
      "Ann_id in getitem:  57302\n",
      "Test inds:  [(2433, 262)]\n",
      "Ann_id in getitem:  55019\n",
      "Test inds:  [(3606, 374)]\n",
      "Ann_id in getitem:  83291\n",
      "Test inds:  [(729, 877)]\n",
      "Ann_id in getitem:  17588\n",
      "Test inds:  [(3638, 1221)]\n",
      "Ann_id in getitem:  83968\n",
      "Test inds:  [(2059, 164)]\n",
      "Ann_id in getitem:  46861\n",
      "Test inds:  [(3506, 1462)]\n",
      "Ann_id in getitem:  80903\n",
      "Test inds:  [(571, 148)]\n",
      "Ann_id in getitem:  13792\n",
      "Test inds:  [(2199, 2022)]\n",
      "Ann_id in getitem:  49505\n",
      "Test inds:  [(3362, 1251)]\n",
      "Ann_id in getitem:  77176\n",
      "Test inds:  [(2271, 2267)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(3048, 3256)]\n",
      "Ann_id in getitem:  70269\n",
      "Test inds:  [(1768, 3066)]\n",
      "Ann_id in getitem:  40851\n",
      "Test inds:  [(492, 3341)]\n",
      "Ann_id in getitem:  11821\n",
      "Test inds:  [(807, 1827)]\n",
      "Ann_id in getitem:  19458\n",
      "Test inds:  [(1376, 1137)]\n",
      "Ann_id in getitem:  32509\n",
      "Test inds:  [(2225, 3265)]\n",
      "Ann_id in getitem:  50142\n",
      "Test inds:  [(3262, 686)]\n",
      "Ann_id in getitem:  74853\n",
      "Test inds:  [(2948, 2781)]\n",
      "Ann_id in getitem:  67914\n",
      "Test inds:  [(3391, 1989)]\n",
      "Ann_id in getitem:  77907\n",
      "Test inds:  [(166, 2126)]\n",
      "Ann_id in getitem:  4193\n",
      "Test inds:  [(1661, 600)]\n",
      "Ann_id in getitem:  38859\n",
      "Test inds:  [(1656, 58)]\n",
      "Ann_id in getitem:  38775\n",
      "Test inds:  [(1351, 1494)]\n",
      "Ann_id in getitem:  31835\n",
      "Test inds:  [(147, 2756)]\n",
      "Ann_id in getitem:  3586\n",
      "Test inds:  [(3526, 2276)]\n",
      "Ann_id in getitem:  81379\n",
      "Test inds:  [(1464, 2461)]\n",
      "Ann_id in getitem:  34664\n",
      "Test inds:  [(2772, 2745)]\n",
      "Ann_id in getitem:  63798\n",
      "Test inds:  [(2958, 2561)]\n",
      "Ann_id in getitem:  68104\n",
      "Test inds:  [(611, 1341)]\n",
      "Ann_id in getitem:  14949\n",
      "Test inds:  [(421, 1348)]\n",
      "Ann_id in getitem:  10216\n",
      "Test inds:  [(1218, 565)]\n",
      "Ann_id in getitem:  28460\n",
      "Test inds:  [(1843, 1273)]\n",
      "Ann_id in getitem:  42375\n",
      "Test inds:  [(426, 3185)]\n",
      "Ann_id in getitem:  10527\n",
      "Test inds:  [(917, 1398)]\n",
      "Ann_id in getitem:  21924\n",
      "Test inds:  [(1912, 896)]\n",
      "Ann_id in getitem:  43775\n",
      "Test inds:  [(1293, 482)]\n",
      "Ann_id in getitem:  30350\n",
      "Test inds:  [(1462, 515)]\n",
      "Ann_id in getitem:  34613\n",
      "Test inds:  [(647, 2527)]\n",
      "Ann_id in getitem:  15755\n",
      "Test inds:  [(3476, 2358)]\n",
      "Ann_id in getitem:  80194\n",
      "Test inds:  [(3473, 2998)]\n",
      "Ann_id in getitem:  80129\n",
      "Test inds:  [(517, 1665)]\n",
      "Ann_id in getitem:  12356\n",
      "Test inds:  [(94, 242)]\n",
      "Ann_id in getitem:  2139\n",
      "Test inds:  [(3107, 3192)]\n",
      "Ann_id in getitem:  71706\n",
      "Test inds:  [(2188, 1743)]\n",
      "Ann_id in getitem:  49282\n",
      "Test inds:  [(1911, 276)]\n",
      "Ann_id in getitem:  43769\n",
      "Test inds:  [(1574, 1547)]\n",
      "Ann_id in getitem:  37275\n",
      "Test inds:  [(1784, 1045)]\n",
      "Ann_id in getitem:  41111\n",
      "Test inds:  [(2152, 953)]\n",
      "Ann_id in getitem:  48627\n",
      "Test inds:  [(3268, 2845)]\n",
      "Ann_id in getitem:  74929\n",
      "Test inds:  [(620, 3083)]\n",
      "Ann_id in getitem:  15185\n",
      "Test inds:  [(1196, 2719)]\n",
      "Ann_id in getitem:  27851\n",
      "Test inds:  [(3523, 366)]\n",
      "Ann_id in getitem:  81287\n",
      "Test inds:  [(215, 1830)]\n",
      "Ann_id in getitem:  5377\n",
      "Test inds:  [(370, 815)]\n",
      "Ann_id in getitem:  9006\n",
      "Test inds:  [(2646, 2247)]\n",
      "Ann_id in getitem:  60603\n",
      "Test inds:  [(1472, 835)]\n",
      "Ann_id in getitem:  34923\n",
      "Test inds:  [(275, 867)]\n",
      "Ann_id in getitem:  6562\n",
      "Test inds:  [(3580, 2701)]\n",
      "Ann_id in getitem:  82483\n",
      "Test inds:  [(1763, 188)]\n",
      "Ann_id in getitem:  40781\n",
      "Test inds:  [(1640, 1862)]\n",
      "Ann_id in getitem:  38499\n",
      "Test inds:  [(1308, 650)]\n",
      "Ann_id in getitem:  30609\n",
      "Test inds:  [(2736, 2851)]\n",
      "Ann_id in getitem:  63007\n",
      "Test inds:  [(2229, 2328)]\n",
      "Ann_id in getitem:  50207\n",
      "Test inds:  [(1659, 2206)]\n",
      "Ann_id in getitem:  38821\n",
      "Test inds:  [(1326, 339)]\n",
      "Ann_id in getitem:  31015\n",
      "Test inds:  [(3453, 119)]\n",
      "Ann_id in getitem:  79645\n",
      "Test inds:  [(699, 1896)]\n",
      "Ann_id in getitem:  16995\n",
      "Test inds:  [(1677, 397)]\n",
      "Ann_id in getitem:  39281\n",
      "Test inds:  [(1524, 3094)]\n",
      "Ann_id in getitem:  36083\n",
      "Test inds:  [(1950, 771)]\n",
      "Ann_id in getitem:  44354\n",
      "Test inds:  [(2858, 427)]\n",
      "Ann_id in getitem:  65708\n",
      "Test inds:  [(2770, 578)]\n",
      "Ann_id in getitem:  63766\n",
      "Test inds:  [(2504, 2063)]\n",
      "Ann_id in getitem:  57034\n",
      "Test inds:  [(2603, 2487)]\n",
      "Ann_id in getitem:  59660\n",
      "Test inds:  [(279, 708)]\n",
      "Ann_id in getitem:  6614\n",
      "Test inds:  [(3443, 1016)]\n",
      "Ann_id in getitem:  79362\n",
      "Test inds:  [(2992, 2664)]\n",
      "Ann_id in getitem:  68965\n",
      "Test inds:  [(1340, 171)]\n",
      "Ann_id in getitem:  31469\n",
      "Test inds:  [(845, 315)]\n",
      "Ann_id in getitem:  20472\n",
      "Test inds:  [(362, 215)]\n",
      "Ann_id in getitem:  8739\n",
      "Test inds:  [(2203, 3124)]\n",
      "Ann_id in getitem:  49597\n",
      "Test inds:  [(1426, 134)]\n",
      "Ann_id in getitem:  33809\n",
      "Test inds:  [(61, 3268)]\n",
      "Ann_id in getitem:  1327\n",
      "Test inds:  [(1096, 3609)]\n",
      "Ann_id in getitem:  25507\n",
      "Test inds:  [(2011, 2802)]\n",
      "Ann_id in getitem:  45775\n",
      "Test inds:  [(41, 1181)]\n",
      "Ann_id in getitem:  891\n",
      "Test inds:  [(1484, 2245)]\n",
      "Ann_id in getitem:  35252\n",
      "Test inds:  [(1712, 944)]\n",
      "Ann_id in getitem:  40044\n",
      "Test inds:  [(3669, 2082)]\n",
      "Ann_id in getitem:  84662\n",
      "Test inds:  [(416, 2385)]\n",
      "Ann_id in getitem:  10128\n",
      "Test inds:  [(2383, 1716)]\n",
      "Ann_id in getitem:  53894\n",
      "Test inds:  [(3359, 2243)]\n",
      "Ann_id in getitem:  77075\n",
      "Test inds:  [(2491, 3132)]\n",
      "Ann_id in getitem:  56679\n",
      "Test inds:  [(3159, 52)]\n",
      "Ann_id in getitem:  72813\n",
      "Test inds:  [(2512, 3594)]\n",
      "Ann_id in getitem:  57154\n",
      "Test inds:  [(1808, 2578)]\n",
      "Ann_id in getitem:  41703\n",
      "Test inds:  [(3561, 3175)]\n",
      "Ann_id in getitem:  82098\n",
      "Test inds:  [(772, 3437)]\n",
      "Ann_id in getitem:  18730\n",
      "Test inds:  [(2956, 73)]\n",
      "Ann_id in getitem:  68055\n",
      "Test inds:  [(487, 78)]\n",
      "Ann_id in getitem:  11724\n",
      "Test inds:  [(808, 834)]\n",
      "Ann_id in getitem:  19468\n",
      "Test inds:  [(578, 1082)]\n",
      "Ann_id in getitem:  14058\n",
      "Test inds:  [(523, 3394)]\n",
      "Ann_id in getitem:  12496\n",
      "Test inds:  [(3200, 885)]\n",
      "Ann_id in getitem:  73653\n",
      "Test inds:  [(3219, 1162)]\n",
      "Ann_id in getitem:  74050\n",
      "Test inds:  [(1156, 2438)]\n",
      "Ann_id in getitem:  26881\n",
      "Test inds:  [(1335, 3270)]\n",
      "Ann_id in getitem:  31408\n",
      "Test inds:  [(853, 3)]\n",
      "Ann_id in getitem:  20770\n",
      "Test inds:  [(422, 2516)]\n",
      "Ann_id in getitem:  10243\n",
      "Test inds:  [(527, 1455)]\n",
      "Ann_id in getitem:  12564\n",
      "Test inds:  [(1995, 2631)]\n",
      "Ann_id in getitem:  45494\n",
      "Test inds:  [(3061, 2267)]\n",
      "Ann_id in getitem:  70603\n",
      "Test inds:  [(1145, 3371)]\n",
      "Ann_id in getitem:  26740\n",
      "Test inds:  [(3144, 2243)]\n",
      "Ann_id in getitem:  72528\n",
      "Test inds:  [(2938, 3433)]\n",
      "Ann_id in getitem:  67687\n",
      "Test inds:  [(931, 1610)]\n",
      "Ann_id in getitem:  22211\n",
      "Test inds:  [(703, 2219)]\n",
      "Ann_id in getitem:  17068\n",
      "Test inds:  [(758, 1792)]\n",
      "Ann_id in getitem:  18333\n",
      "Test inds:  [(2010, 3261)]\n",
      "Ann_id in getitem:  45719\n",
      "Test inds:  [(344, 1810)]\n",
      "Ann_id in getitem:  8323\n",
      "Test inds:  [(1575, 1694)]\n",
      "Ann_id in getitem:  37304\n",
      "Test inds:  [(1549, 159)]\n",
      "Ann_id in getitem:  36600\n",
      "Test inds:  [(312, 1853)]\n",
      "Ann_id in getitem:  7627\n",
      "Test inds:  [(804, 1127)]\n",
      "Ann_id in getitem:  19396\n",
      "Test inds:  [(1629, 1742)]\n",
      "Ann_id in getitem:  38235\n",
      "Test inds:  [(3419, 3684)]\n",
      "Ann_id in getitem:  78749\n",
      "Test inds:  [(1774, 1194)]\n",
      "Ann_id in getitem:  41007\n",
      "Test inds:  [(2459, 775)]\n",
      "Ann_id in getitem:  55935\n",
      "Test inds:  [(3641, 256)]\n",
      "Ann_id in getitem:  83996\n",
      "Test inds:  [(239, 3202)]\n",
      "Ann_id in getitem:  5812\n",
      "Test inds:  [(3223, 275)]\n",
      "Ann_id in getitem:  74111\n",
      "Test inds:  [(2023, 599)]\n",
      "Ann_id in getitem:  45981\n",
      "Test inds:  [(697, 754)]\n",
      "Ann_id in getitem:  16930\n",
      "Test inds:  [(3042, 2483)]\n",
      "Ann_id in getitem:  70093\n",
      "Test inds:  [(558, 3014)]\n",
      "Ann_id in getitem:  13497\n",
      "Test inds:  [(823, 1285)]\n",
      "Ann_id in getitem:  19785\n",
      "Test inds:  [(3293, 294)]\n",
      "Ann_id in getitem:  75509\n",
      "Test inds:  [(3086, 148)]\n",
      "Ann_id in getitem:  71201\n",
      "Test inds:  [(185, 3376)]\n",
      "Ann_id in getitem:  4731\n",
      "Test inds:  [(1828, 2498)]\n",
      "Ann_id in getitem:  42028\n",
      "Test inds:  [(2806, 2987)]\n",
      "Ann_id in getitem:  64713\n",
      "Test inds:  [(2341, 2153)]\n",
      "Ann_id in getitem:  52808\n",
      "Test inds:  [(454, 226)]\n",
      "Ann_id in getitem:  10973\n",
      "Test inds:  [(1773, 2123)]\n",
      "Ann_id in getitem:  40948\n",
      "Test inds:  [(3687, 271)]\n",
      "Ann_id in getitem:  85147\n",
      "Test inds:  [(378, 75)]\n",
      "Ann_id in getitem:  9195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2234, 2122)]\n",
      "Ann_id in getitem:  50316\n",
      "Test inds:  [(1285, 1531)]\n",
      "Ann_id in getitem:  30071\n",
      "Test inds:  [(1326, 325)]\n",
      "Ann_id in getitem:  31015\n",
      "Test inds:  [(3522, 2697)]\n",
      "Ann_id in getitem:  81276\n",
      "Test inds:  [(1235, 2736)]\n",
      "Ann_id in getitem:  28884\n",
      "Test inds:  [(3636, 1224)]\n",
      "Ann_id in getitem:  83948\n",
      "Test inds:  [(2686, 974)]\n",
      "Ann_id in getitem:  61648\n",
      "Test inds:  [(133, 656)]\n",
      "Ann_id in getitem:  3202\n",
      "Test inds:  [(3129, 777)]\n",
      "Ann_id in getitem:  72149\n",
      "Test inds:  [(1152, 833)]\n",
      "Ann_id in getitem:  26807\n",
      "Test inds:  [(1330, 1626)]\n",
      "Ann_id in getitem:  31230\n",
      "Test inds:  [(1092, 599)]\n",
      "Ann_id in getitem:  25487\n",
      "Test inds:  [(1744, 3058)]\n",
      "Ann_id in getitem:  40485\n",
      "Test inds:  [(688, 2003)]\n",
      "Ann_id in getitem:  16752\n",
      "Test inds:  [(1325, 1978)]\n",
      "Ann_id in getitem:  31012\n",
      "Test inds:  [(1013, 3626)]\n",
      "Ann_id in getitem:  24056\n",
      "Test inds:  [(423, 948)]\n",
      "Ann_id in getitem:  10264\n",
      "Test inds:  [(2194, 1807)]\n",
      "Ann_id in getitem:  49381\n",
      "Test inds:  [(3096, 2967)]\n",
      "Ann_id in getitem:  71328\n",
      "Test inds:  [(756, 3689)]\n",
      "Ann_id in getitem:  18315\n",
      "Test inds:  [(1957, 1462)]\n",
      "Ann_id in getitem:  44503\n",
      "Test inds:  [(2149, 1008)]\n",
      "Ann_id in getitem:  48563\n",
      "Test inds:  [(52, 805)]\n",
      "Ann_id in getitem:  1104\n",
      "Test inds:  [(1387, 1625)]\n",
      "Ann_id in getitem:  32952\n",
      "Test inds:  [(738, 2157)]\n",
      "Ann_id in getitem:  17883\n",
      "Test inds:  [(1322, 2493)]\n",
      "Ann_id in getitem:  30914\n",
      "Test inds:  [(2197, 2099)]\n",
      "Ann_id in getitem:  49493\n",
      "Test inds:  [(1557, 2857)]\n",
      "Ann_id in getitem:  36794\n",
      "Test inds:  [(1637, 814)]\n",
      "Ann_id in getitem:  38364\n",
      "Test inds:  [(3216, 179)]\n",
      "Ann_id in getitem:  73985\n",
      "Test inds:  [(3064, 2048)]\n",
      "Ann_id in getitem:  70629\n",
      "Test inds:  [(3473, 1601)]\n",
      "Ann_id in getitem:  80129\n",
      "Test inds:  [(2482, 1481)]\n",
      "Ann_id in getitem:  56501\n",
      "Test inds:  [(1725, 1610)]\n",
      "Ann_id in getitem:  40232\n",
      "Test inds:  [(1390, 196)]\n",
      "Ann_id in getitem:  33008\n",
      "Test inds:  [(1145, 1793)]\n",
      "Ann_id in getitem:  26740\n",
      "Test inds:  [(2793, 2183)]\n",
      "Ann_id in getitem:  64471\n",
      "Test inds:  [(1990, 55)]\n",
      "Ann_id in getitem:  45322\n",
      "Test inds:  [(350, 1596)]\n",
      "Ann_id in getitem:  8479\n",
      "Test inds:  [(2179, 1580)]\n",
      "Ann_id in getitem:  49124\n",
      "Test inds:  [(2736, 801)]\n",
      "Ann_id in getitem:  63007\n",
      "Test inds:  [(2719, 2221)]\n",
      "Ann_id in getitem:  62513\n",
      "Test inds:  [(2302, 2736)]\n",
      "Ann_id in getitem:  51919\n",
      "Test inds:  [(3413, 430)]\n",
      "Ann_id in getitem:  78657\n",
      "Test inds:  [(2590, 1871)]\n",
      "Ann_id in getitem:  59384\n",
      "Test inds:  [(2303, 250)]\n",
      "Ann_id in getitem:  51932\n",
      "Test inds:  [(1009, 3026)]\n",
      "Ann_id in getitem:  23966\n",
      "Test inds:  [(512, 1023)]\n",
      "Ann_id in getitem:  12242\n",
      "Test inds:  [(11, 1774)]\n",
      "Ann_id in getitem:  185\n",
      "Test inds:  [(3240, 1495)]\n",
      "Ann_id in getitem:  74511\n",
      "Test inds:  [(3189, 1338)]\n",
      "Ann_id in getitem:  73403\n",
      "Test inds:  [(2817, 2941)]\n",
      "Ann_id in getitem:  64933\n",
      "Test inds:  [(3084, 252)]\n",
      "Ann_id in getitem:  71134\n",
      "Test inds:  [(3556, 1309)]\n",
      "Ann_id in getitem:  81988\n",
      "Test inds:  [(691, 2121)]\n",
      "Ann_id in getitem:  16836\n",
      "Test inds:  [(1142, 888)]\n",
      "Ann_id in getitem:  26704\n",
      "Test inds:  [(486, 3217)]\n",
      "Ann_id in getitem:  11702\n",
      "Test inds:  [(689, 1490)]\n",
      "Ann_id in getitem:  16759\n",
      "Test inds:  [(880, 277)]\n",
      "Ann_id in getitem:  21096\n",
      "Test inds:  [(2638, 575)]\n",
      "Ann_id in getitem:  60373\n",
      "Test inds:  [(2312, 734)]\n",
      "Ann_id in getitem:  52100\n",
      "Test inds:  [(3188, 2994)]\n",
      "Ann_id in getitem:  73388\n",
      "Test inds:  [(581, 1643)]\n",
      "Ann_id in getitem:  14119\n",
      "Test inds:  [(1662, 457)]\n",
      "Ann_id in getitem:  38868\n",
      "Test inds:  [(587, 173)]\n",
      "Ann_id in getitem:  14275\n",
      "Test inds:  [(1310, 3288)]\n",
      "Ann_id in getitem:  30641\n",
      "Test inds:  [(1807, 477)]\n",
      "Ann_id in getitem:  41695\n",
      "Test inds:  [(171, 1845)]\n",
      "Ann_id in getitem:  4347\n",
      "Test inds:  [(1537, 1273)]\n",
      "Ann_id in getitem:  36395\n",
      "Test inds:  [(1184, 1249)]\n",
      "Ann_id in getitem:  27564\n",
      "Test inds:  [(2987, 3085)]\n",
      "Ann_id in getitem:  68923\n",
      "Test inds:  [(2137, 2536)]\n",
      "Ann_id in getitem:  48404\n",
      "Test inds:  [(2695, 2122)]\n",
      "Ann_id in getitem:  61967\n",
      "Test inds:  [(970, 3041)]\n",
      "Ann_id in getitem:  22898\n",
      "Test inds:  [(578, 1493)]\n",
      "Ann_id in getitem:  14058\n",
      "Test inds:  [(3506, 2873)]\n",
      "Ann_id in getitem:  80903\n",
      "Test inds:  [(3400, 3316)]\n",
      "Ann_id in getitem:  78214\n",
      "Test inds:  [(1554, 2535)]\n",
      "Ann_id in getitem:  36772\n",
      "Test inds:  [(370, 2279)]\n",
      "Ann_id in getitem:  9006\n",
      "Test inds:  [(1377, 3572)]\n",
      "Ann_id in getitem:  32557\n",
      "Test inds:  [(3339, 1366)]\n",
      "Ann_id in getitem:  76685\n",
      "Test inds:  [(650, 3328)]\n",
      "Ann_id in getitem:  15861\n",
      "Test inds:  [(3168, 3099)]\n",
      "Ann_id in getitem:  73028\n",
      "Test inds:  [(353, 2196)]\n",
      "Ann_id in getitem:  8510\n",
      "Test inds:  [(1976, 3332)]\n",
      "Ann_id in getitem:  45027\n",
      "Test inds:  [(3081, 205)]\n",
      "Ann_id in getitem:  71066\n",
      "Test inds:  [(749, 109)]\n",
      "Ann_id in getitem:  18138\n",
      "Test inds:  [(875, 2227)]\n",
      "Ann_id in getitem:  21022\n",
      "Test inds:  [(3688, 283)]\n",
      "Ann_id in getitem:  85200\n",
      "Test inds:  [(1270, 2874)]\n",
      "Ann_id in getitem:  29641\n",
      "Test inds:  [(1639, 1008)]\n",
      "Ann_id in getitem:  38479\n",
      "Test inds:  [(2300, 2837)]\n",
      "Ann_id in getitem:  51858\n",
      "Test inds:  [(2646, 1059)]\n",
      "Ann_id in getitem:  60603\n",
      "Test inds:  [(3174, 3352)]\n",
      "Ann_id in getitem:  73075\n",
      "Test inds:  [(1662, 1614)]\n",
      "Ann_id in getitem:  38868\n",
      "Test inds:  [(265, 1138)]\n",
      "Ann_id in getitem:  6301\n",
      "Test inds:  [(729, 96)]\n",
      "Ann_id in getitem:  17588\n",
      "Test inds:  [(2962, 3659)]\n",
      "Ann_id in getitem:  68179\n",
      "Test inds:  [(1999, 1035)]\n",
      "Ann_id in getitem:  45551\n",
      "Test inds:  [(2858, 2951)]\n",
      "Ann_id in getitem:  65708\n",
      "Test inds:  [(2059, 2663)]\n",
      "Ann_id in getitem:  46861\n",
      "Test inds:  [(2725, 368)]\n",
      "Ann_id in getitem:  62664\n",
      "Test inds:  [(2407, 1429)]\n",
      "Ann_id in getitem:  54427\n",
      "Test inds:  [(118, 286)]\n",
      "Ann_id in getitem:  2761\n",
      "Test inds:  [(1150, 894)]\n",
      "Ann_id in getitem:  26767\n",
      "Test inds:  [(2206, 1606)]\n",
      "Ann_id in getitem:  49667\n",
      "Test inds:  [(581, 2563)]\n",
      "Ann_id in getitem:  14119\n",
      "Test inds:  [(1516, 2350)]\n",
      "Ann_id in getitem:  35938\n",
      "Test inds:  [(3018, 1363)]\n",
      "Ann_id in getitem:  69534\n",
      "Test inds:  [(101, 2839)]\n",
      "Ann_id in getitem:  2219\n",
      "Test inds:  [(282, 3135)]\n",
      "Ann_id in getitem:  6638\n",
      "Test inds:  [(3111, 1189)]\n",
      "Ann_id in getitem:  71777\n",
      "Test inds:  [(280, 3506)]\n",
      "Ann_id in getitem:  6615\n",
      "Test inds:  [(939, 1136)]\n",
      "Ann_id in getitem:  22341\n",
      "Test inds:  [(2401, 1744)]\n",
      "Ann_id in getitem:  54328\n",
      "Test inds:  [(1231, 458)]\n",
      "Ann_id in getitem:  28779\n",
      "Test inds:  [(386, 407)]\n",
      "Ann_id in getitem:  9575\n",
      "Test inds:  [(708, 1964)]\n",
      "Ann_id in getitem:  17161\n",
      "Test inds:  [(1313, 2758)]\n",
      "Ann_id in getitem:  30718\n",
      "Test inds:  [(448, 847)]\n",
      "Ann_id in getitem:  10935\n",
      "Test inds:  [(2346, 1841)]\n",
      "Ann_id in getitem:  52945\n",
      "Test inds:  [(3554, 589)]\n",
      "Ann_id in getitem:  81952\n",
      "Test inds:  [(2237, 3605)]\n",
      "Ann_id in getitem:  50411\n",
      "Test inds:  [(1886, 1020)]\n",
      "Ann_id in getitem:  43376\n",
      "Test inds:  [(2210, 3458)]\n",
      "Ann_id in getitem:  49723\n",
      "Test inds:  [(2075, 2412)]\n",
      "Ann_id in getitem:  47137\n",
      "Test inds:  [(3656, 1300)]\n",
      "Ann_id in getitem:  84466\n",
      "Test inds:  [(838, 2785)]\n",
      "Ann_id in getitem:  20143\n",
      "Test inds:  [(2283, 3182)]\n",
      "Ann_id in getitem:  51617\n",
      "Test inds:  [(3196, 875)]\n",
      "Ann_id in getitem:  73530\n",
      "Test inds:  [(2453, 2572)]\n",
      "Ann_id in getitem:  55705\n",
      "Test inds:  [(3070, 194)]\n",
      "Ann_id in getitem:  70743\n",
      "Test inds:  [(2099, 859)]\n",
      "Ann_id in getitem:  47510\n",
      "Test inds:  [(1877, 2991)]\n",
      "Ann_id in getitem:  43172\n",
      "Test inds:  [(3371, 2556)]\n",
      "Ann_id in getitem:  77508\n",
      "Test inds:  [(1889, 2999)]\n",
      "Ann_id in getitem:  43405\n",
      "Test inds:  [(2822, 1039)]\n",
      "Ann_id in getitem:  65049\n",
      "Test inds:  [(3127, 3427)]\n",
      "Ann_id in getitem:  72114\n",
      "Test inds:  [(256, 1782)]\n",
      "Ann_id in getitem:  6151\n",
      "Test inds:  [(2110, 2587)]\n",
      "Ann_id in getitem:  47851\n",
      "Test inds:  [(2496, 970)]\n",
      "Ann_id in getitem:  56792\n",
      "Test inds:  [(3567, 1811)]\n",
      "Ann_id in getitem:  82265\n",
      "Test inds:  [(1789, 3399)]\n",
      "Ann_id in getitem:  41293\n",
      "Test inds:  [(143, 3324)]\n",
      "Ann_id in getitem:  3464\n",
      "Test inds:  [(628, 1429)]\n",
      "Ann_id in getitem:  15327\n",
      "Test inds:  [(2279, 218)]\n",
      "Ann_id in getitem:  51542\n",
      "Test inds:  [(2640, 2779)]\n",
      "Ann_id in getitem:  60456\n",
      "Test inds:  [(2686, 1014)]\n",
      "Ann_id in getitem:  61648\n",
      "Test inds:  [(317, 2116)]\n",
      "Ann_id in getitem:  7732\n",
      "Test inds:  [(2291, 1448)]\n",
      "Ann_id in getitem:  51732\n",
      "Test inds:  [(1493, 109)]\n",
      "Ann_id in getitem:  35480\n",
      "Test inds:  [(3105, 1898)]\n",
      "Ann_id in getitem:  71652\n",
      "Test inds:  [(674, 3543)]\n",
      "Ann_id in getitem:  16395\n",
      "Test inds:  [(2303, 363)]\n",
      "Ann_id in getitem:  51932\n",
      "Test inds:  [(1661, 492)]\n",
      "Ann_id in getitem:  38859\n",
      "Test inds:  [(1144, 2620)]\n",
      "Ann_id in getitem:  26728\n",
      "Test inds:  [(273, 865)]\n",
      "Ann_id in getitem:  6475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2936, 1456)]\n",
      "Ann_id in getitem:  67660\n",
      "Test inds:  [(117, 3361)]\n",
      "Ann_id in getitem:  2734\n",
      "Test inds:  [(1691, 2715)]\n",
      "Ann_id in getitem:  39673\n",
      "Test inds:  [(3080, 1869)]\n",
      "Ann_id in getitem:  71062\n",
      "Test inds:  [(1163, 2484)]\n",
      "Ann_id in getitem:  27101\n",
      "Test inds:  [(2039, 1682)]\n",
      "Ann_id in getitem:  46433\n",
      "Test inds:  [(3323, 3081)]\n",
      "Ann_id in getitem:  76368\n",
      "Test inds:  [(1049, 329)]\n",
      "Ann_id in getitem:  24779\n",
      "Test inds:  [(2088, 2315)]\n",
      "Ann_id in getitem:  47370\n",
      "Test inds:  [(1437, 2684)]\n",
      "Ann_id in getitem:  34092\n",
      "Test inds:  [(2954, 3244)]\n",
      "Ann_id in getitem:  68034\n",
      "Test inds:  [(476, 2907)]\n",
      "Ann_id in getitem:  11512\n",
      "Test inds:  [(3575, 155)]\n",
      "Ann_id in getitem:  82426\n",
      "Test inds:  [(2469, 1301)]\n",
      "Ann_id in getitem:  56160\n",
      "Test inds:  [(910, 481)]\n",
      "Ann_id in getitem:  21662\n",
      "Test inds:  [(1671, 1456)]\n",
      "Ann_id in getitem:  39137\n",
      "Test inds:  [(2931, 3156)]\n",
      "Ann_id in getitem:  67503\n",
      "Test inds:  [(1386, 2300)]\n",
      "Ann_id in getitem:  32931\n",
      "Test inds:  [(741, 1516)]\n",
      "Ann_id in getitem:  17964\n",
      "Test inds:  [(3033, 1730)]\n",
      "Ann_id in getitem:  69913\n",
      "Test inds:  [(1840, 2754)]\n",
      "Ann_id in getitem:  42233\n",
      "Test inds:  [(3348, 779)]\n",
      "Ann_id in getitem:  76887\n",
      "Test inds:  [(3027, 3489)]\n",
      "Ann_id in getitem:  69827\n",
      "Test inds:  [(1786, 1411)]\n",
      "Ann_id in getitem:  41184\n",
      "Test inds:  [(1652, 2880)]\n",
      "Ann_id in getitem:  38696\n",
      "Test inds:  [(3655, 1075)]\n",
      "Ann_id in getitem:  84414\n",
      "Test inds:  [(2366, 873)]\n",
      "Ann_id in getitem:  53509\n",
      "Test inds:  [(1912, 1232)]\n",
      "Ann_id in getitem:  43775\n",
      "Test inds:  [(2999, 2712)]\n",
      "Ann_id in getitem:  69118\n",
      "Test inds:  [(2326, 1476)]\n",
      "Ann_id in getitem:  52380\n",
      "Test inds:  [(1792, 1683)]\n",
      "Ann_id in getitem:  41410\n",
      "Test inds:  [(826, 3005)]\n",
      "Ann_id in getitem:  19812\n",
      "Test inds:  [(1461, 567)]\n",
      "Ann_id in getitem:  34611\n",
      "Test inds:  [(1629, 743)]\n",
      "Ann_id in getitem:  38235\n",
      "Test inds:  [(3513, 2296)]\n",
      "Ann_id in getitem:  81072\n",
      "Test inds:  [(1553, 1260)]\n",
      "Ann_id in getitem:  36713\n",
      "Test inds:  [(150, 213)]\n",
      "Ann_id in getitem:  3728\n",
      "Test inds:  [(2096, 549)]\n",
      "Ann_id in getitem:  47456\n",
      "Test inds:  [(1910, 3070)]\n",
      "Ann_id in getitem:  43755\n",
      "Test inds:  [(340, 465)]\n",
      "Ann_id in getitem:  8272\n",
      "Test inds:  [(1983, 3663)]\n",
      "Ann_id in getitem:  45234\n",
      "Test inds:  [(1657, 2271)]\n",
      "Ann_id in getitem:  38797\n",
      "Test inds:  [(3506, 1840)]\n",
      "Ann_id in getitem:  80903\n",
      "Test inds:  [(1267, 3269)]\n",
      "Ann_id in getitem:  29605\n",
      "Test inds:  [(2934, 701)]\n",
      "Ann_id in getitem:  67627\n",
      "Test inds:  [(2558, 339)]\n",
      "Ann_id in getitem:  58138\n",
      "Test inds:  [(1344, 1136)]\n",
      "Ann_id in getitem:  31651\n",
      "Test inds:  [(768, 2565)]\n",
      "Ann_id in getitem:  18562\n",
      "Test inds:  [(3617, 2794)]\n",
      "Ann_id in getitem:  83519\n",
      "Test inds:  [(1532, 329)]\n",
      "Ann_id in getitem:  36246\n",
      "Test inds:  [(1310, 2828)]\n",
      "Ann_id in getitem:  30641\n",
      "Test inds:  [(2482, 1461)]\n",
      "Ann_id in getitem:  56501\n",
      "Test inds:  [(3493, 3427)]\n",
      "Ann_id in getitem:  80490\n",
      "Test inds:  [(1109, 792)]\n",
      "Ann_id in getitem:  25766\n",
      "Test inds:  [(2841, 1083)]\n",
      "Ann_id in getitem:  65428\n",
      "Test inds:  [(2376, 1713)]\n",
      "Ann_id in getitem:  53701\n",
      "Test inds:  [(2514, 3680)]\n",
      "Ann_id in getitem:  57172\n",
      "Test inds:  [(1081, 2076)]\n",
      "Ann_id in getitem:  25257\n",
      "Test inds:  [(1588, 3156)]\n",
      "Ann_id in getitem:  37450\n",
      "Test inds:  [(1609, 2007)]\n",
      "Ann_id in getitem:  37795\n",
      "Test inds:  [(2533, 475)]\n",
      "Ann_id in getitem:  57496\n",
      "Test inds:  [(2791, 2354)]\n",
      "Ann_id in getitem:  64441\n",
      "Test inds:  [(1632, 2943)]\n",
      "Ann_id in getitem:  38294\n",
      "Test inds:  [(622, 1822)]\n",
      "Ann_id in getitem:  15189\n",
      "Test inds:  [(363, 624)]\n",
      "Ann_id in getitem:  8754\n",
      "Test inds:  [(1947, 1619)]\n",
      "Ann_id in getitem:  44320\n",
      "Test inds:  [(216, 1171)]\n",
      "Ann_id in getitem:  5384\n",
      "Test inds:  [(1665, 2462)]\n",
      "Ann_id in getitem:  38955\n",
      "Test inds:  [(893, 1963)]\n",
      "Ann_id in getitem:  21407\n",
      "Test inds:  [(1221, 223)]\n",
      "Ann_id in getitem:  28520\n",
      "Test inds:  [(3387, 2678)]\n",
      "Ann_id in getitem:  77849\n",
      "Test inds:  [(2485, 2138)]\n",
      "Ann_id in getitem:  56558\n",
      "Test inds:  [(2782, 1697)]\n",
      "Ann_id in getitem:  64161\n",
      "Test inds:  [(1683, 1169)]\n",
      "Ann_id in getitem:  39490\n",
      "Test inds:  [(724, 1622)]\n",
      "Ann_id in getitem:  17539\n",
      "Test inds:  [(2328, 1429)]\n",
      "Ann_id in getitem:  52512\n",
      "Test inds:  [(2618, 1194)]\n",
      "Ann_id in getitem:  59927\n",
      "Test inds:  [(221, 3247)]\n",
      "Ann_id in getitem:  5433\n",
      "Test inds:  [(128, 3021)]\n",
      "Ann_id in getitem:  3043\n",
      "Test inds:  [(521, 1312)]\n",
      "Ann_id in getitem:  12427\n",
      "Test inds:  [(3256, 549)]\n",
      "Ann_id in getitem:  74775\n",
      "Test inds:  [(2936, 2968)]\n",
      "Ann_id in getitem:  67660\n",
      "Test inds:  [(1282, 1742)]\n",
      "Ann_id in getitem:  30006\n",
      "Test inds:  [(1603, 2970)]\n",
      "Ann_id in getitem:  37765\n",
      "Test inds:  [(3487, 418)]\n",
      "Ann_id in getitem:  80344\n",
      "Test inds:  [(2598, 893)]\n",
      "Ann_id in getitem:  59529\n",
      "Test inds:  [(2109, 2397)]\n",
      "Ann_id in getitem:  47795\n",
      "Test inds:  [(3195, 1880)]\n",
      "Ann_id in getitem:  73521\n",
      "Test inds:  [(1814, 914)]\n",
      "Ann_id in getitem:  41772\n",
      "Test inds:  [(2687, 3292)]\n",
      "Ann_id in getitem:  61673\n",
      "Test inds:  [(1636, 987)]\n",
      "Ann_id in getitem:  38356\n",
      "Test inds:  [(52, 2384)]\n",
      "Ann_id in getitem:  1104\n",
      "Test inds:  [(2995, 3181)]\n",
      "Ann_id in getitem:  69035\n",
      "Test inds:  [(3259, 2672)]\n",
      "Ann_id in getitem:  74810\n",
      "Test inds:  [(3394, 1468)]\n",
      "Ann_id in getitem:  78013\n",
      "Test inds:  [(24, 441)]\n",
      "Ann_id in getitem:  478\n",
      "Test inds:  [(731, 575)]\n",
      "Ann_id in getitem:  17755\n",
      "Test inds:  [(2957, 997)]\n",
      "Ann_id in getitem:  68075\n",
      "Test inds:  [(2413, 1225)]\n",
      "Ann_id in getitem:  54599\n",
      "Test inds:  [(3351, 1613)]\n",
      "Ann_id in getitem:  76900\n",
      "Test inds:  [(656, 1739)]\n",
      "Ann_id in getitem:  15995\n",
      "Test inds:  [(1974, 2582)]\n",
      "Ann_id in getitem:  44994\n",
      "Test inds:  [(968, 562)]\n",
      "Ann_id in getitem:  22864\n",
      "Test inds:  [(3657, 2453)]\n",
      "Ann_id in getitem:  84471\n",
      "Test inds:  [(1524, 899)]\n",
      "Ann_id in getitem:  36083\n",
      "Test inds:  [(2057, 1836)]\n",
      "Ann_id in getitem:  46834\n",
      "Test inds:  [(453, 3216)]\n",
      "Ann_id in getitem:  10960\n",
      "Test inds:  [(2758, 288)]\n",
      "Ann_id in getitem:  63437\n",
      "Test inds:  [(2603, 2812)]\n",
      "Ann_id in getitem:  59660\n",
      "Test inds:  [(2286, 2910)]\n",
      "Ann_id in getitem:  51635\n",
      "Test inds:  [(1642, 2345)]\n",
      "Ann_id in getitem:  38504\n",
      "Test inds:  [(3663, 2918)]\n",
      "Ann_id in getitem:  84593\n",
      "Test inds:  [(435, 1099)]\n",
      "Ann_id in getitem:  10668\n",
      "Test inds:  [(2340, 2674)]\n",
      "Ann_id in getitem:  52787\n",
      "Test inds:  [(172, 1515)]\n",
      "Ann_id in getitem:  4355\n",
      "Test inds:  [(2165, 1516)]\n",
      "Ann_id in getitem:  48865\n",
      "Test inds:  [(1891, 2496)]\n",
      "Ann_id in getitem:  43422\n",
      "Test inds:  [(57, 3381)]\n",
      "Ann_id in getitem:  1221\n",
      "Test inds:  [(1205, 155)]\n",
      "Ann_id in getitem:  28095\n",
      "Test inds:  [(1927, 2629)]\n",
      "Ann_id in getitem:  44037\n",
      "Test inds:  [(2325, 144)]\n",
      "Ann_id in getitem:  52356\n",
      "Test inds:  [(1490, 1177)]\n",
      "Ann_id in getitem:  35393\n",
      "Test inds:  [(836, 2324)]\n",
      "Ann_id in getitem:  20033\n",
      "Test inds:  [(2704, 1914)]\n",
      "Ann_id in getitem:  62146\n",
      "Test inds:  [(853, 3395)]\n",
      "Ann_id in getitem:  20770\n",
      "Test inds:  [(2499, 2539)]\n",
      "Ann_id in getitem:  56897\n",
      "Test inds:  [(370, 1138)]\n",
      "Ann_id in getitem:  9006\n",
      "Test inds:  [(1937, 230)]\n",
      "Ann_id in getitem:  44178\n",
      "Test inds:  [(839, 2866)]\n",
      "Ann_id in getitem:  20148\n",
      "Test inds:  [(2511, 3521)]\n",
      "Ann_id in getitem:  57146\n",
      "Test inds:  [(3069, 1657)]\n",
      "Ann_id in getitem:  70739\n",
      "Test inds:  [(246, 2730)]\n",
      "Ann_id in getitem:  5958\n",
      "Test inds:  [(2499, 1874)]\n",
      "Ann_id in getitem:  56897\n",
      "Test inds:  [(3469, 734)]\n",
      "Ann_id in getitem:  80073\n",
      "Test inds:  [(1936, 2171)]\n",
      "Ann_id in getitem:  44151\n",
      "Test inds:  [(2908, 1704)]\n",
      "Ann_id in getitem:  67070\n",
      "Test inds:  [(427, 2066)]\n",
      "Ann_id in getitem:  10533\n",
      "Test inds:  [(2907, 567)]\n",
      "Ann_id in getitem:  67051\n",
      "Test inds:  [(2422, 1927)]\n",
      "Ann_id in getitem:  54775\n",
      "Test inds:  [(522, 2909)]\n",
      "Ann_id in getitem:  12433\n",
      "Test inds:  [(2064, 908)]\n",
      "Ann_id in getitem:  46982\n",
      "Test inds:  [(2100, 290)]\n",
      "Ann_id in getitem:  47529\n",
      "Test inds:  [(3238, 1684)]\n",
      "Ann_id in getitem:  74418\n",
      "Test inds:  [(2312, 1567)]\n",
      "Ann_id in getitem:  52100\n",
      "Test inds:  [(1950, 1588)]\n",
      "Ann_id in getitem:  44354\n",
      "Test inds:  [(3626, 580)]\n",
      "Ann_id in getitem:  83645\n",
      "Test inds:  [(3114, 1954)]\n",
      "Ann_id in getitem:  71805\n",
      "Test inds:  [(3285, 241)]\n",
      "Ann_id in getitem:  75249\n",
      "Test inds:  [(965, 1845)]\n",
      "Ann_id in getitem:  22851\n",
      "Test inds:  [(1421, 1234)]\n",
      "Ann_id in getitem:  33710\n",
      "Test inds:  [(1337, 440)]\n",
      "Ann_id in getitem:  31421\n",
      "Test inds:  [(2211, 1011)]\n",
      "Ann_id in getitem:  49740\n",
      "Test inds:  [(3415, 1815)]\n",
      "Ann_id in getitem:  78683\n",
      "Test inds:  [(1763, 950)]\n",
      "Ann_id in getitem:  40781\n",
      "Test inds:  [(1538, 3477)]\n",
      "Ann_id in getitem:  36453\n",
      "Test inds:  [(3072, 1258)]\n",
      "Ann_id in getitem:  70804\n",
      "Test inds:  [(200, 851)]\n",
      "Ann_id in getitem:  5008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2052, 2205)]\n",
      "Ann_id in getitem:  46731\n",
      "Test inds:  [(2727, 738)]\n",
      "Ann_id in getitem:  62746\n",
      "Test inds:  [(3340, 1345)]\n",
      "Ann_id in getitem:  76767\n",
      "Test inds:  [(2361, 1767)]\n",
      "Ann_id in getitem:  53387\n",
      "Test inds:  [(2673, 2713)]\n",
      "Ann_id in getitem:  61322\n",
      "Test inds:  [(617, 1616)]\n",
      "Ann_id in getitem:  15161\n",
      "Test inds:  [(2634, 1784)]\n",
      "Ann_id in getitem:  60296\n",
      "Test inds:  [(1803, 6)]\n",
      "Ann_id in getitem:  41600\n",
      "Test inds:  [(3243, 1620)]\n",
      "Ann_id in getitem:  74554\n",
      "Test inds:  [(550, 263)]\n",
      "Ann_id in getitem:  13214\n",
      "Test inds:  [(2078, 3078)]\n",
      "Ann_id in getitem:  47189\n",
      "Test inds:  [(191, 3258)]\n",
      "Ann_id in getitem:  4844\n",
      "Test inds:  [(2423, 823)]\n",
      "Ann_id in getitem:  54783\n",
      "Test inds:  [(1101, 2537)]\n",
      "Ann_id in getitem:  25609\n",
      "Test inds:  [(2441, 231)]\n",
      "Ann_id in getitem:  55355\n",
      "Test inds:  [(2456, 2769)]\n",
      "Ann_id in getitem:  55772\n",
      "Test inds:  [(2335, 1760)]\n",
      "Ann_id in getitem:  52659\n",
      "Test inds:  [(2611, 179)]\n",
      "Ann_id in getitem:  59841\n",
      "Test inds:  [(3140, 2505)]\n",
      "Ann_id in getitem:  72439\n",
      "Test inds:  [(239, 591)]\n",
      "Ann_id in getitem:  5812\n",
      "Test inds:  [(1349, 2243)]\n",
      "Ann_id in getitem:  31795\n",
      "Test inds:  [(1338, 85)]\n",
      "Ann_id in getitem:  31425\n",
      "Test inds:  [(49, 235)]\n",
      "Ann_id in getitem:  981\n",
      "Test inds:  [(3243, 2308)]\n",
      "Ann_id in getitem:  74554\n",
      "Test inds:  [(989, 2593)]\n",
      "Ann_id in getitem:  23534\n",
      "Test inds:  [(3105, 829)]\n",
      "Ann_id in getitem:  71652\n",
      "Test inds:  [(3331, 3391)]\n",
      "Ann_id in getitem:  76562\n",
      "Test inds:  [(3401, 2416)]\n",
      "Ann_id in getitem:  78262\n",
      "Test inds:  [(3355, 33)]\n",
      "Ann_id in getitem:  76950\n",
      "Test inds:  [(1548, 545)]\n",
      "Ann_id in getitem:  36579\n",
      "Test inds:  [(3635, 3289)]\n",
      "Ann_id in getitem:  83942\n",
      "Test inds:  [(1994, 1309)]\n",
      "Ann_id in getitem:  45456\n",
      "Test inds:  [(3231, 1072)]\n",
      "Ann_id in getitem:  74274\n",
      "Test inds:  [(2197, 1953)]\n",
      "Ann_id in getitem:  49493\n",
      "Test inds:  [(3626, 2878)]\n",
      "Ann_id in getitem:  83645\n",
      "Test inds:  [(2725, 3150)]\n",
      "Ann_id in getitem:  62664\n",
      "Test inds:  [(410, 1062)]\n",
      "Ann_id in getitem:  10031\n",
      "Test inds:  [(998, 48)]\n",
      "Ann_id in getitem:  23696\n",
      "Test inds:  [(1087, 3105)]\n",
      "Ann_id in getitem:  25373\n",
      "Test inds:  [(1308, 3491)]\n",
      "Ann_id in getitem:  30609\n",
      "Test inds:  [(1499, 3206)]\n",
      "Ann_id in getitem:  35667\n",
      "Test inds:  [(3545, 3382)]\n",
      "Ann_id in getitem:  81789\n",
      "Test inds:  [(3332, 470)]\n",
      "Ann_id in getitem:  76597\n",
      "Test inds:  [(2901, 1956)]\n",
      "Ann_id in getitem:  66792\n",
      "Test inds:  [(3149, 1440)]\n",
      "Ann_id in getitem:  72598\n",
      "Test inds:  [(2290, 853)]\n",
      "Ann_id in getitem:  51723\n",
      "Test inds:  [(1906, 2574)]\n",
      "Ann_id in getitem:  43699\n",
      "Test inds:  [(106, 2974)]\n",
      "Ann_id in getitem:  2405\n",
      "Test inds:  [(2635, 2399)]\n",
      "Ann_id in getitem:  60300\n",
      "Test inds:  [(454, 1620)]\n",
      "Ann_id in getitem:  10973\n",
      "Test inds:  [(2129, 1693)]\n",
      "Ann_id in getitem:  48222\n",
      "Test inds:  [(2583, 1518)]\n",
      "Ann_id in getitem:  59052\n",
      "Test inds:  [(817, 3678)]\n",
      "Ann_id in getitem:  19685\n",
      "Test inds:  [(1295, 1371)]\n",
      "Ann_id in getitem:  30372\n",
      "Test inds:  [(1840, 623)]\n",
      "Ann_id in getitem:  42233\n",
      "Test inds:  [(1667, 3310)]\n",
      "Ann_id in getitem:  38983\n",
      "Test inds:  [(1192, 104)]\n",
      "Ann_id in getitem:  27755\n",
      "Test inds:  [(948, 559)]\n",
      "Ann_id in getitem:  22514\n",
      "Test inds:  [(1942, 3170)]\n",
      "Ann_id in getitem:  44241\n",
      "Test inds:  [(2871, 2466)]\n",
      "Ann_id in getitem:  66019\n",
      "Test inds:  [(633, 3373)]\n",
      "Ann_id in getitem:  15411\n",
      "Test inds:  [(1380, 1779)]\n",
      "Ann_id in getitem:  32809\n",
      "Test inds:  [(1358, 2585)]\n",
      "Ann_id in getitem:  32038\n",
      "Test inds:  [(197, 2491)]\n",
      "Ann_id in getitem:  4957\n",
      "Test inds:  [(3200, 2704)]\n",
      "Ann_id in getitem:  73653\n",
      "Test inds:  [(1106, 3406)]\n",
      "Ann_id in getitem:  25701\n",
      "Test inds:  [(1579, 2749)]\n",
      "Ann_id in getitem:  37354\n",
      "Test inds:  [(613, 186)]\n",
      "Ann_id in getitem:  14979\n",
      "Test inds:  [(2977, 3679)]\n",
      "Ann_id in getitem:  68578\n",
      "Test inds:  [(123, 1677)]\n",
      "Ann_id in getitem:  2946\n",
      "Test inds:  [(2837, 3460)]\n",
      "Ann_id in getitem:  65387\n",
      "Test inds:  [(1107, 3422)]\n",
      "Ann_id in getitem:  25712\n",
      "Test inds:  [(534, 2022)]\n",
      "Ann_id in getitem:  12713\n",
      "Test inds:  [(3007, 1795)]\n",
      "Ann_id in getitem:  69275\n",
      "Test inds:  [(3489, 2009)]\n",
      "Ann_id in getitem:  80394\n",
      "Test inds:  [(657, 1780)]\n",
      "Ann_id in getitem:  16073\n",
      "Test inds:  [(3103, 2525)]\n",
      "Ann_id in getitem:  71590\n",
      "Test inds:  [(591, 317)]\n",
      "Ann_id in getitem:  14343\n",
      "Test inds:  [(1629, 680)]\n",
      "Ann_id in getitem:  38235\n",
      "Test inds:  [(630, 679)]\n",
      "Ann_id in getitem:  15378\n",
      "Test inds:  [(2414, 2437)]\n",
      "Ann_id in getitem:  54601\n",
      "Test inds:  [(2074, 2216)]\n",
      "Ann_id in getitem:  47124\n",
      "Test inds:  [(899, 1476)]\n",
      "Ann_id in getitem:  21516\n",
      "Test inds:  [(672, 3037)]\n",
      "Ann_id in getitem:  16341\n",
      "Test inds:  [(2864, 1073)]\n",
      "Ann_id in getitem:  65865\n",
      "Test inds:  [(3116, 1977)]\n",
      "Ann_id in getitem:  71909\n",
      "Test inds:  [(21, 1831)]\n",
      "Ann_id in getitem:  455\n",
      "Test inds:  [(1073, 1828)]\n",
      "Ann_id in getitem:  25160\n",
      "Test inds:  [(908, 1420)]\n",
      "Ann_id in getitem:  21641\n",
      "Test inds:  [(2990, 3599)]\n",
      "Ann_id in getitem:  68939\n",
      "Test inds:  [(1668, 1303)]\n",
      "Ann_id in getitem:  39009\n",
      "Test inds:  [(3547, 1112)]\n",
      "Ann_id in getitem:  81836\n",
      "Test inds:  [(3374, 2384)]\n",
      "Ann_id in getitem:  77630\n",
      "Test inds:  [(1898, 1302)]\n",
      "Ann_id in getitem:  43542\n",
      "Test inds:  [(6, 1098)]\n",
      "Ann_id in getitem:  109\n",
      "Test inds:  [(1707, 3539)]\n",
      "Ann_id in getitem:  39944\n",
      "Test inds:  [(1501, 2943)]\n",
      "Ann_id in getitem:  35694\n",
      "Test inds:  [(2916, 1580)]\n",
      "Ann_id in getitem:  67135\n",
      "Test inds:  [(3050, 3657)]\n",
      "Ann_id in getitem:  70297\n",
      "Test inds:  [(3262, 3028)]\n",
      "Ann_id in getitem:  74853\n",
      "Test inds:  [(1234, 3477)]\n",
      "Ann_id in getitem:  28883\n",
      "Test inds:  [(361, 2479)]\n",
      "Ann_id in getitem:  8733\n",
      "Test inds:  [(2426, 754)]\n",
      "Ann_id in getitem:  54841\n",
      "Test inds:  [(311, 2780)]\n",
      "Ann_id in getitem:  7522\n",
      "Test inds:  [(2136, 536)]\n",
      "Ann_id in getitem:  48396\n",
      "Test inds:  [(3312, 1449)]\n",
      "Ann_id in getitem:  76011\n",
      "Test inds:  [(3421, 2609)]\n",
      "Ann_id in getitem:  78822\n",
      "Test inds:  [(422, 2434)]\n",
      "Ann_id in getitem:  10243\n",
      "Test inds:  [(3088, 200)]\n",
      "Ann_id in getitem:  71214\n",
      "Test inds:  [(1437, 2904)]\n",
      "Ann_id in getitem:  34092\n",
      "Test inds:  [(3542, 3493)]\n",
      "Ann_id in getitem:  81710\n",
      "Test inds:  [(1477, 1213)]\n",
      "Ann_id in getitem:  35022\n",
      "Test inds:  [(540, 70)]\n",
      "Ann_id in getitem:  12851\n",
      "Test inds:  [(473, 2543)]\n",
      "Ann_id in getitem:  11331\n",
      "Test inds:  [(585, 329)]\n",
      "Ann_id in getitem:  14218\n",
      "Test inds:  [(1331, 2428)]\n",
      "Ann_id in getitem:  31292\n",
      "Test inds:  [(1541, 1848)]\n",
      "Ann_id in getitem:  36508\n",
      "Test inds:  [(2861, 1476)]\n",
      "Ann_id in getitem:  65734\n",
      "Test inds:  [(2424, 1836)]\n",
      "Ann_id in getitem:  54798\n",
      "Test inds:  [(3073, 1913)]\n",
      "Ann_id in getitem:  70816\n",
      "Test inds:  [(2970, 2686)]\n",
      "Ann_id in getitem:  68330\n",
      "Test inds:  [(1842, 3647)]\n",
      "Ann_id in getitem:  42373\n",
      "Test inds:  [(741, 2491)]\n",
      "Ann_id in getitem:  17964\n",
      "Test inds:  [(440, 2211)]\n",
      "Ann_id in getitem:  10730\n",
      "Test inds:  [(1649, 3380)]\n",
      "Ann_id in getitem:  38628\n",
      "Test inds:  [(1482, 1561)]\n",
      "Ann_id in getitem:  35136\n",
      "Test inds:  [(2363, 901)]\n",
      "Ann_id in getitem:  53396\n",
      "Test inds:  [(2846, 1897)]\n",
      "Ann_id in getitem:  65541\n",
      "Test inds:  [(2881, 3345)]\n",
      "Ann_id in getitem:  66219\n",
      "Test inds:  [(2201, 2055)]\n",
      "Ann_id in getitem:  49577\n",
      "Test inds:  [(3658, 2912)]\n",
      "Ann_id in getitem:  84486\n",
      "Test inds:  [(1783, 1665)]\n",
      "Ann_id in getitem:  41100\n",
      "Test inds:  [(1597, 3128)]\n",
      "Ann_id in getitem:  37704\n",
      "Test inds:  [(2226, 3517)]\n",
      "Ann_id in getitem:  50147\n",
      "Test inds:  [(1792, 463)]\n",
      "Ann_id in getitem:  41410\n",
      "Test inds:  [(1875, 2519)]\n",
      "Ann_id in getitem:  43151\n",
      "Test inds:  [(225, 433)]\n",
      "Ann_id in getitem:  5509\n",
      "Test inds:  [(3385, 2832)]\n",
      "Ann_id in getitem:  77829\n",
      "Test inds:  [(1905, 2482)]\n",
      "Ann_id in getitem:  43680\n",
      "Test inds:  [(1430, 3145)]\n",
      "Ann_id in getitem:  33895\n",
      "Test inds:  [(3441, 2104)]\n",
      "Ann_id in getitem:  79336\n",
      "Test inds:  [(2793, 2289)]\n",
      "Ann_id in getitem:  64471\n",
      "Test inds:  [(928, 3304)]\n",
      "Ann_id in getitem:  22166\n",
      "Test inds:  [(1641, 1605)]\n",
      "Ann_id in getitem:  38500\n",
      "Test inds:  [(1791, 3638)]\n",
      "Ann_id in getitem:  41406\n",
      "Test inds:  [(2577, 2445)]\n",
      "Ann_id in getitem:  58761\n",
      "Test inds:  [(2166, 807)]\n",
      "Ann_id in getitem:  48868\n",
      "Test inds:  [(2659, 1206)]\n",
      "Ann_id in getitem:  61016\n",
      "Test inds:  [(224, 178)]\n",
      "Ann_id in getitem:  5459\n",
      "Test inds:  [(2540, 749)]\n",
      "Ann_id in getitem:  57675\n",
      "Test inds:  [(3419, 1769)]\n",
      "Ann_id in getitem:  78749\n",
      "Test inds:  [(3190, 3212)]\n",
      "Ann_id in getitem:  73432\n",
      "Test inds:  [(2588, 1574)]\n",
      "Ann_id in getitem:  59353\n",
      "Test inds:  [(1454, 1984)]\n",
      "Ann_id in getitem:  34463\n",
      "Test inds:  [(40, 2267)]\n",
      "Ann_id in getitem:  882\n",
      "Test inds:  [(3185, 1008)]\n",
      "Ann_id in getitem:  73339\n",
      "Test inds:  [(924, 706)]\n",
      "Ann_id in getitem:  22119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1105, 1773)]\n",
      "Ann_id in getitem:  25692\n",
      "Test inds:  [(3599, 1563)]\n",
      "Ann_id in getitem:  83057\n",
      "Test inds:  [(699, 148)]\n",
      "Ann_id in getitem:  16995\n",
      "Test inds:  [(2562, 712)]\n",
      "Ann_id in getitem:  58233\n",
      "Test inds:  [(2367, 295)]\n",
      "Ann_id in getitem:  53536\n",
      "Test inds:  [(3645, 1893)]\n",
      "Ann_id in getitem:  84145\n",
      "Test inds:  [(2697, 748)]\n",
      "Ann_id in getitem:  62007\n",
      "Test inds:  [(1215, 1925)]\n",
      "Ann_id in getitem:  28350\n",
      "Test inds:  [(1777, 969)]\n",
      "Ann_id in getitem:  41029\n",
      "Test inds:  [(1776, 1794)]\n",
      "Ann_id in getitem:  41018\n",
      "Test inds:  [(2953, 388)]\n",
      "Ann_id in getitem:  68021\n",
      "Test inds:  [(718, 457)]\n",
      "Ann_id in getitem:  17374\n",
      "Test inds:  [(2428, 279)]\n",
      "Ann_id in getitem:  54859\n",
      "Test inds:  [(3388, 2910)]\n",
      "Ann_id in getitem:  77853\n",
      "Test inds:  [(2970, 2403)]\n",
      "Ann_id in getitem:  68330\n",
      "Test inds:  [(1359, 2883)]\n",
      "Ann_id in getitem:  32039\n",
      "Test inds:  [(689, 1960)]\n",
      "Ann_id in getitem:  16759\n",
      "Test inds:  [(898, 2429)]\n",
      "Ann_id in getitem:  21512\n",
      "Test inds:  [(1957, 1193)]\n",
      "Ann_id in getitem:  44503\n",
      "Test inds:  [(1317, 3651)]\n",
      "Ann_id in getitem:  30813\n",
      "Test inds:  [(1121, 1645)]\n",
      "Ann_id in getitem:  26049\n",
      "Test inds:  [(2255, 1607)]\n",
      "Ann_id in getitem:  50948\n",
      "Test inds:  [(478, 589)]\n",
      "Ann_id in getitem:  11519\n",
      "Test inds:  [(1181, 1889)]\n",
      "Ann_id in getitem:  27484\n",
      "Test inds:  [(271, 760)]\n",
      "Ann_id in getitem:  6443\n",
      "Test inds:  [(334, 3054)]\n",
      "Ann_id in getitem:  8173\n",
      "Test inds:  [(500, 616)]\n",
      "Ann_id in getitem:  11969\n",
      "Test inds:  [(2875, 623)]\n",
      "Ann_id in getitem:  66059\n",
      "Test inds:  [(1424, 1086)]\n",
      "Ann_id in getitem:  33765\n",
      "Test inds:  [(1176, 2536)]\n",
      "Ann_id in getitem:  27403\n",
      "Test inds:  [(1508, 572)]\n",
      "Ann_id in getitem:  35794\n",
      "Test inds:  [(321, 467)]\n",
      "Ann_id in getitem:  7911\n",
      "Test inds:  [(2327, 2574)]\n",
      "Ann_id in getitem:  52386\n",
      "Test inds:  [(1385, 2163)]\n",
      "Ann_id in getitem:  32907\n",
      "Test inds:  [(1886, 1740)]\n",
      "Ann_id in getitem:  43376\n",
      "Test inds:  [(2443, 2587)]\n",
      "Ann_id in getitem:  55515\n",
      "Test inds:  [(2613, 3587)]\n",
      "Ann_id in getitem:  59857\n",
      "Test inds:  [(74, 3680)]\n",
      "Ann_id in getitem:  1638\n",
      "Test inds:  [(195, 470)]\n",
      "Ann_id in getitem:  4882\n",
      "Test inds:  [(338, 1470)]\n",
      "Ann_id in getitem:  8233\n",
      "Test inds:  [(2558, 235)]\n",
      "Ann_id in getitem:  58138\n",
      "Test inds:  [(3123, 1500)]\n",
      "Ann_id in getitem:  72016\n",
      "Test inds:  [(158, 1342)]\n",
      "Ann_id in getitem:  4036\n",
      "Test inds:  [(2626, 247)]\n",
      "Ann_id in getitem:  60111\n",
      "Test inds:  [(3161, 967)]\n",
      "Ann_id in getitem:  72833\n",
      "Test inds:  [(2015, 1615)]\n",
      "Ann_id in getitem:  45845\n",
      "Test inds:  [(863, 1269)]\n",
      "Ann_id in getitem:  20885\n",
      "Test inds:  [(661, 271)]\n",
      "Ann_id in getitem:  16136\n",
      "Test inds:  [(2859, 1005)]\n",
      "Ann_id in getitem:  65727\n",
      "Test inds:  [(1066, 444)]\n",
      "Ann_id in getitem:  25051\n",
      "Test inds:  [(535, 949)]\n",
      "Ann_id in getitem:  12731\n",
      "Test inds:  [(1797, 135)]\n",
      "Ann_id in getitem:  41529\n",
      "Test inds:  [(1807, 3675)]\n",
      "Ann_id in getitem:  41695\n",
      "Test inds:  [(2026, 1588)]\n",
      "Ann_id in getitem:  46047\n",
      "Test inds:  [(1178, 3061)]\n",
      "Ann_id in getitem:  27434\n",
      "Test inds:  [(3603, 852)]\n",
      "Ann_id in getitem:  83130\n",
      "Test inds:  [(1236, 731)]\n",
      "Ann_id in getitem:  28894\n",
      "Test inds:  [(208, 2676)]\n",
      "Ann_id in getitem:  5209\n",
      "Test inds:  [(2441, 1489)]\n",
      "Ann_id in getitem:  55355\n",
      "Test inds:  [(2018, 1732)]\n",
      "Ann_id in getitem:  45873\n",
      "Test inds:  [(1799, 717)]\n",
      "Ann_id in getitem:  41575\n",
      "Test inds:  [(2650, 876)]\n",
      "Ann_id in getitem:  60694\n",
      "Test inds:  [(2515, 3007)]\n",
      "Ann_id in getitem:  57200\n",
      "Test inds:  [(1529, 2631)]\n",
      "Ann_id in getitem:  36191\n",
      "Test inds:  [(772, 1963)]\n",
      "Ann_id in getitem:  18730\n",
      "Test inds:  [(3629, 1680)]\n",
      "Ann_id in getitem:  83760\n",
      "Test inds:  [(1455, 60)]\n",
      "Ann_id in getitem:  34464\n",
      "Test inds:  [(1041, 265)]\n",
      "Ann_id in getitem:  24663\n",
      "Test inds:  [(1038, 2100)]\n",
      "Ann_id in getitem:  24539\n",
      "Test inds:  [(2903, 2089)]\n",
      "Ann_id in getitem:  66924\n",
      "Test inds:  [(463, 3387)]\n",
      "Ann_id in getitem:  11200\n",
      "Test inds:  [(1368, 1340)]\n",
      "Ann_id in getitem:  32346\n",
      "Test inds:  [(2442, 2391)]\n",
      "Ann_id in getitem:  55481\n",
      "Test inds:  [(1179, 2287)]\n",
      "Ann_id in getitem:  27439\n",
      "Test inds:  [(1713, 198)]\n",
      "Ann_id in getitem:  40051\n",
      "Test inds:  [(1840, 306)]\n",
      "Ann_id in getitem:  42233\n",
      "Test inds:  [(1777, 918)]\n",
      "Ann_id in getitem:  41029\n",
      "Test inds:  [(2099, 3562)]\n",
      "Ann_id in getitem:  47510\n",
      "Test inds:  [(597, 857)]\n",
      "Ann_id in getitem:  14439\n",
      "Test inds:  [(1446, 3583)]\n",
      "Ann_id in getitem:  34252\n",
      "Test inds:  [(2342, 1957)]\n",
      "Ann_id in getitem:  52873\n",
      "Test inds:  [(1681, 2932)]\n",
      "Ann_id in getitem:  39449\n",
      "Test inds:  [(684, 2520)]\n",
      "Ann_id in getitem:  16638\n",
      "Test inds:  [(2298, 2235)]\n",
      "Ann_id in getitem:  51848\n",
      "Test inds:  [(569, 3280)]\n",
      "Ann_id in getitem:  13745\n",
      "Test inds:  [(832, 175)]\n",
      "Ann_id in getitem:  19992\n",
      "Test inds:  [(1809, 1956)]\n",
      "Ann_id in getitem:  41709\n",
      "Test inds:  [(3205, 2243)]\n",
      "Ann_id in getitem:  73728\n",
      "Test inds:  [(3514, 1907)]\n",
      "Ann_id in getitem:  81076\n",
      "Test inds:  [(2736, 2955)]\n",
      "Ann_id in getitem:  63007\n",
      "Test inds:  [(344, 22)]\n",
      "Ann_id in getitem:  8323\n",
      "Test inds:  [(1409, 45)]\n",
      "Ann_id in getitem:  33336\n",
      "Test inds:  [(2122, 2488)]\n",
      "Ann_id in getitem:  48071\n",
      "Test inds:  [(1996, 2933)]\n",
      "Ann_id in getitem:  45495\n",
      "Test inds:  [(3487, 3605)]\n",
      "Ann_id in getitem:  80344\n",
      "Test inds:  [(2986, 1186)]\n",
      "Ann_id in getitem:  68894\n",
      "Test inds:  [(24, 2311)]\n",
      "Ann_id in getitem:  478\n",
      "Test inds:  [(2106, 2984)]\n",
      "Ann_id in getitem:  47683\n",
      "Test inds:  [(167, 487)]\n",
      "Ann_id in getitem:  4205\n",
      "Test inds:  [(590, 3542)]\n",
      "Ann_id in getitem:  14330\n",
      "Test inds:  [(1557, 1812)]\n",
      "Ann_id in getitem:  36794\n",
      "Test inds:  [(1780, 2996)]\n",
      "Ann_id in getitem:  41085\n",
      "Test inds:  [(1541, 3556)]\n",
      "Ann_id in getitem:  36508\n",
      "Test inds:  [(810, 770)]\n",
      "Ann_id in getitem:  19526\n",
      "Test inds:  [(1987, 366)]\n",
      "Ann_id in getitem:  45304\n",
      "Test inds:  [(3264, 3456)]\n",
      "Ann_id in getitem:  74865\n",
      "Test inds:  [(2415, 1187)]\n",
      "Ann_id in getitem:  54602\n",
      "Test inds:  [(3595, 1998)]\n",
      "Ann_id in getitem:  82901\n",
      "Test inds:  [(1061, 2843)]\n",
      "Ann_id in getitem:  24983\n",
      "Test inds:  [(2439, 3493)]\n",
      "Ann_id in getitem:  55312\n",
      "Test inds:  [(2958, 3520)]\n",
      "Ann_id in getitem:  68104\n",
      "Test inds:  [(604, 2091)]\n",
      "Ann_id in getitem:  14618\n",
      "Test inds:  [(1320, 3613)]\n",
      "Ann_id in getitem:  30875\n",
      "Test inds:  [(1327, 3463)]\n",
      "Ann_id in getitem:  31025\n",
      "Test inds:  [(2304, 869)]\n",
      "Ann_id in getitem:  51975\n",
      "Test inds:  [(2236, 610)]\n",
      "Ann_id in getitem:  50350\n",
      "Test inds:  [(1551, 1161)]\n",
      "Ann_id in getitem:  36687\n",
      "Test inds:  [(292, 3511)]\n",
      "Ann_id in getitem:  6802\n",
      "Test inds:  [(3066, 1868)]\n",
      "Ann_id in getitem:  70643\n",
      "Test inds:  [(739, 1955)]\n",
      "Ann_id in getitem:  17903\n",
      "Test inds:  [(2611, 1868)]\n",
      "Ann_id in getitem:  59841\n",
      "Test inds:  [(2521, 2015)]\n",
      "Ann_id in getitem:  57302\n",
      "Test inds:  [(2734, 246)]\n",
      "Ann_id in getitem:  62919\n",
      "Test inds:  [(3388, 3096)]\n",
      "Ann_id in getitem:  77853\n",
      "Test inds:  [(1403, 211)]\n",
      "Ann_id in getitem:  33214\n",
      "Test inds:  [(2122, 1838)]\n",
      "Ann_id in getitem:  48071\n",
      "Test inds:  [(2892, 2979)]\n",
      "Ann_id in getitem:  66507\n",
      "Test inds:  [(1467, 1745)]\n",
      "Ann_id in getitem:  34732\n",
      "Test inds:  [(3257, 3567)]\n",
      "Ann_id in getitem:  74789\n",
      "Test inds:  [(3592, 1327)]\n",
      "Ann_id in getitem:  82841\n",
      "Test inds:  [(1225, 1318)]\n",
      "Ann_id in getitem:  28589\n",
      "Test inds:  [(717, 893)]\n",
      "Ann_id in getitem:  17358\n",
      "Test inds:  [(1614, 1773)]\n",
      "Ann_id in getitem:  37855\n",
      "Test inds:  [(2482, 205)]\n",
      "Ann_id in getitem:  56501\n",
      "Test inds:  [(3625, 699)]\n",
      "Ann_id in getitem:  83643\n",
      "Test inds:  [(2606, 1928)]\n",
      "Ann_id in getitem:  59688\n",
      "Test inds:  [(1875, 2127)]\n",
      "Ann_id in getitem:  43151\n",
      "Test inds:  [(2249, 269)]\n",
      "Ann_id in getitem:  50819\n",
      "Test inds:  [(3698, 1230)]\n",
      "Ann_id in getitem:  85452\n",
      "Test inds:  [(2114, 2366)]\n",
      "Ann_id in getitem:  47929\n",
      "Test inds:  [(1801, 3222)]\n",
      "Ann_id in getitem:  41579\n",
      "Test inds:  [(1087, 489)]\n",
      "Ann_id in getitem:  25373\n",
      "Test inds:  [(2269, 2312)]\n",
      "Ann_id in getitem:  51256\n",
      "Test inds:  [(3069, 439)]\n",
      "Ann_id in getitem:  70739\n",
      "Test inds:  [(3598, 3665)]\n",
      "Ann_id in getitem:  82989\n",
      "Test inds:  [(1973, 1724)]\n",
      "Ann_id in getitem:  44991\n",
      "Test inds:  [(302, 1623)]\n",
      "Ann_id in getitem:  7096\n",
      "Test inds:  [(2472, 1555)]\n",
      "Ann_id in getitem:  56252\n",
      "Test inds:  [(3395, 1924)]\n",
      "Ann_id in getitem:  78052\n",
      "Test inds:  [(785, 213)]\n",
      "Ann_id in getitem:  19009\n",
      "Test inds:  [(740, 2877)]\n",
      "Ann_id in getitem:  17962\n",
      "Test inds:  [(286, 2472)]\n",
      "Ann_id in getitem:  6676\n",
      "Test inds:  [(204, 3593)]\n",
      "Ann_id in getitem:  5037\n",
      "Test inds:  [(1215, 202)]\n",
      "Ann_id in getitem:  28350\n",
      "Test inds:  [(3141, 2991)]\n",
      "Ann_id in getitem:  72453\n",
      "Test inds:  [(3101, 116)]\n",
      "Ann_id in getitem:  71501\n",
      "Test inds:  [(1109, 1959)]\n",
      "Ann_id in getitem:  25766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3357, 1577)]\n",
      "Ann_id in getitem:  77015\n",
      "Test inds:  [(1350, 2394)]\n",
      "Ann_id in getitem:  31821\n",
      "Test inds:  [(463, 693)]\n",
      "Ann_id in getitem:  11200\n",
      "Test inds:  [(87, 1952)]\n",
      "Ann_id in getitem:  2028\n",
      "Test inds:  [(233, 650)]\n",
      "Ann_id in getitem:  5653\n",
      "Test inds:  [(1871, 802)]\n",
      "Ann_id in getitem:  43067\n",
      "Test inds:  [(2797, 2127)]\n",
      "Ann_id in getitem:  64518\n",
      "Test inds:  [(2205, 732)]\n",
      "Ann_id in getitem:  49639\n",
      "Test inds:  [(1801, 475)]\n",
      "Ann_id in getitem:  41579\n",
      "Test inds:  [(1217, 3037)]\n",
      "Ann_id in getitem:  28419\n",
      "Test inds:  [(83, 3642)]\n",
      "Ann_id in getitem:  1886\n",
      "Test inds:  [(37, 2746)]\n",
      "Ann_id in getitem:  833\n",
      "Test inds:  [(110, 428)]\n",
      "Ann_id in getitem:  2599\n",
      "Test inds:  [(952, 1305)]\n",
      "Ann_id in getitem:  22575\n",
      "Test inds:  [(2851, 3661)]\n",
      "Ann_id in getitem:  65613\n",
      "Test inds:  [(2542, 3032)]\n",
      "Ann_id in getitem:  57740\n",
      "Test inds:  [(194, 1982)]\n",
      "Ann_id in getitem:  4857\n",
      "Test inds:  [(2795, 2819)]\n",
      "Ann_id in getitem:  64487\n",
      "Test inds:  [(3058, 2063)]\n",
      "Ann_id in getitem:  70591\n",
      "Test inds:  [(2745, 3379)]\n",
      "Ann_id in getitem:  63173\n",
      "Test inds:  [(136, 1372)]\n",
      "Ann_id in getitem:  3302\n",
      "Test inds:  [(1421, 1763)]\n",
      "Ann_id in getitem:  33710\n",
      "Test inds:  [(1566, 1301)]\n",
      "Ann_id in getitem:  36993\n",
      "Test inds:  [(2787, 678)]\n",
      "Ann_id in getitem:  64330\n",
      "Test inds:  [(915, 979)]\n",
      "Ann_id in getitem:  21802\n",
      "Test inds:  [(1866, 2006)]\n",
      "Ann_id in getitem:  42973\n",
      "Test inds:  [(3338, 1970)]\n",
      "Ann_id in getitem:  76661\n",
      "Test inds:  [(143, 1240)]\n",
      "Ann_id in getitem:  3464\n",
      "Test inds:  [(3576, 3598)]\n",
      "Ann_id in getitem:  82428\n",
      "Test inds:  [(1425, 1751)]\n",
      "Ann_id in getitem:  33797\n",
      "Test inds:  [(2772, 2440)]\n",
      "Ann_id in getitem:  63798\n",
      "Test inds:  [(3019, 2856)]\n",
      "Ann_id in getitem:  69543\n",
      "Test inds:  [(1484, 403)]\n",
      "Ann_id in getitem:  35252\n",
      "Test inds:  [(1386, 2800)]\n",
      "Ann_id in getitem:  32931\n",
      "Test inds:  [(2633, 3517)]\n",
      "Ann_id in getitem:  60290\n",
      "Test inds:  [(2716, 472)]\n",
      "Ann_id in getitem:  62454\n",
      "Test inds:  [(3403, 1420)]\n",
      "Ann_id in getitem:  78319\n",
      "Test inds:  [(2665, 2843)]\n",
      "Ann_id in getitem:  61160\n",
      "Test inds:  [(2587, 406)]\n",
      "Ann_id in getitem:  59284\n",
      "Test inds:  [(3501, 2069)]\n",
      "Ann_id in getitem:  80649\n",
      "Test inds:  [(888, 2074)]\n",
      "Ann_id in getitem:  21197\n",
      "Test inds:  [(850, 1738)]\n",
      "Ann_id in getitem:  20678\n",
      "Test inds:  [(3113, 2190)]\n",
      "Ann_id in getitem:  71793\n",
      "Test inds:  [(3141, 874)]\n",
      "Ann_id in getitem:  72453\n",
      "Test inds:  [(788, 1163)]\n",
      "Ann_id in getitem:  19055\n",
      "Test inds:  [(1622, 271)]\n",
      "Ann_id in getitem:  38043\n",
      "Test inds:  [(98, 2929)]\n",
      "Ann_id in getitem:  2158\n",
      "Test inds:  [(786, 1722)]\n",
      "Ann_id in getitem:  19042\n",
      "Test inds:  [(182, 1174)]\n",
      "Ann_id in getitem:  4653\n",
      "Test inds:  [(2376, 3238)]\n",
      "Ann_id in getitem:  53701\n",
      "Test inds:  [(3673, 973)]\n",
      "Ann_id in getitem:  84720\n",
      "Test inds:  [(1545, 1929)]\n",
      "Ann_id in getitem:  36558\n",
      "Test inds:  [(866, 949)]\n",
      "Ann_id in getitem:  20914\n",
      "Test inds:  [(1737, 2775)]\n",
      "Ann_id in getitem:  40418\n",
      "Test inds:  [(3483, 1537)]\n",
      "Ann_id in getitem:  80266\n",
      "Test inds:  [(1572, 2808)]\n",
      "Ann_id in getitem:  37199\n",
      "Test inds:  [(3297, 2518)]\n",
      "Ann_id in getitem:  75592\n",
      "Test inds:  [(1220, 1170)]\n",
      "Ann_id in getitem:  28505\n",
      "Test inds:  [(834, 264)]\n",
      "Ann_id in getitem:  20024\n",
      "Test inds:  [(2883, 2514)]\n",
      "Ann_id in getitem:  66318\n",
      "Test inds:  [(330, 688)]\n",
      "Ann_id in getitem:  8089\n",
      "Test inds:  [(706, 314)]\n",
      "Ann_id in getitem:  17137\n",
      "Test inds:  [(1906, 1135)]\n",
      "Ann_id in getitem:  43699\n",
      "Test inds:  [(3645, 2776)]\n",
      "Ann_id in getitem:  84145\n",
      "Test inds:  [(225, 1983)]\n",
      "Ann_id in getitem:  5509\n",
      "Test inds:  [(2907, 681)]\n",
      "Ann_id in getitem:  67051\n",
      "Test inds:  [(558, 2422)]\n",
      "Ann_id in getitem:  13497\n",
      "Test inds:  [(2832, 3683)]\n",
      "Ann_id in getitem:  65328\n",
      "Test inds:  [(564, 1255)]\n",
      "Ann_id in getitem:  13573\n",
      "Test inds:  [(1203, 1167)]\n",
      "Ann_id in getitem:  27952\n",
      "Test inds:  [(603, 2370)]\n",
      "Ann_id in getitem:  14592\n",
      "Test inds:  [(2559, 1431)]\n",
      "Ann_id in getitem:  58158\n",
      "Test inds:  [(1980, 148)]\n",
      "Ann_id in getitem:  45155\n",
      "Test inds:  [(1665, 400)]\n",
      "Ann_id in getitem:  38955\n",
      "Test inds:  [(1514, 1)]\n",
      "Ann_id in getitem:  35912\n",
      "Test inds:  [(28, 3126)]\n",
      "Ann_id in getitem:  589\n",
      "Test inds:  [(238, 871)]\n",
      "Ann_id in getitem:  5795\n",
      "Test inds:  [(2882, 705)]\n",
      "Ann_id in getitem:  66227\n",
      "Test inds:  [(3475, 2881)]\n",
      "Ann_id in getitem:  80163\n",
      "Test inds:  [(101, 1251)]\n",
      "Ann_id in getitem:  2219\n",
      "Test inds:  [(3305, 1659)]\n",
      "Ann_id in getitem:  75853\n",
      "Test inds:  [(24, 2271)]\n",
      "Ann_id in getitem:  478\n",
      "Test inds:  [(3174, 3254)]\n",
      "Ann_id in getitem:  73075\n",
      "Test inds:  [(665, 2159)]\n",
      "Ann_id in getitem:  16182\n",
      "Test inds:  [(77, 1815)]\n",
      "Ann_id in getitem:  1707\n",
      "Test inds:  [(3587, 2649)]\n",
      "Ann_id in getitem:  82750\n",
      "Test inds:  [(3421, 1324)]\n",
      "Ann_id in getitem:  78822\n",
      "Test inds:  [(2605, 420)]\n",
      "Ann_id in getitem:  59675\n",
      "Test inds:  [(3402, 2437)]\n",
      "Ann_id in getitem:  78308\n",
      "Test inds:  [(3460, 625)]\n",
      "Ann_id in getitem:  79849\n",
      "Test inds:  [(1434, 3577)]\n",
      "Ann_id in getitem:  33991\n",
      "Test inds:  [(3485, 3285)]\n",
      "Ann_id in getitem:  80284\n",
      "Test inds:  [(596, 1546)]\n",
      "Ann_id in getitem:  14428\n",
      "Test inds:  [(2334, 238)]\n",
      "Ann_id in getitem:  52637\n",
      "Test inds:  [(2037, 3156)]\n",
      "Ann_id in getitem:  46407\n",
      "Test inds:  [(1780, 1968)]\n",
      "Ann_id in getitem:  41085\n",
      "Test inds:  [(3651, 545)]\n",
      "Ann_id in getitem:  84307\n",
      "Test inds:  [(1554, 3296)]\n",
      "Ann_id in getitem:  36772\n",
      "Test inds:  [(939, 1099)]\n",
      "Ann_id in getitem:  22341\n",
      "Test inds:  [(638, 169)]\n",
      "Ann_id in getitem:  15466\n",
      "Test inds:  [(1218, 1255)]\n",
      "Ann_id in getitem:  28460\n",
      "Test inds:  [(3022, 1215)]\n",
      "Ann_id in getitem:  69562\n",
      "Test inds:  [(3044, 2940)]\n",
      "Ann_id in getitem:  70219\n",
      "Test inds:  [(633, 3212)]\n",
      "Ann_id in getitem:  15411\n",
      "Test inds:  [(2227, 2423)]\n",
      "Ann_id in getitem:  50158\n",
      "Test inds:  [(2480, 1609)]\n",
      "Ann_id in getitem:  56445\n",
      "Test inds:  [(972, 1991)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(194, 1629)]\n",
      "Ann_id in getitem:  4857\n",
      "Test inds:  [(1055, 1224)]\n",
      "Ann_id in getitem:  24930\n",
      "Test inds:  [(424, 3628)]\n",
      "Ann_id in getitem:  10325\n",
      "Test inds:  [(672, 3596)]\n",
      "Ann_id in getitem:  16341\n",
      "Test inds:  [(119, 2739)]\n",
      "Ann_id in getitem:  2830\n",
      "Test inds:  [(2243, 36)]\n",
      "Ann_id in getitem:  50665\n",
      "Test inds:  [(183, 865)]\n",
      "Ann_id in getitem:  4700\n",
      "Test inds:  [(3691, 3188)]\n",
      "Ann_id in getitem:  85334\n",
      "Test inds:  [(3453, 1779)]\n",
      "Ann_id in getitem:  79645\n",
      "Test inds:  [(1965, 2581)]\n",
      "Ann_id in getitem:  44823\n",
      "Test inds:  [(1733, 748)]\n",
      "Ann_id in getitem:  40354\n",
      "Test inds:  [(1981, 1848)]\n",
      "Ann_id in getitem:  45166\n",
      "Test inds:  [(416, 974)]\n",
      "Ann_id in getitem:  10128\n",
      "Test inds:  [(238, 616)]\n",
      "Ann_id in getitem:  5795\n",
      "Test inds:  [(491, 333)]\n",
      "Ann_id in getitem:  11805\n",
      "Test inds:  [(481, 2533)]\n",
      "Ann_id in getitem:  11574\n",
      "Test inds:  [(2981, 1745)]\n",
      "Ann_id in getitem:  68777\n",
      "Test inds:  [(530, 2533)]\n",
      "Ann_id in getitem:  12597\n",
      "Test inds:  [(1868, 1937)]\n",
      "Ann_id in getitem:  42998\n",
      "Test inds:  [(1012, 2885)]\n",
      "Ann_id in getitem:  24045\n",
      "Test inds:  [(3160, 3326)]\n",
      "Ann_id in getitem:  72829\n",
      "Test inds:  [(2604, 878)]\n",
      "Ann_id in getitem:  59664\n",
      "Test inds:  [(3589, 1985)]\n",
      "Ann_id in getitem:  82774\n",
      "Test inds:  [(3628, 1365)]\n",
      "Ann_id in getitem:  83699\n",
      "Test inds:  [(3085, 485)]\n",
      "Ann_id in getitem:  71136\n",
      "Test inds:  [(1786, 20)]\n",
      "Ann_id in getitem:  41184\n",
      "Test inds:  [(2410, 2315)]\n",
      "Ann_id in getitem:  54522\n",
      "Test inds:  [(647, 116)]\n",
      "Ann_id in getitem:  15755\n",
      "Test inds:  [(1065, 2080)]\n",
      "Ann_id in getitem:  25040\n",
      "Test inds:  [(987, 475)]\n",
      "Ann_id in getitem:  23451\n",
      "Test inds:  [(3500, 2656)]\n",
      "Ann_id in getitem:  80593\n",
      "Test inds:  [(3486, 316)]\n",
      "Ann_id in getitem:  80301\n",
      "Test inds:  [(2651, 2141)]\n",
      "Ann_id in getitem:  60756\n",
      "Test inds:  [(220, 740)]\n",
      "Ann_id in getitem:  5431\n",
      "Test inds:  [(1357, 905)]\n",
      "Ann_id in getitem:  32031\n",
      "Test inds:  [(835, 2690)]\n",
      "Ann_id in getitem:  20028\n",
      "Test inds:  [(3037, 3408)]\n",
      "Ann_id in getitem:  70022\n",
      "Test inds:  [(844, 1057)]\n",
      "Ann_id in getitem:  20431\n",
      "Test inds:  [(2741, 3576)]\n",
      "Ann_id in getitem:  63079\n",
      "Test inds:  [(3120, 3221)]\n",
      "Ann_id in getitem:  71963\n",
      "Test inds:  [(2400, 1436)]\n",
      "Ann_id in getitem:  54293\n",
      "Test inds:  [(3142, 1596)]\n",
      "Ann_id in getitem:  72472\n",
      "Test inds:  [(3287, 2343)]\n",
      "Ann_id in getitem:  75289\n",
      "Test inds:  [(344, 1820)]\n",
      "Ann_id in getitem:  8323\n",
      "Test inds:  [(1320, 3510)]\n",
      "Ann_id in getitem:  30875\n",
      "Test inds:  [(3691, 323)]\n",
      "Ann_id in getitem:  85334\n",
      "Test inds:  [(1265, 1760)]\n",
      "Ann_id in getitem:  29575\n",
      "Test inds:  [(720, 826)]\n",
      "Ann_id in getitem:  17402\n",
      "Test inds:  [(2949, 3223)]\n",
      "Ann_id in getitem:  67952\n",
      "Test inds:  [(3395, 46)]\n",
      "Ann_id in getitem:  78052\n",
      "Test inds:  [(1389, 2368)]\n",
      "Ann_id in getitem:  32967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3522, 368)]\n",
      "Ann_id in getitem:  81276\n",
      "Test inds:  [(2553, 2708)]\n",
      "Ann_id in getitem:  58014\n",
      "Test inds:  [(1121, 970)]\n",
      "Ann_id in getitem:  26049\n",
      "Test inds:  [(1726, 3622)]\n",
      "Ann_id in getitem:  40251\n",
      "Test inds:  [(2385, 1534)]\n",
      "Ann_id in getitem:  53913\n",
      "Test inds:  [(114, 752)]\n",
      "Ann_id in getitem:  2666\n",
      "Test inds:  [(1419, 767)]\n",
      "Ann_id in getitem:  33592\n",
      "Test inds:  [(2306, 425)]\n",
      "Ann_id in getitem:  52013\n",
      "Test inds:  [(14, 1739)]\n",
      "Ann_id in getitem:  342\n",
      "Test inds:  [(81, 3559)]\n",
      "Ann_id in getitem:  1865\n",
      "Test inds:  [(3696, 2081)]\n",
      "Ann_id in getitem:  85427\n",
      "Test inds:  [(265, 2661)]\n",
      "Ann_id in getitem:  6301\n",
      "Test inds:  [(2695, 86)]\n",
      "Ann_id in getitem:  61967\n",
      "Test inds:  [(38, 930)]\n",
      "Ann_id in getitem:  834\n",
      "Test inds:  [(2981, 1285)]\n",
      "Ann_id in getitem:  68777\n",
      "Test inds:  [(3535, 2791)]\n",
      "Ann_id in getitem:  81561\n",
      "Test inds:  [(949, 3408)]\n",
      "Ann_id in getitem:  22516\n",
      "Test inds:  [(504, 1026)]\n",
      "Ann_id in getitem:  12014\n",
      "Test inds:  [(2829, 35)]\n",
      "Ann_id in getitem:  65267\n",
      "Test inds:  [(762, 734)]\n",
      "Ann_id in getitem:  18511\n",
      "Test inds:  [(3635, 954)]\n",
      "Ann_id in getitem:  83942\n",
      "Test inds:  [(3550, 1845)]\n",
      "Ann_id in getitem:  81878\n",
      "Test inds:  [(3269, 2905)]\n",
      "Ann_id in getitem:  74930\n",
      "Test inds:  [(1314, 548)]\n",
      "Ann_id in getitem:  30769\n",
      "Test inds:  [(1172, 112)]\n",
      "Ann_id in getitem:  27254\n",
      "Test inds:  [(2495, 2771)]\n",
      "Ann_id in getitem:  56735\n",
      "Test inds:  [(2127, 611)]\n",
      "Ann_id in getitem:  48216\n",
      "Test inds:  [(3187, 933)]\n",
      "Ann_id in getitem:  73377\n",
      "Test inds:  [(155, 3211)]\n",
      "Ann_id in getitem:  3840\n",
      "Test inds:  [(1595, 1665)]\n",
      "Ann_id in getitem:  37651\n",
      "Test inds:  [(1822, 3308)]\n",
      "Ann_id in getitem:  41928\n",
      "Test inds:  [(693, 2112)]\n",
      "Ann_id in getitem:  16873\n",
      "Test inds:  [(1473, 1587)]\n",
      "Ann_id in getitem:  34935\n",
      "Test inds:  [(3516, 2506)]\n",
      "Ann_id in getitem:  81120\n",
      "Test inds:  [(1525, 1171)]\n",
      "Ann_id in getitem:  36111\n",
      "Test inds:  [(2236, 2120)]\n",
      "Ann_id in getitem:  50350\n",
      "Test inds:  [(1778, 1501)]\n",
      "Ann_id in getitem:  41030\n",
      "Test inds:  [(1377, 2642)]\n",
      "Ann_id in getitem:  32557\n",
      "Test inds:  [(774, 1473)]\n",
      "Ann_id in getitem:  18796\n",
      "Test inds:  [(1311, 1528)]\n",
      "Ann_id in getitem:  30678\n",
      "Test inds:  [(3317, 3494)]\n",
      "Ann_id in getitem:  76267\n",
      "Test inds:  [(939, 3155)]\n",
      "Ann_id in getitem:  22341\n",
      "Test inds:  [(1303, 3036)]\n",
      "Ann_id in getitem:  30491\n",
      "Test inds:  [(872, 1909)]\n",
      "Ann_id in getitem:  20982\n",
      "Test inds:  [(65, 1918)]\n",
      "Ann_id in getitem:  1436\n",
      "Test inds:  [(2893, 1256)]\n",
      "Ann_id in getitem:  66533\n",
      "Test inds:  [(3367, 191)]\n",
      "Ann_id in getitem:  77348\n",
      "Test inds:  [(2004, 1767)]\n",
      "Ann_id in getitem:  45648\n",
      "Test inds:  [(1110, 973)]\n",
      "Ann_id in getitem:  25767\n",
      "Test inds:  [(2767, 2884)]\n",
      "Ann_id in getitem:  63643\n",
      "Test inds:  [(1393, 2066)]\n",
      "Ann_id in getitem:  33092\n",
      "Test inds:  [(838, 3408)]\n",
      "Ann_id in getitem:  20143\n",
      "Test inds:  [(3222, 1808)]\n",
      "Ann_id in getitem:  74083\n",
      "Test inds:  [(2187, 2182)]\n",
      "Ann_id in getitem:  49257\n",
      "Test inds:  [(2925, 3180)]\n",
      "Ann_id in getitem:  67308\n",
      "Test inds:  [(2299, 2087)]\n",
      "Ann_id in getitem:  51855\n",
      "Test inds:  [(231, 1316)]\n",
      "Ann_id in getitem:  5618\n",
      "Test inds:  [(2667, 2733)]\n",
      "Ann_id in getitem:  61205\n",
      "Test inds:  [(2323, 2986)]\n",
      "Ann_id in getitem:  52330\n",
      "Test inds:  [(1360, 1141)]\n",
      "Ann_id in getitem:  32054\n",
      "Test inds:  [(3640, 1437)]\n",
      "Ann_id in getitem:  83982\n",
      "Test inds:  [(2918, 2159)]\n",
      "Ann_id in getitem:  67160\n",
      "Test inds:  [(2470, 2422)]\n",
      "Ann_id in getitem:  56161\n",
      "Test inds:  [(3270, 2811)]\n",
      "Ann_id in getitem:  74942\n",
      "Test inds:  [(246, 1603)]\n",
      "Ann_id in getitem:  5958\n",
      "Test inds:  [(2232, 3519)]\n",
      "Ann_id in getitem:  50228\n",
      "Test inds:  [(3533, 947)]\n",
      "Ann_id in getitem:  81544\n",
      "Test inds:  [(1345, 2794)]\n",
      "Ann_id in getitem:  31701\n",
      "Test inds:  [(96, 136)]\n",
      "Ann_id in getitem:  2154\n",
      "Test inds:  [(3569, 2623)]\n",
      "Ann_id in getitem:  82291\n",
      "Test inds:  [(2271, 1187)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(3004, 3515)]\n",
      "Ann_id in getitem:  69261\n",
      "Test inds:  [(3387, 2761)]\n",
      "Ann_id in getitem:  77849\n",
      "Test inds:  [(3679, 3057)]\n",
      "Ann_id in getitem:  84853\n",
      "Test inds:  [(1902, 1136)]\n",
      "Ann_id in getitem:  43646\n",
      "Test inds:  [(3492, 32)]\n",
      "Ann_id in getitem:  80478\n",
      "Test inds:  [(2683, 969)]\n",
      "Ann_id in getitem:  61622\n",
      "Test inds:  [(2418, 1398)]\n",
      "Ann_id in getitem:  54672\n",
      "Test inds:  [(2423, 3549)]\n",
      "Ann_id in getitem:  54783\n",
      "Test inds:  [(193, 624)]\n",
      "Ann_id in getitem:  4855\n",
      "Test inds:  [(2914, 595)]\n",
      "Ann_id in getitem:  67119\n",
      "Test inds:  [(2862, 383)]\n",
      "Ann_id in getitem:  65761\n",
      "Test inds:  [(2091, 1736)]\n",
      "Ann_id in getitem:  47403\n",
      "Test inds:  [(1363, 2569)]\n",
      "Ann_id in getitem:  32112\n",
      "Test inds:  [(1900, 2037)]\n",
      "Ann_id in getitem:  43579\n",
      "Test inds:  [(2746, 2256)]\n",
      "Ann_id in getitem:  63175\n",
      "Test inds:  [(2233, 387)]\n",
      "Ann_id in getitem:  50232\n",
      "Test inds:  [(2770, 731)]\n",
      "Ann_id in getitem:  63766\n",
      "Test inds:  [(1195, 2995)]\n",
      "Ann_id in getitem:  27841\n",
      "Test inds:  [(3128, 2616)]\n",
      "Ann_id in getitem:  72119\n",
      "Test inds:  [(1578, 435)]\n",
      "Ann_id in getitem:  37339\n",
      "Test inds:  [(1748, 2595)]\n",
      "Ann_id in getitem:  40548\n",
      "Test inds:  [(1804, 1978)]\n",
      "Ann_id in getitem:  41620\n",
      "Test inds:  [(1834, 1085)]\n",
      "Ann_id in getitem:  42143\n",
      "Test inds:  [(2367, 1097)]\n",
      "Ann_id in getitem:  53536\n",
      "Test inds:  [(577, 2548)]\n",
      "Ann_id in getitem:  14044\n",
      "Test inds:  [(3539, 994)]\n",
      "Ann_id in getitem:  81612\n",
      "Test inds:  [(1799, 1286)]\n",
      "Ann_id in getitem:  41575\n",
      "Test inds:  [(3248, 576)]\n",
      "Ann_id in getitem:  74627\n",
      "Test inds:  [(2886, 2540)]\n",
      "Ann_id in getitem:  66410\n",
      "Test inds:  [(383, 3002)]\n",
      "Ann_id in getitem:  9434\n",
      "Test inds:  [(619, 1550)]\n",
      "Ann_id in getitem:  15172\n",
      "Test inds:  [(1355, 602)]\n",
      "Ann_id in getitem:  31978\n",
      "Test inds:  [(1480, 2315)]\n",
      "Ann_id in getitem:  35073\n",
      "Test inds:  [(3653, 3050)]\n",
      "Ann_id in getitem:  84386\n",
      "Test inds:  [(297, 2959)]\n",
      "Ann_id in getitem:  6928\n",
      "Test inds:  [(1166, 2144)]\n",
      "Ann_id in getitem:  27152\n",
      "Test inds:  [(2997, 646)]\n",
      "Ann_id in getitem:  69090\n",
      "Test inds:  [(3062, 2727)]\n",
      "Ann_id in getitem:  70624\n",
      "Test inds:  [(300, 3353)]\n",
      "Ann_id in getitem:  7049\n",
      "Test inds:  [(2445, 1124)]\n",
      "Ann_id in getitem:  55577\n",
      "Test inds:  [(2259, 3066)]\n",
      "Ann_id in getitem:  51079\n",
      "Test inds:  [(3162, 2827)]\n",
      "Ann_id in getitem:  72870\n",
      "Test inds:  [(263, 2478)]\n",
      "Ann_id in getitem:  6282\n",
      "Test inds:  [(3463, 1736)]\n",
      "Ann_id in getitem:  79929\n",
      "Test inds:  [(1780, 3136)]\n",
      "Ann_id in getitem:  41085\n",
      "Test inds:  [(248, 350)]\n",
      "Ann_id in getitem:  6023\n",
      "Test inds:  [(3018, 1160)]\n",
      "Ann_id in getitem:  69534\n",
      "Test inds:  [(1157, 870)]\n",
      "Ann_id in getitem:  26920\n",
      "Test inds:  [(2453, 2216)]\n",
      "Ann_id in getitem:  55705\n",
      "Test inds:  [(338, 1303)]\n",
      "Ann_id in getitem:  8233\n",
      "Test inds:  [(3263, 1086)]\n",
      "Ann_id in getitem:  74856\n",
      "Test inds:  [(1041, 882)]\n",
      "Ann_id in getitem:  24663\n",
      "Test inds:  [(3071, 1190)]\n",
      "Ann_id in getitem:  70797\n",
      "Test inds:  [(1072, 2781)]\n",
      "Ann_id in getitem:  25154\n",
      "Test inds:  [(975, 1008)]\n",
      "Ann_id in getitem:  22991\n",
      "Test inds:  [(2645, 830)]\n",
      "Ann_id in getitem:  60584\n",
      "Test inds:  [(2308, 2086)]\n",
      "Ann_id in getitem:  52026\n",
      "Test inds:  [(1928, 1355)]\n",
      "Ann_id in getitem:  44042\n",
      "Test inds:  [(274, 2779)]\n",
      "Ann_id in getitem:  6501\n",
      "Test inds:  [(2919, 2925)]\n",
      "Ann_id in getitem:  67228\n",
      "Test inds:  [(176, 1317)]\n",
      "Ann_id in getitem:  4451\n",
      "Test inds:  [(2353, 413)]\n",
      "Ann_id in getitem:  53232\n",
      "Test inds:  [(3408, 2440)]\n",
      "Ann_id in getitem:  78432\n",
      "Test inds:  [(384, 348)]\n",
      "Ann_id in getitem:  9509\n",
      "Test inds:  [(3567, 1399)]\n",
      "Ann_id in getitem:  82265\n",
      "Test inds:  [(424, 1705)]\n",
      "Ann_id in getitem:  10325\n",
      "Test inds:  [(1056, 2654)]\n",
      "Ann_id in getitem:  24948\n",
      "Test inds:  [(2990, 1973)]\n",
      "Ann_id in getitem:  68939\n",
      "Test inds:  [(749, 1990)]\n",
      "Ann_id in getitem:  18138\n",
      "Test inds:  [(2904, 1283)]\n",
      "Ann_id in getitem:  66990\n",
      "Test inds:  [(1959, 628)]\n",
      "Ann_id in getitem:  44542\n",
      "Test inds:  [(494, 2402)]\n",
      "Ann_id in getitem:  11860\n",
      "Test inds:  [(2637, 3474)]\n",
      "Ann_id in getitem:  60348\n",
      "Test inds:  [(819, 3505)]\n",
      "Ann_id in getitem:  19710\n",
      "Test inds:  [(2634, 1984)]\n",
      "Ann_id in getitem:  60296\n",
      "Test inds:  [(1426, 881)]\n",
      "Ann_id in getitem:  33809\n",
      "Test inds:  [(1505, 415)]\n",
      "Ann_id in getitem:  35742\n",
      "Test inds:  [(797, 3603)]\n",
      "Ann_id in getitem:  19281\n",
      "Test inds:  [(1298, 2059)]\n",
      "Ann_id in getitem:  30473\n",
      "Test inds:  [(3467, 818)]\n",
      "Ann_id in getitem:  80049\n",
      "Test inds:  [(2643, 3690)]\n",
      "Ann_id in getitem:  60524\n",
      "Test inds:  [(1044, 1676)]\n",
      "Ann_id in getitem:  24681\n",
      "Test inds:  [(183, 3062)]\n",
      "Ann_id in getitem:  4700\n",
      "Test inds:  [(156, 3058)]\n",
      "Ann_id in getitem:  3903\n",
      "Test inds:  [(1139, 3670)]\n",
      "Ann_id in getitem:  26548\n",
      "Test inds:  [(2202, 339)]\n",
      "Ann_id in getitem:  49584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3273, 1670)]\n",
      "Ann_id in getitem:  74988\n",
      "Test inds:  [(1029, 954)]\n",
      "Ann_id in getitem:  24278\n",
      "Test inds:  [(3217, 2504)]\n",
      "Ann_id in getitem:  73990\n",
      "Test inds:  [(2253, 2791)]\n",
      "Ann_id in getitem:  50937\n",
      "Test inds:  [(3136, 572)]\n",
      "Ann_id in getitem:  72308\n",
      "Test inds:  [(1347, 3302)]\n",
      "Ann_id in getitem:  31739\n",
      "Test inds:  [(2300, 433)]\n",
      "Ann_id in getitem:  51858\n",
      "Test inds:  [(2696, 615)]\n",
      "Ann_id in getitem:  61994\n",
      "Test inds:  [(2352, 3629)]\n",
      "Ann_id in getitem:  53192\n",
      "Test inds:  [(3583, 359)]\n",
      "Ann_id in getitem:  82545\n",
      "Test inds:  [(321, 935)]\n",
      "Ann_id in getitem:  7911\n",
      "Test inds:  [(1373, 1961)]\n",
      "Ann_id in getitem:  32386\n",
      "Test inds:  [(2117, 2712)]\n",
      "Ann_id in getitem:  47986\n",
      "Test inds:  [(2106, 782)]\n",
      "Ann_id in getitem:  47683\n",
      "Test inds:  [(501, 1960)]\n",
      "Ann_id in getitem:  11986\n",
      "Test inds:  [(1777, 112)]\n",
      "Ann_id in getitem:  41029\n",
      "Test inds:  [(546, 1272)]\n",
      "Ann_id in getitem:  13014\n",
      "Test inds:  [(2358, 2080)]\n",
      "Ann_id in getitem:  53318\n",
      "Test inds:  [(1140, 2314)]\n",
      "Ann_id in getitem:  26661\n",
      "Test inds:  [(921, 1281)]\n",
      "Ann_id in getitem:  22052\n",
      "Test inds:  [(153, 1042)]\n",
      "Ann_id in getitem:  3762\n",
      "Test inds:  [(699, 1335)]\n",
      "Ann_id in getitem:  16995\n",
      "Test inds:  [(846, 2583)]\n",
      "Ann_id in getitem:  20513\n",
      "Test inds:  [(2272, 744)]\n",
      "Ann_id in getitem:  51390\n",
      "Test inds:  [(291, 3578)]\n",
      "Ann_id in getitem:  6785\n",
      "Test inds:  [(779, 3327)]\n",
      "Ann_id in getitem:  18903\n",
      "Test inds:  [(1370, 2440)]\n",
      "Ann_id in getitem:  32353\n",
      "Test inds:  [(3214, 3259)]\n",
      "Ann_id in getitem:  73941\n",
      "Test inds:  [(272, 2937)]\n",
      "Ann_id in getitem:  6444\n",
      "Test inds:  [(3112, 3318)]\n",
      "Ann_id in getitem:  71790\n",
      "Test inds:  [(2295, 2077)]\n",
      "Ann_id in getitem:  51786\n",
      "Test inds:  [(2080, 2024)]\n",
      "Ann_id in getitem:  47210\n",
      "Test inds:  [(2629, 1259)]\n",
      "Ann_id in getitem:  60199\n",
      "Test inds:  [(1848, 137)]\n",
      "Ann_id in getitem:  42557\n",
      "Test inds:  [(2740, 2692)]\n",
      "Ann_id in getitem:  63078\n",
      "Test inds:  [(2740, 937)]\n",
      "Ann_id in getitem:  63078\n",
      "Test inds:  [(3543, 3486)]\n",
      "Ann_id in getitem:  81757\n",
      "Test inds:  [(1545, 2626)]\n",
      "Ann_id in getitem:  36558\n",
      "Test inds:  [(1172, 1899)]\n",
      "Ann_id in getitem:  27254\n",
      "Test inds:  [(1811, 2613)]\n",
      "Ann_id in getitem:  41728\n",
      "Test inds:  [(2546, 450)]\n",
      "Ann_id in getitem:  57849\n",
      "Test inds:  [(2052, 872)]\n",
      "Ann_id in getitem:  46731\n",
      "Test inds:  [(1243, 953)]\n",
      "Ann_id in getitem:  29124\n",
      "Test inds:  [(3121, 2095)]\n",
      "Ann_id in getitem:  71994\n",
      "Test inds:  [(2396, 141)]\n",
      "Ann_id in getitem:  54215\n",
      "Test inds:  [(126, 2148)]\n",
      "Ann_id in getitem:  2970\n",
      "Test inds:  [(3644, 3240)]\n",
      "Ann_id in getitem:  84119\n",
      "Test inds:  [(2862, 3337)]\n",
      "Ann_id in getitem:  65761\n",
      "Test inds:  [(3311, 791)]\n",
      "Ann_id in getitem:  76008\n",
      "Test inds:  [(2536, 2000)]\n",
      "Ann_id in getitem:  57566\n",
      "Test inds:  [(1806, 1529)]\n",
      "Ann_id in getitem:  41687\n",
      "Test inds:  [(3674, 1108)]\n",
      "Ann_id in getitem:  84726\n",
      "Test inds:  [(2646, 1420)]\n",
      "Ann_id in getitem:  60603\n",
      "Test inds:  [(2890, 1597)]\n",
      "Ann_id in getitem:  66469\n",
      "Test inds:  [(1290, 710)]\n",
      "Ann_id in getitem:  30285\n",
      "Test inds:  [(1558, 2532)]\n",
      "Ann_id in getitem:  36808\n",
      "Test inds:  [(3563, 652)]\n",
      "Ann_id in getitem:  82158\n",
      "Test inds:  [(2732, 1847)]\n",
      "Ann_id in getitem:  62823\n",
      "Test inds:  [(569, 2728)]\n",
      "Ann_id in getitem:  13745\n",
      "Test inds:  [(385, 778)]\n",
      "Ann_id in getitem:  9564\n",
      "Test inds:  [(2861, 849)]\n",
      "Ann_id in getitem:  65734\n",
      "Test inds:  [(1491, 3481)]\n",
      "Ann_id in getitem:  35407\n",
      "Test inds:  [(2623, 2030)]\n",
      "Ann_id in getitem:  59971\n",
      "Test inds:  [(81, 1037)]\n",
      "Ann_id in getitem:  1865\n",
      "Test inds:  [(2756, 1229)]\n",
      "Ann_id in getitem:  63397\n",
      "Test inds:  [(1424, 1588)]\n",
      "Ann_id in getitem:  33765\n",
      "Test inds:  [(2001, 1920)]\n",
      "Ann_id in getitem:  45576\n",
      "Test inds:  [(1093, 2309)]\n",
      "Ann_id in getitem:  25491\n",
      "Test inds:  [(1177, 1120)]\n",
      "Ann_id in getitem:  27411\n",
      "Test inds:  [(344, 2682)]\n",
      "Ann_id in getitem:  8323\n",
      "Test inds:  [(198, 1663)]\n",
      "Ann_id in getitem:  4985\n",
      "Test inds:  [(449, 2244)]\n",
      "Ann_id in getitem:  10939\n",
      "Test inds:  [(205, 1662)]\n",
      "Ann_id in getitem:  5098\n",
      "Test inds:  [(639, 518)]\n",
      "Ann_id in getitem:  15485\n",
      "Test inds:  [(1023, 2893)]\n",
      "Ann_id in getitem:  24179\n",
      "Test inds:  [(1647, 1749)]\n",
      "Ann_id in getitem:  38577\n",
      "Test inds:  [(3642, 113)]\n",
      "Ann_id in getitem:  84037\n",
      "Test inds:  [(1583, 2796)]\n",
      "Ann_id in getitem:  37390\n",
      "Test inds:  [(2170, 103)]\n",
      "Ann_id in getitem:  48923\n",
      "Test inds:  [(3202, 463)]\n",
      "Ann_id in getitem:  73693\n",
      "Test inds:  [(2502, 2615)]\n",
      "Ann_id in getitem:  57008\n",
      "Test inds:  [(2489, 1733)]\n",
      "Ann_id in getitem:  56656\n",
      "Test inds:  [(2544, 2014)]\n",
      "Ann_id in getitem:  57824\n",
      "Test inds:  [(3296, 1578)]\n",
      "Ann_id in getitem:  75584\n",
      "Test inds:  [(2025, 2670)]\n",
      "Ann_id in getitem:  45991\n",
      "Test inds:  [(900, 1534)]\n",
      "Ann_id in getitem:  21526\n",
      "Test inds:  [(307, 55)]\n",
      "Ann_id in getitem:  7424\n",
      "Test inds:  [(924, 2874)]\n",
      "Ann_id in getitem:  22119\n",
      "Test inds:  [(2519, 1386)]\n",
      "Ann_id in getitem:  57269\n",
      "Test inds:  [(423, 2546)]\n",
      "Ann_id in getitem:  10264\n",
      "Test inds:  [(955, 1646)]\n",
      "Ann_id in getitem:  22603\n",
      "Test inds:  [(1289, 2791)]\n",
      "Ann_id in getitem:  30246\n",
      "Test inds:  [(2482, 188)]\n",
      "Ann_id in getitem:  56501\n",
      "Test inds:  [(682, 127)]\n",
      "Ann_id in getitem:  16613\n",
      "Test inds:  [(677, 45)]\n",
      "Ann_id in getitem:  16422\n",
      "Test inds:  [(1843, 3627)]\n",
      "Ann_id in getitem:  42375\n",
      "Test inds:  [(174, 719)]\n",
      "Ann_id in getitem:  4386\n",
      "Test inds:  [(511, 1612)]\n",
      "Ann_id in getitem:  12217\n",
      "Test inds:  [(679, 3496)]\n",
      "Ann_id in getitem:  16437\n",
      "Test inds:  [(766, 1328)]\n",
      "Ann_id in getitem:  18542\n",
      "Test inds:  [(2951, 584)]\n",
      "Ann_id in getitem:  68015\n",
      "Test inds:  [(3331, 2474)]\n",
      "Ann_id in getitem:  76562\n",
      "Test inds:  [(3277, 1249)]\n",
      "Ann_id in getitem:  75070\n",
      "Test inds:  [(1153, 1115)]\n",
      "Ann_id in getitem:  26813\n",
      "Test inds:  [(1881, 2589)]\n",
      "Ann_id in getitem:  43283\n",
      "Test inds:  [(2320, 3118)]\n",
      "Ann_id in getitem:  52229\n",
      "Test inds:  [(1219, 866)]\n",
      "Ann_id in getitem:  28477\n",
      "Test inds:  [(3107, 839)]\n",
      "Ann_id in getitem:  71706\n",
      "Test inds:  [(3134, 684)]\n",
      "Ann_id in getitem:  72276\n",
      "Test inds:  [(2272, 1807)]\n",
      "Ann_id in getitem:  51390\n",
      "Test inds:  [(2388, 758)]\n",
      "Ann_id in getitem:  54063\n",
      "Test inds:  [(2694, 421)]\n",
      "Ann_id in getitem:  61954\n",
      "Test inds:  [(3673, 1798)]\n",
      "Ann_id in getitem:  84720\n",
      "Test inds:  [(1715, 3280)]\n",
      "Ann_id in getitem:  40070\n",
      "Test inds:  [(2267, 2693)]\n",
      "Ann_id in getitem:  51199\n",
      "Test inds:  [(2014, 1457)]\n",
      "Ann_id in getitem:  45833\n",
      "Test inds:  [(2365, 3030)]\n",
      "Ann_id in getitem:  53465\n",
      "Test inds:  [(818, 1456)]\n",
      "Ann_id in getitem:  19702\n",
      "Test inds:  [(2061, 3561)]\n",
      "Ann_id in getitem:  46879\n",
      "Test inds:  [(2393, 1392)]\n",
      "Ann_id in getitem:  54145\n",
      "Test inds:  [(1799, 2672)]\n",
      "Ann_id in getitem:  41575\n",
      "Test inds:  [(3548, 1598)]\n",
      "Ann_id in getitem:  81846\n",
      "Test inds:  [(2841, 2442)]\n",
      "Ann_id in getitem:  65428\n",
      "Test inds:  [(2938, 367)]\n",
      "Ann_id in getitem:  67687\n",
      "Test inds:  [(2852, 2886)]\n",
      "Ann_id in getitem:  65635\n",
      "Test inds:  [(3580, 1100)]\n",
      "Ann_id in getitem:  82483\n",
      "Test inds:  [(2335, 944)]\n",
      "Ann_id in getitem:  52659\n",
      "Test inds:  [(1285, 2341)]\n",
      "Ann_id in getitem:  30071\n",
      "Test inds:  [(3280, 923)]\n",
      "Ann_id in getitem:  75098\n",
      "Test inds:  [(3218, 3267)]\n",
      "Ann_id in getitem:  74015\n",
      "Test inds:  [(3621, 884)]\n",
      "Ann_id in getitem:  83575\n",
      "Test inds:  [(1090, 337)]\n",
      "Ann_id in getitem:  25414\n",
      "Test inds:  [(2234, 2782)]\n",
      "Ann_id in getitem:  50316\n",
      "Test inds:  [(1040, 1704)]\n",
      "Ann_id in getitem:  24591\n",
      "Test inds:  [(2956, 3492)]\n",
      "Ann_id in getitem:  68055\n",
      "Test inds:  [(2924, 2499)]\n",
      "Ann_id in getitem:  67297\n",
      "Test inds:  [(3497, 3566)]\n",
      "Ann_id in getitem:  80554\n",
      "Test inds:  [(919, 1167)]\n",
      "Ann_id in getitem:  21951\n",
      "Test inds:  [(592, 991)]\n",
      "Ann_id in getitem:  14358\n",
      "Test inds:  [(2568, 579)]\n",
      "Ann_id in getitem:  58448\n",
      "Test inds:  [(1845, 1505)]\n",
      "Ann_id in getitem:  42475\n",
      "Test inds:  [(418, 428)]\n",
      "Ann_id in getitem:  10176\n",
      "Test inds:  [(2448, 143)]\n",
      "Ann_id in getitem:  55655\n",
      "Test inds:  [(3502, 859)]\n",
      "Ann_id in getitem:  80738\n",
      "Test inds:  [(3289, 2331)]\n",
      "Ann_id in getitem:  75318\n",
      "Test inds:  [(505, 3038)]\n",
      "Ann_id in getitem:  12029\n",
      "Test inds:  [(2712, 2696)]\n",
      "Ann_id in getitem:  62387\n",
      "Test inds:  [(80, 3340)]\n",
      "Ann_id in getitem:  1828\n",
      "Test inds:  [(2787, 3436)]\n",
      "Ann_id in getitem:  64330\n",
      "Test inds:  [(465, 31)]\n",
      "Ann_id in getitem:  11221\n",
      "Test inds:  [(337, 113)]\n",
      "Ann_id in getitem:  8226\n",
      "Test inds:  [(2517, 3693)]\n",
      "Ann_id in getitem:  57225\n",
      "Test inds:  [(3066, 3017)]\n",
      "Ann_id in getitem:  70643\n",
      "Test inds:  [(2011, 3343)]\n",
      "Ann_id in getitem:  45775\n",
      "Test inds:  [(907, 3365)]\n",
      "Ann_id in getitem:  21617\n",
      "Test inds:  [(2030, 3317)]\n",
      "Ann_id in getitem:  46193\n",
      "Test inds:  [(603, 1925)]\n",
      "Ann_id in getitem:  14592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3639, 2930)]\n",
      "Ann_id in getitem:  83970\n",
      "Test inds:  [(2574, 19)]\n",
      "Ann_id in getitem:  58663\n",
      "Test inds:  [(3207, 164)]\n",
      "Ann_id in getitem:  73741\n",
      "Test inds:  [(3538, 2026)]\n",
      "Ann_id in getitem:  81588\n",
      "Test inds:  [(2428, 3369)]\n",
      "Ann_id in getitem:  54859\n",
      "Test inds:  [(70, 295)]\n",
      "Ann_id in getitem:  1562\n",
      "Test inds:  [(900, 1688)]\n",
      "Ann_id in getitem:  21526\n",
      "Test inds:  [(634, 476)]\n",
      "Ann_id in getitem:  15425\n",
      "Test inds:  [(3429, 1368)]\n",
      "Ann_id in getitem:  79028\n",
      "Test inds:  [(1372, 3612)]\n",
      "Ann_id in getitem:  32365\n",
      "Test inds:  [(1005, 2905)]\n",
      "Ann_id in getitem:  23874\n",
      "Test inds:  [(3368, 2258)]\n",
      "Ann_id in getitem:  77355\n",
      "Test inds:  [(1453, 2528)]\n",
      "Ann_id in getitem:  34392\n",
      "Test inds:  [(3419, 1667)]\n",
      "Ann_id in getitem:  78749\n",
      "Test inds:  [(2846, 2316)]\n",
      "Ann_id in getitem:  65541\n",
      "Test inds:  [(2307, 2944)]\n",
      "Ann_id in getitem:  52025\n",
      "Test inds:  [(2520, 694)]\n",
      "Ann_id in getitem:  57279\n",
      "Test inds:  [(2119, 3519)]\n",
      "Ann_id in getitem:  48004\n",
      "Test inds:  [(1284, 1885)]\n",
      "Ann_id in getitem:  30063\n",
      "Test inds:  [(3093, 2826)]\n",
      "Ann_id in getitem:  71283\n",
      "Test inds:  [(843, 2854)]\n",
      "Ann_id in getitem:  20421\n",
      "Test inds:  [(1019, 347)]\n",
      "Ann_id in getitem:  24117\n",
      "Test inds:  [(1412, 3033)]\n",
      "Ann_id in getitem:  33439\n",
      "Test inds:  [(3429, 2739)]\n",
      "Ann_id in getitem:  79028\n",
      "Test inds:  [(793, 36)]\n",
      "Ann_id in getitem:  19206\n",
      "Test inds:  [(3344, 3566)]\n",
      "Ann_id in getitem:  76854\n",
      "Test inds:  [(2864, 1058)]\n",
      "Ann_id in getitem:  65865\n",
      "Test inds:  [(410, 1160)]\n",
      "Ann_id in getitem:  10031\n",
      "Test inds:  [(3108, 433)]\n",
      "Ann_id in getitem:  71709\n",
      "Test inds:  [(2659, 728)]\n",
      "Ann_id in getitem:  61016\n",
      "Test inds:  [(2024, 1006)]\n",
      "Ann_id in getitem:  45988\n",
      "Test inds:  [(422, 3542)]\n",
      "Ann_id in getitem:  10243\n",
      "Test inds:  [(2950, 429)]\n",
      "Ann_id in getitem:  67958\n",
      "Test inds:  [(2407, 1583)]\n",
      "Ann_id in getitem:  54427\n",
      "Test inds:  [(2161, 3455)]\n",
      "Ann_id in getitem:  48766\n",
      "Test inds:  [(3484, 3449)]\n",
      "Ann_id in getitem:  80271\n",
      "Test inds:  [(1904, 357)]\n",
      "Ann_id in getitem:  43667\n",
      "Test inds:  [(679, 1448)]\n",
      "Ann_id in getitem:  16437\n",
      "Test inds:  [(3110, 1004)]\n",
      "Ann_id in getitem:  71760\n",
      "Test inds:  [(3654, 3065)]\n",
      "Ann_id in getitem:  84412\n",
      "Test inds:  [(437, 2795)]\n",
      "Ann_id in getitem:  10682\n",
      "Test inds:  [(834, 188)]\n",
      "Ann_id in getitem:  20024\n",
      "Test inds:  [(2767, 2378)]\n",
      "Ann_id in getitem:  63643\n",
      "Test inds:  [(3602, 2012)]\n",
      "Ann_id in getitem:  83079\n",
      "Test inds:  [(635, 1375)]\n",
      "Ann_id in getitem:  15441\n",
      "Test inds:  [(2284, 962)]\n",
      "Ann_id in getitem:  51621\n",
      "Test inds:  [(703, 2086)]\n",
      "Ann_id in getitem:  17068\n",
      "Test inds:  [(956, 1802)]\n",
      "Ann_id in getitem:  22608\n",
      "Test inds:  [(752, 976)]\n",
      "Ann_id in getitem:  18236\n",
      "Test inds:  [(2299, 843)]\n",
      "Ann_id in getitem:  51855\n",
      "Test inds:  [(76, 2376)]\n",
      "Ann_id in getitem:  1706\n",
      "Test inds:  [(653, 3284)]\n",
      "Ann_id in getitem:  15959\n",
      "Test inds:  [(551, 645)]\n",
      "Ann_id in getitem:  13271\n",
      "Test inds:  [(2038, 154)]\n",
      "Ann_id in getitem:  46412\n",
      "Test inds:  [(2732, 1197)]\n",
      "Ann_id in getitem:  62823\n",
      "Test inds:  [(1618, 922)]\n",
      "Ann_id in getitem:  37965\n",
      "Test inds:  [(3319, 3238)]\n",
      "Ann_id in getitem:  76271\n",
      "Test inds:  [(2897, 2698)]\n",
      "Ann_id in getitem:  66631\n",
      "Test inds:  [(2784, 3575)]\n",
      "Ann_id in getitem:  64236\n",
      "Test inds:  [(1257, 1877)]\n",
      "Ann_id in getitem:  29483\n",
      "Test inds:  [(1390, 934)]\n",
      "Ann_id in getitem:  33008\n",
      "Test inds:  [(480, 2076)]\n",
      "Ann_id in getitem:  11542\n",
      "Test inds:  [(3083, 608)]\n",
      "Ann_id in getitem:  71106\n",
      "Test inds:  [(2707, 2146)]\n",
      "Ann_id in getitem:  62181\n",
      "Test inds:  [(1168, 42)]\n",
      "Ann_id in getitem:  27196\n",
      "Test inds:  [(578, 2516)]\n",
      "Ann_id in getitem:  14058\n",
      "Test inds:  [(2757, 3098)]\n",
      "Ann_id in getitem:  63417\n",
      "Test inds:  [(2740, 844)]\n",
      "Ann_id in getitem:  63078\n",
      "Test inds:  [(3422, 1297)]\n",
      "Ann_id in getitem:  78853\n",
      "Test inds:  [(968, 2043)]\n",
      "Ann_id in getitem:  22864\n",
      "Test inds:  [(436, 343)]\n",
      "Ann_id in getitem:  10673\n",
      "Test inds:  [(2008, 12)]\n",
      "Ann_id in getitem:  45701\n",
      "Test inds:  [(2213, 1636)]\n",
      "Ann_id in getitem:  49805\n",
      "Test inds:  [(1011, 707)]\n",
      "Ann_id in getitem:  23982\n",
      "Test inds:  [(1906, 2384)]\n",
      "Ann_id in getitem:  43699\n",
      "Test inds:  [(2106, 2171)]\n",
      "Ann_id in getitem:  47683\n",
      "Test inds:  [(89, 3604)]\n",
      "Ann_id in getitem:  2049\n",
      "Test inds:  [(342, 3606)]\n",
      "Ann_id in getitem:  8280\n",
      "Test inds:  [(2400, 205)]\n",
      "Ann_id in getitem:  54293\n",
      "Test inds:  [(2119, 1157)]\n",
      "Ann_id in getitem:  48004\n",
      "Test inds:  [(2185, 190)]\n",
      "Ann_id in getitem:  49232\n",
      "Test inds:  [(3642, 1050)]\n",
      "Ann_id in getitem:  84037\n",
      "Test inds:  [(1264, 2556)]\n",
      "Ann_id in getitem:  29570\n",
      "Test inds:  [(1256, 3175)]\n",
      "Ann_id in getitem:  29448\n",
      "Test inds:  [(1731, 1234)]\n",
      "Ann_id in getitem:  40315\n",
      "Test inds:  [(2201, 630)]\n",
      "Ann_id in getitem:  49577\n",
      "Test inds:  [(1244, 180)]\n",
      "Ann_id in getitem:  29129\n",
      "Test inds:  [(3266, 1600)]\n",
      "Ann_id in getitem:  74900\n",
      "Test inds:  [(202, 1670)]\n",
      "Ann_id in getitem:  5018\n",
      "Test inds:  [(2187, 2881)]\n",
      "Ann_id in getitem:  49257\n",
      "Test inds:  [(2565, 1477)]\n",
      "Ann_id in getitem:  58327\n",
      "Test inds:  [(2557, 2523)]\n",
      "Ann_id in getitem:  58109\n",
      "Test inds:  [(1540, 1996)]\n",
      "Ann_id in getitem:  36496\n",
      "Test inds:  [(694, 307)]\n",
      "Ann_id in getitem:  16924\n",
      "Test inds:  [(875, 2860)]\n",
      "Ann_id in getitem:  21022\n",
      "Test inds:  [(347, 2947)]\n",
      "Ann_id in getitem:  8427\n",
      "Test inds:  [(2761, 2968)]\n",
      "Ann_id in getitem:  63510\n",
      "Test inds:  [(178, 1215)]\n",
      "Ann_id in getitem:  4571\n",
      "Test inds:  [(3310, 2646)]\n",
      "Ann_id in getitem:  76006\n",
      "Test inds:  [(576, 2839)]\n",
      "Ann_id in getitem:  14041\n",
      "Test inds:  [(2740, 3356)]\n",
      "Ann_id in getitem:  63078\n",
      "Test inds:  [(966, 2917)]\n",
      "Ann_id in getitem:  22854\n",
      "Test inds:  [(3458, 199)]\n",
      "Ann_id in getitem:  79796\n",
      "Test inds:  [(47, 2533)]\n",
      "Ann_id in getitem:  961\n",
      "Test inds:  [(115, 2080)]\n",
      "Ann_id in getitem:  2686\n",
      "Test inds:  [(3055, 1378)]\n",
      "Ann_id in getitem:  70521\n",
      "Test inds:  [(3341, 2969)]\n",
      "Ann_id in getitem:  76812\n",
      "Test inds:  [(181, 673)]\n",
      "Ann_id in getitem:  4633\n",
      "Test inds:  [(92, 1672)]\n",
      "Ann_id in getitem:  2099\n",
      "Test inds:  [(2405, 2717)]\n",
      "Ann_id in getitem:  54377\n",
      "Test inds:  [(383, 3435)]\n",
      "Ann_id in getitem:  9434\n",
      "Test inds:  [(1524, 2604)]\n",
      "Ann_id in getitem:  36083\n",
      "Test inds:  [(2535, 1526)]\n",
      "Ann_id in getitem:  57554\n",
      "Test inds:  [(2127, 2129)]\n",
      "Ann_id in getitem:  48216\n",
      "Test inds:  [(3157, 3222)]\n",
      "Ann_id in getitem:  72771\n",
      "Test inds:  [(76, 1155)]\n",
      "Ann_id in getitem:  1706\n",
      "Test inds:  [(1276, 1734)]\n",
      "Ann_id in getitem:  29844\n",
      "Test inds:  [(2683, 3175)]\n",
      "Ann_id in getitem:  61622\n",
      "Test inds:  [(436, 720)]\n",
      "Ann_id in getitem:  10673\n",
      "Test inds:  [(2970, 3539)]\n",
      "Ann_id in getitem:  68330\n",
      "Test inds:  [(3246, 1777)]\n",
      "Ann_id in getitem:  74594\n",
      "Test inds:  [(36, 2379)]\n",
      "Ann_id in getitem:  827\n",
      "Test inds:  [(1051, 1279)]\n",
      "Ann_id in getitem:  24785\n",
      "Test inds:  [(1437, 1663)]\n",
      "Ann_id in getitem:  34092\n",
      "Test inds:  [(2176, 1018)]\n",
      "Ann_id in getitem:  49028\n",
      "Test inds:  [(375, 1732)]\n",
      "Ann_id in getitem:  9174\n",
      "Test inds:  [(1889, 1298)]\n",
      "Ann_id in getitem:  43405\n",
      "Test inds:  [(2814, 488)]\n",
      "Ann_id in getitem:  64865\n",
      "Test inds:  [(5, 383)]\n",
      "Ann_id in getitem:  101\n",
      "Test inds:  [(671, 218)]\n",
      "Ann_id in getitem:  16340\n",
      "Test inds:  [(1817, 715)]\n",
      "Ann_id in getitem:  41838\n",
      "Test inds:  [(812, 1784)]\n",
      "Ann_id in getitem:  19553\n",
      "Test inds:  [(2590, 2072)]\n",
      "Ann_id in getitem:  59384\n",
      "Test inds:  [(3259, 243)]\n",
      "Ann_id in getitem:  74810\n",
      "Test inds:  [(2652, 524)]\n",
      "Ann_id in getitem:  60770\n",
      "Test inds:  [(3063, 2630)]\n",
      "Ann_id in getitem:  70625\n",
      "Test inds:  [(1127, 147)]\n",
      "Ann_id in getitem:  26273\n",
      "Test inds:  [(2872, 1889)]\n",
      "Ann_id in getitem:  66028\n",
      "Test inds:  [(1894, 358)]\n",
      "Ann_id in getitem:  43476\n",
      "Test inds:  [(2776, 1129)]\n",
      "Ann_id in getitem:  63953\n",
      "Test inds:  [(1836, 1891)]\n",
      "Ann_id in getitem:  42166\n",
      "Test inds:  [(3108, 3271)]\n",
      "Ann_id in getitem:  71709\n",
      "Test inds:  [(2080, 1056)]\n",
      "Ann_id in getitem:  47210\n",
      "Test inds:  [(1888, 682)]\n",
      "Ann_id in getitem:  43380\n",
      "Test inds:  [(695, 187)]\n",
      "Ann_id in getitem:  16927\n",
      "Test inds:  [(3664, 3503)]\n",
      "Ann_id in getitem:  84600\n",
      "Test inds:  [(2782, 3125)]\n",
      "Ann_id in getitem:  64161\n",
      "Test inds:  [(3280, 670)]\n",
      "Ann_id in getitem:  75098\n",
      "Test inds:  [(625, 2640)]\n",
      "Ann_id in getitem:  15243\n",
      "Test inds:  [(3229, 2742)]\n",
      "Ann_id in getitem:  74217\n",
      "Test inds:  [(963, 3422)]\n",
      "Ann_id in getitem:  22776\n",
      "Test inds:  [(1466, 3135)]\n",
      "Ann_id in getitem:  34720\n",
      "Test inds:  [(990, 1464)]\n",
      "Ann_id in getitem:  23564\n",
      "Test inds:  [(910, 2777)]\n",
      "Ann_id in getitem:  21662\n",
      "Test inds:  [(2607, 1491)]\n",
      "Ann_id in getitem:  59730\n",
      "Test inds:  [(1141, 1642)]\n",
      "Ann_id in getitem:  26670\n",
      "Test inds:  [(1797, 2538)]\n",
      "Ann_id in getitem:  41529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(865, 1567)]\n",
      "Ann_id in getitem:  20910\n",
      "Test inds:  [(77, 3619)]\n",
      "Ann_id in getitem:  1707\n",
      "Test inds:  [(2941, 3263)]\n",
      "Ann_id in getitem:  67736\n",
      "Test inds:  [(753, 441)]\n",
      "Ann_id in getitem:  18251\n",
      "Test inds:  [(2493, 3375)]\n",
      "Ann_id in getitem:  56700\n",
      "Test inds:  [(2554, 1113)]\n",
      "Ann_id in getitem:  58015\n",
      "Test inds:  [(20, 1878)]\n",
      "Ann_id in getitem:  452\n",
      "Test inds:  [(19, 3420)]\n",
      "Ann_id in getitem:  447\n",
      "Test inds:  [(1440, 3611)]\n",
      "Ann_id in getitem:  34155\n",
      "Test inds:  [(2377, 3609)]\n",
      "Ann_id in getitem:  53753\n",
      "Test inds:  [(592, 1659)]\n",
      "Ann_id in getitem:  14358\n",
      "Test inds:  [(3127, 2475)]\n",
      "Ann_id in getitem:  72114\n",
      "Test inds:  [(3353, 800)]\n",
      "Ann_id in getitem:  76922\n",
      "Test inds:  [(3673, 2858)]\n",
      "Ann_id in getitem:  84720\n",
      "Test inds:  [(1520, 2880)]\n",
      "Ann_id in getitem:  36030\n",
      "Test inds:  [(48, 3581)]\n",
      "Ann_id in getitem:  974\n",
      "Test inds:  [(197, 1246)]\n",
      "Ann_id in getitem:  4957\n",
      "Test inds:  [(3634, 1038)]\n",
      "Ann_id in getitem:  83867\n",
      "Test inds:  [(769, 3568)]\n",
      "Ann_id in getitem:  18639\n",
      "Test inds:  [(534, 354)]\n",
      "Ann_id in getitem:  12713\n",
      "Test inds:  [(653, 1171)]\n",
      "Ann_id in getitem:  15959\n",
      "Test inds:  [(515, 1004)]\n",
      "Ann_id in getitem:  12313\n",
      "Test inds:  [(1246, 887)]\n",
      "Ann_id in getitem:  29195\n",
      "Test inds:  [(645, 1366)]\n",
      "Ann_id in getitem:  15621\n",
      "Test inds:  [(2383, 529)]\n",
      "Ann_id in getitem:  53894\n",
      "Test inds:  [(3511, 3336)]\n",
      "Ann_id in getitem:  81022\n",
      "Test inds:  [(1178, 3083)]\n",
      "Ann_id in getitem:  27434\n",
      "Test inds:  [(1946, 3612)]\n",
      "Ann_id in getitem:  44309\n",
      "Test inds:  [(186, 2149)]\n",
      "Ann_id in getitem:  4740\n",
      "Test inds:  [(1236, 319)]\n",
      "Ann_id in getitem:  28894\n",
      "Test inds:  [(1996, 1821)]\n",
      "Ann_id in getitem:  45495\n",
      "Test inds:  [(3447, 1952)]\n",
      "Ann_id in getitem:  79500\n",
      "Test inds:  [(1854, 676)]\n",
      "Ann_id in getitem:  42675\n",
      "Test inds:  [(286, 2471)]\n",
      "Ann_id in getitem:  6676\n",
      "Test inds:  [(139, 3075)]\n",
      "Ann_id in getitem:  3408\n",
      "Test inds:  [(3472, 715)]\n",
      "Ann_id in getitem:  80122\n",
      "Test inds:  [(1104, 953)]\n",
      "Ann_id in getitem:  25689\n",
      "Test inds:  [(2668, 824)]\n",
      "Ann_id in getitem:  61233\n",
      "Test inds:  [(1233, 3683)]\n",
      "Ann_id in getitem:  28805\n",
      "Test inds:  [(3486, 2386)]\n",
      "Ann_id in getitem:  80301\n",
      "Test inds:  [(1236, 3401)]\n",
      "Ann_id in getitem:  28894\n",
      "Test inds:  [(1056, 231)]\n",
      "Ann_id in getitem:  24948\n",
      "Test inds:  [(1617, 1388)]\n",
      "Ann_id in getitem:  37890\n",
      "Test inds:  [(2869, 760)]\n",
      "Ann_id in getitem:  65983\n",
      "Test inds:  [(1417, 1768)]\n",
      "Ann_id in getitem:  33495\n",
      "Test inds:  [(1687, 3012)]\n",
      "Ann_id in getitem:  39518\n",
      "Test inds:  [(1490, 67)]\n",
      "Ann_id in getitem:  35393\n",
      "Test inds:  [(1043, 447)]\n",
      "Ann_id in getitem:  24667\n",
      "Test inds:  [(1705, 3540)]\n",
      "Ann_id in getitem:  39888\n",
      "Test inds:  [(118, 755)]\n",
      "Ann_id in getitem:  2761\n",
      "Test inds:  [(1458, 2038)]\n",
      "Ann_id in getitem:  34537\n",
      "Test inds:  [(2231, 1057)]\n",
      "Ann_id in getitem:  50219\n",
      "Test inds:  [(1107, 1207)]\n",
      "Ann_id in getitem:  25712\n",
      "Test inds:  [(2277, 2632)]\n",
      "Ann_id in getitem:  51521\n",
      "Test inds:  [(2335, 73)]\n",
      "Ann_id in getitem:  52659\n",
      "Test inds:  [(2630, 9)]\n",
      "Ann_id in getitem:  60215\n",
      "Test inds:  [(2946, 2804)]\n",
      "Ann_id in getitem:  67897\n",
      "Test inds:  [(3134, 3025)]\n",
      "Ann_id in getitem:  72276\n",
      "Test inds:  [(2892, 2232)]\n",
      "Ann_id in getitem:  66507\n",
      "Test inds:  [(2494, 1451)]\n",
      "Ann_id in getitem:  56718\n",
      "Test inds:  [(3447, 3239)]\n",
      "Ann_id in getitem:  79500\n",
      "Test inds:  [(2999, 483)]\n",
      "Ann_id in getitem:  69118\n",
      "Test inds:  [(3339, 2554)]\n",
      "Ann_id in getitem:  76685\n",
      "Test inds:  [(1532, 2321)]\n",
      "Ann_id in getitem:  36246\n",
      "Test inds:  [(2193, 961)]\n",
      "Ann_id in getitem:  49374\n",
      "Test inds:  [(1136, 3247)]\n",
      "Ann_id in getitem:  26492\n",
      "Test inds:  [(3522, 2657)]\n",
      "Ann_id in getitem:  81276\n",
      "Test inds:  [(2153, 1264)]\n",
      "Ann_id in getitem:  48633\n",
      "Test inds:  [(2925, 3374)]\n",
      "Ann_id in getitem:  67308\n",
      "Test inds:  [(538, 1341)]\n",
      "Ann_id in getitem:  12762\n",
      "Test inds:  [(3532, 2443)]\n",
      "Ann_id in getitem:  81499\n",
      "Test inds:  [(1694, 1071)]\n",
      "Ann_id in getitem:  39751\n",
      "Test inds:  [(2964, 438)]\n",
      "Ann_id in getitem:  68246\n",
      "Test inds:  [(124, 850)]\n",
      "Ann_id in getitem:  2960\n",
      "Test inds:  [(837, 3646)]\n",
      "Ann_id in getitem:  20078\n",
      "Test inds:  [(752, 3181)]\n",
      "Ann_id in getitem:  18236\n",
      "Test inds:  [(2620, 2670)]\n",
      "Ann_id in getitem:  59941\n",
      "Test inds:  [(1162, 213)]\n",
      "Ann_id in getitem:  27076\n",
      "Test inds:  [(235, 1937)]\n",
      "Ann_id in getitem:  5749\n",
      "Test inds:  [(3325, 1195)]\n",
      "Ann_id in getitem:  76389\n",
      "Test inds:  [(2544, 1434)]\n",
      "Ann_id in getitem:  57824\n",
      "Test inds:  [(2878, 1173)]\n",
      "Ann_id in getitem:  66180\n",
      "Test inds:  [(2686, 406)]\n",
      "Ann_id in getitem:  61648\n",
      "Test inds:  [(2087, 2214)]\n",
      "Ann_id in getitem:  47354\n",
      "Test inds:  [(3360, 21)]\n",
      "Ann_id in getitem:  77096\n",
      "Test inds:  [(3567, 3413)]\n",
      "Ann_id in getitem:  82265\n",
      "Test inds:  [(1962, 3398)]\n",
      "Ann_id in getitem:  44627\n",
      "Test inds:  [(2495, 1811)]\n",
      "Ann_id in getitem:  56735\n",
      "Test inds:  [(360, 3699)]\n",
      "Ann_id in getitem:  8724\n",
      "Test inds:  [(2398, 347)]\n",
      "Ann_id in getitem:  54288\n",
      "Test inds:  [(906, 1568)]\n",
      "Ann_id in getitem:  21608\n",
      "Test inds:  [(3496, 1368)]\n",
      "Ann_id in getitem:  80522\n",
      "Test inds:  [(3084, 1056)]\n",
      "Ann_id in getitem:  71134\n",
      "Test inds:  [(571, 933)]\n",
      "Ann_id in getitem:  13792\n",
      "Test inds:  [(182, 1266)]\n",
      "Ann_id in getitem:  4653\n",
      "Test inds:  [(3657, 1658)]\n",
      "Ann_id in getitem:  84471\n",
      "Test inds:  [(1884, 1969)]\n",
      "Ann_id in getitem:  43361\n",
      "Test inds:  [(1042, 3190)]\n",
      "Ann_id in getitem:  24664\n",
      "Test inds:  [(3641, 751)]\n",
      "Ann_id in getitem:  83996\n",
      "Test inds:  [(2153, 1952)]\n",
      "Ann_id in getitem:  48633\n",
      "Test inds:  [(1012, 191)]\n",
      "Ann_id in getitem:  24045\n",
      "Test inds:  [(375, 2110)]\n",
      "Ann_id in getitem:  9174\n",
      "Test inds:  [(1007, 3082)]\n",
      "Ann_id in getitem:  23909\n",
      "Test inds:  [(40, 3666)]\n",
      "Ann_id in getitem:  882\n",
      "Test inds:  [(58, 3527)]\n",
      "Ann_id in getitem:  1229\n",
      "Test inds:  [(3464, 1757)]\n",
      "Ann_id in getitem:  79958\n",
      "Test inds:  [(506, 651)]\n",
      "Ann_id in getitem:  12111\n",
      "Test inds:  [(2446, 1261)]\n",
      "Ann_id in getitem:  55596\n",
      "Test inds:  [(2284, 3453)]\n",
      "Ann_id in getitem:  51621\n",
      "Test inds:  [(905, 306)]\n",
      "Ann_id in getitem:  21603\n",
      "Test inds:  [(2878, 3011)]\n",
      "Ann_id in getitem:  66180\n",
      "Test inds:  [(563, 1781)]\n",
      "Ann_id in getitem:  13557\n",
      "Test inds:  [(1495, 209)]\n",
      "Ann_id in getitem:  35537\n",
      "Test inds:  [(2619, 539)]\n",
      "Ann_id in getitem:  59940\n",
      "Test inds:  [(3444, 911)]\n",
      "Ann_id in getitem:  79379\n",
      "Test inds:  [(2703, 3524)]\n",
      "Ann_id in getitem:  62141\n",
      "Test inds:  [(1531, 1014)]\n",
      "Ann_id in getitem:  36245\n",
      "Test inds:  [(1979, 2718)]\n",
      "Ann_id in getitem:  45150\n",
      "Test inds:  [(304, 1744)]\n",
      "Ann_id in getitem:  7274\n",
      "Test inds:  [(1943, 2587)]\n",
      "Ann_id in getitem:  44244\n",
      "Test inds:  [(2081, 2341)]\n",
      "Ann_id in getitem:  47222\n",
      "Test inds:  [(3039, 2986)]\n",
      "Ann_id in getitem:  70044\n",
      "Test inds:  [(2271, 88)]\n",
      "Ann_id in getitem:  51386\n",
      "Test inds:  [(625, 3127)]\n",
      "Ann_id in getitem:  15243\n",
      "Test inds:  [(591, 1705)]\n",
      "Ann_id in getitem:  14343\n",
      "Test inds:  [(2823, 1969)]\n",
      "Ann_id in getitem:  65076\n",
      "Test inds:  [(1503, 3668)]\n",
      "Ann_id in getitem:  35716\n",
      "Test inds:  [(87, 3176)]\n",
      "Ann_id in getitem:  2028\n",
      "Test inds:  [(3345, 1185)]\n",
      "Ann_id in getitem:  76870\n",
      "Test inds:  [(3601, 3052)]\n",
      "Ann_id in getitem:  83060\n",
      "Test inds:  [(42, 1620)]\n",
      "Ann_id in getitem:  931\n",
      "Test inds:  [(1948, 2163)]\n",
      "Ann_id in getitem:  44325\n",
      "Test inds:  [(167, 960)]\n",
      "Ann_id in getitem:  4205\n",
      "Test inds:  [(1357, 2980)]\n",
      "Ann_id in getitem:  32031\n",
      "Test inds:  [(1965, 2352)]\n",
      "Ann_id in getitem:  44823\n",
      "Test inds:  [(2650, 2925)]\n",
      "Ann_id in getitem:  60694\n",
      "Test inds:  [(3667, 240)]\n",
      "Ann_id in getitem:  84640\n",
      "Test inds:  [(1774, 858)]\n",
      "Ann_id in getitem:  41007\n",
      "Test inds:  [(2985, 3377)]\n",
      "Ann_id in getitem:  68876\n",
      "Test inds:  [(1296, 2477)]\n",
      "Ann_id in getitem:  30399\n",
      "Test inds:  [(1910, 663)]\n",
      "Ann_id in getitem:  43755\n",
      "Test inds:  [(1945, 298)]\n",
      "Ann_id in getitem:  44278\n",
      "Test inds:  [(3080, 3413)]\n",
      "Ann_id in getitem:  71062\n",
      "Test inds:  [(3348, 526)]\n",
      "Ann_id in getitem:  76887\n",
      "Test inds:  [(2372, 1018)]\n",
      "Ann_id in getitem:  53613\n",
      "Test inds:  [(2924, 3038)]\n",
      "Ann_id in getitem:  67297\n",
      "Test inds:  [(3582, 3690)]\n",
      "Ann_id in getitem:  82543\n",
      "Test inds:  [(1412, 3282)]\n",
      "Ann_id in getitem:  33439\n",
      "Test inds:  [(1088, 3060)]\n",
      "Ann_id in getitem:  25388\n",
      "Test inds:  [(802, 1606)]\n",
      "Ann_id in getitem:  19391\n",
      "Test inds:  [(2456, 1156)]\n",
      "Ann_id in getitem:  55772\n",
      "Test inds:  [(973, 541)]\n",
      "Ann_id in getitem:  22960\n",
      "Test inds:  [(1562, 149)]\n",
      "Ann_id in getitem:  36886\n",
      "Test inds:  [(2573, 669)]\n",
      "Ann_id in getitem:  58650\n",
      "Test inds:  [(390, 2677)]\n",
      "Ann_id in getitem:  9673\n",
      "Test inds:  [(2667, 1358)]\n",
      "Ann_id in getitem:  61205\n",
      "Test inds:  [(693, 140)]\n",
      "Ann_id in getitem:  16873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2629, 3278)]\n",
      "Ann_id in getitem:  60199\n",
      "Test inds:  [(2426, 914)]\n",
      "Ann_id in getitem:  54841\n",
      "Test inds:  [(1286, 432)]\n",
      "Ann_id in getitem:  30110\n",
      "Test inds:  [(287, 2485)]\n",
      "Ann_id in getitem:  6700\n",
      "Test inds:  [(3697, 2122)]\n",
      "Ann_id in getitem:  85435\n",
      "Test inds:  [(3346, 402)]\n",
      "Ann_id in getitem:  76881\n",
      "Test inds:  [(1115, 1839)]\n",
      "Ann_id in getitem:  25844\n",
      "Test inds:  [(2855, 1195)]\n",
      "Ann_id in getitem:  65690\n",
      "Test inds:  [(1540, 58)]\n",
      "Ann_id in getitem:  36496\n",
      "Test inds:  [(3205, 3429)]\n",
      "Ann_id in getitem:  73728\n",
      "Test inds:  [(2405, 2052)]\n",
      "Ann_id in getitem:  54377\n",
      "Test inds:  [(1243, 2224)]\n",
      "Ann_id in getitem:  29124\n",
      "Test inds:  [(2008, 3555)]\n",
      "Ann_id in getitem:  45701\n",
      "Test inds:  [(41, 1786)]\n",
      "Ann_id in getitem:  891\n",
      "Test inds:  [(2684, 2456)]\n",
      "Ann_id in getitem:  61636\n",
      "Test inds:  [(2700, 950)]\n",
      "Ann_id in getitem:  62024\n",
      "Test inds:  [(1876, 883)]\n",
      "Ann_id in getitem:  43156\n",
      "Test inds:  [(2468, 1342)]\n",
      "Ann_id in getitem:  56148\n",
      "Test inds:  [(1679, 2855)]\n",
      "Ann_id in getitem:  39303\n",
      "Test inds:  [(477, 3459)]\n",
      "Ann_id in getitem:  11517\n",
      "Test inds:  [(1151, 2081)]\n",
      "Ann_id in getitem:  26781\n",
      "Test inds:  [(1758, 3418)]\n",
      "Ann_id in getitem:  40670\n",
      "Test inds:  [(343, 2541)]\n",
      "Ann_id in getitem:  8299\n",
      "Test inds:  [(1173, 3212)]\n",
      "Ann_id in getitem:  27289\n",
      "Test inds:  [(2414, 390)]\n",
      "Ann_id in getitem:  54601\n",
      "Test inds:  [(3140, 1003)]\n",
      "Ann_id in getitem:  72439\n",
      "Test inds:  [(1843, 837)]\n",
      "Ann_id in getitem:  42375\n",
      "Test inds:  [(950, 845)]\n",
      "Ann_id in getitem:  22526\n",
      "Test inds:  [(1198, 2228)]\n",
      "Ann_id in getitem:  27869\n",
      "Test inds:  [(1244, 429)]\n",
      "Ann_id in getitem:  29129\n",
      "Test inds:  [(402, 1494)]\n",
      "Ann_id in getitem:  9897\n",
      "Test inds:  [(3132, 2592)]\n",
      "Ann_id in getitem:  72190\n",
      "Test inds:  [(2439, 2513)]\n",
      "Ann_id in getitem:  55312\n",
      "Test inds:  [(1833, 2790)]\n",
      "Ann_id in getitem:  42135\n",
      "Test inds:  [(3235, 3635)]\n",
      "Ann_id in getitem:  74370\n",
      "Test inds:  [(1360, 2628)]\n",
      "Ann_id in getitem:  32054\n",
      "Test inds:  [(1066, 2923)]\n",
      "Ann_id in getitem:  25051\n",
      "Test inds:  [(214, 421)]\n",
      "Ann_id in getitem:  5369\n",
      "Test inds:  [(290, 65)]\n",
      "Ann_id in getitem:  6752\n",
      "Test inds:  [(3309, 535)]\n",
      "Ann_id in getitem:  75992\n",
      "Test inds:  [(2164, 861)]\n",
      "Ann_id in getitem:  48818\n",
      "Test inds:  [(3254, 3320)]\n",
      "Ann_id in getitem:  74750\n",
      "Test inds:  [(1328, 1661)]\n",
      "Ann_id in getitem:  31105\n",
      "Test inds:  [(2642, 493)]\n",
      "Ann_id in getitem:  60503\n",
      "Test inds:  [(316, 258)]\n",
      "Ann_id in getitem:  7717\n",
      "Test inds:  [(1904, 1927)]\n",
      "Ann_id in getitem:  43667\n",
      "Test inds:  [(2071, 3325)]\n",
      "Ann_id in getitem:  47064\n",
      "Test inds:  [(3209, 1048)]\n",
      "Ann_id in getitem:  73780\n",
      "Test inds:  [(3305, 3307)]\n",
      "Ann_id in getitem:  75853\n",
      "Test inds:  [(3206, 591)]\n",
      "Ann_id in getitem:  73732\n",
      "Test inds:  [(1863, 2540)]\n",
      "Ann_id in getitem:  42934\n",
      "Test inds:  [(227, 1993)]\n",
      "Ann_id in getitem:  5535\n",
      "Test inds:  [(420, 2368)]\n",
      "Ann_id in getitem:  10208\n",
      "Test inds:  [(3481, 1042)]\n",
      "Ann_id in getitem:  80259\n",
      "Test inds:  [(2108, 2729)]\n",
      "Ann_id in getitem:  47790\n",
      "Test inds:  [(3358, 1888)]\n",
      "Ann_id in getitem:  77016\n",
      "Test inds:  [(336, 3048)]\n",
      "Ann_id in getitem:  8206\n",
      "Test inds:  [(18, 2028)]\n",
      "Ann_id in getitem:  441\n",
      "Test inds:  [(2170, 3083)]\n",
      "Ann_id in getitem:  48923\n",
      "Test inds:  [(1979, 2730)]\n",
      "Ann_id in getitem:  45150\n",
      "Test inds:  [(2420, 1157)]\n",
      "Ann_id in getitem:  54679\n",
      "Test inds:  [(3081, 2914)]\n",
      "Ann_id in getitem:  71066\n",
      "Test inds:  [(457, 3074)]\n",
      "Ann_id in getitem:  11053\n",
      "Test inds:  [(1060, 2098)]\n",
      "Ann_id in getitem:  24978\n",
      "Test inds:  [(2014, 1485)]\n",
      "Ann_id in getitem:  45833\n",
      "Test inds:  [(1704, 2769)]\n",
      "Ann_id in getitem:  39872\n",
      "Test inds:  [(704, 2790)]\n",
      "Ann_id in getitem:  17085\n",
      "Test inds:  [(2670, 2977)]\n",
      "Ann_id in getitem:  61286\n",
      "Test inds:  [(194, 33)]\n",
      "Ann_id in getitem:  4857\n",
      "Test inds:  [(57, 220)]\n",
      "Ann_id in getitem:  1221\n",
      "Test inds:  [(425, 2940)]\n",
      "Ann_id in getitem:  10359\n",
      "Test inds:  [(826, 2379)]\n",
      "Ann_id in getitem:  19812\n",
      "Test inds:  [(2407, 1244)]\n",
      "Ann_id in getitem:  54427\n",
      "Test inds:  [(1087, 1413)]\n",
      "Ann_id in getitem:  25373\n",
      "Test inds:  [(2538, 2970)]\n",
      "Ann_id in getitem:  57603\n",
      "Test inds:  [(2552, 3210)]\n",
      "Ann_id in getitem:  57974\n",
      "Test inds:  [(3133, 82)]\n",
      "Ann_id in getitem:  72259\n",
      "Test inds:  [(1356, 13)]\n",
      "Ann_id in getitem:  31991\n",
      "Test inds:  [(1148, 678)]\n",
      "Ann_id in getitem:  26760\n",
      "Test inds:  [(3648, 2135)]\n",
      "Ann_id in getitem:  84173\n",
      "Test inds:  [(2376, 2625)]\n",
      "Ann_id in getitem:  53701\n",
      "Test inds:  [(1233, 2114)]\n",
      "Ann_id in getitem:  28805\n",
      "Test inds:  [(2170, 1416)]\n",
      "Ann_id in getitem:  48923\n",
      "Test inds:  [(2036, 2410)]\n",
      "Ann_id in getitem:  46334\n",
      "Test inds:  [(75, 179)]\n",
      "Ann_id in getitem:  1693\n",
      "Test inds:  [(1878, 2159)]\n",
      "Ann_id in getitem:  43176\n",
      "Test inds:  [(2763, 2364)]\n",
      "Ann_id in getitem:  63560\n",
      "Test inds:  [(1821, 1896)]\n",
      "Ann_id in getitem:  41926\n",
      "Test inds:  [(2062, 319)]\n",
      "Ann_id in getitem:  46911\n",
      "Test inds:  [(837, 1849)]\n",
      "Ann_id in getitem:  20078\n",
      "Test inds:  [(24, 259)]\n",
      "Ann_id in getitem:  478\n",
      "Test inds:  [(1117, 1565)]\n",
      "Ann_id in getitem:  25906\n",
      "Test inds:  [(2212, 2469)]\n",
      "Ann_id in getitem:  49791\n",
      "Test inds:  [(2922, 1027)]\n",
      "Ann_id in getitem:  67286\n",
      "Test inds:  [(385, 2267)]\n",
      "Ann_id in getitem:  9564\n",
      "Test inds:  [(827, 1934)]\n",
      "Ann_id in getitem:  19843\n",
      "Test inds:  [(874, 1169)]\n",
      "Ann_id in getitem:  21004\n",
      "Test inds:  [(113, 137)]\n",
      "Ann_id in getitem:  2655\n",
      "Test inds:  [(911, 1537)]\n",
      "Ann_id in getitem:  21670\n",
      "Test inds:  [(3626, 3388)]\n",
      "Ann_id in getitem:  83645\n",
      "Test inds:  [(454, 2578)]\n",
      "Ann_id in getitem:  10973\n",
      "Test inds:  [(1943, 1353)]\n",
      "Ann_id in getitem:  44244\n",
      "Test inds:  [(2467, 2165)]\n",
      "Ann_id in getitem:  56139\n",
      "Test inds:  [(1429, 2689)]\n",
      "Ann_id in getitem:  33892\n",
      "Test inds:  [(495, 2969)]\n",
      "Ann_id in getitem:  11880\n",
      "Test inds:  [(1966, 1892)]\n",
      "Ann_id in getitem:  44888\n",
      "Test inds:  [(563, 1878)]\n",
      "Ann_id in getitem:  13557\n",
      "Test inds:  [(1471, 765)]\n",
      "Ann_id in getitem:  34906\n",
      "Test inds:  [(2893, 1218)]\n",
      "Ann_id in getitem:  66533\n",
      "Test inds:  [(2346, 3512)]\n",
      "Ann_id in getitem:  52945\n",
      "Test inds:  [(1165, 499)]\n",
      "Ann_id in getitem:  27148\n",
      "Test inds:  [(569, 175)]\n",
      "Ann_id in getitem:  13745\n",
      "Test inds:  [(2412, 1169)]\n",
      "Ann_id in getitem:  54580\n",
      "Test inds:  [(2154, 1514)]\n",
      "Ann_id in getitem:  48648\n",
      "Test inds:  [(2662, 81)]\n",
      "Ann_id in getitem:  61060\n",
      "Test inds:  [(2721, 3090)]\n",
      "Ann_id in getitem:  62544\n",
      "Test inds:  [(2984, 394)]\n",
      "Ann_id in getitem:  68819\n",
      "Test inds:  [(1981, 3281)]\n",
      "Ann_id in getitem:  45166\n",
      "Test inds:  [(2273, 88)]\n",
      "Ann_id in getitem:  51405\n",
      "Test inds:  [(181, 70)]\n",
      "Ann_id in getitem:  4633\n",
      "Test inds:  [(313, 3342)]\n",
      "Ann_id in getitem:  7637\n",
      "Test inds:  [(1507, 998)]\n",
      "Ann_id in getitem:  35763\n",
      "Test inds:  [(154, 2826)]\n",
      "Ann_id in getitem:  3765\n",
      "Test inds:  [(2512, 892)]\n",
      "Ann_id in getitem:  57154\n",
      "Test inds:  [(301, 1810)]\n",
      "Ann_id in getitem:  7090\n",
      "Test inds:  [(1484, 3258)]\n",
      "Ann_id in getitem:  35252\n",
      "Test inds:  [(291, 3192)]\n",
      "Ann_id in getitem:  6785\n",
      "Test inds:  [(3176, 2829)]\n",
      "Ann_id in getitem:  73113\n",
      "Test inds:  [(543, 248)]\n",
      "Ann_id in getitem:  12949\n",
      "Test inds:  [(2237, 282)]\n",
      "Ann_id in getitem:  50411\n",
      "Test inds:  [(344, 1829)]\n",
      "Ann_id in getitem:  8323\n",
      "Test inds:  [(2689, 353)]\n",
      "Ann_id in getitem:  61729\n",
      "Test inds:  [(1897, 1731)]\n",
      "Ann_id in getitem:  43529\n",
      "Test inds:  [(2604, 2223)]\n",
      "Ann_id in getitem:  59664\n",
      "Test inds:  [(293, 3529)]\n",
      "Ann_id in getitem:  6803\n",
      "Test inds:  [(2311, 36)]\n",
      "Ann_id in getitem:  52098\n",
      "Test inds:  [(2916, 1751)]\n",
      "Ann_id in getitem:  67135\n",
      "Test inds:  [(2681, 3569)]\n",
      "Ann_id in getitem:  61586\n",
      "Test inds:  [(2465, 2865)]\n",
      "Ann_id in getitem:  56083\n",
      "Test inds:  [(1933, 2567)]\n",
      "Ann_id in getitem:  44105\n",
      "Test inds:  [(1609, 168)]\n",
      "Ann_id in getitem:  37795\n",
      "Test inds:  [(1803, 1663)]\n",
      "Ann_id in getitem:  41600\n",
      "Test inds:  [(904, 543)]\n",
      "Ann_id in getitem:  21602\n",
      "Test inds:  [(1526, 55)]\n",
      "Ann_id in getitem:  36114\n",
      "Test inds:  [(3623, 2242)]\n",
      "Ann_id in getitem:  83592\n",
      "Test inds:  [(551, 2970)]\n",
      "Ann_id in getitem:  13271\n",
      "Test inds:  [(472, 1149)]\n",
      "Ann_id in getitem:  11329\n",
      "Test inds:  [(3196, 447)]\n",
      "Ann_id in getitem:  73530\n",
      "Test inds:  [(2631, 2770)]\n",
      "Ann_id in getitem:  60240\n",
      "Test inds:  [(2260, 3494)]\n",
      "Ann_id in getitem:  51083\n",
      "Test inds:  [(975, 1055)]\n",
      "Ann_id in getitem:  22991\n",
      "Test inds:  [(2263, 3328)]\n",
      "Ann_id in getitem:  51107\n",
      "Test inds:  [(188, 3245)]\n",
      "Ann_id in getitem:  4774\n",
      "Test inds:  [(3483, 808)]\n",
      "Ann_id in getitem:  80266\n",
      "Test inds:  [(26, 2067)]\n",
      "Ann_id in getitem:  540\n",
      "Test inds:  [(1428, 2204)]\n",
      "Ann_id in getitem:  33859\n",
      "Test inds:  [(1384, 3485)]\n",
      "Ann_id in getitem:  32866\n",
      "Test inds:  [(1078, 2983)]\n",
      "Ann_id in getitem:  25229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1847, 906)]\n",
      "Ann_id in getitem:  42519\n",
      "Test inds:  [(3548, 2211)]\n",
      "Ann_id in getitem:  81846\n",
      "Test inds:  [(3354, 1913)]\n",
      "Ann_id in getitem:  76925\n",
      "Test inds:  [(867, 2132)]\n",
      "Ann_id in getitem:  20919\n",
      "Test inds:  [(2991, 520)]\n",
      "Ann_id in getitem:  68948\n",
      "Test inds:  [(1055, 316)]\n",
      "Ann_id in getitem:  24930\n",
      "Test inds:  [(1616, 526)]\n",
      "Ann_id in getitem:  37888\n",
      "Test inds:  [(1469, 2191)]\n",
      "Ann_id in getitem:  34786\n",
      "Test inds:  [(3371, 2947)]\n",
      "Ann_id in getitem:  77508\n",
      "Test inds:  [(2159, 2741)]\n",
      "Ann_id in getitem:  48721\n",
      "Test inds:  [(1533, 3148)]\n",
      "Ann_id in getitem:  36312\n",
      "Test inds:  [(2010, 426)]\n",
      "Ann_id in getitem:  45719\n",
      "Test inds:  [(3440, 2835)]\n",
      "Ann_id in getitem:  79259\n",
      "Test inds:  [(3306, 3472)]\n",
      "Ann_id in getitem:  75935\n",
      "Test inds:  [(867, 567)]\n",
      "Ann_id in getitem:  20919\n",
      "Test inds:  [(3062, 2736)]\n",
      "Ann_id in getitem:  70624\n",
      "Test inds:  [(2335, 1072)]\n",
      "Ann_id in getitem:  52659\n",
      "Test inds:  [(1110, 1919)]\n",
      "Ann_id in getitem:  25767\n",
      "Test inds:  [(1950, 1989)]\n",
      "Ann_id in getitem:  44354\n",
      "Test inds:  [(972, 3634)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(2251, 146)]\n",
      "Ann_id in getitem:  50882\n",
      "Test inds:  [(1609, 1997)]\n",
      "Ann_id in getitem:  37795\n",
      "Test inds:  [(2162, 3185)]\n",
      "Ann_id in getitem:  48777\n",
      "Test inds:  [(2031, 2614)]\n",
      "Ann_id in getitem:  46238\n",
      "Test inds:  [(774, 104)]\n",
      "Ann_id in getitem:  18796\n",
      "Test inds:  [(1247, 3270)]\n",
      "Ann_id in getitem:  29227\n",
      "Test inds:  [(2784, 1220)]\n",
      "Ann_id in getitem:  64236\n",
      "Test inds:  [(1351, 1231)]\n",
      "Ann_id in getitem:  31835\n",
      "Test inds:  [(2341, 1561)]\n",
      "Ann_id in getitem:  52808\n",
      "Test inds:  [(2548, 3494)]\n",
      "Ann_id in getitem:  57904\n",
      "Test inds:  [(3208, 810)]\n",
      "Ann_id in getitem:  73766\n",
      "Test inds:  [(102, 50)]\n",
      "Ann_id in getitem:  2242\n",
      "Test inds:  [(1865, 3542)]\n",
      "Ann_id in getitem:  42971\n",
      "Test inds:  [(1897, 1871)]\n",
      "Ann_id in getitem:  43529\n",
      "Test inds:  [(1787, 1215)]\n",
      "Ann_id in getitem:  41205\n",
      "Test inds:  [(2227, 152)]\n",
      "Ann_id in getitem:  50158\n",
      "Test inds:  [(2590, 3122)]\n",
      "Ann_id in getitem:  59384\n",
      "Test inds:  [(2874, 789)]\n",
      "Ann_id in getitem:  66053\n",
      "Test inds:  [(1790, 3104)]\n",
      "Ann_id in getitem:  41318\n",
      "Test inds:  [(35, 3567)]\n",
      "Ann_id in getitem:  791\n",
      "Test inds:  [(2645, 1912)]\n",
      "Ann_id in getitem:  60584\n",
      "Test inds:  [(2812, 2036)]\n",
      "Ann_id in getitem:  64859\n",
      "Test inds:  [(3171, 334)]\n",
      "Ann_id in getitem:  73055\n",
      "Test inds:  [(823, 2454)]\n",
      "Ann_id in getitem:  19785\n",
      "Test inds:  [(2898, 856)]\n",
      "Ann_id in getitem:  66643\n",
      "Test inds:  [(2633, 977)]\n",
      "Ann_id in getitem:  60290\n",
      "Test inds:  [(1354, 2528)]\n",
      "Ann_id in getitem:  31963\n",
      "Test inds:  [(2478, 3435)]\n",
      "Ann_id in getitem:  56418\n",
      "Test inds:  [(1885, 787)]\n",
      "Ann_id in getitem:  43370\n",
      "Test inds:  [(3268, 3670)]\n",
      "Ann_id in getitem:  74929\n",
      "Test inds:  [(3307, 1075)]\n",
      "Ann_id in getitem:  75972\n",
      "Test inds:  [(3035, 3526)]\n",
      "Ann_id in getitem:  69944\n",
      "Test inds:  [(1534, 935)]\n",
      "Ann_id in getitem:  36322\n",
      "Test inds:  [(1387, 3011)]\n",
      "Ann_id in getitem:  32952\n",
      "Test inds:  [(2558, 2580)]\n",
      "Ann_id in getitem:  58138\n",
      "Test inds:  [(1952, 2965)]\n",
      "Ann_id in getitem:  44430\n",
      "Test inds:  [(1315, 1749)]\n",
      "Ann_id in getitem:  30775\n",
      "Test inds:  [(2307, 979)]\n",
      "Ann_id in getitem:  52025\n",
      "Test inds:  [(108, 247)]\n",
      "Ann_id in getitem:  2473\n",
      "Test inds:  [(1919, 1139)]\n",
      "Ann_id in getitem:  43938\n",
      "Test inds:  [(3687, 2991)]\n",
      "Ann_id in getitem:  85147\n",
      "Test inds:  [(545, 1063)]\n",
      "Ann_id in getitem:  12973\n",
      "Test inds:  [(853, 3294)]\n",
      "Ann_id in getitem:  20770\n",
      "Test inds:  [(2461, 1948)]\n",
      "Ann_id in getitem:  55976\n",
      "Test inds:  [(439, 1530)]\n",
      "Ann_id in getitem:  10725\n",
      "Test inds:  [(2369, 1687)]\n",
      "Ann_id in getitem:  53579\n",
      "Test inds:  [(1795, 2457)]\n",
      "Ann_id in getitem:  41460\n",
      "Test inds:  [(2088, 2518)]\n",
      "Ann_id in getitem:  47370\n",
      "Test inds:  [(2538, 683)]\n",
      "Ann_id in getitem:  57603\n",
      "Test inds:  [(1277, 116)]\n",
      "Ann_id in getitem:  29852\n",
      "Test inds:  [(1624, 1485)]\n",
      "Ann_id in getitem:  38046\n",
      "Test inds:  [(1299, 474)]\n",
      "Ann_id in getitem:  30484\n",
      "Test inds:  [(3216, 986)]\n",
      "Ann_id in getitem:  73985\n",
      "Test inds:  [(2975, 2882)]\n",
      "Ann_id in getitem:  68531\n",
      "Test inds:  [(3627, 3546)]\n",
      "Ann_id in getitem:  83655\n",
      "Test inds:  [(3090, 1524)]\n",
      "Ann_id in getitem:  71238\n",
      "Test inds:  [(1381, 3001)]\n",
      "Ann_id in getitem:  32820\n",
      "Test inds:  [(2342, 1520)]\n",
      "Ann_id in getitem:  52873\n",
      "Test inds:  [(1197, 461)]\n",
      "Ann_id in getitem:  27858\n",
      "Test inds:  [(408, 239)]\n",
      "Ann_id in getitem:  10002\n",
      "Test inds:  [(3424, 2407)]\n",
      "Ann_id in getitem:  78917\n",
      "Test inds:  [(3663, 2502)]\n",
      "Ann_id in getitem:  84593\n",
      "Test inds:  [(1476, 934)]\n",
      "Ann_id in getitem:  34992\n",
      "Test inds:  [(2261, 708)]\n",
      "Ann_id in getitem:  51089\n",
      "Test inds:  [(937, 1181)]\n",
      "Ann_id in getitem:  22335\n",
      "Test inds:  [(1384, 2279)]\n",
      "Ann_id in getitem:  32866\n",
      "Test inds:  [(1956, 1782)]\n",
      "Ann_id in getitem:  44477\n",
      "Test inds:  [(3262, 888)]\n",
      "Ann_id in getitem:  74853\n",
      "Test inds:  [(2327, 412)]\n",
      "Ann_id in getitem:  52386\n",
      "Test inds:  [(2347, 2319)]\n",
      "Ann_id in getitem:  52955\n",
      "Test inds:  [(3156, 493)]\n",
      "Ann_id in getitem:  72762\n",
      "Test inds:  [(979, 875)]\n",
      "Ann_id in getitem:  23097\n",
      "Test inds:  [(1329, 680)]\n",
      "Ann_id in getitem:  31225\n",
      "Test inds:  [(117, 3693)]\n",
      "Ann_id in getitem:  2734\n",
      "Test inds:  [(941, 2191)]\n",
      "Ann_id in getitem:  22353\n",
      "Test inds:  [(1376, 1660)]\n",
      "Ann_id in getitem:  32509\n",
      "Test inds:  [(2189, 1313)]\n",
      "Ann_id in getitem:  49285\n",
      "Test inds:  [(2082, 145)]\n",
      "Ann_id in getitem:  47256\n",
      "Test inds:  [(1568, 2915)]\n",
      "Ann_id in getitem:  37096\n",
      "Test inds:  [(412, 2479)]\n",
      "Ann_id in getitem:  10069\n",
      "Test inds:  [(1148, 3353)]\n",
      "Ann_id in getitem:  26760\n",
      "Test inds:  [(2843, 3262)]\n",
      "Ann_id in getitem:  65444\n",
      "Test inds:  [(876, 3607)]\n",
      "Ann_id in getitem:  21028\n",
      "Test inds:  [(1826, 2593)]\n",
      "Ann_id in getitem:  42020\n",
      "Test inds:  [(2613, 2805)]\n",
      "Ann_id in getitem:  59857\n",
      "Test inds:  [(743, 2101)]\n",
      "Ann_id in getitem:  18010\n",
      "Test inds:  [(3264, 154)]\n",
      "Ann_id in getitem:  74865\n",
      "Test inds:  [(396, 1998)]\n",
      "Ann_id in getitem:  9740\n",
      "Test inds:  [(2152, 1481)]\n",
      "Ann_id in getitem:  48627\n",
      "Test inds:  [(551, 805)]\n",
      "Ann_id in getitem:  13271\n",
      "Test inds:  [(2570, 765)]\n",
      "Ann_id in getitem:  58607\n",
      "Test inds:  [(1359, 973)]\n",
      "Ann_id in getitem:  32039\n",
      "Test inds:  [(418, 577)]\n",
      "Ann_id in getitem:  10176\n",
      "Test inds:  [(1779, 298)]\n",
      "Ann_id in getitem:  41078\n",
      "Test inds:  [(2977, 2123)]\n",
      "Ann_id in getitem:  68578\n",
      "Test inds:  [(1802, 384)]\n",
      "Ann_id in getitem:  41585\n",
      "Test inds:  [(2848, 3667)]\n",
      "Ann_id in getitem:  65545\n",
      "Test inds:  [(1969, 1519)]\n",
      "Ann_id in getitem:  44953\n",
      "Test inds:  [(613, 1736)]\n",
      "Ann_id in getitem:  14979\n",
      "Test inds:  [(66, 845)]\n",
      "Ann_id in getitem:  1437\n",
      "Test inds:  [(1025, 3189)]\n",
      "Ann_id in getitem:  24202\n",
      "Test inds:  [(1417, 1356)]\n",
      "Ann_id in getitem:  33495\n",
      "Test inds:  [(619, 1189)]\n",
      "Ann_id in getitem:  15172\n",
      "Test inds:  [(3099, 1459)]\n",
      "Ann_id in getitem:  71428\n",
      "Test inds:  [(1898, 1275)]\n",
      "Ann_id in getitem:  43542\n",
      "Test inds:  [(2334, 526)]\n",
      "Ann_id in getitem:  52637\n",
      "Test inds:  [(1841, 3389)]\n",
      "Ann_id in getitem:  42253\n",
      "Test inds:  [(1910, 3180)]\n",
      "Ann_id in getitem:  43755\n",
      "Test inds:  [(539, 3646)]\n",
      "Ann_id in getitem:  12831\n",
      "Test inds:  [(16, 2752)]\n",
      "Ann_id in getitem:  401\n",
      "Test inds:  [(2704, 2312)]\n",
      "Ann_id in getitem:  62146\n",
      "Test inds:  [(2441, 3366)]\n",
      "Ann_id in getitem:  55355\n",
      "Test inds:  [(3163, 1541)]\n",
      "Ann_id in getitem:  72875\n",
      "Test inds:  [(1100, 3275)]\n",
      "Ann_id in getitem:  25581\n",
      "Test inds:  [(1086, 1216)]\n",
      "Ann_id in getitem:  25327\n",
      "Test inds:  [(2557, 2807)]\n",
      "Ann_id in getitem:  58109\n",
      "Test inds:  [(1913, 755)]\n",
      "Ann_id in getitem:  43827\n",
      "Test inds:  [(3474, 1566)]\n",
      "Ann_id in getitem:  80153\n",
      "Test inds:  [(2142, 1188)]\n",
      "Ann_id in getitem:  48491\n",
      "Test inds:  [(2060, 3459)]\n",
      "Ann_id in getitem:  46872\n",
      "Test inds:  [(2194, 2328)]\n",
      "Ann_id in getitem:  49381\n",
      "Test inds:  [(3621, 3011)]\n",
      "Ann_id in getitem:  83575\n",
      "Test inds:  [(1767, 1295)]\n",
      "Ann_id in getitem:  40839\n",
      "Test inds:  [(42, 2608)]\n",
      "Ann_id in getitem:  931\n",
      "Test inds:  [(1889, 261)]\n",
      "Ann_id in getitem:  43405\n",
      "Test inds:  [(314, 2310)]\n",
      "Ann_id in getitem:  7670\n",
      "Test inds:  [(2714, 18)]\n",
      "Ann_id in getitem:  62433\n",
      "Test inds:  [(208, 2401)]\n",
      "Ann_id in getitem:  5209\n",
      "Test inds:  [(2020, 954)]\n",
      "Ann_id in getitem:  45905\n",
      "Test inds:  [(3391, 959)]\n",
      "Ann_id in getitem:  77907\n",
      "Test inds:  [(2379, 441)]\n",
      "Ann_id in getitem:  53768\n",
      "Test inds:  [(9, 3451)]\n",
      "Ann_id in getitem:  181\n",
      "Test inds:  [(3361, 3240)]\n",
      "Ann_id in getitem:  77144\n",
      "Test inds:  [(941, 3042)]\n",
      "Ann_id in getitem:  22353\n",
      "Test inds:  [(2584, 3011)]\n",
      "Ann_id in getitem:  59079\n",
      "Test inds:  [(2587, 752)]\n",
      "Ann_id in getitem:  59284\n",
      "Test inds:  [(1004, 713)]\n",
      "Ann_id in getitem:  23799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2510, 1067)]\n",
      "Ann_id in getitem:  57133\n",
      "Test inds:  [(2199, 77)]\n",
      "Ann_id in getitem:  49505\n",
      "Test inds:  [(2657, 2042)]\n",
      "Ann_id in getitem:  60988\n",
      "Test inds:  [(1306, 3410)]\n",
      "Ann_id in getitem:  30522\n",
      "Test inds:  [(3671, 3639)]\n",
      "Ann_id in getitem:  84679\n",
      "Test inds:  [(1309, 292)]\n",
      "Ann_id in getitem:  30639\n",
      "Test inds:  [(1658, 333)]\n",
      "Ann_id in getitem:  38806\n",
      "Test inds:  [(2511, 1195)]\n",
      "Ann_id in getitem:  57146\n",
      "Test inds:  [(1837, 1210)]\n",
      "Ann_id in getitem:  42181\n",
      "Test inds:  [(1454, 2822)]\n",
      "Ann_id in getitem:  34463\n",
      "Test inds:  [(1800, 1702)]\n",
      "Ann_id in getitem:  41577\n",
      "Test inds:  [(143, 2568)]\n",
      "Ann_id in getitem:  3464\n",
      "Test inds:  [(2879, 658)]\n",
      "Ann_id in getitem:  66209\n",
      "Test inds:  [(3687, 470)]\n",
      "Ann_id in getitem:  85147\n",
      "Test inds:  [(1457, 2231)]\n",
      "Ann_id in getitem:  34516\n",
      "Test inds:  [(156, 2863)]\n",
      "Ann_id in getitem:  3903\n",
      "Test inds:  [(2853, 1736)]\n",
      "Ann_id in getitem:  65665\n",
      "Test inds:  [(1084, 840)]\n",
      "Ann_id in getitem:  25277\n",
      "Test inds:  [(1756, 730)]\n",
      "Ann_id in getitem:  40646\n",
      "Test inds:  [(3585, 1715)]\n",
      "Ann_id in getitem:  82662\n",
      "Test inds:  [(2554, 2888)]\n",
      "Ann_id in getitem:  58015\n",
      "Test inds:  [(2030, 2426)]\n",
      "Ann_id in getitem:  46193\n",
      "Test inds:  [(2879, 3095)]\n",
      "Ann_id in getitem:  66209\n",
      "Test inds:  [(2637, 2853)]\n",
      "Ann_id in getitem:  60348\n",
      "Test inds:  [(2093, 959)]\n",
      "Ann_id in getitem:  47425\n",
      "Test inds:  [(937, 821)]\n",
      "Ann_id in getitem:  22335\n",
      "Test inds:  [(334, 3298)]\n",
      "Ann_id in getitem:  8173\n",
      "Test inds:  [(2777, 3178)]\n",
      "Ann_id in getitem:  63977\n",
      "Test inds:  [(3434, 1915)]\n",
      "Ann_id in getitem:  79157\n",
      "Test inds:  [(1347, 1495)]\n",
      "Ann_id in getitem:  31739\n",
      "Test inds:  [(3516, 2387)]\n",
      "Ann_id in getitem:  81120\n",
      "Test inds:  [(94, 2736)]\n",
      "Ann_id in getitem:  2139\n",
      "Test inds:  [(1119, 3272)]\n",
      "Ann_id in getitem:  25935\n",
      "Test inds:  [(1989, 584)]\n",
      "Ann_id in getitem:  45321\n",
      "Test inds:  [(3246, 858)]\n",
      "Ann_id in getitem:  74594\n",
      "Test inds:  [(3582, 2904)]\n",
      "Ann_id in getitem:  82543\n",
      "Test inds:  [(1279, 3179)]\n",
      "Ann_id in getitem:  29962\n",
      "Test inds:  [(3365, 1246)]\n",
      "Ann_id in getitem:  77274\n",
      "Test inds:  [(2636, 1550)]\n",
      "Ann_id in getitem:  60310\n",
      "Test inds:  [(788, 1337)]\n",
      "Ann_id in getitem:  19055\n",
      "Test inds:  [(496, 2240)]\n",
      "Ann_id in getitem:  11897\n",
      "Test inds:  [(2427, 859)]\n",
      "Ann_id in getitem:  54854\n",
      "Test inds:  [(2525, 3301)]\n",
      "Ann_id in getitem:  57329\n",
      "Test inds:  [(1025, 3510)]\n",
      "Ann_id in getitem:  24202\n",
      "Test inds:  [(574, 2775)]\n",
      "Ann_id in getitem:  13846\n",
      "Test inds:  [(3637, 477)]\n",
      "Ann_id in getitem:  83957\n",
      "Test inds:  [(3615, 3023)]\n",
      "Ann_id in getitem:  83445\n",
      "Test inds:  [(888, 2392)]\n",
      "Ann_id in getitem:  21197\n",
      "Test inds:  [(2059, 2370)]\n",
      "Ann_id in getitem:  46861\n",
      "Test inds:  [(1081, 656)]\n",
      "Ann_id in getitem:  25257\n",
      "Test inds:  [(3110, 1061)]\n",
      "Ann_id in getitem:  71760\n",
      "Test inds:  [(1484, 2362)]\n",
      "Ann_id in getitem:  35252\n",
      "Test inds:  [(1101, 1680)]\n",
      "Ann_id in getitem:  25609\n",
      "Test inds:  [(3116, 1258)]\n",
      "Ann_id in getitem:  71909\n",
      "Test inds:  [(2734, 2172)]\n",
      "Ann_id in getitem:  62919\n",
      "Test inds:  [(446, 1012)]\n",
      "Ann_id in getitem:  10865\n",
      "Test inds:  [(1365, 3389)]\n",
      "Ann_id in getitem:  32197\n",
      "Test inds:  [(741, 3505)]\n",
      "Ann_id in getitem:  17964\n",
      "Test inds:  [(2473, 3509)]\n",
      "Ann_id in getitem:  56274\n",
      "Test inds:  [(183, 931)]\n",
      "Ann_id in getitem:  4700\n",
      "Test inds:  [(28, 1177)]\n",
      "Ann_id in getitem:  589\n",
      "Test inds:  [(780, 257)]\n",
      "Ann_id in getitem:  18906\n",
      "Test inds:  [(2672, 361)]\n",
      "Ann_id in getitem:  61306\n",
      "Test inds:  [(1071, 2478)]\n",
      "Ann_id in getitem:  25148\n",
      "Test inds:  [(2478, 3640)]\n",
      "Ann_id in getitem:  56418\n",
      "Test inds:  [(688, 397)]\n",
      "Ann_id in getitem:  16752\n",
      "Test inds:  [(3624, 2200)]\n",
      "Ann_id in getitem:  83639\n",
      "Test inds:  [(715, 3286)]\n",
      "Ann_id in getitem:  17336\n",
      "Test inds:  [(394, 2576)]\n",
      "Ann_id in getitem:  9709\n",
      "Test inds:  [(1231, 473)]\n",
      "Ann_id in getitem:  28779\n",
      "Test inds:  [(2500, 2942)]\n",
      "Ann_id in getitem:  56952\n",
      "Test inds:  [(180, 3057)]\n",
      "Ann_id in getitem:  4604\n",
      "Test inds:  [(941, 1297)]\n",
      "Ann_id in getitem:  22353\n",
      "Test inds:  [(1781, 2555)]\n",
      "Ann_id in getitem:  41090\n",
      "Test inds:  [(1690, 724)]\n",
      "Ann_id in getitem:  39638\n",
      "Test inds:  [(3460, 836)]\n",
      "Ann_id in getitem:  79849\n",
      "Test inds:  [(3273, 2080)]\n",
      "Ann_id in getitem:  74988\n",
      "Test inds:  [(2182, 1992)]\n",
      "Ann_id in getitem:  49148\n",
      "Test inds:  [(2285, 2720)]\n",
      "Ann_id in getitem:  51632\n",
      "Test inds:  [(3060, 1155)]\n",
      "Ann_id in getitem:  70600\n",
      "Test inds:  [(3157, 1123)]\n",
      "Ann_id in getitem:  72771\n",
      "Test inds:  [(549, 1915)]\n",
      "Ann_id in getitem:  13155\n",
      "Test inds:  [(349, 2441)]\n",
      "Ann_id in getitem:  8469\n",
      "Test inds:  [(269, 1349)]\n",
      "Ann_id in getitem:  6394\n",
      "Test inds:  [(3244, 2239)]\n",
      "Ann_id in getitem:  74557\n",
      "Test inds:  [(1952, 3485)]\n",
      "Ann_id in getitem:  44430\n",
      "Test inds:  [(728, 1665)]\n",
      "Ann_id in getitem:  17583\n",
      "Test inds:  [(409, 542)]\n",
      "Ann_id in getitem:  10030\n",
      "Test inds:  [(796, 3636)]\n",
      "Ann_id in getitem:  19268\n",
      "Test inds:  [(3429, 665)]\n",
      "Ann_id in getitem:  79028\n",
      "Test inds:  [(149, 2136)]\n",
      "Ann_id in getitem:  3710\n",
      "Test inds:  [(2119, 3212)]\n",
      "Ann_id in getitem:  48004\n",
      "Test inds:  [(268, 2564)]\n",
      "Ann_id in getitem:  6371\n",
      "Test inds:  [(303, 2189)]\n",
      "Ann_id in getitem:  7237\n",
      "Test inds:  [(1783, 661)]\n",
      "Ann_id in getitem:  41100\n",
      "Test inds:  [(1267, 2355)]\n",
      "Ann_id in getitem:  29605\n",
      "Test inds:  [(2325, 682)]\n",
      "Ann_id in getitem:  52356\n",
      "Test inds:  [(2699, 3208)]\n",
      "Ann_id in getitem:  62015\n",
      "Test inds:  [(2633, 418)]\n",
      "Ann_id in getitem:  60290\n",
      "Test inds:  [(1621, 482)]\n",
      "Ann_id in getitem:  38030\n",
      "Test inds:  [(3122, 1361)]\n",
      "Ann_id in getitem:  72009\n",
      "Test inds:  [(3098, 3137)]\n",
      "Ann_id in getitem:  71418\n",
      "Test inds:  [(1841, 2724)]\n",
      "Ann_id in getitem:  42253\n",
      "Test inds:  [(1331, 3043)]\n",
      "Ann_id in getitem:  31292\n",
      "Test inds:  [(3417, 3337)]\n",
      "Ann_id in getitem:  78714\n",
      "Test inds:  [(2492, 87)]\n",
      "Ann_id in getitem:  56693\n",
      "Test inds:  [(2658, 2585)]\n",
      "Ann_id in getitem:  61013\n",
      "Test inds:  [(6, 2751)]\n",
      "Ann_id in getitem:  109\n",
      "Test inds:  [(2400, 1049)]\n",
      "Ann_id in getitem:  54293\n",
      "Test inds:  [(347, 295)]\n",
      "Ann_id in getitem:  8427\n",
      "Test inds:  [(2255, 2720)]\n",
      "Ann_id in getitem:  50948\n",
      "Test inds:  [(3453, 1311)]\n",
      "Ann_id in getitem:  79645\n",
      "Test inds:  [(3142, 3504)]\n",
      "Ann_id in getitem:  72472\n",
      "Test inds:  [(3150, 3467)]\n",
      "Ann_id in getitem:  72611\n",
      "Test inds:  [(2470, 545)]\n",
      "Ann_id in getitem:  56161\n",
      "Test inds:  [(93, 582)]\n",
      "Ann_id in getitem:  2121\n",
      "Test inds:  [(2953, 2252)]\n",
      "Ann_id in getitem:  68021\n",
      "Test inds:  [(1019, 1205)]\n",
      "Ann_id in getitem:  24117\n",
      "Test inds:  [(997, 275)]\n",
      "Ann_id in getitem:  23663\n",
      "Test inds:  [(794, 154)]\n",
      "Ann_id in getitem:  19244\n",
      "Test inds:  [(192, 2700)]\n",
      "Ann_id in getitem:  4852\n",
      "Test inds:  [(149, 444)]\n",
      "Ann_id in getitem:  3710\n",
      "Test inds:  [(3575, 2500)]\n",
      "Ann_id in getitem:  82426\n",
      "Test inds:  [(2035, 2047)]\n",
      "Ann_id in getitem:  46314\n",
      "Test inds:  [(2255, 3461)]\n",
      "Ann_id in getitem:  50948\n",
      "Test inds:  [(2842, 376)]\n",
      "Ann_id in getitem:  65439\n",
      "Test inds:  [(1740, 1021)]\n",
      "Ann_id in getitem:  40443\n",
      "Test inds:  [(2898, 1514)]\n",
      "Ann_id in getitem:  66643\n",
      "Test inds:  [(1009, 3157)]\n",
      "Ann_id in getitem:  23966\n",
      "Test inds:  [(3560, 434)]\n",
      "Ann_id in getitem:  82096\n",
      "Test inds:  [(687, 1276)]\n",
      "Ann_id in getitem:  16726\n",
      "Test inds:  [(1773, 2438)]\n",
      "Ann_id in getitem:  40948\n",
      "Test inds:  [(2767, 675)]\n",
      "Ann_id in getitem:  63643\n",
      "Test inds:  [(3563, 2758)]\n",
      "Ann_id in getitem:  82158\n",
      "Test inds:  [(1422, 3177)]\n",
      "Ann_id in getitem:  33737\n",
      "Test inds:  [(495, 728)]\n",
      "Ann_id in getitem:  11880\n",
      "Test inds:  [(3110, 2944)]\n",
      "Ann_id in getitem:  71760\n",
      "Test inds:  [(1473, 2558)]\n",
      "Ann_id in getitem:  34935\n",
      "Test inds:  [(3100, 203)]\n",
      "Ann_id in getitem:  71435\n",
      "Test inds:  [(3418, 2363)]\n",
      "Ann_id in getitem:  78740\n",
      "Test inds:  [(2195, 2765)]\n",
      "Ann_id in getitem:  49448\n",
      "Test inds:  [(3346, 1183)]\n",
      "Ann_id in getitem:  76881\n",
      "Test inds:  [(2349, 3454)]\n",
      "Ann_id in getitem:  53057\n",
      "Test inds:  [(2865, 3330)]\n",
      "Ann_id in getitem:  65882\n",
      "Test inds:  [(2411, 786)]\n",
      "Ann_id in getitem:  54530\n",
      "Test inds:  [(1265, 1800)]\n",
      "Ann_id in getitem:  29575\n",
      "Test inds:  [(2936, 3143)]\n",
      "Ann_id in getitem:  67660\n",
      "Test inds:  [(1390, 1460)]\n",
      "Ann_id in getitem:  33008\n",
      "Test inds:  [(226, 766)]\n",
      "Ann_id in getitem:  5520\n",
      "Test inds:  [(3582, 3680)]\n",
      "Ann_id in getitem:  82543\n",
      "Test inds:  [(608, 84)]\n",
      "Ann_id in getitem:  14850\n",
      "Test inds:  [(697, 3175)]\n",
      "Ann_id in getitem:  16930\n",
      "Test inds:  [(1196, 3250)]\n",
      "Ann_id in getitem:  27851\n",
      "Test inds:  [(1222, 1453)]\n",
      "Ann_id in getitem:  28538\n",
      "Test inds:  [(1258, 240)]\n",
      "Ann_id in getitem:  29493\n",
      "Test inds:  [(1958, 3318)]\n",
      "Ann_id in getitem:  44511\n",
      "Test inds:  [(2451, 3132)]\n",
      "Ann_id in getitem:  55680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3614, 2285)]\n",
      "Ann_id in getitem:  83432\n",
      "Test inds:  [(2392, 221)]\n",
      "Ann_id in getitem:  54130\n",
      "Test inds:  [(1922, 1718)]\n",
      "Ann_id in getitem:  43980\n",
      "Test inds:  [(2451, 732)]\n",
      "Ann_id in getitem:  55680\n",
      "Test inds:  [(767, 80)]\n",
      "Ann_id in getitem:  18549\n",
      "Test inds:  [(663, 141)]\n",
      "Ann_id in getitem:  16179\n",
      "Test inds:  [(3245, 3183)]\n",
      "Ann_id in getitem:  74570\n",
      "Test inds:  [(3533, 2005)]\n",
      "Ann_id in getitem:  81544\n",
      "Test inds:  [(1974, 2527)]\n",
      "Ann_id in getitem:  44994\n",
      "Test inds:  [(537, 1609)]\n",
      "Ann_id in getitem:  12746\n",
      "Test inds:  [(1145, 3468)]\n",
      "Ann_id in getitem:  26740\n",
      "Test inds:  [(195, 1506)]\n",
      "Ann_id in getitem:  4882\n",
      "Test inds:  [(982, 355)]\n",
      "Ann_id in getitem:  23306\n",
      "Test inds:  [(985, 1548)]\n",
      "Ann_id in getitem:  23419\n",
      "Test inds:  [(3252, 1230)]\n",
      "Ann_id in getitem:  74681\n",
      "Test inds:  [(3256, 1852)]\n",
      "Ann_id in getitem:  74775\n",
      "Test inds:  [(3313, 184)]\n",
      "Ann_id in getitem:  76065\n",
      "Test inds:  [(1262, 1452)]\n",
      "Ann_id in getitem:  29544\n",
      "Test inds:  [(649, 70)]\n",
      "Ann_id in getitem:  15827\n",
      "Test inds:  [(511, 2380)]\n",
      "Ann_id in getitem:  12217\n",
      "Test inds:  [(2318, 2562)]\n",
      "Ann_id in getitem:  52218\n",
      "Test inds:  [(364, 2019)]\n",
      "Ann_id in getitem:  8833\n",
      "Test inds:  [(1863, 1348)]\n",
      "Ann_id in getitem:  42934\n",
      "Test inds:  [(1212, 1968)]\n",
      "Ann_id in getitem:  28241\n",
      "Test inds:  [(2798, 2436)]\n",
      "Ann_id in getitem:  64523\n",
      "Test inds:  [(2984, 2712)]\n",
      "Ann_id in getitem:  68819\n",
      "Test inds:  [(430, 2768)]\n",
      "Ann_id in getitem:  10581\n",
      "Test inds:  [(2863, 1337)]\n",
      "Ann_id in getitem:  65814\n",
      "Test inds:  [(1195, 1412)]\n",
      "Ann_id in getitem:  27841\n",
      "Test inds:  [(3502, 2771)]\n",
      "Ann_id in getitem:  80738\n",
      "Test inds:  [(3069, 1612)]\n",
      "Ann_id in getitem:  70739\n",
      "Test inds:  [(3232, 1157)]\n",
      "Ann_id in getitem:  74284\n",
      "Test inds:  [(2553, 2248)]\n",
      "Ann_id in getitem:  58014\n",
      "Test inds:  [(1672, 844)]\n",
      "Ann_id in getitem:  39151\n",
      "Test inds:  [(2791, 1446)]\n",
      "Ann_id in getitem:  64441\n",
      "Test inds:  [(3444, 2322)]\n",
      "Ann_id in getitem:  79379\n",
      "Test inds:  [(270, 823)]\n",
      "Ann_id in getitem:  6401\n",
      "Test inds:  [(1799, 1239)]\n",
      "Ann_id in getitem:  41575\n",
      "Test inds:  [(1262, 1278)]\n",
      "Ann_id in getitem:  29544\n",
      "Test inds:  [(2758, 1242)]\n",
      "Ann_id in getitem:  63437\n",
      "Test inds:  [(1154, 609)]\n",
      "Ann_id in getitem:  26822\n",
      "Test inds:  [(1447, 3562)]\n",
      "Ann_id in getitem:  34266\n",
      "Test inds:  [(2463, 3384)]\n",
      "Ann_id in getitem:  56006\n",
      "Test inds:  [(2253, 1418)]\n",
      "Ann_id in getitem:  50937\n",
      "Test inds:  [(3358, 915)]\n",
      "Ann_id in getitem:  77016\n",
      "Test inds:  [(2316, 3074)]\n",
      "Ann_id in getitem:  52188\n",
      "Test inds:  [(922, 1223)]\n",
      "Ann_id in getitem:  22094\n",
      "Test inds:  [(128, 2267)]\n",
      "Ann_id in getitem:  3043\n",
      "Test inds:  [(2769, 2589)]\n",
      "Ann_id in getitem:  63753\n",
      "Test inds:  [(251, 2297)]\n",
      "Ann_id in getitem:  6079\n",
      "Test inds:  [(411, 3252)]\n",
      "Ann_id in getitem:  10045\n",
      "Test inds:  [(1697, 1137)]\n",
      "Ann_id in getitem:  39786\n",
      "Test inds:  [(1580, 3397)]\n",
      "Ann_id in getitem:  37362\n",
      "Test inds:  [(63, 141)]\n",
      "Ann_id in getitem:  1392\n",
      "Test inds:  [(3047, 3207)]\n",
      "Ann_id in getitem:  70257\n",
      "Test inds:  [(2906, 1114)]\n",
      "Ann_id in getitem:  67047\n",
      "Test inds:  [(1513, 2047)]\n",
      "Ann_id in getitem:  35905\n",
      "Test inds:  [(69, 280)]\n",
      "Ann_id in getitem:  1536\n",
      "Test inds:  [(632, 1328)]\n",
      "Ann_id in getitem:  15404\n",
      "Test inds:  [(997, 445)]\n",
      "Ann_id in getitem:  23663\n",
      "Test inds:  [(2444, 256)]\n",
      "Ann_id in getitem:  55553\n",
      "Test inds:  [(2965, 2764)]\n",
      "Ann_id in getitem:  68275\n",
      "Test inds:  [(2071, 3614)]\n",
      "Ann_id in getitem:  47064\n",
      "Test inds:  [(2006, 1817)]\n",
      "Ann_id in getitem:  45673\n",
      "Test inds:  [(3568, 224)]\n",
      "Ann_id in getitem:  82290\n",
      "Test inds:  [(277, 1200)]\n",
      "Ann_id in getitem:  6583\n",
      "Test inds:  [(1548, 2560)]\n",
      "Ann_id in getitem:  36579\n",
      "Test inds:  [(2533, 1694)]\n",
      "Ann_id in getitem:  57496\n",
      "Test inds:  [(1871, 2280)]\n",
      "Ann_id in getitem:  43067\n",
      "Test inds:  [(2641, 299)]\n",
      "Ann_id in getitem:  60472\n",
      "Test inds:  [(58, 2203)]\n",
      "Ann_id in getitem:  1229\n",
      "Test inds:  [(708, 1505)]\n",
      "Ann_id in getitem:  17161\n",
      "Test inds:  [(2534, 266)]\n",
      "Ann_id in getitem:  57536\n",
      "Test inds:  [(1198, 1654)]\n",
      "Ann_id in getitem:  27869\n",
      "Test inds:  [(2693, 167)]\n",
      "Ann_id in getitem:  61915\n",
      "Test inds:  [(2777, 3535)]\n",
      "Ann_id in getitem:  63977\n",
      "Test inds:  [(743, 1018)]\n",
      "Ann_id in getitem:  18010\n",
      "Test inds:  [(1860, 2202)]\n",
      "Ann_id in getitem:  42807\n",
      "Test inds:  [(3676, 1533)]\n",
      "Ann_id in getitem:  84764\n",
      "Test inds:  [(26, 1819)]\n",
      "Ann_id in getitem:  540\n",
      "Test inds:  [(1122, 1891)]\n",
      "Ann_id in getitem:  26063\n",
      "Test inds:  [(1477, 3038)]\n",
      "Ann_id in getitem:  35022\n",
      "Test inds:  [(212, 2392)]\n",
      "Ann_id in getitem:  5292\n",
      "Test inds:  [(3080, 2048)]\n",
      "Ann_id in getitem:  71062\n",
      "Test inds:  [(1987, 3170)]\n",
      "Ann_id in getitem:  45304\n",
      "Test inds:  [(1332, 647)]\n",
      "Ann_id in getitem:  31315\n",
      "Test inds:  [(3404, 2997)]\n",
      "Ann_id in getitem:  78362\n",
      "Test inds:  [(3475, 2324)]\n",
      "Ann_id in getitem:  80163\n",
      "Test inds:  [(2973, 852)]\n",
      "Ann_id in getitem:  68413\n",
      "Test inds:  [(1590, 2580)]\n",
      "Ann_id in getitem:  37511\n",
      "Test inds:  [(3577, 2643)]\n",
      "Ann_id in getitem:  82448\n",
      "Test inds:  [(2868, 1592)]\n",
      "Ann_id in getitem:  65951\n",
      "Test inds:  [(2869, 2246)]\n",
      "Ann_id in getitem:  65983\n",
      "Test inds:  [(1618, 3640)]\n",
      "Ann_id in getitem:  37965\n",
      "Test inds:  [(2890, 653)]\n",
      "Ann_id in getitem:  66469\n",
      "Test inds:  [(652, 2308)]\n",
      "Ann_id in getitem:  15956\n",
      "Test inds:  [(941, 3675)]\n",
      "Ann_id in getitem:  22353\n",
      "Test inds:  [(3199, 2678)]\n",
      "Ann_id in getitem:  73600\n",
      "Test inds:  [(3171, 1459)]\n",
      "Ann_id in getitem:  73055\n",
      "Test inds:  [(616, 1283)]\n",
      "Ann_id in getitem:  15155\n",
      "Test inds:  [(159, 2865)]\n",
      "Ann_id in getitem:  4047\n",
      "Test inds:  [(1452, 1308)]\n",
      "Ann_id in getitem:  34359\n",
      "Test inds:  [(358, 3035)]\n",
      "Ann_id in getitem:  8648\n",
      "Test inds:  [(3505, 195)]\n",
      "Ann_id in getitem:  80866\n",
      "Test inds:  [(2046, 1788)]\n",
      "Ann_id in getitem:  46627\n",
      "Test inds:  [(500, 3417)]\n",
      "Ann_id in getitem:  11969\n",
      "Test inds:  [(869, 1201)]\n",
      "Ann_id in getitem:  20939\n",
      "Test inds:  [(2747, 818)]\n",
      "Ann_id in getitem:  63243\n",
      "Test inds:  [(477, 2107)]\n",
      "Ann_id in getitem:  11517\n",
      "Test inds:  [(2330, 972)]\n",
      "Ann_id in getitem:  52542\n",
      "Test inds:  [(3456, 3430)]\n",
      "Ann_id in getitem:  79737\n",
      "Test inds:  [(1358, 2274)]\n",
      "Ann_id in getitem:  32038\n",
      "Test inds:  [(340, 3355)]\n",
      "Ann_id in getitem:  8272\n",
      "Test inds:  [(2326, 1395)]\n",
      "Ann_id in getitem:  52380\n",
      "Test inds:  [(501, 959)]\n",
      "Ann_id in getitem:  11986\n",
      "Test inds:  [(1304, 1621)]\n",
      "Ann_id in getitem:  30493\n",
      "Test inds:  [(2156, 660)]\n",
      "Ann_id in getitem:  48659\n",
      "Test inds:  [(1641, 2485)]\n",
      "Ann_id in getitem:  38500\n",
      "Test inds:  [(2472, 2973)]\n",
      "Ann_id in getitem:  56252\n",
      "Test inds:  [(3447, 2945)]\n",
      "Ann_id in getitem:  79500\n",
      "Test inds:  [(1013, 3142)]\n",
      "Ann_id in getitem:  24056\n",
      "Test inds:  [(3385, 1759)]\n",
      "Ann_id in getitem:  77829\n",
      "Test inds:  [(1766, 1754)]\n",
      "Ann_id in getitem:  40811\n",
      "Test inds:  [(29, 2148)]\n",
      "Ann_id in getitem:  626\n",
      "Test inds:  [(1897, 117)]\n",
      "Ann_id in getitem:  43529\n",
      "Test inds:  [(3265, 3471)]\n",
      "Ann_id in getitem:  74882\n",
      "Test inds:  [(1753, 712)]\n",
      "Ann_id in getitem:  40575\n",
      "Test inds:  [(3698, 2586)]\n",
      "Ann_id in getitem:  85452\n",
      "Test inds:  [(2300, 3527)]\n",
      "Ann_id in getitem:  51858\n",
      "Test inds:  [(3000, 1398)]\n",
      "Ann_id in getitem:  69126\n",
      "Test inds:  [(1193, 3212)]\n",
      "Ann_id in getitem:  27827\n",
      "Test inds:  [(2971, 1090)]\n",
      "Ann_id in getitem:  68358\n",
      "Test inds:  [(705, 379)]\n",
      "Ann_id in getitem:  17127\n",
      "Test inds:  [(1396, 2004)]\n",
      "Ann_id in getitem:  33126\n",
      "Test inds:  [(171, 1894)]\n",
      "Ann_id in getitem:  4347\n",
      "Test inds:  [(104, 322)]\n",
      "Ann_id in getitem:  2376\n",
      "Test inds:  [(561, 1026)]\n",
      "Ann_id in getitem:  13526\n",
      "Test inds:  [(3025, 2762)]\n",
      "Ann_id in getitem:  69796\n",
      "Test inds:  [(98, 1861)]\n",
      "Ann_id in getitem:  2158\n",
      "Test inds:  [(2669, 1996)]\n",
      "Ann_id in getitem:  61253\n",
      "Test inds:  [(2674, 2323)]\n",
      "Ann_id in getitem:  61341\n",
      "Test inds:  [(3081, 2947)]\n",
      "Ann_id in getitem:  71066\n",
      "Test inds:  [(119, 721)]\n",
      "Ann_id in getitem:  2830\n",
      "Test inds:  [(1941, 2665)]\n",
      "Ann_id in getitem:  44231\n",
      "Test inds:  [(3366, 2215)]\n",
      "Ann_id in getitem:  77283\n",
      "Test inds:  [(2714, 1234)]\n",
      "Ann_id in getitem:  62433\n",
      "Test inds:  [(2881, 2653)]\n",
      "Ann_id in getitem:  66219\n",
      "Test inds:  [(593, 1848)]\n",
      "Ann_id in getitem:  14370\n",
      "Test inds:  [(1785, 3287)]\n",
      "Ann_id in getitem:  41113\n",
      "Test inds:  [(816, 2661)]\n",
      "Ann_id in getitem:  19681\n",
      "Test inds:  [(2574, 2627)]\n",
      "Ann_id in getitem:  58663\n",
      "Test inds:  [(2181, 113)]\n",
      "Ann_id in getitem:  49145\n",
      "Test inds:  [(1106, 2027)]\n",
      "Ann_id in getitem:  25701\n",
      "Test inds:  [(1803, 972)]\n",
      "Ann_id in getitem:  41600\n",
      "Test inds:  [(2409, 2741)]\n",
      "Ann_id in getitem:  54511\n",
      "Test inds:  [(2282, 655)]\n",
      "Ann_id in getitem:  51611\n",
      "Test inds:  [(2137, 1454)]\n",
      "Ann_id in getitem:  48404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(313, 2482)]\n",
      "Ann_id in getitem:  7637\n",
      "Test inds:  [(3655, 2319)]\n",
      "Ann_id in getitem:  84414\n",
      "Test inds:  [(1175, 2776)]\n",
      "Ann_id in getitem:  27341\n",
      "Test inds:  [(2295, 3176)]\n",
      "Ann_id in getitem:  51786\n",
      "Test inds:  [(3486, 2941)]\n",
      "Ann_id in getitem:  80301\n",
      "Test inds:  [(3265, 2863)]\n",
      "Ann_id in getitem:  74882\n",
      "Test inds:  [(3214, 3109)]\n",
      "Ann_id in getitem:  73941\n",
      "Test inds:  [(988, 1131)]\n",
      "Ann_id in getitem:  23520\n",
      "Test inds:  [(2916, 3384)]\n",
      "Ann_id in getitem:  67135\n",
      "Test inds:  [(3197, 1816)]\n",
      "Ann_id in getitem:  73538\n",
      "Test inds:  [(248, 901)]\n",
      "Ann_id in getitem:  6023\n",
      "Test inds:  [(2987, 863)]\n",
      "Ann_id in getitem:  68923\n",
      "Test inds:  [(1695, 2971)]\n",
      "Ann_id in getitem:  39757\n",
      "Test inds:  [(3113, 969)]\n",
      "Ann_id in getitem:  71793\n",
      "Test inds:  [(1186, 1090)]\n",
      "Ann_id in getitem:  27671\n",
      "Test inds:  [(2654, 2749)]\n",
      "Ann_id in getitem:  60806\n",
      "Test inds:  [(1741, 3237)]\n",
      "Ann_id in getitem:  40458\n",
      "Test inds:  [(3111, 3259)]\n",
      "Ann_id in getitem:  71777\n",
      "Test inds:  [(3623, 2744)]\n",
      "Ann_id in getitem:  83592\n",
      "Test inds:  [(3634, 3071)]\n",
      "Ann_id in getitem:  83867\n",
      "Test inds:  [(531, 2444)]\n",
      "Ann_id in getitem:  12627\n",
      "Test inds:  [(1372, 1898)]\n",
      "Ann_id in getitem:  32365\n",
      "Test inds:  [(3520, 3229)]\n",
      "Ann_id in getitem:  81210\n",
      "Test inds:  [(1737, 2758)]\n",
      "Ann_id in getitem:  40418\n",
      "Test inds:  [(1990, 2020)]\n",
      "Ann_id in getitem:  45322\n",
      "Test inds:  [(930, 205)]\n",
      "Ann_id in getitem:  22185\n",
      "Test inds:  [(1257, 384)]\n",
      "Ann_id in getitem:  29483\n",
      "Test inds:  [(3209, 3532)]\n",
      "Ann_id in getitem:  73780\n",
      "Test inds:  [(138, 2682)]\n",
      "Ann_id in getitem:  3365\n",
      "Test inds:  [(2614, 3680)]\n",
      "Ann_id in getitem:  59861\n",
      "Test inds:  [(2565, 1822)]\n",
      "Ann_id in getitem:  58327\n",
      "Test inds:  [(2545, 2649)]\n",
      "Ann_id in getitem:  57846\n",
      "Test inds:  [(579, 595)]\n",
      "Ann_id in getitem:  14090\n",
      "Test inds:  [(1329, 1871)]\n",
      "Ann_id in getitem:  31225\n",
      "Test inds:  [(358, 2131)]\n",
      "Ann_id in getitem:  8648\n",
      "Test inds:  [(2615, 777)]\n",
      "Ann_id in getitem:  59876\n",
      "Test inds:  [(252, 2432)]\n",
      "Ann_id in getitem:  6101\n",
      "Test inds:  [(293, 1043)]\n",
      "Ann_id in getitem:  6803\n",
      "Test inds:  [(3250, 2413)]\n",
      "Ann_id in getitem:  74658\n",
      "Test inds:  [(1076, 1806)]\n",
      "Ann_id in getitem:  25178\n",
      "Test inds:  [(941, 3091)]\n",
      "Ann_id in getitem:  22353\n",
      "Test inds:  [(1770, 1245)]\n",
      "Ann_id in getitem:  40888\n",
      "Test inds:  [(752, 675)]\n",
      "Ann_id in getitem:  18236\n",
      "Test inds:  [(2247, 3244)]\n",
      "Ann_id in getitem:  50758\n",
      "Test inds:  [(2909, 411)]\n",
      "Ann_id in getitem:  67089\n",
      "Test inds:  [(1329, 16)]\n",
      "Ann_id in getitem:  31225\n",
      "Test inds:  [(486, 3111)]\n",
      "Ann_id in getitem:  11702\n",
      "Test inds:  [(1395, 1381)]\n",
      "Ann_id in getitem:  33122\n",
      "Test inds:  [(469, 3044)]\n",
      "Ann_id in getitem:  11315\n",
      "Test inds:  [(1076, 1343)]\n",
      "Ann_id in getitem:  25178\n",
      "Test inds:  [(1358, 412)]\n",
      "Ann_id in getitem:  32038\n",
      "Test inds:  [(2157, 2013)]\n",
      "Ann_id in getitem:  48662\n",
      "Test inds:  [(2642, 2534)]\n",
      "Ann_id in getitem:  60503\n",
      "Test inds:  [(2671, 273)]\n",
      "Ann_id in getitem:  61303\n",
      "Test inds:  [(33, 2098)]\n",
      "Ann_id in getitem:  748\n",
      "Test inds:  [(1578, 1147)]\n",
      "Ann_id in getitem:  37339\n",
      "Test inds:  [(3148, 2490)]\n",
      "Ann_id in getitem:  72589\n",
      "Test inds:  [(1063, 522)]\n",
      "Ann_id in getitem:  24998\n",
      "Test inds:  [(1096, 2407)]\n",
      "Ann_id in getitem:  25507\n",
      "Test inds:  [(108, 3109)]\n",
      "Ann_id in getitem:  2473\n",
      "Test inds:  [(1917, 258)]\n",
      "Ann_id in getitem:  43913\n",
      "Test inds:  [(1320, 3058)]\n",
      "Ann_id in getitem:  30875\n",
      "Test inds:  [(2134, 1992)]\n",
      "Ann_id in getitem:  48348\n",
      "Test inds:  [(3074, 2840)]\n",
      "Ann_id in getitem:  70900\n",
      "Test inds:  [(3465, 1437)]\n",
      "Ann_id in getitem:  80003\n",
      "Test inds:  [(3653, 2315)]\n",
      "Ann_id in getitem:  84386\n",
      "Test inds:  [(2654, 2332)]\n",
      "Ann_id in getitem:  60806\n",
      "Test inds:  [(2075, 783)]\n",
      "Ann_id in getitem:  47137\n",
      "Test inds:  [(3474, 3597)]\n",
      "Ann_id in getitem:  80153\n",
      "Test inds:  [(1664, 2645)]\n",
      "Ann_id in getitem:  38916\n",
      "Test inds:  [(1046, 3605)]\n",
      "Ann_id in getitem:  24695\n",
      "Test inds:  [(130, 2842)]\n",
      "Ann_id in getitem:  3125\n",
      "Test inds:  [(1359, 3249)]\n",
      "Ann_id in getitem:  32039\n",
      "Test inds:  [(676, 1259)]\n",
      "Ann_id in getitem:  16418\n",
      "Test inds:  [(955, 2924)]\n",
      "Ann_id in getitem:  22603\n",
      "Test inds:  [(848, 1105)]\n",
      "Ann_id in getitem:  20657\n",
      "Test inds:  [(2335, 3153)]\n",
      "Ann_id in getitem:  52659\n",
      "Test inds:  [(464, 3665)]\n",
      "Ann_id in getitem:  11208\n",
      "Test inds:  [(1933, 2534)]\n",
      "Ann_id in getitem:  44105\n",
      "Test inds:  [(528, 2027)]\n",
      "Ann_id in getitem:  12570\n",
      "Test inds:  [(1781, 1433)]\n",
      "Ann_id in getitem:  41090\n",
      "Test inds:  [(3695, 393)]\n",
      "Ann_id in getitem:  85421\n",
      "Test inds:  [(2054, 1972)]\n",
      "Ann_id in getitem:  46791\n",
      "Test inds:  [(1716, 2932)]\n",
      "Ann_id in getitem:  40072\n",
      "Test inds:  [(1051, 2900)]\n",
      "Ann_id in getitem:  24785\n",
      "Test inds:  [(3413, 939)]\n",
      "Ann_id in getitem:  78657\n",
      "Test inds:  [(2549, 318)]\n",
      "Ann_id in getitem:  57927\n",
      "Test inds:  [(1417, 1756)]\n",
      "Ann_id in getitem:  33495\n",
      "Test inds:  [(2146, 561)]\n",
      "Ann_id in getitem:  48531\n",
      "Test inds:  [(653, 2215)]\n",
      "Ann_id in getitem:  15959\n",
      "Test inds:  [(2510, 2980)]\n",
      "Ann_id in getitem:  57133\n",
      "Test inds:  [(1513, 3102)]\n",
      "Ann_id in getitem:  35905\n",
      "Test inds:  [(654, 2356)]\n",
      "Ann_id in getitem:  15969\n",
      "Test inds:  [(1950, 1249)]\n",
      "Ann_id in getitem:  44354\n",
      "Test inds:  [(360, 1263)]\n",
      "Ann_id in getitem:  8724\n",
      "Test inds:  [(1869, 1371)]\n",
      "Ann_id in getitem:  43048\n",
      "Test inds:  [(1276, 3156)]\n",
      "Ann_id in getitem:  29844\n",
      "Test inds:  [(370, 3223)]\n",
      "Ann_id in getitem:  9006\n",
      "Test inds:  [(2967, 314)]\n",
      "Ann_id in getitem:  68295\n",
      "Test inds:  [(1704, 3094)]\n",
      "Ann_id in getitem:  39872\n",
      "Test inds:  [(1678, 5)]\n",
      "Ann_id in getitem:  39292\n",
      "Test inds:  [(2592, 2929)]\n",
      "Ann_id in getitem:  59430\n",
      "Test inds:  [(2628, 3364)]\n",
      "Ann_id in getitem:  60163\n",
      "Test inds:  [(1445, 2774)]\n",
      "Ann_id in getitem:  34246\n",
      "Test inds:  [(3096, 3608)]\n",
      "Ann_id in getitem:  71328\n",
      "Test inds:  [(1721, 2839)]\n",
      "Ann_id in getitem:  40158\n",
      "Test inds:  [(1907, 3450)]\n",
      "Ann_id in getitem:  43705\n",
      "Test inds:  [(3013, 3102)]\n",
      "Ann_id in getitem:  69484\n",
      "Test inds:  [(1699, 3269)]\n",
      "Ann_id in getitem:  39807\n",
      "Test inds:  [(1549, 3042)]\n",
      "Ann_id in getitem:  36600\n",
      "Test inds:  [(2478, 989)]\n",
      "Ann_id in getitem:  56418\n",
      "Test inds:  [(1246, 2376)]\n",
      "Ann_id in getitem:  29195\n",
      "Test inds:  [(2986, 2494)]\n",
      "Ann_id in getitem:  68894\n",
      "Test inds:  [(3658, 2410)]\n",
      "Ann_id in getitem:  84486\n",
      "Test inds:  [(1918, 206)]\n",
      "Ann_id in getitem:  43916\n",
      "Test inds:  [(417, 779)]\n",
      "Ann_id in getitem:  10146\n",
      "Test inds:  [(533, 1339)]\n",
      "Ann_id in getitem:  12675\n",
      "Test inds:  [(476, 3631)]\n",
      "Ann_id in getitem:  11512\n",
      "Test inds:  [(2370, 3539)]\n",
      "Ann_id in getitem:  53599\n",
      "Test inds:  [(101, 2706)]\n",
      "Ann_id in getitem:  2219\n",
      "Test inds:  [(826, 157)]\n",
      "Ann_id in getitem:  19812\n",
      "Test inds:  [(440, 2526)]\n",
      "Ann_id in getitem:  10730\n",
      "Test inds:  [(454, 982)]\n",
      "Ann_id in getitem:  10973\n",
      "Test inds:  [(2316, 85)]\n",
      "Ann_id in getitem:  52188\n",
      "Test inds:  [(3261, 3576)]\n",
      "Ann_id in getitem:  74844\n",
      "Test inds:  [(3205, 1719)]\n",
      "Ann_id in getitem:  73728\n",
      "Test inds:  [(1372, 2887)]\n",
      "Ann_id in getitem:  32365\n",
      "Test inds:  [(2194, 2230)]\n",
      "Ann_id in getitem:  49381\n",
      "Test inds:  [(891, 2966)]\n",
      "Ann_id in getitem:  21302\n",
      "Test inds:  [(52, 1402)]\n",
      "Ann_id in getitem:  1104\n",
      "Test inds:  [(1088, 1696)]\n",
      "Ann_id in getitem:  25388\n",
      "Test inds:  [(1969, 2872)]\n",
      "Ann_id in getitem:  44953\n",
      "Test inds:  [(2110, 1708)]\n",
      "Ann_id in getitem:  47851\n",
      "Test inds:  [(1881, 2485)]\n",
      "Ann_id in getitem:  43283\n",
      "Test inds:  [(1932, 2940)]\n",
      "Ann_id in getitem:  44097\n",
      "Test inds:  [(773, 1788)]\n",
      "Ann_id in getitem:  18756\n",
      "Test inds:  [(3250, 1999)]\n",
      "Ann_id in getitem:  74658\n",
      "Test inds:  [(24, 2987)]\n",
      "Ann_id in getitem:  478\n",
      "Test inds:  [(3358, 2883)]\n",
      "Ann_id in getitem:  77016\n",
      "Test inds:  [(434, 30)]\n",
      "Ann_id in getitem:  10667\n",
      "Test inds:  [(1848, 1028)]\n",
      "Ann_id in getitem:  42557\n",
      "Test inds:  [(3495, 2786)]\n",
      "Ann_id in getitem:  80518\n",
      "Test inds:  [(2439, 302)]\n",
      "Ann_id in getitem:  55312\n",
      "Test inds:  [(1286, 1663)]\n",
      "Ann_id in getitem:  30110\n",
      "Test inds:  [(1220, 2162)]\n",
      "Ann_id in getitem:  28505\n",
      "Test inds:  [(1441, 3162)]\n",
      "Ann_id in getitem:  34185\n",
      "Test inds:  [(3349, 205)]\n",
      "Ann_id in getitem:  76888\n",
      "Test inds:  [(509, 1815)]\n",
      "Ann_id in getitem:  12189\n",
      "Test inds:  [(1451, 2868)]\n",
      "Ann_id in getitem:  34357\n",
      "Test inds:  [(1759, 879)]\n",
      "Ann_id in getitem:  40714\n",
      "Test inds:  [(2119, 399)]\n",
      "Ann_id in getitem:  48004\n",
      "Test inds:  [(113, 2757)]\n",
      "Ann_id in getitem:  2655\n",
      "Test inds:  [(556, 492)]\n",
      "Ann_id in getitem:  13488\n",
      "Test inds:  [(467, 1496)]\n",
      "Ann_id in getitem:  11252\n",
      "Test inds:  [(2980, 2512)]\n",
      "Ann_id in getitem:  68758\n",
      "Test inds:  [(798, 2722)]\n",
      "Ann_id in getitem:  19322\n",
      "Test inds:  [(287, 545)]\n",
      "Ann_id in getitem:  6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(586, 1900)]\n",
      "Ann_id in getitem:  14235\n",
      "Test inds:  [(1538, 2906)]\n",
      "Ann_id in getitem:  36453\n",
      "Test inds:  [(2156, 3363)]\n",
      "Ann_id in getitem:  48659\n",
      "Test inds:  [(2243, 3381)]\n",
      "Ann_id in getitem:  50665\n",
      "Test inds:  [(1325, 1311)]\n",
      "Ann_id in getitem:  31012\n",
      "Test inds:  [(2472, 3288)]\n",
      "Ann_id in getitem:  56252\n",
      "Test inds:  [(858, 2211)]\n",
      "Ann_id in getitem:  20818\n",
      "Test inds:  [(2495, 2207)]\n",
      "Ann_id in getitem:  56735\n",
      "Test inds:  [(3340, 2229)]\n",
      "Ann_id in getitem:  76767\n",
      "Test inds:  [(2821, 1300)]\n",
      "Ann_id in getitem:  65005\n",
      "Test inds:  [(2239, 3587)]\n",
      "Ann_id in getitem:  50558\n",
      "Test inds:  [(508, 339)]\n",
      "Ann_id in getitem:  12169\n",
      "Test inds:  [(2037, 1875)]\n",
      "Ann_id in getitem:  46407\n",
      "Test inds:  [(314, 1886)]\n",
      "Ann_id in getitem:  7670\n",
      "Test inds:  [(978, 3268)]\n",
      "Ann_id in getitem:  23081\n",
      "Test inds:  [(1830, 2006)]\n",
      "Ann_id in getitem:  42053\n",
      "Test inds:  [(2195, 1230)]\n",
      "Ann_id in getitem:  49448\n",
      "Test inds:  [(3544, 3279)]\n",
      "Ann_id in getitem:  81777\n",
      "Test inds:  [(3465, 2655)]\n",
      "Ann_id in getitem:  80003\n",
      "Test inds:  [(3325, 3001)]\n",
      "Ann_id in getitem:  76389\n",
      "Test inds:  [(1954, 3644)]\n",
      "Ann_id in getitem:  44460\n",
      "Test inds:  [(738, 1930)]\n",
      "Ann_id in getitem:  17883\n",
      "Test inds:  [(1061, 3209)]\n",
      "Ann_id in getitem:  24983\n",
      "Test inds:  [(3412, 3685)]\n",
      "Ann_id in getitem:  78653\n",
      "Test inds:  [(1750, 2982)]\n",
      "Ann_id in getitem:  40556\n",
      "Test inds:  [(3457, 3310)]\n",
      "Ann_id in getitem:  79754\n",
      "Test inds:  [(2913, 264)]\n",
      "Ann_id in getitem:  67107\n",
      "Test inds:  [(1659, 1357)]\n",
      "Ann_id in getitem:  38821\n",
      "Test inds:  [(3492, 2645)]\n",
      "Ann_id in getitem:  80478\n",
      "Test inds:  [(2791, 1022)]\n",
      "Ann_id in getitem:  64441\n",
      "Test inds:  [(953, 2917)]\n",
      "Ann_id in getitem:  22578\n",
      "Test inds:  [(2863, 1940)]\n",
      "Ann_id in getitem:  65814\n",
      "Test inds:  [(673, 1810)]\n",
      "Ann_id in getitem:  16349\n",
      "Test inds:  [(1915, 1258)]\n",
      "Ann_id in getitem:  43843\n",
      "Test inds:  [(3604, 2724)]\n",
      "Ann_id in getitem:  83162\n",
      "Test inds:  [(1575, 2878)]\n",
      "Ann_id in getitem:  37304\n",
      "Test inds:  [(2696, 3199)]\n",
      "Ann_id in getitem:  61994\n",
      "Test inds:  [(2295, 2956)]\n",
      "Ann_id in getitem:  51786\n",
      "Test inds:  [(418, 920)]\n",
      "Ann_id in getitem:  10176\n",
      "Test inds:  [(1443, 217)]\n",
      "Ann_id in getitem:  34196\n",
      "Test inds:  [(2493, 3287)]\n",
      "Ann_id in getitem:  56700\n",
      "Test inds:  [(3140, 2794)]\n",
      "Ann_id in getitem:  72439\n",
      "Test inds:  [(1920, 3164)]\n",
      "Ann_id in getitem:  43945\n",
      "Test inds:  [(3666, 371)]\n",
      "Ann_id in getitem:  84626\n",
      "Test inds:  [(2986, 0)]\n",
      "Ann_id in getitem:  68894\n",
      "Test inds:  [(994, 1635)]\n",
      "Ann_id in getitem:  23654\n",
      "Test inds:  [(2729, 343)]\n",
      "Ann_id in getitem:  62787\n",
      "Test inds:  [(1661, 2669)]\n",
      "Ann_id in getitem:  38859\n",
      "Test inds:  [(1396, 1461)]\n",
      "Ann_id in getitem:  33126\n",
      "Test inds:  [(1039, 3326)]\n",
      "Ann_id in getitem:  24546\n",
      "Test inds:  [(3570, 1641)]\n",
      "Ann_id in getitem:  82292\n",
      "Test inds:  [(3117, 2005)]\n",
      "Ann_id in getitem:  71924\n",
      "Test inds:  [(1368, 2400)]\n",
      "Ann_id in getitem:  32346\n",
      "Test inds:  [(3665, 3024)]\n",
      "Ann_id in getitem:  84608\n",
      "Test inds:  [(1398, 2644)]\n",
      "Ann_id in getitem:  33179\n",
      "Test inds:  [(2824, 2675)]\n",
      "Ann_id in getitem:  65096\n",
      "Test inds:  [(1388, 923)]\n",
      "Ann_id in getitem:  32955\n",
      "Test inds:  [(548, 2309)]\n",
      "Ann_id in getitem:  13138\n",
      "Test inds:  [(883, 1195)]\n",
      "Ann_id in getitem:  21139\n",
      "Test inds:  [(1436, 2246)]\n",
      "Ann_id in getitem:  34021\n",
      "Test inds:  [(2513, 446)]\n",
      "Ann_id in getitem:  57170\n",
      "Test inds:  [(806, 1702)]\n",
      "Ann_id in getitem:  19434\n",
      "Test inds:  [(3639, 2071)]\n",
      "Ann_id in getitem:  83970\n",
      "Test inds:  [(2307, 3457)]\n",
      "Ann_id in getitem:  52025\n",
      "Test inds:  [(1662, 1063)]\n",
      "Ann_id in getitem:  38868\n",
      "Test inds:  [(350, 1940)]\n",
      "Ann_id in getitem:  8479\n",
      "Test inds:  [(1329, 148)]\n",
      "Ann_id in getitem:  31225\n",
      "Test inds:  [(863, 993)]\n",
      "Ann_id in getitem:  20885\n",
      "Test inds:  [(2263, 869)]\n",
      "Ann_id in getitem:  51107\n",
      "Test inds:  [(468, 61)]\n",
      "Ann_id in getitem:  11279\n",
      "Test inds:  [(3209, 2910)]\n",
      "Ann_id in getitem:  73780\n",
      "Test inds:  [(659, 325)]\n",
      "Ann_id in getitem:  16114\n",
      "Test inds:  [(220, 889)]\n",
      "Ann_id in getitem:  5431\n",
      "Test inds:  [(3350, 1942)]\n",
      "Ann_id in getitem:  76897\n",
      "Test inds:  [(2705, 199)]\n",
      "Ann_id in getitem:  62152\n",
      "Test inds:  [(677, 2273)]\n",
      "Ann_id in getitem:  16422\n",
      "Test inds:  [(901, 2980)]\n",
      "Ann_id in getitem:  21534\n",
      "Test inds:  [(775, 3658)]\n",
      "Ann_id in getitem:  18801\n",
      "Test inds:  [(821, 3505)]\n",
      "Ann_id in getitem:  19712\n",
      "Test inds:  [(840, 2998)]\n",
      "Ann_id in getitem:  20226\n",
      "Test inds:  [(3445, 1849)]\n",
      "Ann_id in getitem:  79380\n",
      "Test inds:  [(2851, 2785)]\n",
      "Ann_id in getitem:  65613\n",
      "Test inds:  [(2149, 2093)]\n",
      "Ann_id in getitem:  48563\n",
      "Test inds:  [(846, 1155)]\n",
      "Ann_id in getitem:  20513\n",
      "Test inds:  [(1872, 1345)]\n",
      "Ann_id in getitem:  43071\n",
      "Test inds:  [(143, 1004)]\n",
      "Ann_id in getitem:  3464\n",
      "Test inds:  [(3560, 596)]\n",
      "Ann_id in getitem:  82096\n",
      "Test inds:  [(3011, 3641)]\n",
      "Ann_id in getitem:  69435\n",
      "Test inds:  [(1182, 2788)]\n",
      "Ann_id in getitem:  27488\n",
      "Test inds:  [(780, 2618)]\n",
      "Ann_id in getitem:  18906\n",
      "Test inds:  [(3391, 767)]\n",
      "Ann_id in getitem:  77907\n",
      "Test inds:  [(949, 347)]\n",
      "Ann_id in getitem:  22516\n",
      "Test inds:  [(2623, 3006)]\n",
      "Ann_id in getitem:  59971\n",
      "Test inds:  [(1511, 3301)]\n",
      "Ann_id in getitem:  35841\n",
      "Test inds:  [(693, 1886)]\n",
      "Ann_id in getitem:  16873\n",
      "Test inds:  [(2134, 2548)]\n",
      "Ann_id in getitem:  48348\n",
      "Test inds:  [(1551, 2892)]\n",
      "Ann_id in getitem:  36687\n",
      "Test inds:  [(1954, 3213)]\n",
      "Ann_id in getitem:  44460\n",
      "Test inds:  [(2778, 14)]\n",
      "Ann_id in getitem:  63990\n",
      "Test inds:  [(3050, 102)]\n",
      "Ann_id in getitem:  70297\n",
      "Test inds:  [(3363, 3250)]\n",
      "Ann_id in getitem:  77203\n",
      "Test inds:  [(3157, 1730)]\n",
      "Ann_id in getitem:  72771\n",
      "Test inds:  [(971, 19)]\n",
      "Ann_id in getitem:  22910\n",
      "Test inds:  [(796, 2710)]\n",
      "Ann_id in getitem:  19268\n",
      "Test inds:  [(1087, 2018)]\n",
      "Ann_id in getitem:  25373\n",
      "Test inds:  [(313, 2386)]\n",
      "Ann_id in getitem:  7637\n",
      "Test inds:  [(1089, 553)]\n",
      "Ann_id in getitem:  25412\n",
      "Test inds:  [(512, 626)]\n",
      "Ann_id in getitem:  12242\n",
      "Test inds:  [(3443, 2727)]\n",
      "Ann_id in getitem:  79362\n",
      "Test inds:  [(3295, 1452)]\n",
      "Ann_id in getitem:  75575\n",
      "Test inds:  [(758, 352)]\n",
      "Ann_id in getitem:  18333\n",
      "Test inds:  [(3210, 2553)]\n",
      "Ann_id in getitem:  73812\n",
      "Test inds:  [(2100, 260)]\n",
      "Ann_id in getitem:  47529\n",
      "Test inds:  [(730, 3266)]\n",
      "Ann_id in getitem:  17696\n",
      "Test inds:  [(3188, 412)]\n",
      "Ann_id in getitem:  73388\n",
      "Test inds:  [(3465, 417)]\n",
      "Ann_id in getitem:  80003\n",
      "Test inds:  [(98, 3128)]\n",
      "Ann_id in getitem:  2158\n",
      "Test inds:  [(3007, 2785)]\n",
      "Ann_id in getitem:  69275\n",
      "Test inds:  [(3582, 3037)]\n",
      "Ann_id in getitem:  82543\n",
      "Test inds:  [(2326, 2440)]\n",
      "Ann_id in getitem:  52380\n",
      "Test inds:  [(2075, 896)]\n",
      "Ann_id in getitem:  47137\n",
      "Test inds:  [(512, 1188)]\n",
      "Ann_id in getitem:  12242\n",
      "Test inds:  [(671, 370)]\n",
      "Ann_id in getitem:  16340\n",
      "Test inds:  [(1715, 2365)]\n",
      "Ann_id in getitem:  40070\n",
      "Test inds:  [(2777, 2793)]\n",
      "Ann_id in getitem:  63977\n",
      "Test inds:  [(1800, 701)]\n",
      "Ann_id in getitem:  41577\n",
      "Test inds:  [(1430, 1589)]\n",
      "Ann_id in getitem:  33895\n",
      "Test inds:  [(927, 2162)]\n",
      "Ann_id in getitem:  22157\n",
      "Test inds:  [(1592, 690)]\n",
      "Ann_id in getitem:  37549\n",
      "Test inds:  [(671, 1868)]\n",
      "Ann_id in getitem:  16340\n",
      "Test inds:  [(243, 1345)]\n",
      "Ann_id in getitem:  5884\n",
      "Test inds:  [(3342, 3320)]\n",
      "Ann_id in getitem:  76818\n",
      "Test inds:  [(1504, 361)]\n",
      "Ann_id in getitem:  35719\n",
      "Test inds:  [(212, 2906)]\n",
      "Ann_id in getitem:  5292\n",
      "Test inds:  [(2830, 3558)]\n",
      "Ann_id in getitem:  65278\n",
      "Test inds:  [(406, 1650)]\n",
      "Ann_id in getitem:  9986\n",
      "Test inds:  [(1088, 3264)]\n",
      "Ann_id in getitem:  25388\n",
      "Test inds:  [(3681, 2502)]\n",
      "Ann_id in getitem:  84869\n",
      "Test inds:  [(3177, 388)]\n",
      "Ann_id in getitem:  73139\n",
      "Test inds:  [(1948, 21)]\n",
      "Ann_id in getitem:  44325\n",
      "Test inds:  [(63, 3350)]\n",
      "Ann_id in getitem:  1392\n",
      "Test inds:  [(3222, 2262)]\n",
      "Ann_id in getitem:  74083\n",
      "Test inds:  [(1295, 652)]\n",
      "Ann_id in getitem:  30372\n",
      "Test inds:  [(3088, 2705)]\n",
      "Ann_id in getitem:  71214\n",
      "Test inds:  [(2146, 858)]\n",
      "Ann_id in getitem:  48531\n",
      "Test inds:  [(728, 639)]\n",
      "Ann_id in getitem:  17583\n",
      "Test inds:  [(1655, 2904)]\n",
      "Ann_id in getitem:  38742\n",
      "Test inds:  [(3095, 1863)]\n",
      "Ann_id in getitem:  71296\n",
      "Test inds:  [(2528, 1138)]\n",
      "Ann_id in getitem:  57432\n",
      "Test inds:  [(16, 3451)]\n",
      "Ann_id in getitem:  401\n",
      "Test inds:  [(1054, 1091)]\n",
      "Ann_id in getitem:  24877\n",
      "Test inds:  [(3353, 588)]\n",
      "Ann_id in getitem:  76922\n",
      "Test inds:  [(295, 553)]\n",
      "Ann_id in getitem:  6841\n",
      "Test inds:  [(1026, 190)]\n",
      "Ann_id in getitem:  24205\n",
      "Test inds:  [(3668, 1731)]\n",
      "Ann_id in getitem:  84657\n",
      "Test inds:  [(2927, 2385)]\n",
      "Ann_id in getitem:  67357\n",
      "Test inds:  [(2876, 304)]\n",
      "Ann_id in getitem:  66086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3049, 3245)]\n",
      "Ann_id in getitem:  70292\n",
      "Test inds:  [(692, 2999)]\n",
      "Ann_id in getitem:  16853\n",
      "Test inds:  [(671, 1085)]\n",
      "Ann_id in getitem:  16340\n",
      "Test inds:  [(923, 2977)]\n",
      "Ann_id in getitem:  22116\n",
      "Test inds:  [(988, 3696)]\n",
      "Ann_id in getitem:  23520\n",
      "Test inds:  [(1304, 2640)]\n",
      "Ann_id in getitem:  30493\n",
      "Test inds:  [(237, 2970)]\n",
      "Ann_id in getitem:  5786\n",
      "Test inds:  [(447, 680)]\n",
      "Ann_id in getitem:  10897\n",
      "Test inds:  [(3291, 2633)]\n",
      "Ann_id in getitem:  75455\n",
      "Test inds:  [(3159, 1349)]\n",
      "Ann_id in getitem:  72813\n",
      "Test inds:  [(2350, 3260)]\n",
      "Ann_id in getitem:  53156\n",
      "Test inds:  [(2550, 2122)]\n",
      "Ann_id in getitem:  57948\n",
      "Test inds:  [(3523, 2374)]\n",
      "Ann_id in getitem:  81287\n",
      "Test inds:  [(2007, 1066)]\n",
      "Ann_id in getitem:  45683\n",
      "Test inds:  [(539, 1860)]\n",
      "Ann_id in getitem:  12831\n",
      "Test inds:  [(3345, 799)]\n",
      "Ann_id in getitem:  76870\n",
      "Test inds:  [(3078, 2379)]\n",
      "Ann_id in getitem:  71032\n",
      "Test inds:  [(908, 2736)]\n",
      "Ann_id in getitem:  21641\n",
      "Test inds:  [(925, 3181)]\n",
      "Ann_id in getitem:  22129\n",
      "Test inds:  [(28, 1814)]\n",
      "Ann_id in getitem:  589\n",
      "Test inds:  [(1081, 3072)]\n",
      "Ann_id in getitem:  25257\n",
      "Test inds:  [(2580, 1792)]\n",
      "Ann_id in getitem:  58953\n",
      "Test inds:  [(1183, 1497)]\n",
      "Ann_id in getitem:  27489\n",
      "Test inds:  [(2125, 1083)]\n",
      "Ann_id in getitem:  48198\n",
      "Test inds:  [(2798, 3082)]\n",
      "Ann_id in getitem:  64523\n",
      "Test inds:  [(1532, 891)]\n",
      "Ann_id in getitem:  36246\n",
      "Test inds:  [(3206, 3670)]\n",
      "Ann_id in getitem:  73732\n",
      "Test inds:  [(3327, 3059)]\n",
      "Ann_id in getitem:  76414\n",
      "Test inds:  [(2423, 1869)]\n",
      "Ann_id in getitem:  54783\n",
      "Test inds:  [(1388, 719)]\n",
      "Ann_id in getitem:  32955\n",
      "Test inds:  [(3561, 1404)]\n",
      "Ann_id in getitem:  82098\n",
      "Test inds:  [(1701, 628)]\n",
      "Ann_id in getitem:  39861\n",
      "Test inds:  [(2159, 2789)]\n",
      "Ann_id in getitem:  48721\n",
      "Test inds:  [(3573, 1477)]\n",
      "Ann_id in getitem:  82359\n",
      "Test inds:  [(96, 3301)]\n",
      "Ann_id in getitem:  2154\n",
      "Test inds:  [(1342, 1754)]\n",
      "Ann_id in getitem:  31597\n",
      "Test inds:  [(3494, 3348)]\n",
      "Ann_id in getitem:  80510\n",
      "Test inds:  [(3014, 722)]\n",
      "Ann_id in getitem:  69501\n",
      "Test inds:  [(2634, 3304)]\n",
      "Ann_id in getitem:  60296\n",
      "Test inds:  [(511, 195)]\n",
      "Ann_id in getitem:  12217\n",
      "Test inds:  [(1046, 621)]\n",
      "Ann_id in getitem:  24695\n",
      "Test inds:  [(277, 484)]\n",
      "Ann_id in getitem:  6583\n",
      "Test inds:  [(2414, 2715)]\n",
      "Ann_id in getitem:  54601\n",
      "Test inds:  [(322, 2202)]\n",
      "Ann_id in getitem:  7941\n",
      "Test inds:  [(2044, 611)]\n",
      "Ann_id in getitem:  46557\n",
      "Test inds:  [(205, 2599)]\n",
      "Ann_id in getitem:  5098\n",
      "Test inds:  [(1873, 3155)]\n",
      "Ann_id in getitem:  43075\n",
      "Test inds:  [(1904, 205)]\n",
      "Ann_id in getitem:  43667\n",
      "Test inds:  [(2458, 75)]\n",
      "Ann_id in getitem:  55898\n",
      "Test inds:  [(1178, 1816)]\n",
      "Ann_id in getitem:  27434\n",
      "Test inds:  [(1412, 929)]\n",
      "Ann_id in getitem:  33439\n",
      "Test inds:  [(1093, 2146)]\n",
      "Ann_id in getitem:  25491\n",
      "Test inds:  [(169, 1673)]\n",
      "Ann_id in getitem:  4319\n",
      "Test inds:  [(1941, 112)]\n",
      "Ann_id in getitem:  44231\n",
      "Test inds:  [(501, 269)]\n",
      "Ann_id in getitem:  11986\n",
      "Test inds:  [(271, 3594)]\n",
      "Ann_id in getitem:  6443\n",
      "Test inds:  [(1544, 3529)]\n",
      "Ann_id in getitem:  36524\n",
      "Test inds:  [(1437, 3120)]\n",
      "Ann_id in getitem:  34092\n",
      "Test inds:  [(1521, 3277)]\n",
      "Ann_id in getitem:  36039\n",
      "Test inds:  [(2838, 223)]\n",
      "Ann_id in getitem:  65391\n",
      "Test inds:  [(3449, 3012)]\n",
      "Ann_id in getitem:  79547\n",
      "Test inds:  [(1551, 1822)]\n",
      "Ann_id in getitem:  36687\n",
      "Test inds:  [(3500, 1992)]\n",
      "Ann_id in getitem:  80593\n",
      "Test inds:  [(2630, 3516)]\n",
      "Ann_id in getitem:  60215\n",
      "Test inds:  [(2815, 690)]\n",
      "Ann_id in getitem:  64875\n",
      "Test inds:  [(1285, 968)]\n",
      "Ann_id in getitem:  30071\n",
      "Test inds:  [(3526, 2564)]\n",
      "Ann_id in getitem:  81379\n",
      "Test inds:  [(2047, 170)]\n",
      "Ann_id in getitem:  46652\n",
      "Test inds:  [(2503, 1517)]\n",
      "Ann_id in getitem:  57011\n",
      "Test inds:  [(49, 2307)]\n",
      "Ann_id in getitem:  981\n",
      "Test inds:  [(3181, 3254)]\n",
      "Ann_id in getitem:  73268\n",
      "Test inds:  [(451, 1660)]\n",
      "Ann_id in getitem:  10947\n",
      "Test inds:  [(2951, 3561)]\n",
      "Ann_id in getitem:  68015\n",
      "Test inds:  [(3569, 977)]\n",
      "Ann_id in getitem:  82291\n",
      "Test inds:  [(3234, 1363)]\n",
      "Ann_id in getitem:  74355\n",
      "Test inds:  [(3170, 191)]\n",
      "Ann_id in getitem:  73044\n",
      "Test inds:  [(833, 941)]\n",
      "Ann_id in getitem:  20019\n",
      "Test inds:  [(457, 621)]\n",
      "Ann_id in getitem:  11053\n",
      "Test inds:  [(6, 91)]\n",
      "Ann_id in getitem:  109\n",
      "Test inds:  [(1194, 2444)]\n",
      "Ann_id in getitem:  27832\n",
      "Test inds:  [(2406, 1239)]\n",
      "Ann_id in getitem:  54420\n",
      "Test inds:  [(3002, 1074)]\n",
      "Ann_id in getitem:  69211\n",
      "Test inds:  [(3486, 3384)]\n",
      "Ann_id in getitem:  80301\n",
      "Test inds:  [(3242, 320)]\n",
      "Ann_id in getitem:  74523\n",
      "Test inds:  [(3223, 1212)]\n",
      "Ann_id in getitem:  74111\n",
      "Test inds:  [(2294, 1336)]\n",
      "Ann_id in getitem:  51776\n",
      "Test inds:  [(3206, 2078)]\n",
      "Ann_id in getitem:  73732\n",
      "Test inds:  [(2948, 1824)]\n",
      "Ann_id in getitem:  67914\n",
      "Test inds:  [(1705, 1830)]\n",
      "Ann_id in getitem:  39888\n",
      "Test inds:  [(761, 3007)]\n",
      "Ann_id in getitem:  18483\n",
      "Test inds:  [(2611, 1065)]\n",
      "Ann_id in getitem:  59841\n",
      "Test inds:  [(3395, 576)]\n",
      "Ann_id in getitem:  78052\n",
      "Test inds:  [(2285, 2044)]\n",
      "Ann_id in getitem:  51632\n",
      "Test inds:  [(841, 1058)]\n",
      "Ann_id in getitem:  20304\n",
      "Test inds:  [(2134, 279)]\n",
      "Ann_id in getitem:  48348\n",
      "Test inds:  [(1563, 3677)]\n",
      "Ann_id in getitem:  36925\n",
      "Test inds:  [(1586, 1653)]\n",
      "Ann_id in getitem:  37444\n",
      "Test inds:  [(2683, 1562)]\n",
      "Ann_id in getitem:  61622\n",
      "Test inds:  [(577, 1188)]\n",
      "Ann_id in getitem:  14044\n",
      "Test inds:  [(3318, 3613)]\n",
      "Ann_id in getitem:  76269\n",
      "Test inds:  [(3213, 1169)]\n",
      "Ann_id in getitem:  73857\n",
      "Test inds:  [(3432, 1346)]\n",
      "Ann_id in getitem:  79088\n",
      "Test inds:  [(3189, 2540)]\n",
      "Ann_id in getitem:  73403\n",
      "Test inds:  [(42, 2653)]\n",
      "Ann_id in getitem:  931\n",
      "Test inds:  [(380, 110)]\n",
      "Ann_id in getitem:  9264\n",
      "Test inds:  [(3344, 621)]\n",
      "Ann_id in getitem:  76854\n",
      "Test inds:  [(2488, 2762)]\n",
      "Ann_id in getitem:  56607\n",
      "Test inds:  [(1074, 2280)]\n",
      "Ann_id in getitem:  25164\n",
      "Test inds:  [(964, 1361)]\n",
      "Ann_id in getitem:  22829\n",
      "Test inds:  [(355, 591)]\n",
      "Ann_id in getitem:  8523\n",
      "Test inds:  [(3073, 29)]\n",
      "Ann_id in getitem:  70816\n",
      "Test inds:  [(3685, 1470)]\n",
      "Ann_id in getitem:  84986\n",
      "Test inds:  [(2722, 626)]\n",
      "Ann_id in getitem:  62553\n",
      "Test inds:  [(1063, 453)]\n",
      "Ann_id in getitem:  24998\n",
      "Test inds:  [(603, 609)]\n",
      "Ann_id in getitem:  14592\n",
      "Test inds:  [(2097, 2933)]\n",
      "Ann_id in getitem:  47473\n",
      "Test inds:  [(556, 3370)]\n",
      "Ann_id in getitem:  13488\n",
      "Test inds:  [(3071, 3389)]\n",
      "Ann_id in getitem:  70797\n",
      "Test inds:  [(949, 437)]\n",
      "Ann_id in getitem:  22516\n",
      "Test inds:  [(3322, 1282)]\n",
      "Ann_id in getitem:  76367\n",
      "Test inds:  [(2460, 2475)]\n",
      "Ann_id in getitem:  55940\n",
      "Test inds:  [(751, 3319)]\n",
      "Ann_id in getitem:  18232\n",
      "Test inds:  [(1590, 1704)]\n",
      "Ann_id in getitem:  37511\n",
      "Test inds:  [(3571, 3429)]\n",
      "Ann_id in getitem:  82346\n",
      "Test inds:  [(1949, 2272)]\n",
      "Ann_id in getitem:  44341\n",
      "Test inds:  [(986, 569)]\n",
      "Ann_id in getitem:  23444\n",
      "Test inds:  [(3151, 1370)]\n",
      "Ann_id in getitem:  72632\n",
      "Test inds:  [(3625, 2461)]\n",
      "Ann_id in getitem:  83643\n",
      "Test inds:  [(3352, 216)]\n",
      "Ann_id in getitem:  76904\n",
      "Test inds:  [(99, 2485)]\n",
      "Ann_id in getitem:  2167\n",
      "Test inds:  [(3595, 2540)]\n",
      "Ann_id in getitem:  82901\n",
      "Test inds:  [(475, 2577)]\n",
      "Ann_id in getitem:  11508\n",
      "Test inds:  [(2272, 1196)]\n",
      "Ann_id in getitem:  51390\n",
      "Test inds:  [(973, 1751)]\n",
      "Ann_id in getitem:  22960\n",
      "Test inds:  [(532, 2673)]\n",
      "Ann_id in getitem:  12639\n",
      "Test inds:  [(3481, 199)]\n",
      "Ann_id in getitem:  80259\n",
      "Test inds:  [(960, 1245)]\n",
      "Ann_id in getitem:  22641\n",
      "Test inds:  [(1269, 2681)]\n",
      "Ann_id in getitem:  29634\n",
      "Test inds:  [(2369, 3113)]\n",
      "Ann_id in getitem:  53579\n",
      "Test inds:  [(987, 2407)]\n",
      "Ann_id in getitem:  23451\n",
      "Test inds:  [(1110, 2800)]\n",
      "Ann_id in getitem:  25767\n",
      "Test inds:  [(2513, 2631)]\n",
      "Ann_id in getitem:  57170\n",
      "Test inds:  [(2537, 1110)]\n",
      "Ann_id in getitem:  57575\n",
      "Test inds:  [(3447, 3420)]\n",
      "Ann_id in getitem:  79500\n",
      "Test inds:  [(240, 132)]\n",
      "Ann_id in getitem:  5835\n",
      "Test inds:  [(499, 884)]\n",
      "Ann_id in getitem:  11933\n",
      "Test inds:  [(694, 1625)]\n",
      "Ann_id in getitem:  16924\n",
      "Test inds:  [(1527, 980)]\n",
      "Ann_id in getitem:  36178\n",
      "Test inds:  [(3172, 1673)]\n",
      "Ann_id in getitem:  73066\n",
      "Test inds:  [(3489, 730)]\n",
      "Ann_id in getitem:  80394\n",
      "Test inds:  [(597, 2009)]\n",
      "Ann_id in getitem:  14439\n",
      "Test inds:  [(453, 1366)]\n",
      "Ann_id in getitem:  10960\n",
      "Test inds:  [(805, 2013)]\n",
      "Ann_id in getitem:  19433\n",
      "Test inds:  [(625, 2192)]\n",
      "Ann_id in getitem:  15243\n",
      "Test inds:  [(299, 2814)]\n",
      "Ann_id in getitem:  7039\n",
      "Test inds:  [(847, 2110)]\n",
      "Ann_id in getitem:  20639\n",
      "Test inds:  [(876, 2763)]\n",
      "Ann_id in getitem:  21028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(98, 2083)]\n",
      "Ann_id in getitem:  2158\n",
      "Test inds:  [(3015, 1566)]\n",
      "Ann_id in getitem:  69504\n",
      "Test inds:  [(1194, 455)]\n",
      "Ann_id in getitem:  27832\n",
      "Test inds:  [(15, 550)]\n",
      "Ann_id in getitem:  391\n",
      "Test inds:  [(1397, 173)]\n",
      "Ann_id in getitem:  33147\n",
      "Test inds:  [(1163, 1198)]\n",
      "Ann_id in getitem:  27101\n",
      "Test inds:  [(2702, 2298)]\n",
      "Ann_id in getitem:  62121\n",
      "Test inds:  [(3516, 2976)]\n",
      "Ann_id in getitem:  81120\n",
      "Test inds:  [(2488, 184)]\n",
      "Ann_id in getitem:  56607\n",
      "Test inds:  [(2077, 2942)]\n",
      "Ann_id in getitem:  47186\n",
      "Test inds:  [(3691, 2180)]\n",
      "Ann_id in getitem:  85334\n",
      "Test inds:  [(1208, 33)]\n",
      "Ann_id in getitem:  28145\n",
      "Test inds:  [(1500, 778)]\n",
      "Ann_id in getitem:  35693\n",
      "Test inds:  [(3386, 461)]\n",
      "Ann_id in getitem:  77842\n",
      "Test inds:  [(1596, 3328)]\n",
      "Ann_id in getitem:  37674\n",
      "Test inds:  [(3345, 2378)]\n",
      "Ann_id in getitem:  76870\n",
      "Test inds:  [(2881, 1562)]\n",
      "Ann_id in getitem:  66219\n",
      "Test inds:  [(345, 668)]\n",
      "Ann_id in getitem:  8357\n",
      "Test inds:  [(1617, 240)]\n",
      "Ann_id in getitem:  37890\n",
      "Test inds:  [(3634, 995)]\n",
      "Ann_id in getitem:  83867\n",
      "Test inds:  [(1225, 2993)]\n",
      "Ann_id in getitem:  28589\n",
      "Test inds:  [(970, 2131)]\n",
      "Ann_id in getitem:  22898\n",
      "Test inds:  [(270, 2988)]\n",
      "Ann_id in getitem:  6401\n",
      "Test inds:  [(879, 69)]\n",
      "Ann_id in getitem:  21078\n",
      "Test inds:  [(1058, 3392)]\n",
      "Ann_id in getitem:  24954\n",
      "Test inds:  [(1937, 921)]\n",
      "Ann_id in getitem:  44178\n",
      "Test inds:  [(1718, 604)]\n",
      "Ann_id in getitem:  40106\n",
      "Test inds:  [(89, 1106)]\n",
      "Ann_id in getitem:  2049\n",
      "Test inds:  [(2600, 1821)]\n",
      "Ann_id in getitem:  59568\n",
      "Test inds:  [(2939, 1508)]\n",
      "Ann_id in getitem:  67698\n",
      "Test inds:  [(3351, 2089)]\n",
      "Ann_id in getitem:  76900\n",
      "Test inds:  [(676, 1019)]\n",
      "Ann_id in getitem:  16418\n",
      "Test inds:  [(123, 1757)]\n",
      "Ann_id in getitem:  2946\n",
      "Test inds:  [(1849, 3251)]\n",
      "Ann_id in getitem:  42562\n",
      "Test inds:  [(2801, 2160)]\n",
      "Ann_id in getitem:  64644\n",
      "Test inds:  [(1086, 975)]\n",
      "Ann_id in getitem:  25327\n",
      "Test inds:  [(1630, 46)]\n",
      "Ann_id in getitem:  38253\n",
      "Test inds:  [(3299, 605)]\n",
      "Ann_id in getitem:  75613\n",
      "Test inds:  [(3507, 1690)]\n",
      "Ann_id in getitem:  80940\n",
      "Test inds:  [(1235, 2154)]\n",
      "Ann_id in getitem:  28884\n",
      "Test inds:  [(910, 1270)]\n",
      "Ann_id in getitem:  21662\n",
      "Test inds:  [(3330, 614)]\n",
      "Ann_id in getitem:  76518\n",
      "Test inds:  [(604, 1654)]\n",
      "Ann_id in getitem:  14618\n",
      "Test inds:  [(2006, 547)]\n",
      "Ann_id in getitem:  45673\n",
      "Test inds:  [(3285, 2536)]\n",
      "Ann_id in getitem:  75249\n",
      "Test inds:  [(2266, 926)]\n",
      "Ann_id in getitem:  51182\n",
      "Test inds:  [(3666, 1558)]\n",
      "Ann_id in getitem:  84626\n",
      "Test inds:  [(520, 1543)]\n",
      "Ann_id in getitem:  12426\n",
      "Test inds:  [(281, 2588)]\n",
      "Ann_id in getitem:  6637\n",
      "Test inds:  [(280, 2457)]\n",
      "Ann_id in getitem:  6615\n",
      "Test inds:  [(950, 1870)]\n",
      "Ann_id in getitem:  22526\n",
      "Test inds:  [(35, 1327)]\n",
      "Ann_id in getitem:  791\n",
      "Test inds:  [(2150, 1661)]\n",
      "Ann_id in getitem:  48576\n",
      "Test inds:  [(3150, 3145)]\n",
      "Ann_id in getitem:  72611\n",
      "Test inds:  [(413, 411)]\n",
      "Ann_id in getitem:  10096\n",
      "Test inds:  [(1378, 1454)]\n",
      "Ann_id in getitem:  32598\n",
      "Test inds:  [(1057, 1830)]\n",
      "Ann_id in getitem:  24953\n",
      "Test inds:  [(2727, 3308)]\n",
      "Ann_id in getitem:  62746\n",
      "Test inds:  [(2320, 1739)]\n",
      "Ann_id in getitem:  52229\n",
      "Test inds:  [(2899, 3220)]\n",
      "Ann_id in getitem:  66652\n",
      "Test inds:  [(1568, 1591)]\n",
      "Ann_id in getitem:  37096\n",
      "Test inds:  [(998, 1558)]\n",
      "Ann_id in getitem:  23696\n",
      "Test inds:  [(520, 433)]\n",
      "Ann_id in getitem:  12426\n",
      "Test inds:  [(588, 2486)]\n",
      "Ann_id in getitem:  14305\n",
      "Test inds:  [(2746, 1997)]\n",
      "Ann_id in getitem:  63175\n",
      "Test inds:  [(3036, 233)]\n",
      "Ann_id in getitem:  70015\n",
      "Test inds:  [(1629, 2417)]\n",
      "Ann_id in getitem:  38235\n",
      "Test inds:  [(3647, 1331)]\n",
      "Ann_id in getitem:  84161\n",
      "Test inds:  [(1874, 1067)]\n",
      "Ann_id in getitem:  43127\n",
      "Test inds:  [(3106, 2938)]\n",
      "Ann_id in getitem:  71691\n",
      "Test inds:  [(2429, 740)]\n",
      "Ann_id in getitem:  54907\n",
      "Test inds:  [(3206, 912)]\n",
      "Ann_id in getitem:  73732\n",
      "Test inds:  [(1402, 939)]\n",
      "Ann_id in getitem:  33201\n",
      "Test inds:  [(1125, 3408)]\n",
      "Ann_id in getitem:  26216\n",
      "Test inds:  [(1824, 1394)]\n",
      "Ann_id in getitem:  41983\n",
      "Test inds:  [(548, 126)]\n",
      "Ann_id in getitem:  13138\n",
      "Test inds:  [(1930, 2356)]\n",
      "Ann_id in getitem:  44078\n",
      "Test inds:  [(1909, 3571)]\n",
      "Ann_id in getitem:  43728\n",
      "Test inds:  [(347, 2563)]\n",
      "Ann_id in getitem:  8427\n",
      "Test inds:  [(779, 1234)]\n",
      "Ann_id in getitem:  18903\n",
      "Test inds:  [(74, 1716)]\n",
      "Ann_id in getitem:  1638\n",
      "Test inds:  [(1463, 631)]\n",
      "Ann_id in getitem:  34654\n",
      "Test inds:  [(3129, 1539)]\n",
      "Ann_id in getitem:  72149\n",
      "Test inds:  [(2452, 940)]\n",
      "Ann_id in getitem:  55702\n",
      "Test inds:  [(2961, 2905)]\n",
      "Ann_id in getitem:  68145\n",
      "Test inds:  [(2136, 1393)]\n",
      "Ann_id in getitem:  48396\n",
      "Test inds:  [(3029, 2982)]\n",
      "Ann_id in getitem:  69882\n",
      "Test inds:  [(267, 3267)]\n",
      "Ann_id in getitem:  6343\n",
      "Test inds:  [(2617, 21)]\n",
      "Ann_id in getitem:  59921\n",
      "Test inds:  [(2690, 324)]\n",
      "Ann_id in getitem:  61838\n",
      "Test inds:  [(3360, 3138)]\n",
      "Ann_id in getitem:  77096\n",
      "Test inds:  [(1738, 2153)]\n",
      "Ann_id in getitem:  40426\n",
      "Test inds:  [(19, 792)]\n",
      "Ann_id in getitem:  447\n",
      "Test inds:  [(1689, 1991)]\n",
      "Ann_id in getitem:  39564\n",
      "Test inds:  [(3318, 2196)]\n",
      "Ann_id in getitem:  76269\n",
      "Test inds:  [(130, 2546)]\n",
      "Ann_id in getitem:  3125\n",
      "Test inds:  [(3501, 3066)]\n",
      "Ann_id in getitem:  80649\n",
      "Test inds:  [(61, 2038)]\n",
      "Ann_id in getitem:  1327\n",
      "Test inds:  [(985, 296)]\n",
      "Ann_id in getitem:  23419\n",
      "Test inds:  [(2679, 2705)]\n",
      "Ann_id in getitem:  61456\n",
      "Test inds:  [(380, 793)]\n",
      "Ann_id in getitem:  9264\n",
      "Test inds:  [(3699, 873)]\n",
      "Ann_id in getitem:  85453\n",
      "Test inds:  [(2527, 2492)]\n",
      "Ann_id in getitem:  57402\n",
      "Test inds:  [(1266, 2764)]\n",
      "Ann_id in getitem:  29600\n",
      "Test inds:  [(1768, 2448)]\n",
      "Ann_id in getitem:  40851\n",
      "Test inds:  [(1383, 305)]\n",
      "Ann_id in getitem:  32854\n",
      "Test inds:  [(382, 2712)]\n",
      "Ann_id in getitem:  9345\n",
      "Test inds:  [(2054, 3001)]\n",
      "Ann_id in getitem:  46791\n",
      "Test inds:  [(534, 154)]\n",
      "Ann_id in getitem:  12713\n",
      "Test inds:  [(2920, 1218)]\n",
      "Ann_id in getitem:  67248\n",
      "Test inds:  [(189, 67)]\n",
      "Ann_id in getitem:  4781\n",
      "Test inds:  [(1071, 664)]\n",
      "Ann_id in getitem:  25148\n",
      "Test inds:  [(736, 40)]\n",
      "Ann_id in getitem:  17866\n",
      "Test inds:  [(2590, 2457)]\n",
      "Ann_id in getitem:  59384\n",
      "Test inds:  [(1782, 215)]\n",
      "Ann_id in getitem:  41096\n",
      "Test inds:  [(1053, 1751)]\n",
      "Ann_id in getitem:  24847\n",
      "Test inds:  [(1091, 3692)]\n",
      "Ann_id in getitem:  25434\n",
      "Test inds:  [(2114, 3454)]\n",
      "Ann_id in getitem:  47929\n",
      "Test inds:  [(2747, 3585)]\n",
      "Ann_id in getitem:  63243\n",
      "Test inds:  [(171, 2520)]\n",
      "Ann_id in getitem:  4347\n",
      "Test inds:  [(3403, 2067)]\n",
      "Ann_id in getitem:  78319\n",
      "Test inds:  [(1526, 982)]\n",
      "Ann_id in getitem:  36114\n",
      "Test inds:  [(2863, 2801)]\n",
      "Ann_id in getitem:  65814\n",
      "Test inds:  [(1768, 1091)]\n",
      "Ann_id in getitem:  40851\n",
      "Test inds:  [(536, 896)]\n",
      "Ann_id in getitem:  12740\n",
      "Test inds:  [(1877, 2200)]\n",
      "Ann_id in getitem:  43172\n",
      "Test inds:  [(3261, 2686)]\n",
      "Ann_id in getitem:  74844\n",
      "Test inds:  [(2005, 2643)]\n",
      "Ann_id in getitem:  45668\n",
      "Test inds:  [(527, 1685)]\n",
      "Ann_id in getitem:  12564\n",
      "Test inds:  [(1845, 3650)]\n",
      "Ann_id in getitem:  42475\n",
      "Test inds:  [(498, 2035)]\n",
      "Ann_id in getitem:  11931\n",
      "Test inds:  [(2006, 326)]\n",
      "Ann_id in getitem:  45673\n",
      "Test inds:  [(939, 2313)]\n",
      "Ann_id in getitem:  22341\n",
      "Test inds:  [(3512, 479)]\n",
      "Ann_id in getitem:  81066\n",
      "Test inds:  [(1497, 287)]\n",
      "Ann_id in getitem:  35575\n",
      "Test inds:  [(49, 1872)]\n",
      "Ann_id in getitem:  981\n",
      "Test inds:  [(21, 733)]\n",
      "Ann_id in getitem:  455\n",
      "Test inds:  [(2149, 1402)]\n",
      "Ann_id in getitem:  48563\n",
      "Test inds:  [(1354, 805)]\n",
      "Ann_id in getitem:  31963\n",
      "Test inds:  [(3324, 2264)]\n",
      "Ann_id in getitem:  76380\n",
      "Test inds:  [(3131, 844)]\n",
      "Ann_id in getitem:  72184\n",
      "Test inds:  [(89, 1460)]\n",
      "Ann_id in getitem:  2049\n",
      "Test inds:  [(428, 1705)]\n",
      "Ann_id in getitem:  10539\n",
      "Test inds:  [(3340, 2273)]\n",
      "Ann_id in getitem:  76767\n",
      "Test inds:  [(2918, 382)]\n",
      "Ann_id in getitem:  67160\n",
      "Test inds:  [(3580, 2715)]\n",
      "Ann_id in getitem:  82483\n",
      "Test inds:  [(1651, 2366)]\n",
      "Ann_id in getitem:  38642\n",
      "Test inds:  [(2904, 1437)]\n",
      "Ann_id in getitem:  66990\n",
      "Test inds:  [(3108, 233)]\n",
      "Ann_id in getitem:  71709\n",
      "Test inds:  [(3060, 1987)]\n",
      "Ann_id in getitem:  70600\n",
      "Test inds:  [(1889, 2474)]\n",
      "Ann_id in getitem:  43405\n",
      "Test inds:  [(2295, 190)]\n",
      "Ann_id in getitem:  51786\n",
      "Test inds:  [(1530, 2480)]\n",
      "Ann_id in getitem:  36222\n",
      "Test inds:  [(3001, 1520)]\n",
      "Ann_id in getitem:  69144\n",
      "Test inds:  [(2014, 2462)]\n",
      "Ann_id in getitem:  45833\n",
      "Test inds:  [(749, 308)]\n",
      "Ann_id in getitem:  18138\n",
      "Test inds:  [(1005, 2680)]\n",
      "Ann_id in getitem:  23874\n",
      "Test inds:  [(2409, 1628)]\n",
      "Ann_id in getitem:  54511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2993, 3318)]\n",
      "Ann_id in getitem:  68987\n",
      "Test inds:  [(3490, 2520)]\n",
      "Ann_id in getitem:  80401\n",
      "Test inds:  [(2040, 1712)]\n",
      "Ann_id in getitem:  46440\n",
      "Test inds:  [(2244, 2632)]\n",
      "Ann_id in getitem:  50687\n",
      "Test inds:  [(795, 98)]\n",
      "Ann_id in getitem:  19259\n",
      "Test inds:  [(1975, 1670)]\n",
      "Ann_id in getitem:  45007\n",
      "Test inds:  [(1670, 2515)]\n",
      "Ann_id in getitem:  39069\n",
      "Test inds:  [(1446, 104)]\n",
      "Ann_id in getitem:  34252\n",
      "Test inds:  [(1091, 3347)]\n",
      "Ann_id in getitem:  25434\n",
      "Test inds:  [(2370, 1151)]\n",
      "Ann_id in getitem:  53599\n",
      "Test inds:  [(34, 875)]\n",
      "Ann_id in getitem:  754\n",
      "Test inds:  [(1405, 2446)]\n",
      "Ann_id in getitem:  33265\n",
      "Test inds:  [(866, 2349)]\n",
      "Ann_id in getitem:  20914\n",
      "Test inds:  [(1417, 2398)]\n",
      "Ann_id in getitem:  33495\n",
      "Test inds:  [(3314, 2011)]\n",
      "Ann_id in getitem:  76128\n",
      "Test inds:  [(1434, 405)]\n",
      "Ann_id in getitem:  33991\n",
      "Test inds:  [(312, 198)]\n",
      "Ann_id in getitem:  7627\n",
      "Test inds:  [(1522, 1646)]\n",
      "Ann_id in getitem:  36046\n",
      "Test inds:  [(3152, 1661)]\n",
      "Ann_id in getitem:  72637\n",
      "Test inds:  [(1511, 465)]\n",
      "Ann_id in getitem:  35841\n",
      "Test inds:  [(1026, 1789)]\n",
      "Ann_id in getitem:  24205\n",
      "Test inds:  [(1809, 2895)]\n",
      "Ann_id in getitem:  41709\n",
      "Test inds:  [(943, 2273)]\n",
      "Ann_id in getitem:  22384\n",
      "Test inds:  [(363, 679)]\n",
      "Ann_id in getitem:  8754\n",
      "Test inds:  [(2125, 2111)]\n",
      "Ann_id in getitem:  48198\n",
      "Test inds:  [(770, 1482)]\n",
      "Ann_id in getitem:  18651\n",
      "Test inds:  [(870, 599)]\n",
      "Ann_id in getitem:  20955\n",
      "Test inds:  [(621, 2143)]\n",
      "Ann_id in getitem:  15187\n",
      "Test inds:  [(326, 2688)]\n",
      "Ann_id in getitem:  7996\n",
      "Test inds:  [(959, 760)]\n",
      "Ann_id in getitem:  22627\n",
      "Test inds:  [(852, 1570)]\n",
      "Ann_id in getitem:  20715\n",
      "Test inds:  [(3193, 1983)]\n",
      "Ann_id in getitem:  73443\n",
      "Test inds:  [(2301, 3659)]\n",
      "Ann_id in getitem:  51875\n",
      "Test inds:  [(263, 2202)]\n",
      "Ann_id in getitem:  6282\n",
      "Test inds:  [(547, 2337)]\n",
      "Ann_id in getitem:  13055\n",
      "Test inds:  [(486, 3312)]\n",
      "Ann_id in getitem:  11702\n",
      "Test inds:  [(3029, 2553)]\n",
      "Ann_id in getitem:  69882\n",
      "Test inds:  [(109, 288)]\n",
      "Ann_id in getitem:  2576\n",
      "Test inds:  [(259, 1040)]\n",
      "Ann_id in getitem:  6216\n",
      "Test inds:  [(3138, 957)]\n",
      "Ann_id in getitem:  72386\n",
      "Test inds:  [(1305, 2114)]\n",
      "Ann_id in getitem:  30507\n",
      "Test inds:  [(474, 3276)]\n",
      "Ann_id in getitem:  11460\n",
      "Test inds:  [(2384, 1513)]\n",
      "Ann_id in getitem:  53904\n",
      "Test inds:  [(105, 3656)]\n",
      "Ann_id in getitem:  2383\n",
      "Test inds:  [(3087, 1908)]\n",
      "Ann_id in getitem:  71208\n",
      "Test inds:  [(2201, 2298)]\n",
      "Ann_id in getitem:  49577\n",
      "Test inds:  [(129, 621)]\n",
      "Ann_id in getitem:  3106\n",
      "Test inds:  [(2804, 1892)]\n",
      "Ann_id in getitem:  64707\n",
      "Test inds:  [(1437, 3374)]\n",
      "Ann_id in getitem:  34092\n",
      "Test inds:  [(1184, 2944)]\n",
      "Ann_id in getitem:  27564\n",
      "Test inds:  [(764, 745)]\n",
      "Ann_id in getitem:  18520\n",
      "Test inds:  [(3232, 3319)]\n",
      "Ann_id in getitem:  74284\n",
      "Test inds:  [(112, 907)]\n",
      "Ann_id in getitem:  2620\n",
      "Test inds:  [(2533, 2273)]\n",
      "Ann_id in getitem:  57496\n",
      "Test inds:  [(1213, 3558)]\n",
      "Ann_id in getitem:  28255\n",
      "Test inds:  [(3066, 2338)]\n",
      "Ann_id in getitem:  70643\n",
      "Test inds:  [(181, 651)]\n",
      "Ann_id in getitem:  4633\n",
      "Test inds:  [(2147, 1535)]\n",
      "Ann_id in getitem:  48536\n",
      "Test inds:  [(2553, 1958)]\n",
      "Ann_id in getitem:  58014\n",
      "Test inds:  [(58, 928)]\n",
      "Ann_id in getitem:  1229\n",
      "Test inds:  [(76, 2603)]\n",
      "Ann_id in getitem:  1706\n",
      "Test inds:  [(2489, 3463)]\n",
      "Ann_id in getitem:  56656\n",
      "Test inds:  [(3132, 227)]\n",
      "Ann_id in getitem:  72190\n",
      "Test inds:  [(1230, 868)]\n",
      "Ann_id in getitem:  28761\n",
      "Test inds:  [(193, 451)]\n",
      "Ann_id in getitem:  4855\n",
      "Test inds:  [(951, 1415)]\n",
      "Ann_id in getitem:  22560\n",
      "Test inds:  [(1426, 723)]\n",
      "Ann_id in getitem:  33809\n",
      "Test inds:  [(485, 3640)]\n",
      "Ann_id in getitem:  11673\n",
      "Test inds:  [(17, 1397)]\n",
      "Ann_id in getitem:  437\n",
      "Test inds:  [(300, 237)]\n",
      "Ann_id in getitem:  7049\n",
      "Test inds:  [(146, 3010)]\n",
      "Ann_id in getitem:  3577\n",
      "Test inds:  [(2331, 1259)]\n",
      "Ann_id in getitem:  52569\n",
      "Test inds:  [(74, 103)]\n",
      "Ann_id in getitem:  1638\n",
      "Test inds:  [(3251, 323)]\n",
      "Ann_id in getitem:  74669\n",
      "Test inds:  [(2252, 569)]\n",
      "Ann_id in getitem:  50887\n",
      "Test inds:  [(2692, 2295)]\n",
      "Ann_id in getitem:  61905\n",
      "Test inds:  [(3250, 293)]\n",
      "Ann_id in getitem:  74658\n",
      "Test inds:  [(123, 611)]\n",
      "Ann_id in getitem:  2946\n",
      "Test inds:  [(2108, 1362)]\n",
      "Ann_id in getitem:  47790\n",
      "Test inds:  [(2190, 404)]\n",
      "Ann_id in getitem:  49343\n",
      "Test inds:  [(3304, 2252)]\n",
      "Ann_id in getitem:  75833\n",
      "Test inds:  [(2116, 3200)]\n",
      "Ann_id in getitem:  47941\n",
      "Test inds:  [(984, 184)]\n",
      "Ann_id in getitem:  23330\n",
      "Test inds:  [(1192, 169)]\n",
      "Ann_id in getitem:  27755\n",
      "Test inds:  [(1516, 3252)]\n",
      "Ann_id in getitem:  35938\n",
      "Test inds:  [(1083, 924)]\n",
      "Ann_id in getitem:  25262\n",
      "Test inds:  [(3232, 1166)]\n",
      "Ann_id in getitem:  74284\n",
      "Test inds:  [(2671, 2963)]\n",
      "Ann_id in getitem:  61303\n",
      "Test inds:  [(2875, 2503)]\n",
      "Ann_id in getitem:  66059\n",
      "Test inds:  [(967, 35)]\n",
      "Ann_id in getitem:  22855\n",
      "Test inds:  [(3297, 1559)]\n",
      "Ann_id in getitem:  75592\n",
      "Test inds:  [(2525, 1755)]\n",
      "Ann_id in getitem:  57329\n",
      "Test inds:  [(2310, 3334)]\n",
      "Ann_id in getitem:  52078\n",
      "Test inds:  [(2732, 1265)]\n",
      "Ann_id in getitem:  62823\n",
      "Test inds:  [(662, 1608)]\n",
      "Ann_id in getitem:  16177\n",
      "Test inds:  [(2489, 573)]\n",
      "Ann_id in getitem:  56656\n",
      "Test inds:  [(2305, 2734)]\n",
      "Ann_id in getitem:  51996\n",
      "Test inds:  [(3352, 3256)]\n",
      "Ann_id in getitem:  76904\n",
      "Test inds:  [(1000, 1583)]\n",
      "Ann_id in getitem:  23720\n",
      "Test inds:  [(1857, 2790)]\n",
      "Ann_id in getitem:  42701\n",
      "Test inds:  [(3512, 2443)]\n",
      "Ann_id in getitem:  81066\n",
      "Test inds:  [(2098, 299)]\n",
      "Ann_id in getitem:  47474\n",
      "Test inds:  [(3496, 2396)]\n",
      "Ann_id in getitem:  80522\n",
      "Test inds:  [(721, 984)]\n",
      "Ann_id in getitem:  17438\n",
      "Test inds:  [(2602, 205)]\n",
      "Ann_id in getitem:  59628\n",
      "Test inds:  [(3228, 1892)]\n",
      "Ann_id in getitem:  74185\n",
      "Test inds:  [(655, 3487)]\n",
      "Ann_id in getitem:  15980\n",
      "Test inds:  [(1690, 3346)]\n",
      "Ann_id in getitem:  39638\n",
      "Test inds:  [(104, 831)]\n",
      "Ann_id in getitem:  2376\n",
      "Test inds:  [(2397, 2084)]\n",
      "Ann_id in getitem:  54242\n",
      "Test inds:  [(3027, 64)]\n",
      "Ann_id in getitem:  69827\n",
      "Test inds:  [(3570, 3154)]\n",
      "Ann_id in getitem:  82292\n",
      "Test inds:  [(293, 3613)]\n",
      "Ann_id in getitem:  6803\n",
      "Test inds:  [(1416, 148)]\n",
      "Ann_id in getitem:  33482\n",
      "Test inds:  [(2764, 915)]\n",
      "Ann_id in getitem:  63573\n",
      "Test inds:  [(2811, 566)]\n",
      "Ann_id in getitem:  64855\n",
      "Test inds:  [(823, 3001)]\n",
      "Ann_id in getitem:  19785\n",
      "Test inds:  [(1894, 1735)]\n",
      "Ann_id in getitem:  43476\n",
      "Test inds:  [(2569, 1672)]\n",
      "Ann_id in getitem:  58460\n",
      "Test inds:  [(1711, 2728)]\n",
      "Ann_id in getitem:  39995\n",
      "Test inds:  [(81, 1133)]\n",
      "Ann_id in getitem:  1865\n",
      "Test inds:  [(3544, 2660)]\n",
      "Ann_id in getitem:  81777\n",
      "Test inds:  [(3562, 1710)]\n",
      "Ann_id in getitem:  82145\n",
      "Test inds:  [(3508, 601)]\n",
      "Ann_id in getitem:  80960\n",
      "Test inds:  [(1767, 2130)]\n",
      "Ann_id in getitem:  40839\n",
      "Test inds:  [(3222, 1018)]\n",
      "Ann_id in getitem:  74083\n",
      "Test inds:  [(1963, 1453)]\n",
      "Ann_id in getitem:  44724\n",
      "Test inds:  [(1828, 3402)]\n",
      "Ann_id in getitem:  42028\n",
      "Test inds:  [(2630, 707)]\n",
      "Ann_id in getitem:  60215\n",
      "Test inds:  [(1273, 1487)]\n",
      "Ann_id in getitem:  29707\n",
      "Test inds:  [(375, 2802)]\n",
      "Ann_id in getitem:  9174\n",
      "Test inds:  [(984, 1664)]\n",
      "Ann_id in getitem:  23330\n",
      "Test inds:  [(3010, 2490)]\n",
      "Ann_id in getitem:  69388\n",
      "Test inds:  [(753, 686)]\n",
      "Ann_id in getitem:  18251\n",
      "Test inds:  [(882, 1270)]\n",
      "Ann_id in getitem:  21117\n",
      "Test inds:  [(2095, 914)]\n",
      "Ann_id in getitem:  47451\n",
      "Test inds:  [(1045, 2329)]\n",
      "Ann_id in getitem:  24687\n",
      "Test inds:  [(701, 2486)]\n",
      "Ann_id in getitem:  17058\n",
      "Test inds:  [(1841, 922)]\n",
      "Ann_id in getitem:  42253\n",
      "Test inds:  [(153, 2583)]\n",
      "Ann_id in getitem:  3762\n",
      "Test inds:  [(3649, 1712)]\n",
      "Ann_id in getitem:  84230\n",
      "Test inds:  [(1749, 2939)]\n",
      "Ann_id in getitem:  40552\n",
      "Test inds:  [(3246, 3389)]\n",
      "Ann_id in getitem:  74594\n",
      "Test inds:  [(564, 275)]\n",
      "Ann_id in getitem:  13573\n",
      "Test inds:  [(555, 1814)]\n",
      "Ann_id in getitem:  13423\n",
      "Test inds:  [(3515, 3274)]\n",
      "Ann_id in getitem:  81112\n",
      "Test inds:  [(12, 2261)]\n",
      "Ann_id in getitem:  221\n",
      "Test inds:  [(1023, 792)]\n",
      "Ann_id in getitem:  24179\n",
      "Test inds:  [(2396, 3)]\n",
      "Ann_id in getitem:  54215\n",
      "Test inds:  [(2609, 2013)]\n",
      "Ann_id in getitem:  59819\n",
      "Test inds:  [(2269, 2872)]\n",
      "Ann_id in getitem:  51256\n",
      "Test inds:  [(1246, 3476)]\n",
      "Ann_id in getitem:  29195\n",
      "Test inds:  [(1333, 1967)]\n",
      "Ann_id in getitem:  31396\n",
      "Test inds:  [(812, 423)]\n",
      "Ann_id in getitem:  19553\n",
      "Test inds:  [(3593, 1429)]\n",
      "Ann_id in getitem:  82851\n",
      "Test inds:  [(20, 897)]\n",
      "Ann_id in getitem:  452\n",
      "Test inds:  [(2761, 1039)]\n",
      "Ann_id in getitem:  63510\n",
      "Test inds:  [(1294, 280)]\n",
      "Ann_id in getitem:  30367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(3559, 1765)]\n",
      "Ann_id in getitem:  82087\n",
      "Test inds:  [(2, 3533)]\n",
      "Ann_id in getitem:  49\n",
      "Test inds:  [(3380, 89)]\n",
      "Ann_id in getitem:  77732\n",
      "Test inds:  [(549, 2081)]\n",
      "Ann_id in getitem:  13155\n",
      "Test inds:  [(623, 609)]\n",
      "Ann_id in getitem:  15198\n",
      "Test inds:  [(3177, 3440)]\n",
      "Ann_id in getitem:  73139\n",
      "Test inds:  [(3153, 2874)]\n",
      "Ann_id in getitem:  72644\n",
      "Test inds:  [(2594, 2584)]\n",
      "Ann_id in getitem:  59476\n",
      "Test inds:  [(2657, 3088)]\n",
      "Ann_id in getitem:  60988\n",
      "Test inds:  [(1120, 1886)]\n",
      "Ann_id in getitem:  26024\n",
      "Test inds:  [(3176, 3171)]\n",
      "Ann_id in getitem:  73113\n",
      "Test inds:  [(3465, 1697)]\n",
      "Ann_id in getitem:  80003\n",
      "Test inds:  [(2460, 3234)]\n",
      "Ann_id in getitem:  55940\n",
      "Test inds:  [(2253, 3439)]\n",
      "Ann_id in getitem:  50937\n",
      "Test inds:  [(329, 2476)]\n",
      "Ann_id in getitem:  8083\n",
      "Test inds:  [(3512, 1447)]\n",
      "Ann_id in getitem:  81066\n",
      "Test inds:  [(2341, 2012)]\n",
      "Ann_id in getitem:  52808\n",
      "Test inds:  [(872, 2543)]\n",
      "Ann_id in getitem:  20982\n",
      "Test inds:  [(3660, 2816)]\n",
      "Ann_id in getitem:  84499\n",
      "Test inds:  [(1997, 2790)]\n",
      "Ann_id in getitem:  45522\n",
      "Test inds:  [(1625, 1208)]\n",
      "Ann_id in getitem:  38084\n",
      "Test inds:  [(2784, 89)]\n",
      "Ann_id in getitem:  64236\n",
      "Test inds:  [(3420, 1494)]\n",
      "Ann_id in getitem:  78757\n",
      "Test inds:  [(3399, 2414)]\n",
      "Ann_id in getitem:  78176\n",
      "Test inds:  [(2824, 1775)]\n",
      "Ann_id in getitem:  65096\n",
      "Test inds:  [(800, 1498)]\n",
      "Ann_id in getitem:  19354\n",
      "Test inds:  [(2681, 589)]\n",
      "Ann_id in getitem:  61586\n",
      "Test inds:  [(154, 3642)]\n",
      "Ann_id in getitem:  3765\n",
      "Test inds:  [(584, 2556)]\n",
      "Ann_id in getitem:  14209\n",
      "Test inds:  [(2614, 157)]\n",
      "Ann_id in getitem:  59861\n",
      "Test inds:  [(381, 3314)]\n",
      "Ann_id in getitem:  9270\n",
      "Test inds:  [(2158, 334)]\n",
      "Ann_id in getitem:  48679\n",
      "Test inds:  [(1892, 3436)]\n",
      "Ann_id in getitem:  43427\n",
      "Test inds:  [(297, 3615)]\n",
      "Ann_id in getitem:  6928\n",
      "Test inds:  [(545, 2435)]\n",
      "Ann_id in getitem:  12973\n",
      "Test inds:  [(1767, 2639)]\n",
      "Ann_id in getitem:  40839\n",
      "Test inds:  [(1545, 3456)]\n",
      "Ann_id in getitem:  36558\n",
      "Test inds:  [(2707, 1381)]\n",
      "Ann_id in getitem:  62181\n",
      "Test inds:  [(377, 3130)]\n",
      "Ann_id in getitem:  9180\n",
      "Test inds:  [(2500, 407)]\n",
      "Ann_id in getitem:  56952\n",
      "Test inds:  [(991, 826)]\n",
      "Ann_id in getitem:  23583\n",
      "Test inds:  [(2106, 2179)]\n",
      "Ann_id in getitem:  47683\n",
      "Test inds:  [(207, 2835)]\n",
      "Ann_id in getitem:  5174\n",
      "Test inds:  [(2545, 1862)]\n",
      "Ann_id in getitem:  57846\n",
      "Test inds:  [(3617, 277)]\n",
      "Ann_id in getitem:  83519\n",
      "Test inds:  [(114, 625)]\n",
      "Ann_id in getitem:  2666\n",
      "Test inds:  [(3349, 2334)]\n",
      "Ann_id in getitem:  76888\n",
      "Test inds:  [(1348, 3035)]\n",
      "Ann_id in getitem:  31781\n",
      "Test inds:  [(3387, 181)]\n",
      "Ann_id in getitem:  77849\n",
      "Test inds:  [(1120, 2138)]\n",
      "Ann_id in getitem:  26024\n",
      "Test inds:  [(2940, 3348)]\n",
      "Ann_id in getitem:  67716\n",
      "Test inds:  [(2090, 3174)]\n",
      "Ann_id in getitem:  47399\n",
      "Test inds:  [(3468, 1155)]\n",
      "Ann_id in getitem:  80052\n",
      "Test inds:  [(3646, 276)]\n",
      "Ann_id in getitem:  84149\n",
      "Test inds:  [(271, 3612)]\n",
      "Ann_id in getitem:  6443\n",
      "Test inds:  [(660, 1337)]\n",
      "Ann_id in getitem:  16123\n",
      "Test inds:  [(1938, 2975)]\n",
      "Ann_id in getitem:  44183\n",
      "Test inds:  [(3311, 3616)]\n",
      "Ann_id in getitem:  76008\n",
      "Test inds:  [(564, 2678)]\n",
      "Ann_id in getitem:  13573\n",
      "Test inds:  [(80, 1124)]\n",
      "Ann_id in getitem:  1828\n",
      "Test inds:  [(1688, 3574)]\n",
      "Ann_id in getitem:  39530\n",
      "Test inds:  [(2339, 3447)]\n",
      "Ann_id in getitem:  52740\n",
      "Test inds:  [(647, 225)]\n",
      "Ann_id in getitem:  15755\n",
      "Test inds:  [(586, 1041)]\n",
      "Ann_id in getitem:  14235\n",
      "Test inds:  [(3017, 2876)]\n",
      "Ann_id in getitem:  69532\n",
      "Test inds:  [(109, 2179)]\n",
      "Ann_id in getitem:  2576\n",
      "Test inds:  [(1783, 2589)]\n",
      "Ann_id in getitem:  41100\n",
      "Test inds:  [(725, 308)]\n",
      "Ann_id in getitem:  17548\n",
      "Test inds:  [(2194, 520)]\n",
      "Ann_id in getitem:  49381\n",
      "Test inds:  [(1794, 3345)]\n",
      "Ann_id in getitem:  41445\n",
      "Test inds:  [(3196, 2116)]\n",
      "Ann_id in getitem:  73530\n",
      "Test inds:  [(2, 1906)]\n",
      "Ann_id in getitem:  49\n",
      "Test inds:  [(688, 171)]\n",
      "Ann_id in getitem:  16752\n",
      "Test inds:  [(3061, 1352)]\n",
      "Ann_id in getitem:  70603\n",
      "Test inds:  [(3650, 2480)]\n",
      "Ann_id in getitem:  84238\n",
      "Test inds:  [(3073, 581)]\n",
      "Ann_id in getitem:  70816\n",
      "Test inds:  [(3154, 1664)]\n",
      "Ann_id in getitem:  72679\n",
      "Test inds:  [(1819, 2219)]\n",
      "Ann_id in getitem:  41869\n",
      "Test inds:  [(461, 24)]\n",
      "Ann_id in getitem:  11138\n",
      "Test inds:  [(1279, 1747)]\n",
      "Ann_id in getitem:  29962\n",
      "Test inds:  [(3673, 2941)]\n",
      "Ann_id in getitem:  84720\n",
      "Test inds:  [(689, 3620)]\n",
      "Ann_id in getitem:  16759\n",
      "Test inds:  [(2571, 2735)]\n",
      "Ann_id in getitem:  58628\n",
      "Test inds:  [(1759, 2428)]\n",
      "Ann_id in getitem:  40714\n",
      "Test inds:  [(2619, 1138)]\n",
      "Ann_id in getitem:  59940\n",
      "Test inds:  [(952, 2022)]\n",
      "Ann_id in getitem:  22575\n",
      "Test inds:  [(59, 1297)]\n",
      "Ann_id in getitem:  1248\n",
      "Test inds:  [(872, 56)]\n",
      "Ann_id in getitem:  20982\n",
      "Test inds:  [(1042, 3208)]\n",
      "Ann_id in getitem:  24664\n",
      "Test inds:  [(2970, 63)]\n",
      "Ann_id in getitem:  68330\n",
      "Test inds:  [(3318, 2988)]\n",
      "Ann_id in getitem:  76269\n",
      "Test inds:  [(772, 3192)]\n",
      "Ann_id in getitem:  18730\n",
      "Test inds:  [(278, 463)]\n",
      "Ann_id in getitem:  6588\n",
      "Test inds:  [(2946, 1341)]\n",
      "Ann_id in getitem:  67897\n",
      "Test inds:  [(1158, 2631)]\n",
      "Ann_id in getitem:  26952\n",
      "Test inds:  [(2506, 1868)]\n",
      "Ann_id in getitem:  57054\n",
      "Test inds:  [(2784, 3060)]\n",
      "Ann_id in getitem:  64236\n",
      "Test inds:  [(511, 1658)]\n",
      "Ann_id in getitem:  12217\n",
      "Test inds:  [(3576, 2845)]\n",
      "Ann_id in getitem:  82428\n",
      "Test inds:  [(3049, 1315)]\n",
      "Ann_id in getitem:  70292\n",
      "Test inds:  [(1603, 1166)]\n",
      "Ann_id in getitem:  37765\n",
      "Test inds:  [(1995, 2155)]\n",
      "Ann_id in getitem:  45494\n",
      "Test inds:  [(587, 1634)]\n",
      "Ann_id in getitem:  14275\n",
      "Test inds:  [(3179, 2365)]\n",
      "Ann_id in getitem:  73242\n",
      "Test inds:  [(1456, 3632)]\n",
      "Ann_id in getitem:  34471\n",
      "Test inds:  [(2505, 1975)]\n",
      "Ann_id in getitem:  57045\n",
      "Test inds:  [(2476, 1025)]\n",
      "Ann_id in getitem:  56395\n",
      "Test inds:  [(764, 146)]\n",
      "Ann_id in getitem:  18520\n",
      "Test inds:  [(1286, 3559)]\n",
      "Ann_id in getitem:  30110\n",
      "Test inds:  [(313, 3635)]\n",
      "Ann_id in getitem:  7637\n",
      "Test inds:  [(861, 3262)]\n",
      "Ann_id in getitem:  20850\n",
      "Test inds:  [(1525, 1910)]\n",
      "Ann_id in getitem:  36111\n",
      "Test inds:  [(2714, 3430)]\n",
      "Ann_id in getitem:  62433\n",
      "Test inds:  [(431, 2157)]\n",
      "Ann_id in getitem:  10614\n",
      "Test inds:  [(333, 1616)]\n",
      "Ann_id in getitem:  8113\n",
      "Test inds:  [(2125, 3149)]\n",
      "Ann_id in getitem:  48198\n",
      "Test inds:  [(2321, 278)]\n",
      "Ann_id in getitem:  52231\n",
      "Test inds:  [(2405, 260)]\n",
      "Ann_id in getitem:  54377\n",
      "Test inds:  [(3073, 1672)]\n",
      "Ann_id in getitem:  70816\n",
      "Test inds:  [(1881, 1747)]\n",
      "Ann_id in getitem:  43283\n",
      "Test inds:  [(3455, 3185)]\n",
      "Ann_id in getitem:  79727\n",
      "Test inds:  [(1585, 2738)]\n",
      "Ann_id in getitem:  37435\n",
      "Test inds:  [(2439, 2518)]\n",
      "Ann_id in getitem:  55312\n",
      "Test inds:  [(1406, 1913)]\n",
      "Ann_id in getitem:  33299\n",
      "Test inds:  [(258, 234)]\n",
      "Ann_id in getitem:  6190\n",
      "Test inds:  [(3016, 2130)]\n",
      "Ann_id in getitem:  69506\n",
      "Test inds:  [(354, 2427)]\n",
      "Ann_id in getitem:  8522\n",
      "Test inds:  [(1510, 3236)]\n",
      "Ann_id in getitem:  35827\n",
      "Test inds:  [(1881, 2769)]\n",
      "Ann_id in getitem:  43283\n",
      "Test inds:  [(3458, 1188)]\n",
      "Ann_id in getitem:  79796\n",
      "Test inds:  [(989, 2466)]\n",
      "Ann_id in getitem:  23534\n",
      "Test inds:  [(1457, 1294)]\n",
      "Ann_id in getitem:  34516\n",
      "Test inds:  [(1476, 839)]\n",
      "Ann_id in getitem:  34992\n",
      "Test inds:  [(1117, 3176)]\n",
      "Ann_id in getitem:  25906\n",
      "Test inds:  [(1881, 896)]\n",
      "Ann_id in getitem:  43283\n",
      "Test inds:  [(1603, 1619)]\n",
      "Ann_id in getitem:  37765\n",
      "Test inds:  [(3248, 215)]\n",
      "Ann_id in getitem:  74627\n",
      "Test inds:  [(237, 645)]\n",
      "Ann_id in getitem:  5786\n",
      "Test inds:  [(2455, 929)]\n",
      "Ann_id in getitem:  55771\n",
      "Test inds:  [(1633, 2771)]\n",
      "Ann_id in getitem:  38308\n",
      "Test inds:  [(1344, 1270)]\n",
      "Ann_id in getitem:  31651\n",
      "Test inds:  [(2742, 847)]\n",
      "Ann_id in getitem:  63099\n",
      "Test inds:  [(121, 2921)]\n",
      "Ann_id in getitem:  2884\n",
      "Test inds:  [(1226, 2977)]\n",
      "Ann_id in getitem:  28635\n",
      "Test inds:  [(1211, 216)]\n",
      "Ann_id in getitem:  28234\n",
      "Test inds:  [(1108, 3535)]\n",
      "Ann_id in getitem:  25733\n",
      "Test inds:  [(748, 2741)]\n",
      "Ann_id in getitem:  18037\n",
      "Test inds:  [(3105, 3558)]\n",
      "Ann_id in getitem:  71652\n",
      "Test inds:  [(1992, 314)]\n",
      "Ann_id in getitem:  45385\n",
      "Test inds:  [(1192, 93)]\n",
      "Ann_id in getitem:  27755\n",
      "Test inds:  [(364, 1796)]\n",
      "Ann_id in getitem:  8833\n",
      "Test inds:  [(1800, 937)]\n",
      "Ann_id in getitem:  41577\n",
      "Test inds:  [(1406, 581)]\n",
      "Ann_id in getitem:  33299\n",
      "Test inds:  [(2788, 3385)]\n",
      "Ann_id in getitem:  64370\n",
      "Test inds:  [(3046, 1320)]\n",
      "Ann_id in getitem:  70248\n",
      "Test inds:  [(936, 1197)]\n",
      "Ann_id in getitem:  22329\n",
      "Test inds:  [(3372, 48)]\n",
      "Ann_id in getitem:  77585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1165, 261)]\n",
      "Ann_id in getitem:  27148\n",
      "Test inds:  [(3000, 2285)]\n",
      "Ann_id in getitem:  69126\n",
      "Test inds:  [(1970, 2314)]\n",
      "Ann_id in getitem:  44957\n",
      "Test inds:  [(2024, 2327)]\n",
      "Ann_id in getitem:  45988\n",
      "Test inds:  [(3624, 2382)]\n",
      "Ann_id in getitem:  83639\n",
      "Test inds:  [(3537, 2828)]\n",
      "Ann_id in getitem:  81573\n",
      "Test inds:  [(1735, 959)]\n",
      "Ann_id in getitem:  40385\n",
      "Test inds:  [(3081, 2295)]\n",
      "Ann_id in getitem:  71066\n",
      "Test inds:  [(2296, 2513)]\n",
      "Ann_id in getitem:  51800\n",
      "Test inds:  [(3686, 2421)]\n",
      "Ann_id in getitem:  85001\n",
      "Test inds:  [(3577, 1329)]\n",
      "Ann_id in getitem:  82448\n",
      "Test inds:  [(2728, 1746)]\n",
      "Ann_id in getitem:  62756\n",
      "Test inds:  [(674, 3163)]\n",
      "Ann_id in getitem:  16395\n",
      "Test inds:  [(1537, 3356)]\n",
      "Ann_id in getitem:  36395\n",
      "Test inds:  [(1289, 638)]\n",
      "Ann_id in getitem:  30246\n",
      "Test inds:  [(692, 105)]\n",
      "Ann_id in getitem:  16853\n",
      "Test inds:  [(2950, 2557)]\n",
      "Ann_id in getitem:  67958\n",
      "Test inds:  [(27, 461)]\n",
      "Ann_id in getitem:  565\n",
      "Test inds:  [(893, 2825)]\n",
      "Ann_id in getitem:  21407\n",
      "Test inds:  [(349, 1021)]\n",
      "Ann_id in getitem:  8469\n",
      "Test inds:  [(300, 455)]\n",
      "Ann_id in getitem:  7049\n",
      "Test inds:  [(2779, 1547)]\n",
      "Ann_id in getitem:  64006\n",
      "Test inds:  [(3217, 1204)]\n",
      "Ann_id in getitem:  73990\n",
      "Test inds:  [(3177, 2416)]\n",
      "Ann_id in getitem:  73139\n",
      "Test inds:  [(2008, 3550)]\n",
      "Ann_id in getitem:  45701\n",
      "Test inds:  [(1135, 3177)]\n",
      "Ann_id in getitem:  26486\n",
      "Test inds:  [(739, 3455)]\n",
      "Ann_id in getitem:  17903\n",
      "Test inds:  [(1258, 141)]\n",
      "Ann_id in getitem:  29493\n",
      "Test inds:  [(1336, 1093)]\n",
      "Ann_id in getitem:  31415\n",
      "Test inds:  [(855, 3045)]\n",
      "Ann_id in getitem:  20777\n",
      "Test inds:  [(550, 3219)]\n",
      "Ann_id in getitem:  13214\n",
      "Test inds:  [(2482, 1692)]\n",
      "Ann_id in getitem:  56501\n",
      "Test inds:  [(2987, 711)]\n",
      "Ann_id in getitem:  68923\n",
      "Test inds:  [(1297, 3462)]\n",
      "Ann_id in getitem:  30406\n",
      "Test inds:  [(3539, 899)]\n",
      "Ann_id in getitem:  81612\n",
      "Test inds:  [(2456, 2400)]\n",
      "Ann_id in getitem:  55772\n",
      "Test inds:  [(1227, 183)]\n",
      "Ann_id in getitem:  28643\n",
      "Test inds:  [(2726, 3044)]\n",
      "Ann_id in getitem:  62715\n",
      "Test inds:  [(2867, 447)]\n",
      "Ann_id in getitem:  65912\n",
      "Test inds:  [(2335, 2146)]\n",
      "Ann_id in getitem:  52659\n",
      "Test inds:  [(1554, 262)]\n",
      "Ann_id in getitem:  36772\n",
      "Test inds:  [(1159, 278)]\n",
      "Ann_id in getitem:  27045\n",
      "Test inds:  [(2866, 2888)]\n",
      "Ann_id in getitem:  65887\n",
      "Test inds:  [(283, 1880)]\n",
      "Ann_id in getitem:  6647\n",
      "Test inds:  [(1223, 2554)]\n",
      "Ann_id in getitem:  28576\n",
      "Test inds:  [(1817, 294)]\n",
      "Ann_id in getitem:  41838\n",
      "Test inds:  [(3543, 2677)]\n",
      "Ann_id in getitem:  81757\n",
      "Test inds:  [(3447, 378)]\n",
      "Ann_id in getitem:  79500\n",
      "Test inds:  [(2104, 2675)]\n",
      "Ann_id in getitem:  47658\n",
      "Test inds:  [(2626, 3226)]\n",
      "Ann_id in getitem:  60111\n",
      "Test inds:  [(2748, 1845)]\n",
      "Ann_id in getitem:  63273\n",
      "Test inds:  [(1662, 651)]\n",
      "Ann_id in getitem:  38868\n",
      "Test inds:  [(228, 1355)]\n",
      "Ann_id in getitem:  5537\n",
      "Test inds:  [(2446, 3623)]\n",
      "Ann_id in getitem:  55596\n",
      "Test inds:  [(3680, 1284)]\n",
      "Ann_id in getitem:  84857\n",
      "Test inds:  [(147, 2392)]\n",
      "Ann_id in getitem:  3586\n",
      "Test inds:  [(238, 1615)]\n",
      "Ann_id in getitem:  5795\n",
      "Test inds:  [(3312, 2799)]\n",
      "Ann_id in getitem:  76011\n",
      "Test inds:  [(3434, 1536)]\n",
      "Ann_id in getitem:  79157\n",
      "Test inds:  [(111, 256)]\n",
      "Ann_id in getitem:  2607\n",
      "Test inds:  [(932, 668)]\n",
      "Ann_id in getitem:  22217\n",
      "Test inds:  [(2705, 303)]\n",
      "Ann_id in getitem:  62152\n",
      "Test inds:  [(1228, 1050)]\n",
      "Ann_id in getitem:  28712\n",
      "Test inds:  [(3117, 833)]\n",
      "Ann_id in getitem:  71924\n",
      "Test inds:  [(2083, 938)]\n",
      "Ann_id in getitem:  47290\n",
      "Test inds:  [(2528, 753)]\n",
      "Ann_id in getitem:  57432\n",
      "Test inds:  [(2908, 3303)]\n",
      "Ann_id in getitem:  67070\n",
      "Test inds:  [(3278, 2224)]\n",
      "Ann_id in getitem:  75082\n",
      "Test inds:  [(2370, 305)]\n",
      "Ann_id in getitem:  53599\n",
      "Test inds:  [(600, 819)]\n",
      "Ann_id in getitem:  14472\n",
      "Test inds:  [(1253, 821)]\n",
      "Ann_id in getitem:  29400\n",
      "Test inds:  [(2997, 3445)]\n",
      "Ann_id in getitem:  69090\n",
      "Test inds:  [(1354, 905)]\n",
      "Ann_id in getitem:  31963\n",
      "Test inds:  [(2378, 2180)]\n",
      "Ann_id in getitem:  53757\n",
      "Test inds:  [(3343, 609)]\n",
      "Ann_id in getitem:  76833\n",
      "Test inds:  [(889, 2361)]\n",
      "Ann_id in getitem:  21210\n",
      "Test inds:  [(2910, 1802)]\n",
      "Ann_id in getitem:  67092\n",
      "Test inds:  [(3598, 156)]\n",
      "Ann_id in getitem:  82989\n",
      "Test inds:  [(1099, 349)]\n",
      "Ann_id in getitem:  25516\n",
      "Test inds:  [(1919, 410)]\n",
      "Ann_id in getitem:  43938\n",
      "Test inds:  [(1656, 1794)]\n",
      "Ann_id in getitem:  38775\n",
      "Test inds:  [(2609, 3122)]\n",
      "Ann_id in getitem:  59819\n",
      "Test inds:  [(2796, 1503)]\n",
      "Ann_id in getitem:  64515\n",
      "Test inds:  [(2915, 3337)]\n",
      "Ann_id in getitem:  67122\n",
      "Test inds:  [(125, 2875)]\n",
      "Ann_id in getitem:  2961\n",
      "Test inds:  [(180, 1048)]\n",
      "Ann_id in getitem:  4604\n",
      "Test inds:  [(1759, 3371)]\n",
      "Ann_id in getitem:  40714\n",
      "Test inds:  [(2605, 543)]\n",
      "Ann_id in getitem:  59675\n",
      "Test inds:  [(374, 3549)]\n",
      "Ann_id in getitem:  9123\n",
      "Test inds:  [(2831, 2111)]\n",
      "Ann_id in getitem:  65285\n",
      "Test inds:  [(1053, 254)]\n",
      "Ann_id in getitem:  24847\n",
      "Test inds:  [(2412, 3575)]\n",
      "Ann_id in getitem:  54580\n",
      "Test inds:  [(1209, 867)]\n",
      "Ann_id in getitem:  28210\n",
      "Test inds:  [(2735, 1493)]\n",
      "Ann_id in getitem:  62956\n",
      "Test inds:  [(123, 2000)]\n",
      "Ann_id in getitem:  2946\n",
      "Test inds:  [(970, 1672)]\n",
      "Ann_id in getitem:  22898\n",
      "Test inds:  [(2551, 437)]\n",
      "Ann_id in getitem:  57956\n",
      "Test inds:  [(3421, 2079)]\n",
      "Ann_id in getitem:  78822\n",
      "Test inds:  [(472, 3140)]\n",
      "Ann_id in getitem:  11329\n",
      "Test inds:  [(600, 2640)]\n",
      "Ann_id in getitem:  14472\n",
      "Test inds:  [(1916, 1844)]\n",
      "Ann_id in getitem:  43869\n",
      "Test inds:  [(3100, 1539)]\n",
      "Ann_id in getitem:  71435\n",
      "Test inds:  [(1090, 983)]\n",
      "Ann_id in getitem:  25414\n",
      "Test inds:  [(185, 2642)]\n",
      "Ann_id in getitem:  4731\n",
      "Test inds:  [(2975, 2530)]\n",
      "Ann_id in getitem:  68531\n",
      "Test inds:  [(3683, 2001)]\n",
      "Ann_id in getitem:  84929\n",
      "Test inds:  [(1782, 1057)]\n",
      "Ann_id in getitem:  41096\n",
      "Test inds:  [(3345, 3547)]\n",
      "Ann_id in getitem:  76870\n",
      "Test inds:  [(2599, 2463)]\n",
      "Ann_id in getitem:  59537\n",
      "Test inds:  [(3072, 2953)]\n",
      "Ann_id in getitem:  70804\n",
      "Test inds:  [(1175, 2927)]\n",
      "Ann_id in getitem:  27341\n",
      "Test inds:  [(2484, 3386)]\n",
      "Ann_id in getitem:  56556\n",
      "Test inds:  [(1020, 2543)]\n",
      "Ann_id in getitem:  24122\n",
      "Test inds:  [(1022, 2554)]\n",
      "Ann_id in getitem:  24168\n",
      "Test inds:  [(1778, 3513)]\n",
      "Ann_id in getitem:  41030\n",
      "Test inds:  [(3411, 3094)]\n",
      "Ann_id in getitem:  78612\n",
      "Test inds:  [(3338, 1790)]\n",
      "Ann_id in getitem:  76661\n",
      "Test inds:  [(2258, 263)]\n",
      "Ann_id in getitem:  50978\n",
      "Test inds:  [(1086, 3545)]\n",
      "Ann_id in getitem:  25327\n",
      "Test inds:  [(41, 1711)]\n",
      "Ann_id in getitem:  891\n",
      "Test inds:  [(3545, 706)]\n",
      "Ann_id in getitem:  81789\n",
      "Test inds:  [(3557, 501)]\n",
      "Ann_id in getitem:  82025\n",
      "Test inds:  [(220, 804)]\n",
      "Ann_id in getitem:  5431\n",
      "Test inds:  [(3223, 1650)]\n",
      "Ann_id in getitem:  74111\n",
      "Test inds:  [(408, 706)]\n",
      "Ann_id in getitem:  10002\n",
      "Test inds:  [(394, 976)]\n",
      "Ann_id in getitem:  9709\n",
      "Test inds:  [(1506, 3525)]\n",
      "Ann_id in getitem:  35757\n",
      "Test inds:  [(797, 2165)]\n",
      "Ann_id in getitem:  19281\n",
      "Test inds:  [(969, 1948)]\n",
      "Ann_id in getitem:  22892\n",
      "Test inds:  [(2892, 3026)]\n",
      "Ann_id in getitem:  66507\n",
      "Test inds:  [(3365, 2623)]\n",
      "Ann_id in getitem:  77274\n",
      "Test inds:  [(1439, 691)]\n",
      "Ann_id in getitem:  34145\n",
      "Test inds:  [(2065, 1979)]\n",
      "Ann_id in getitem:  46987\n",
      "Test inds:  [(34, 3341)]\n",
      "Ann_id in getitem:  754\n",
      "Test inds:  [(97, 1351)]\n",
      "Ann_id in getitem:  2155\n",
      "Test inds:  [(3670, 2542)]\n",
      "Ann_id in getitem:  84666\n",
      "Test inds:  [(2439, 3409)]\n",
      "Ann_id in getitem:  55312\n",
      "Test inds:  [(2761, 2325)]\n",
      "Ann_id in getitem:  63510\n",
      "Test inds:  [(1432, 3534)]\n",
      "Ann_id in getitem:  33929\n",
      "Test inds:  [(1981, 1662)]\n",
      "Ann_id in getitem:  45166\n",
      "Test inds:  [(1669, 3681)]\n",
      "Ann_id in getitem:  39043\n",
      "Test inds:  [(2058, 1947)]\n",
      "Ann_id in getitem:  46850\n",
      "Test inds:  [(1936, 270)]\n",
      "Ann_id in getitem:  44151\n",
      "Test inds:  [(3109, 1872)]\n",
      "Ann_id in getitem:  71745\n",
      "Test inds:  [(158, 1170)]\n",
      "Ann_id in getitem:  4036\n",
      "Test inds:  [(3179, 2961)]\n",
      "Ann_id in getitem:  73242\n",
      "Test inds:  [(2569, 2506)]\n",
      "Ann_id in getitem:  58460\n",
      "Test inds:  [(1969, 2861)]\n",
      "Ann_id in getitem:  44953\n",
      "Test inds:  [(2457, 1756)]\n",
      "Ann_id in getitem:  55877\n",
      "Test inds:  [(1497, 529)]\n",
      "Ann_id in getitem:  35575\n",
      "Test inds:  [(1807, 1411)]\n",
      "Ann_id in getitem:  41695\n",
      "Test inds:  [(2645, 505)]\n",
      "Ann_id in getitem:  60584\n",
      "Test inds:  [(3427, 3247)]\n",
      "Ann_id in getitem:  79018\n",
      "Test inds:  [(34, 1796)]\n",
      "Ann_id in getitem:  754\n",
      "Test inds:  [(1529, 153)]\n",
      "Ann_id in getitem:  36191\n",
      "Test inds:  [(1632, 2142)]\n",
      "Ann_id in getitem:  38294\n",
      "Test inds:  [(1224, 2763)]\n",
      "Ann_id in getitem:  28580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(427, 3292)]\n",
      "Ann_id in getitem:  10533\n",
      "Test inds:  [(1221, 1854)]\n",
      "Ann_id in getitem:  28520\n",
      "Test inds:  [(2231, 2775)]\n",
      "Ann_id in getitem:  50219\n",
      "Test inds:  [(225, 883)]\n",
      "Ann_id in getitem:  5509\n",
      "Test inds:  [(1001, 905)]\n",
      "Ann_id in getitem:  23725\n",
      "Test inds:  [(1720, 764)]\n",
      "Ann_id in getitem:  40136\n",
      "Test inds:  [(1243, 585)]\n",
      "Ann_id in getitem:  29124\n",
      "Test inds:  [(2578, 2018)]\n",
      "Ann_id in getitem:  58767\n",
      "Test inds:  [(354, 291)]\n",
      "Ann_id in getitem:  8522\n",
      "Test inds:  [(2226, 2486)]\n",
      "Ann_id in getitem:  50147\n",
      "Test inds:  [(538, 1778)]\n",
      "Ann_id in getitem:  12762\n",
      "Test inds:  [(63, 138)]\n",
      "Ann_id in getitem:  1392\n",
      "Test inds:  [(2911, 2110)]\n",
      "Ann_id in getitem:  67095\n",
      "Test inds:  [(1075, 3686)]\n",
      "Ann_id in getitem:  25173\n",
      "Test inds:  [(2724, 3154)]\n",
      "Ann_id in getitem:  62609\n",
      "Test inds:  [(635, 2927)]\n",
      "Ann_id in getitem:  15441\n",
      "Test inds:  [(1272, 3253)]\n",
      "Ann_id in getitem:  29682\n",
      "Test inds:  [(2163, 1132)]\n",
      "Ann_id in getitem:  48782\n",
      "Test inds:  [(870, 3516)]\n",
      "Ann_id in getitem:  20955\n",
      "Test inds:  [(1397, 1215)]\n",
      "Ann_id in getitem:  33147\n",
      "Test inds:  [(1218, 1885)]\n",
      "Ann_id in getitem:  28460\n",
      "Test inds:  [(2199, 1615)]\n",
      "Ann_id in getitem:  49505\n",
      "Test inds:  [(889, 3484)]\n",
      "Ann_id in getitem:  21210\n",
      "Test inds:  [(1817, 762)]\n",
      "Ann_id in getitem:  41838\n",
      "Test inds:  [(1631, 1265)]\n",
      "Ann_id in getitem:  38283\n",
      "Test inds:  [(1813, 1231)]\n",
      "Ann_id in getitem:  41747\n",
      "Test inds:  [(3063, 3499)]\n",
      "Ann_id in getitem:  70625\n",
      "Test inds:  [(2835, 376)]\n",
      "Ann_id in getitem:  65352\n",
      "Test inds:  [(42, 1763)]\n",
      "Ann_id in getitem:  931\n",
      "Test inds:  [(2567, 2080)]\n",
      "Ann_id in getitem:  58345\n",
      "Test inds:  [(227, 264)]\n",
      "Ann_id in getitem:  5535\n",
      "Test inds:  [(2784, 1288)]\n",
      "Ann_id in getitem:  64236\n",
      "Test inds:  [(3314, 303)]\n",
      "Ann_id in getitem:  76128\n",
      "Test inds:  [(2164, 2734)]\n",
      "Ann_id in getitem:  48818\n",
      "Test inds:  [(943, 1602)]\n",
      "Ann_id in getitem:  22384\n",
      "Test inds:  [(2279, 405)]\n",
      "Ann_id in getitem:  51542\n",
      "Test inds:  [(3276, 1766)]\n",
      "Ann_id in getitem:  75053\n",
      "Test inds:  [(2662, 1968)]\n",
      "Ann_id in getitem:  61060\n",
      "Test inds:  [(2972, 3559)]\n",
      "Ann_id in getitem:  68369\n",
      "Test inds:  [(2427, 3555)]\n",
      "Ann_id in getitem:  54854\n",
      "Test inds:  [(2631, 475)]\n",
      "Ann_id in getitem:  60240\n",
      "Test inds:  [(2300, 1002)]\n",
      "Ann_id in getitem:  51858\n",
      "Test inds:  [(1156, 1391)]\n",
      "Ann_id in getitem:  26881\n",
      "Test inds:  [(2419, 338)]\n",
      "Ann_id in getitem:  54678\n",
      "Test inds:  [(425, 2358)]\n",
      "Ann_id in getitem:  10359\n",
      "Test inds:  [(698, 988)]\n",
      "Ann_id in getitem:  16993\n",
      "Test inds:  [(3311, 756)]\n",
      "Ann_id in getitem:  76008\n",
      "Test inds:  [(3657, 1150)]\n",
      "Ann_id in getitem:  84471\n",
      "Test inds:  [(1227, 445)]\n",
      "Ann_id in getitem:  28643\n",
      "Test inds:  [(1618, 2718)]\n",
      "Ann_id in getitem:  37965\n",
      "Test inds:  [(2379, 3081)]\n",
      "Ann_id in getitem:  53768\n",
      "Test inds:  [(3445, 0)]\n",
      "Ann_id in getitem:  79380\n",
      "Test inds:  [(1153, 3514)]\n",
      "Ann_id in getitem:  26813\n",
      "Test inds:  [(788, 1508)]\n",
      "Ann_id in getitem:  19055\n",
      "Test inds:  [(3359, 3180)]\n",
      "Ann_id in getitem:  77075\n",
      "Test inds:  [(2398, 890)]\n",
      "Ann_id in getitem:  54288\n",
      "Test inds:  [(3553, 2274)]\n",
      "Ann_id in getitem:  81939\n",
      "Test inds:  [(1910, 1340)]\n",
      "Ann_id in getitem:  43755\n",
      "Test inds:  [(1494, 946)]\n",
      "Ann_id in getitem:  35494\n",
      "Test inds:  [(3639, 141)]\n",
      "Ann_id in getitem:  83970\n",
      "Test inds:  [(2774, 1666)]\n",
      "Ann_id in getitem:  63885\n",
      "Test inds:  [(2984, 1108)]\n",
      "Ann_id in getitem:  68819\n",
      "Test inds:  [(67, 1811)]\n",
      "Ann_id in getitem:  1484\n",
      "Test inds:  [(1187, 2204)]\n",
      "Ann_id in getitem:  27683\n",
      "Test inds:  [(2056, 1466)]\n",
      "Ann_id in getitem:  46804\n",
      "Test inds:  [(2205, 3685)]\n",
      "Ann_id in getitem:  49639\n",
      "Test inds:  [(3413, 2501)]\n",
      "Ann_id in getitem:  78657\n",
      "Test inds:  [(2063, 448)]\n",
      "Ann_id in getitem:  46965\n",
      "Test inds:  [(1967, 1591)]\n",
      "Ann_id in getitem:  44915\n",
      "Test inds:  [(2069, 387)]\n",
      "Ann_id in getitem:  47011\n",
      "Test inds:  [(3050, 1681)]\n",
      "Ann_id in getitem:  70297\n",
      "Test inds:  [(3173, 496)]\n",
      "Ann_id in getitem:  73071\n",
      "Test inds:  [(1189, 3071)]\n",
      "Ann_id in getitem:  27717\n",
      "Test inds:  [(3513, 3675)]\n",
      "Ann_id in getitem:  81072\n",
      "Test inds:  [(141, 106)]\n",
      "Ann_id in getitem:  3446\n",
      "Test inds:  [(1546, 2085)]\n",
      "Ann_id in getitem:  36563\n",
      "Test inds:  [(750, 2125)]\n",
      "Ann_id in getitem:  18166\n",
      "Test inds:  [(1500, 1246)]\n",
      "Ann_id in getitem:  35693\n",
      "Test inds:  [(2764, 3037)]\n",
      "Ann_id in getitem:  63573\n",
      "Test inds:  [(1709, 1303)]\n",
      "Ann_id in getitem:  39985\n",
      "Test inds:  [(3522, 1254)]\n",
      "Ann_id in getitem:  81276\n",
      "Test inds:  [(953, 1677)]\n",
      "Ann_id in getitem:  22578\n",
      "Test inds:  [(3014, 1310)]\n",
      "Ann_id in getitem:  69501\n",
      "Test inds:  [(1278, 428)]\n",
      "Ann_id in getitem:  29873\n",
      "Test inds:  [(1709, 650)]\n",
      "Ann_id in getitem:  39985\n",
      "Test inds:  [(3693, 1224)]\n",
      "Ann_id in getitem:  85394\n",
      "Test inds:  [(2584, 2598)]\n",
      "Ann_id in getitem:  59079\n",
      "Test inds:  [(2240, 3327)]\n",
      "Ann_id in getitem:  50606\n",
      "Test inds:  [(3627, 1159)]\n",
      "Ann_id in getitem:  83655\n",
      "Test inds:  [(2489, 240)]\n",
      "Ann_id in getitem:  56656\n",
      "Test inds:  [(47, 1362)]\n",
      "Ann_id in getitem:  961\n",
      "Test inds:  [(2919, 2650)]\n",
      "Ann_id in getitem:  67228\n",
      "Test inds:  [(3547, 1708)]\n",
      "Ann_id in getitem:  81836\n",
      "Test inds:  [(1147, 2766)]\n",
      "Ann_id in getitem:  26755\n",
      "Test inds:  [(813, 835)]\n",
      "Ann_id in getitem:  19578\n",
      "Test inds:  [(630, 1976)]\n",
      "Ann_id in getitem:  15378\n",
      "Test inds:  [(2404, 1475)]\n",
      "Ann_id in getitem:  54376\n",
      "Test inds:  [(3204, 924)]\n",
      "Ann_id in getitem:  73712\n",
      "Test inds:  [(414, 436)]\n",
      "Ann_id in getitem:  10100\n",
      "Test inds:  [(1997, 894)]\n",
      "Ann_id in getitem:  45522\n",
      "Test inds:  [(2790, 1258)]\n",
      "Ann_id in getitem:  64408\n",
      "Test inds:  [(2804, 1023)]\n",
      "Ann_id in getitem:  64707\n",
      "Test inds:  [(934, 674)]\n",
      "Ann_id in getitem:  22252\n",
      "Test inds:  [(1060, 2720)]\n",
      "Ann_id in getitem:  24978\n",
      "Test inds:  [(361, 1087)]\n",
      "Ann_id in getitem:  8733\n",
      "Test inds:  [(38, 1764)]\n",
      "Ann_id in getitem:  834\n",
      "Test inds:  [(154, 1815)]\n",
      "Ann_id in getitem:  3765\n",
      "Test inds:  [(1932, 2864)]\n",
      "Ann_id in getitem:  44097\n",
      "Test inds:  [(1572, 629)]\n",
      "Ann_id in getitem:  37199\n",
      "Test inds:  [(302, 357)]\n",
      "Ann_id in getitem:  7096\n",
      "Test inds:  [(1966, 3456)]\n",
      "Ann_id in getitem:  44888\n",
      "Test inds:  [(3386, 2351)]\n",
      "Ann_id in getitem:  77842\n",
      "Test inds:  [(3071, 3082)]\n",
      "Ann_id in getitem:  70797\n",
      "Test inds:  [(1723, 3345)]\n",
      "Ann_id in getitem:  40192\n",
      "Test inds:  [(1873, 2748)]\n",
      "Ann_id in getitem:  43075\n",
      "Test inds:  [(256, 2371)]\n",
      "Ann_id in getitem:  6151\n",
      "Test inds:  [(2692, 3273)]\n",
      "Ann_id in getitem:  61905\n",
      "Test inds:  [(3517, 2216)]\n",
      "Ann_id in getitem:  81156\n",
      "Test inds:  [(1053, 1625)]\n",
      "Ann_id in getitem:  24847\n",
      "Test inds:  [(3155, 1522)]\n",
      "Ann_id in getitem:  72749\n",
      "Test inds:  [(2894, 640)]\n",
      "Ann_id in getitem:  66573\n",
      "Test inds:  [(1330, 926)]\n",
      "Ann_id in getitem:  31230\n",
      "Test inds:  [(3032, 1839)]\n",
      "Ann_id in getitem:  69907\n",
      "Test inds:  [(3332, 3225)]\n",
      "Ann_id in getitem:  76597\n",
      "Test inds:  [(1049, 805)]\n",
      "Ann_id in getitem:  24779\n",
      "Test inds:  [(1096, 1459)]\n",
      "Ann_id in getitem:  25507\n",
      "Test inds:  [(1445, 877)]\n",
      "Ann_id in getitem:  34246\n",
      "Test inds:  [(1706, 635)]\n",
      "Ann_id in getitem:  39906\n",
      "Test inds:  [(1163, 2185)]\n",
      "Ann_id in getitem:  27101\n",
      "Test inds:  [(1442, 3039)]\n",
      "Ann_id in getitem:  34192\n",
      "Test inds:  [(1405, 1864)]\n",
      "Ann_id in getitem:  33265\n",
      "Test inds:  [(3317, 2228)]\n",
      "Ann_id in getitem:  76267\n",
      "Test inds:  [(357, 2806)]\n",
      "Ann_id in getitem:  8612\n",
      "Test inds:  [(2724, 2899)]\n",
      "Ann_id in getitem:  62609\n",
      "Test inds:  [(3558, 2631)]\n",
      "Ann_id in getitem:  82054\n",
      "Test inds:  [(3299, 1683)]\n",
      "Ann_id in getitem:  75613\n",
      "Test inds:  [(2918, 1778)]\n",
      "Ann_id in getitem:  67160\n",
      "Test inds:  [(10, 1221)]\n",
      "Ann_id in getitem:  182\n",
      "Test inds:  [(2825, 3326)]\n",
      "Ann_id in getitem:  65100\n",
      "Test inds:  [(3509, 1860)]\n",
      "Ann_id in getitem:  81006\n",
      "Test inds:  [(957, 847)]\n",
      "Ann_id in getitem:  22622\n",
      "Test inds:  [(3475, 2652)]\n",
      "Ann_id in getitem:  80163\n",
      "Test inds:  [(324, 886)]\n",
      "Ann_id in getitem:  7990\n",
      "Test inds:  [(1633, 1136)]\n",
      "Ann_id in getitem:  38308\n",
      "Test inds:  [(1198, 3047)]\n",
      "Ann_id in getitem:  27869\n",
      "Test inds:  [(587, 3272)]\n",
      "Ann_id in getitem:  14275\n",
      "Test inds:  [(2711, 2912)]\n",
      "Ann_id in getitem:  62385\n",
      "Test inds:  [(2702, 2377)]\n",
      "Ann_id in getitem:  62121\n",
      "Test inds:  [(249, 2420)]\n",
      "Ann_id in getitem:  6024\n",
      "Test inds:  [(1863, 776)]\n",
      "Ann_id in getitem:  42934\n",
      "Test inds:  [(2610, 1056)]\n",
      "Ann_id in getitem:  59833\n",
      "Test inds:  [(1725, 291)]\n",
      "Ann_id in getitem:  40232\n",
      "Test inds:  [(2985, 3427)]\n",
      "Ann_id in getitem:  68876\n",
      "Test inds:  [(1367, 886)]\n",
      "Ann_id in getitem:  32240\n",
      "Test inds:  [(1393, 838)]\n",
      "Ann_id in getitem:  33092\n",
      "Test inds:  [(1851, 2829)]\n",
      "Ann_id in getitem:  42630\n",
      "Test inds:  [(153, 1056)]\n",
      "Ann_id in getitem:  3762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1271, 2666)]\n",
      "Ann_id in getitem:  29649\n",
      "Test inds:  [(1419, 1081)]\n",
      "Ann_id in getitem:  33592\n",
      "Test inds:  [(2862, 1242)]\n",
      "Ann_id in getitem:  65761\n",
      "Test inds:  [(620, 1129)]\n",
      "Ann_id in getitem:  15185\n",
      "Test inds:  [(3038, 990)]\n",
      "Ann_id in getitem:  70026\n",
      "Test inds:  [(575, 1050)]\n",
      "Ann_id in getitem:  14008\n",
      "Test inds:  [(1180, 2774)]\n",
      "Ann_id in getitem:  27482\n",
      "Test inds:  [(1825, 2678)]\n",
      "Ann_id in getitem:  41999\n",
      "Test inds:  [(3133, 2959)]\n",
      "Ann_id in getitem:  72259\n",
      "Test inds:  [(1703, 2753)]\n",
      "Ann_id in getitem:  39868\n",
      "Test inds:  [(3115, 1906)]\n",
      "Ann_id in getitem:  71900\n",
      "Test inds:  [(1442, 3107)]\n",
      "Ann_id in getitem:  34192\n",
      "Test inds:  [(2103, 1982)]\n",
      "Ann_id in getitem:  47624\n",
      "Test inds:  [(314, 367)]\n",
      "Ann_id in getitem:  7670\n",
      "Test inds:  [(1501, 521)]\n",
      "Ann_id in getitem:  35694\n",
      "Test inds:  [(1063, 1640)]\n",
      "Ann_id in getitem:  24998\n",
      "Test inds:  [(483, 3664)]\n",
      "Ann_id in getitem:  11615\n",
      "Test inds:  [(1577, 407)]\n",
      "Ann_id in getitem:  37319\n",
      "Test inds:  [(3145, 3188)]\n",
      "Ann_id in getitem:  72549\n",
      "Test inds:  [(3320, 2902)]\n",
      "Ann_id in getitem:  76287\n",
      "Test inds:  [(1082, 3385)]\n",
      "Ann_id in getitem:  25259\n",
      "Test inds:  [(2567, 1779)]\n",
      "Ann_id in getitem:  58345\n",
      "Test inds:  [(1764, 1493)]\n",
      "Ann_id in getitem:  40804\n",
      "Test inds:  [(618, 3618)]\n",
      "Ann_id in getitem:  15170\n",
      "Test inds:  [(1278, 2124)]\n",
      "Ann_id in getitem:  29873\n",
      "Test inds:  [(1738, 2887)]\n",
      "Ann_id in getitem:  40426\n",
      "Test inds:  [(3613, 1352)]\n",
      "Ann_id in getitem:  83431\n",
      "Test inds:  [(1398, 2826)]\n",
      "Ann_id in getitem:  33179\n",
      "Test inds:  [(366, 1042)]\n",
      "Ann_id in getitem:  8866\n",
      "Test inds:  [(1552, 3347)]\n",
      "Ann_id in getitem:  36700\n",
      "Test inds:  [(750, 1923)]\n",
      "Ann_id in getitem:  18166\n",
      "Test inds:  [(2910, 1955)]\n",
      "Ann_id in getitem:  67092\n",
      "Test inds:  [(2696, 3011)]\n",
      "Ann_id in getitem:  61994\n",
      "Test inds:  [(2411, 2137)]\n",
      "Ann_id in getitem:  54530\n",
      "Test inds:  [(2121, 238)]\n",
      "Ann_id in getitem:  48055\n",
      "Test inds:  [(530, 2661)]\n",
      "Ann_id in getitem:  12597\n",
      "Test inds:  [(1669, 3004)]\n",
      "Ann_id in getitem:  39043\n",
      "Test inds:  [(2780, 268)]\n",
      "Ann_id in getitem:  64039\n",
      "Test inds:  [(2653, 3049)]\n",
      "Ann_id in getitem:  60801\n",
      "Test inds:  [(2802, 2965)]\n",
      "Ann_id in getitem:  64667\n",
      "Test inds:  [(1932, 1371)]\n",
      "Ann_id in getitem:  44097\n",
      "Test inds:  [(1587, 1157)]\n",
      "Ann_id in getitem:  37446\n",
      "Test inds:  [(2161, 3292)]\n",
      "Ann_id in getitem:  48766\n",
      "Test inds:  [(2821, 1479)]\n",
      "Ann_id in getitem:  65005\n",
      "Test inds:  [(3467, 2487)]\n",
      "Ann_id in getitem:  80049\n",
      "Test inds:  [(2173, 1422)]\n",
      "Ann_id in getitem:  49003\n",
      "Test inds:  [(3407, 2963)]\n",
      "Ann_id in getitem:  78412\n",
      "Test inds:  [(209, 326)]\n",
      "Ann_id in getitem:  5227\n",
      "Test inds:  [(864, 2765)]\n",
      "Ann_id in getitem:  20900\n",
      "Test inds:  [(846, 1182)]\n",
      "Ann_id in getitem:  20513\n",
      "Test inds:  [(422, 2616)]\n",
      "Ann_id in getitem:  10243\n",
      "Test inds:  [(2184, 2205)]\n",
      "Ann_id in getitem:  49226\n",
      "Test inds:  [(233, 786)]\n",
      "Ann_id in getitem:  5653\n",
      "Test inds:  [(1178, 1466)]\n",
      "Ann_id in getitem:  27434\n",
      "Test inds:  [(2004, 3373)]\n",
      "Ann_id in getitem:  45648\n",
      "Test inds:  [(2394, 2411)]\n",
      "Ann_id in getitem:  54152\n",
      "Test inds:  [(3453, 706)]\n",
      "Ann_id in getitem:  79645\n",
      "Test inds:  [(2343, 2611)]\n",
      "Ann_id in getitem:  52887\n",
      "Test inds:  [(772, 248)]\n",
      "Ann_id in getitem:  18730\n",
      "Test inds:  [(657, 1132)]\n",
      "Ann_id in getitem:  16073\n",
      "Test inds:  [(816, 394)]\n",
      "Ann_id in getitem:  19681\n",
      "Test inds:  [(946, 2462)]\n",
      "Ann_id in getitem:  22481\n",
      "Test inds:  [(3111, 1815)]\n",
      "Ann_id in getitem:  71777\n",
      "Test inds:  [(715, 1526)]\n",
      "Ann_id in getitem:  17336\n",
      "Test inds:  [(753, 347)]\n",
      "Ann_id in getitem:  18251\n",
      "Test inds:  [(3616, 1656)]\n",
      "Ann_id in getitem:  83499\n",
      "Test inds:  [(1477, 3195)]\n",
      "Ann_id in getitem:  35022\n",
      "Test inds:  [(2585, 1573)]\n",
      "Ann_id in getitem:  59193\n",
      "Test inds:  [(1611, 78)]\n",
      "Ann_id in getitem:  37821\n",
      "Test inds:  [(3580, 1232)]\n",
      "Ann_id in getitem:  82483\n",
      "Test inds:  [(2513, 986)]\n",
      "Ann_id in getitem:  57170\n",
      "Test inds:  [(2500, 2313)]\n",
      "Ann_id in getitem:  56952\n",
      "Test inds:  [(2428, 1819)]\n",
      "Ann_id in getitem:  54859\n",
      "Test inds:  [(3093, 3492)]\n",
      "Ann_id in getitem:  71283\n",
      "Test inds:  [(1621, 470)]\n",
      "Ann_id in getitem:  38030\n",
      "Test inds:  [(3282, 2415)]\n",
      "Ann_id in getitem:  75150\n",
      "Test inds:  [(1615, 45)]\n",
      "Ann_id in getitem:  37868\n",
      "Test inds:  [(3569, 3585)]\n",
      "Ann_id in getitem:  82291\n",
      "Test inds:  [(405, 1089)]\n",
      "Ann_id in getitem:  9977\n",
      "Test inds:  [(2210, 3692)]\n",
      "Ann_id in getitem:  49723\n",
      "Test inds:  [(2503, 153)]\n",
      "Ann_id in getitem:  57011\n",
      "Test inds:  [(2898, 3641)]\n",
      "Ann_id in getitem:  66643\n",
      "Test inds:  [(2540, 1720)]\n",
      "Ann_id in getitem:  57675\n",
      "Test inds:  [(2941, 793)]\n",
      "Ann_id in getitem:  67736\n",
      "Test inds:  [(1999, 1067)]\n",
      "Ann_id in getitem:  45551\n",
      "Test inds:  [(1636, 3508)]\n",
      "Ann_id in getitem:  38356\n",
      "Test inds:  [(3157, 3627)]\n",
      "Ann_id in getitem:  72771\n",
      "Test inds:  [(1462, 1595)]\n",
      "Ann_id in getitem:  34613\n",
      "Test inds:  [(1019, 3168)]\n",
      "Ann_id in getitem:  24117\n",
      "Test inds:  [(3389, 2130)]\n",
      "Ann_id in getitem:  77891\n",
      "Test inds:  [(266, 1103)]\n",
      "Ann_id in getitem:  6319\n",
      "Test inds:  [(2242, 649)]\n",
      "Ann_id in getitem:  50649\n",
      "Test inds:  [(2961, 1373)]\n",
      "Ann_id in getitem:  68145\n",
      "Test inds:  [(2007, 3254)]\n",
      "Ann_id in getitem:  45683\n",
      "Test inds:  [(2367, 1406)]\n",
      "Ann_id in getitem:  53536\n",
      "Test inds:  [(2760, 1527)]\n",
      "Ann_id in getitem:  63458\n",
      "Test inds:  [(1049, 1504)]\n",
      "Ann_id in getitem:  24779\n",
      "Test inds:  [(2806, 3472)]\n",
      "Ann_id in getitem:  64713\n",
      "Test inds:  [(1372, 2767)]\n",
      "Ann_id in getitem:  32365\n",
      "Test inds:  [(2497, 2590)]\n",
      "Ann_id in getitem:  56807\n",
      "Test inds:  [(2387, 901)]\n",
      "Ann_id in getitem:  54051\n",
      "Test inds:  [(205, 3461)]\n",
      "Ann_id in getitem:  5098\n",
      "Test inds:  [(814, 2849)]\n",
      "Ann_id in getitem:  19590\n",
      "Test inds:  [(2701, 2474)]\n",
      "Ann_id in getitem:  62087\n",
      "Test inds:  [(461, 157)]\n",
      "Ann_id in getitem:  11138\n",
      "Test inds:  [(3005, 1569)]\n",
      "Ann_id in getitem:  69267\n",
      "Test inds:  [(2411, 3627)]\n",
      "Ann_id in getitem:  54530\n",
      "Test inds:  [(57, 359)]\n",
      "Ann_id in getitem:  1221\n",
      "Test inds:  [(2294, 1517)]\n",
      "Ann_id in getitem:  51776\n",
      "Test inds:  [(3123, 2825)]\n",
      "Ann_id in getitem:  72016\n",
      "Test inds:  [(3449, 990)]\n",
      "Ann_id in getitem:  79547\n",
      "Test inds:  [(1450, 183)]\n",
      "Ann_id in getitem:  34343\n",
      "Test inds:  [(2907, 307)]\n",
      "Ann_id in getitem:  67051\n",
      "Test inds:  [(791, 3430)]\n",
      "Ann_id in getitem:  19137\n",
      "Test inds:  [(877, 1318)]\n",
      "Ann_id in getitem:  21051\n",
      "Test inds:  [(1812, 885)]\n",
      "Ann_id in getitem:  41739\n",
      "Test inds:  [(1360, 2223)]\n",
      "Ann_id in getitem:  32054\n",
      "Test inds:  [(78, 2630)]\n",
      "Ann_id in getitem:  1766\n",
      "Test inds:  [(2752, 2673)]\n",
      "Ann_id in getitem:  63337\n",
      "Test inds:  [(2878, 3104)]\n",
      "Ann_id in getitem:  66180\n",
      "Test inds:  [(867, 1091)]\n",
      "Ann_id in getitem:  20919\n",
      "Test inds:  [(2719, 751)]\n",
      "Ann_id in getitem:  62513\n",
      "Test inds:  [(3494, 792)]\n",
      "Ann_id in getitem:  80510\n",
      "Test inds:  [(3043, 776)]\n",
      "Ann_id in getitem:  70139\n",
      "Test inds:  [(1985, 2797)]\n",
      "Ann_id in getitem:  45252\n",
      "Test inds:  [(556, 2863)]\n",
      "Ann_id in getitem:  13488\n",
      "Test inds:  [(544, 2115)]\n",
      "Ann_id in getitem:  12972\n",
      "Test inds:  [(3581, 2477)]\n",
      "Ann_id in getitem:  82517\n",
      "Test inds:  [(2006, 3051)]\n",
      "Ann_id in getitem:  45673\n",
      "Test inds:  [(234, 2890)]\n",
      "Ann_id in getitem:  5689\n",
      "Test inds:  [(3235, 2445)]\n",
      "Ann_id in getitem:  74370\n",
      "Test inds:  [(1449, 459)]\n",
      "Ann_id in getitem:  34312\n",
      "Test inds:  [(461, 1823)]\n",
      "Ann_id in getitem:  11138\n",
      "Test inds:  [(471, 2314)]\n",
      "Ann_id in getitem:  11319\n",
      "Test inds:  [(1449, 1044)]\n",
      "Ann_id in getitem:  34312\n",
      "Test inds:  [(947, 3213)]\n",
      "Ann_id in getitem:  22509\n",
      "Test inds:  [(902, 1407)]\n",
      "Ann_id in getitem:  21581\n",
      "Test inds:  [(3555, 3128)]\n",
      "Ann_id in getitem:  81954\n",
      "Test inds:  [(191, 1818)]\n",
      "Ann_id in getitem:  4844\n",
      "Test inds:  [(1456, 3594)]\n",
      "Ann_id in getitem:  34471\n",
      "Test inds:  [(426, 971)]\n",
      "Ann_id in getitem:  10527\n",
      "Test inds:  [(415, 241)]\n",
      "Ann_id in getitem:  10107\n",
      "Test inds:  [(1855, 576)]\n",
      "Ann_id in getitem:  42683\n",
      "Test inds:  [(1709, 1271)]\n",
      "Ann_id in getitem:  39985\n",
      "Test inds:  [(3351, 2710)]\n",
      "Ann_id in getitem:  76900\n",
      "Test inds:  [(74, 663)]\n",
      "Ann_id in getitem:  1638\n",
      "Test inds:  [(2032, 3230)]\n",
      "Ann_id in getitem:  46257\n",
      "Test inds:  [(1163, 123)]\n",
      "Ann_id in getitem:  27101\n",
      "Test inds:  [(3593, 244)]\n",
      "Ann_id in getitem:  82851\n",
      "Test inds:  [(852, 259)]\n",
      "Ann_id in getitem:  20715\n",
      "Test inds:  [(730, 2700)]\n",
      "Ann_id in getitem:  17696\n",
      "Test inds:  [(1713, 1555)]\n",
      "Ann_id in getitem:  40051\n",
      "Test inds:  [(1068, 1511)]\n",
      "Ann_id in getitem:  25069\n",
      "Test inds:  [(3292, 1721)]\n",
      "Ann_id in getitem:  75467\n",
      "Test inds:  [(1561, 878)]\n",
      "Ann_id in getitem:  36877\n",
      "Test inds:  [(318, 237)]\n",
      "Ann_id in getitem:  7748\n",
      "Test inds:  [(913, 1039)]\n",
      "Ann_id in getitem:  21753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(911, 1373)]\n",
      "Ann_id in getitem:  21670\n",
      "Test inds:  [(1840, 2047)]\n",
      "Ann_id in getitem:  42233\n",
      "Test inds:  [(1105, 1246)]\n",
      "Ann_id in getitem:  25692\n",
      "Test inds:  [(863, 1537)]\n",
      "Ann_id in getitem:  20885\n",
      "Test inds:  [(108, 1233)]\n",
      "Ann_id in getitem:  2473\n",
      "Test inds:  [(1390, 856)]\n",
      "Ann_id in getitem:  33008\n",
      "Test inds:  [(981, 654)]\n",
      "Ann_id in getitem:  23182\n",
      "Test inds:  [(372, 3277)]\n",
      "Ann_id in getitem:  9113\n",
      "Test inds:  [(251, 2864)]\n",
      "Ann_id in getitem:  6079\n",
      "Test inds:  [(1137, 3192)]\n",
      "Ann_id in getitem:  26499\n",
      "Test inds:  [(2063, 873)]\n",
      "Ann_id in getitem:  46965\n",
      "Test inds:  [(576, 1567)]\n",
      "Ann_id in getitem:  14041\n",
      "Test inds:  [(714, 543)]\n",
      "Ann_id in getitem:  17325\n",
      "Test inds:  [(3602, 2344)]\n",
      "Ann_id in getitem:  83079\n",
      "Test inds:  [(3051, 3144)]\n",
      "Ann_id in getitem:  70473\n",
      "Test inds:  [(3674, 1959)]\n",
      "Ann_id in getitem:  84726\n",
      "Test inds:  [(1623, 3469)]\n",
      "Ann_id in getitem:  38044\n",
      "Test inds:  [(888, 3400)]\n",
      "Ann_id in getitem:  21197\n",
      "Test inds:  [(639, 2646)]\n",
      "Ann_id in getitem:  15485\n",
      "Test inds:  [(249, 43)]\n",
      "Ann_id in getitem:  6024\n",
      "Test inds:  [(2609, 632)]\n",
      "Ann_id in getitem:  59819\n",
      "Test inds:  [(1462, 1730)]\n",
      "Ann_id in getitem:  34613\n",
      "Test inds:  [(1835, 2454)]\n",
      "Ann_id in getitem:  42156\n",
      "Test inds:  [(2432, 13)]\n",
      "Ann_id in getitem:  55017\n",
      "Test inds:  [(306, 2802)]\n",
      "Ann_id in getitem:  7423\n",
      "Test inds:  [(1549, 2127)]\n",
      "Ann_id in getitem:  36600\n",
      "Test inds:  [(2768, 1727)]\n",
      "Ann_id in getitem:  63693\n",
      "Test inds:  [(1288, 52)]\n",
      "Ann_id in getitem:  30177\n",
      "Test inds:  [(1205, 2619)]\n",
      "Ann_id in getitem:  28095\n",
      "Test inds:  [(945, 2429)]\n",
      "Ann_id in getitem:  22472\n",
      "Test inds:  [(12, 3040)]\n",
      "Ann_id in getitem:  221\n",
      "Test inds:  [(3207, 2690)]\n",
      "Ann_id in getitem:  73741\n",
      "Test inds:  [(2734, 2458)]\n",
      "Ann_id in getitem:  62919\n",
      "Test inds:  [(243, 1511)]\n",
      "Ann_id in getitem:  5884\n",
      "Test inds:  [(837, 1601)]\n",
      "Ann_id in getitem:  20078\n",
      "Test inds:  [(1193, 1415)]\n",
      "Ann_id in getitem:  27827\n",
      "Test inds:  [(2489, 177)]\n",
      "Ann_id in getitem:  56656\n",
      "Test inds:  [(3541, 2359)]\n",
      "Ann_id in getitem:  81674\n",
      "Test inds:  [(1635, 1292)]\n",
      "Ann_id in getitem:  38338\n",
      "Test inds:  [(708, 1226)]\n",
      "Ann_id in getitem:  17161\n",
      "Test inds:  [(1381, 1422)]\n",
      "Ann_id in getitem:  32820\n",
      "Test inds:  [(2218, 2690)]\n",
      "Ann_id in getitem:  49948\n",
      "Test inds:  [(2186, 1970)]\n",
      "Ann_id in getitem:  49244\n",
      "Test inds:  [(1420, 1418)]\n",
      "Ann_id in getitem:  33692\n",
      "Test inds:  [(1728, 1997)]\n",
      "Ann_id in getitem:  40298\n",
      "Test inds:  [(403, 2254)]\n",
      "Ann_id in getitem:  9914\n",
      "Test inds:  [(2735, 1639)]\n",
      "Ann_id in getitem:  62956\n",
      "Test inds:  [(1181, 3535)]\n",
      "Ann_id in getitem:  27484\n",
      "Test inds:  [(2615, 1160)]\n",
      "Ann_id in getitem:  59876\n",
      "Test inds:  [(2257, 91)]\n",
      "Ann_id in getitem:  50976\n",
      "Test inds:  [(3493, 225)]\n",
      "Ann_id in getitem:  80490\n",
      "Test inds:  [(263, 2411)]\n",
      "Ann_id in getitem:  6282\n",
      "Test inds:  [(2673, 1425)]\n",
      "Ann_id in getitem:  61322\n",
      "Test inds:  [(2769, 591)]\n",
      "Ann_id in getitem:  63753\n",
      "Test inds:  [(796, 3186)]\n",
      "Ann_id in getitem:  19268\n",
      "Test inds:  [(2759, 74)]\n",
      "Ann_id in getitem:  63453\n",
      "Test inds:  [(401, 313)]\n",
      "Ann_id in getitem:  9891\n",
      "Test inds:  [(3221, 115)]\n",
      "Ann_id in getitem:  74057\n",
      "Test inds:  [(844, 3279)]\n",
      "Ann_id in getitem:  20431\n",
      "Test inds:  [(540, 1972)]\n",
      "Ann_id in getitem:  12851\n",
      "Test inds:  [(3428, 3204)]\n",
      "Ann_id in getitem:  79023\n",
      "Test inds:  [(3258, 409)]\n",
      "Ann_id in getitem:  74793\n",
      "Test inds:  [(3097, 2239)]\n",
      "Ann_id in getitem:  71331\n",
      "Test inds:  [(1044, 3359)]\n",
      "Ann_id in getitem:  24681\n",
      "Test inds:  [(405, 2144)]\n",
      "Ann_id in getitem:  9977\n",
      "Test inds:  [(204, 399)]\n",
      "Ann_id in getitem:  5037\n",
      "Test inds:  [(2536, 3155)]\n",
      "Ann_id in getitem:  57566\n",
      "Test inds:  [(436, 2711)]\n",
      "Ann_id in getitem:  10673\n",
      "Test inds:  [(2082, 2241)]\n",
      "Ann_id in getitem:  47256\n",
      "Test inds:  [(3390, 1083)]\n",
      "Ann_id in getitem:  77905\n",
      "Test inds:  [(811, 2451)]\n",
      "Ann_id in getitem:  19545\n",
      "Test inds:  [(301, 133)]\n",
      "Ann_id in getitem:  7090\n",
      "Test inds:  [(934, 1182)]\n",
      "Ann_id in getitem:  22252\n",
      "Test inds:  [(1678, 3441)]\n",
      "Ann_id in getitem:  39292\n",
      "Test inds:  [(3431, 289)]\n",
      "Ann_id in getitem:  79085\n",
      "Test inds:  [(1670, 3506)]\n",
      "Ann_id in getitem:  39069\n",
      "Test inds:  [(512, 3688)]\n",
      "Ann_id in getitem:  12242\n",
      "Test inds:  [(2437, 3187)]\n",
      "Ann_id in getitem:  55138\n",
      "Test inds:  [(168, 302)]\n",
      "Ann_id in getitem:  4220\n",
      "Test inds:  [(3225, 734)]\n",
      "Ann_id in getitem:  74130\n",
      "Test inds:  [(3296, 1100)]\n",
      "Ann_id in getitem:  75584\n",
      "Test inds:  [(863, 1980)]\n",
      "Ann_id in getitem:  20885\n",
      "Test inds:  [(706, 64)]\n",
      "Ann_id in getitem:  17137\n",
      "Test inds:  [(3407, 327)]\n",
      "Ann_id in getitem:  78412\n",
      "Test inds:  [(1896, 1487)]\n",
      "Ann_id in getitem:  43516\n",
      "Test inds:  [(224, 2151)]\n",
      "Ann_id in getitem:  5459\n",
      "Test inds:  [(2783, 3548)]\n",
      "Ann_id in getitem:  64233\n",
      "Test inds:  [(2702, 2444)]\n",
      "Ann_id in getitem:  62121\n",
      "Test inds:  [(1859, 1772)]\n",
      "Ann_id in getitem:  42786\n",
      "Test inds:  [(563, 1016)]\n",
      "Ann_id in getitem:  13557\n",
      "Test inds:  [(215, 1629)]\n",
      "Ann_id in getitem:  5377\n",
      "Test inds:  [(3083, 3308)]\n",
      "Ann_id in getitem:  71106\n",
      "Test inds:  [(1803, 247)]\n",
      "Ann_id in getitem:  41600\n",
      "Test inds:  [(3034, 1512)]\n",
      "Ann_id in getitem:  69918\n",
      "Test inds:  [(2434, 3606)]\n",
      "Ann_id in getitem:  55038\n",
      "Test inds:  [(972, 2577)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(16, 3178)]\n",
      "Ann_id in getitem:  401\n",
      "Test inds:  [(248, 747)]\n",
      "Ann_id in getitem:  6023\n",
      "Test inds:  [(1999, 462)]\n",
      "Ann_id in getitem:  45551\n",
      "Test inds:  [(3397, 689)]\n",
      "Ann_id in getitem:  78099\n",
      "Test inds:  [(233, 48)]\n",
      "Ann_id in getitem:  5653\n",
      "Test inds:  [(1052, 3435)]\n",
      "Ann_id in getitem:  24804\n",
      "Test inds:  [(420, 2383)]\n",
      "Ann_id in getitem:  10208\n",
      "Test inds:  [(1716, 3381)]\n",
      "Ann_id in getitem:  40072\n",
      "Test inds:  [(1481, 1024)]\n",
      "Ann_id in getitem:  35089\n",
      "Test inds:  [(345, 222)]\n",
      "Ann_id in getitem:  8357\n",
      "Test inds:  [(2276, 925)]\n",
      "Ann_id in getitem:  51482\n",
      "Test inds:  [(497, 1352)]\n",
      "Ann_id in getitem:  11906\n",
      "Test inds:  [(2701, 2442)]\n",
      "Ann_id in getitem:  62087\n",
      "Test inds:  [(661, 3082)]\n",
      "Ann_id in getitem:  16136\n",
      "Test inds:  [(2569, 555)]\n",
      "Ann_id in getitem:  58460\n",
      "Test inds:  [(1663, 2484)]\n",
      "Ann_id in getitem:  38907\n",
      "Test inds:  [(3288, 2430)]\n",
      "Ann_id in getitem:  75295\n",
      "Test inds:  [(3147, 3586)]\n",
      "Ann_id in getitem:  72558\n",
      "Test inds:  [(2148, 3262)]\n",
      "Ann_id in getitem:  48554\n",
      "Test inds:  [(1271, 1653)]\n",
      "Ann_id in getitem:  29649\n",
      "Test inds:  [(2662, 3298)]\n",
      "Ann_id in getitem:  61060\n",
      "Test inds:  [(31, 3695)]\n",
      "Ann_id in getitem:  699\n",
      "Test inds:  [(3170, 2904)]\n",
      "Ann_id in getitem:  73044\n",
      "Test inds:  [(3213, 489)]\n",
      "Ann_id in getitem:  73857\n",
      "Test inds:  [(1046, 1294)]\n",
      "Ann_id in getitem:  24695\n",
      "Test inds:  [(2698, 1760)]\n",
      "Ann_id in getitem:  62010\n",
      "Test inds:  [(3430, 415)]\n",
      "Ann_id in getitem:  79058\n",
      "Test inds:  [(1015, 1068)]\n",
      "Ann_id in getitem:  24087\n",
      "Test inds:  [(1901, 1568)]\n",
      "Ann_id in getitem:  43609\n",
      "Test inds:  [(3235, 1762)]\n",
      "Ann_id in getitem:  74370\n",
      "Test inds:  [(2740, 1906)]\n",
      "Ann_id in getitem:  63078\n",
      "Test inds:  [(101, 3385)]\n",
      "Ann_id in getitem:  2219\n",
      "Test inds:  [(2976, 2323)]\n",
      "Ann_id in getitem:  68563\n",
      "Test inds:  [(1487, 2299)]\n",
      "Ann_id in getitem:  35350\n",
      "Test inds:  [(769, 2410)]\n",
      "Ann_id in getitem:  18639\n",
      "Test inds:  [(698, 1749)]\n",
      "Ann_id in getitem:  16993\n",
      "Test inds:  [(3668, 116)]\n",
      "Ann_id in getitem:  84657\n",
      "Test inds:  [(2954, 877)]\n",
      "Ann_id in getitem:  68034\n",
      "Test inds:  [(3302, 1424)]\n",
      "Ann_id in getitem:  75751\n",
      "Test inds:  [(1411, 3288)]\n",
      "Ann_id in getitem:  33420\n",
      "Test inds:  [(831, 3203)]\n",
      "Ann_id in getitem:  19973\n",
      "Test inds:  [(1903, 109)]\n",
      "Ann_id in getitem:  43648\n",
      "Test inds:  [(2802, 191)]\n",
      "Ann_id in getitem:  64667\n",
      "Test inds:  [(3551, 1427)]\n",
      "Ann_id in getitem:  81924\n",
      "Test inds:  [(3031, 589)]\n",
      "Ann_id in getitem:  69893\n",
      "Test inds:  [(2154, 2742)]\n",
      "Ann_id in getitem:  48648\n",
      "Test inds:  [(2992, 1976)]\n",
      "Ann_id in getitem:  68965\n",
      "Test inds:  [(540, 510)]\n",
      "Ann_id in getitem:  12851\n",
      "Test inds:  [(332, 3296)]\n",
      "Ann_id in getitem:  8109\n",
      "Test inds:  [(2063, 1973)]\n",
      "Ann_id in getitem:  46965\n",
      "Test inds:  [(1891, 2093)]\n",
      "Ann_id in getitem:  43422\n",
      "Test inds:  [(746, 95)]\n",
      "Ann_id in getitem:  18027\n",
      "Test inds:  [(1330, 2606)]\n",
      "Ann_id in getitem:  31230\n",
      "Test inds:  [(1260, 2260)]\n",
      "Ann_id in getitem:  29512\n",
      "Test inds:  [(3566, 2841)]\n",
      "Ann_id in getitem:  82249\n",
      "Test inds:  [(65, 618)]\n",
      "Ann_id in getitem:  1436\n",
      "Test inds:  [(541, 1975)]\n",
      "Ann_id in getitem:  12938\n",
      "Test inds:  [(3583, 1070)]\n",
      "Ann_id in getitem:  82545\n",
      "Test inds:  [(2291, 1315)]\n",
      "Ann_id in getitem:  51732\n",
      "Test inds:  [(2896, 1839)]\n",
      "Ann_id in getitem:  66617\n",
      "Test inds:  [(2239, 1419)]\n",
      "Ann_id in getitem:  50558\n",
      "Test inds:  [(2035, 822)]\n",
      "Ann_id in getitem:  46314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2709, 2729)]\n",
      "Ann_id in getitem:  62332\n",
      "Test inds:  [(2143, 701)]\n",
      "Ann_id in getitem:  48494\n",
      "Test inds:  [(1726, 301)]\n",
      "Ann_id in getitem:  40251\n",
      "Test inds:  [(2474, 3315)]\n",
      "Ann_id in getitem:  56288\n",
      "Test inds:  [(1027, 1569)]\n",
      "Ann_id in getitem:  24239\n",
      "Test inds:  [(322, 745)]\n",
      "Ann_id in getitem:  7941\n",
      "Test inds:  [(6, 120)]\n",
      "Ann_id in getitem:  109\n",
      "Test inds:  [(512, 1869)]\n",
      "Ann_id in getitem:  12242\n",
      "Test inds:  [(3051, 1048)]\n",
      "Ann_id in getitem:  70473\n",
      "Test inds:  [(988, 831)]\n",
      "Ann_id in getitem:  23520\n",
      "Test inds:  [(3192, 683)]\n",
      "Ann_id in getitem:  73441\n",
      "Test inds:  [(1582, 3217)]\n",
      "Ann_id in getitem:  37382\n",
      "Test inds:  [(928, 3256)]\n",
      "Ann_id in getitem:  22166\n",
      "Test inds:  [(577, 1600)]\n",
      "Ann_id in getitem:  14044\n",
      "Test inds:  [(3402, 24)]\n",
      "Ann_id in getitem:  78308\n",
      "Test inds:  [(2095, 736)]\n",
      "Ann_id in getitem:  47451\n",
      "Test inds:  [(2809, 2701)]\n",
      "Ann_id in getitem:  64750\n",
      "Test inds:  [(2095, 1147)]\n",
      "Ann_id in getitem:  47451\n",
      "Test inds:  [(2099, 2158)]\n",
      "Ann_id in getitem:  47510\n",
      "Test inds:  [(276, 3500)]\n",
      "Ann_id in getitem:  6566\n",
      "Test inds:  [(1694, 1293)]\n",
      "Ann_id in getitem:  39751\n",
      "Test inds:  [(2712, 756)]\n",
      "Ann_id in getitem:  62387\n",
      "Test inds:  [(2791, 2643)]\n",
      "Ann_id in getitem:  64441\n",
      "Test inds:  [(2287, 1586)]\n",
      "Ann_id in getitem:  51686\n",
      "Test inds:  [(610, 3086)]\n",
      "Ann_id in getitem:  14943\n",
      "Test inds:  [(3185, 2224)]\n",
      "Ann_id in getitem:  73339\n",
      "Test inds:  [(2375, 259)]\n",
      "Ann_id in getitem:  53687\n",
      "Test inds:  [(1693, 1025)]\n",
      "Ann_id in getitem:  39688\n",
      "Test inds:  [(88, 1778)]\n",
      "Ann_id in getitem:  2045\n",
      "Test inds:  [(2233, 4)]\n",
      "Ann_id in getitem:  50232\n",
      "Test inds:  [(3371, 86)]\n",
      "Ann_id in getitem:  77508\n",
      "Test inds:  [(872, 2217)]\n",
      "Ann_id in getitem:  20982\n",
      "Test inds:  [(1616, 930)]\n",
      "Ann_id in getitem:  37888\n",
      "Test inds:  [(2951, 2120)]\n",
      "Ann_id in getitem:  68015\n",
      "Test inds:  [(2830, 1438)]\n",
      "Ann_id in getitem:  65278\n",
      "Test inds:  [(1401, 626)]\n",
      "Ann_id in getitem:  33196\n",
      "Test inds:  [(1386, 3654)]\n",
      "Ann_id in getitem:  32931\n",
      "Test inds:  [(59, 862)]\n",
      "Ann_id in getitem:  1248\n",
      "Test inds:  [(3471, 3183)]\n",
      "Ann_id in getitem:  80089\n",
      "Test inds:  [(2902, 109)]\n",
      "Ann_id in getitem:  66899\n",
      "Test inds:  [(2415, 2498)]\n",
      "Ann_id in getitem:  54602\n",
      "Test inds:  [(118, 1255)]\n",
      "Ann_id in getitem:  2761\n",
      "Test inds:  [(546, 1653)]\n",
      "Ann_id in getitem:  13014\n",
      "Test inds:  [(378, 1176)]\n",
      "Ann_id in getitem:  9195\n",
      "Test inds:  [(1238, 2232)]\n",
      "Ann_id in getitem:  28960\n",
      "Test inds:  [(1521, 3392)]\n",
      "Ann_id in getitem:  36039\n",
      "Test inds:  [(1208, 2082)]\n",
      "Ann_id in getitem:  28145\n",
      "Test inds:  [(2294, 1596)]\n",
      "Ann_id in getitem:  51776\n",
      "Test inds:  [(563, 1008)]\n",
      "Ann_id in getitem:  13557\n",
      "Test inds:  [(3390, 2621)]\n",
      "Ann_id in getitem:  77905\n",
      "Test inds:  [(2690, 2037)]\n",
      "Ann_id in getitem:  61838\n",
      "Test inds:  [(2477, 1749)]\n",
      "Ann_id in getitem:  56414\n",
      "Test inds:  [(3182, 833)]\n",
      "Ann_id in getitem:  73298\n",
      "Test inds:  [(1736, 550)]\n",
      "Ann_id in getitem:  40402\n",
      "Test inds:  [(2252, 1049)]\n",
      "Ann_id in getitem:  50887\n",
      "Test inds:  [(1327, 1126)]\n",
      "Ann_id in getitem:  31025\n",
      "Test inds:  [(2858, 2553)]\n",
      "Ann_id in getitem:  65708\n",
      "Test inds:  [(1895, 326)]\n",
      "Ann_id in getitem:  43488\n",
      "Test inds:  [(3327, 1279)]\n",
      "Ann_id in getitem:  76414\n",
      "Test inds:  [(2191, 2392)]\n",
      "Ann_id in getitem:  49356\n",
      "Test inds:  [(2613, 1614)]\n",
      "Ann_id in getitem:  59857\n",
      "Test inds:  [(937, 1663)]\n",
      "Ann_id in getitem:  22335\n",
      "Test inds:  [(3534, 2578)]\n",
      "Ann_id in getitem:  81549\n",
      "Test inds:  [(3317, 1225)]\n",
      "Ann_id in getitem:  76267\n",
      "Test inds:  [(2704, 1017)]\n",
      "Ann_id in getitem:  62146\n",
      "Test inds:  [(893, 2450)]\n",
      "Ann_id in getitem:  21407\n",
      "Test inds:  [(51, 851)]\n",
      "Ann_id in getitem:  1037\n",
      "Test inds:  [(1258, 2957)]\n",
      "Ann_id in getitem:  29493\n",
      "Test inds:  [(506, 803)]\n",
      "Ann_id in getitem:  12111\n",
      "Test inds:  [(866, 2062)]\n",
      "Ann_id in getitem:  20914\n",
      "Test inds:  [(1625, 3682)]\n",
      "Ann_id in getitem:  38084\n",
      "Test inds:  [(2368, 1294)]\n",
      "Ann_id in getitem:  53573\n",
      "Test inds:  [(588, 735)]\n",
      "Ann_id in getitem:  14305\n",
      "Test inds:  [(336, 1785)]\n",
      "Ann_id in getitem:  8206\n",
      "Test inds:  [(1267, 2722)]\n",
      "Ann_id in getitem:  29605\n",
      "Test inds:  [(2931, 1329)]\n",
      "Ann_id in getitem:  67503\n",
      "Test inds:  [(843, 2999)]\n",
      "Ann_id in getitem:  20421\n",
      "Test inds:  [(1833, 867)]\n",
      "Ann_id in getitem:  42135\n",
      "Test inds:  [(2838, 1579)]\n",
      "Ann_id in getitem:  65391\n",
      "Test inds:  [(3540, 129)]\n",
      "Ann_id in getitem:  81667\n",
      "Test inds:  [(1930, 3575)]\n",
      "Ann_id in getitem:  44078\n",
      "Test inds:  [(1526, 135)]\n",
      "Ann_id in getitem:  36114\n",
      "Test inds:  [(2983, 3108)]\n",
      "Ann_id in getitem:  68808\n",
      "Test inds:  [(1852, 3265)]\n",
      "Ann_id in getitem:  42644\n",
      "Test inds:  [(628, 876)]\n",
      "Ann_id in getitem:  15327\n",
      "Test inds:  [(1768, 643)]\n",
      "Ann_id in getitem:  40851\n",
      "Test inds:  [(525, 878)]\n",
      "Ann_id in getitem:  12501\n",
      "Test inds:  [(1382, 1974)]\n",
      "Ann_id in getitem:  32853\n",
      "Test inds:  [(480, 160)]\n",
      "Ann_id in getitem:  11542\n",
      "Test inds:  [(2568, 2258)]\n",
      "Ann_id in getitem:  58448\n",
      "Test inds:  [(2851, 3341)]\n",
      "Ann_id in getitem:  65613\n",
      "Test inds:  [(1189, 3298)]\n",
      "Ann_id in getitem:  27717\n",
      "Test inds:  [(1698, 3369)]\n",
      "Ann_id in getitem:  39801\n",
      "Test inds:  [(3098, 2347)]\n",
      "Ann_id in getitem:  71418\n",
      "Test inds:  [(2115, 1051)]\n",
      "Ann_id in getitem:  47933\n",
      "Test inds:  [(665, 1048)]\n",
      "Ann_id in getitem:  16182\n",
      "Test inds:  [(2318, 3220)]\n",
      "Ann_id in getitem:  52218\n",
      "Test inds:  [(209, 2974)]\n",
      "Ann_id in getitem:  5227\n",
      "Test inds:  [(1114, 24)]\n",
      "Ann_id in getitem:  25816\n",
      "Test inds:  [(3637, 2619)]\n",
      "Ann_id in getitem:  83957\n",
      "Test inds:  [(671, 2081)]\n",
      "Ann_id in getitem:  16340\n",
      "Test inds:  [(3080, 1936)]\n",
      "Ann_id in getitem:  71062\n",
      "Test inds:  [(176, 2516)]\n",
      "Ann_id in getitem:  4451\n",
      "Test inds:  [(3221, 297)]\n",
      "Ann_id in getitem:  74057\n",
      "Test inds:  [(2709, 407)]\n",
      "Ann_id in getitem:  62332\n",
      "Test inds:  [(653, 2108)]\n",
      "Ann_id in getitem:  15959\n",
      "Test inds:  [(1515, 636)]\n",
      "Ann_id in getitem:  35923\n",
      "Test inds:  [(1139, 611)]\n",
      "Ann_id in getitem:  26548\n",
      "Test inds:  [(684, 774)]\n",
      "Ann_id in getitem:  16638\n",
      "Test inds:  [(3544, 1442)]\n",
      "Ann_id in getitem:  81777\n",
      "Test inds:  [(3588, 2236)]\n",
      "Ann_id in getitem:  82754\n",
      "Test inds:  [(1869, 98)]\n",
      "Ann_id in getitem:  43048\n",
      "Test inds:  [(2300, 1092)]\n",
      "Ann_id in getitem:  51858\n",
      "Test inds:  [(3594, 1487)]\n",
      "Ann_id in getitem:  82897\n",
      "Test inds:  [(337, 445)]\n",
      "Ann_id in getitem:  8226\n",
      "Test inds:  [(2368, 3554)]\n",
      "Ann_id in getitem:  53573\n",
      "Test inds:  [(904, 1100)]\n",
      "Ann_id in getitem:  21602\n",
      "Test inds:  [(3558, 1261)]\n",
      "Ann_id in getitem:  82054\n",
      "Test inds:  [(2946, 2447)]\n",
      "Ann_id in getitem:  67897\n",
      "Test inds:  [(235, 2266)]\n",
      "Ann_id in getitem:  5749\n",
      "Test inds:  [(2068, 65)]\n",
      "Ann_id in getitem:  47000\n",
      "Test inds:  [(2188, 3036)]\n",
      "Ann_id in getitem:  49282\n",
      "Test inds:  [(1700, 3423)]\n",
      "Ann_id in getitem:  39849\n",
      "Test inds:  [(314, 1376)]\n",
      "Ann_id in getitem:  7670\n",
      "Test inds:  [(1977, 2602)]\n",
      "Ann_id in getitem:  45039\n",
      "Test inds:  [(429, 3182)]\n",
      "Ann_id in getitem:  10570\n",
      "Test inds:  [(1637, 3405)]\n",
      "Ann_id in getitem:  38364\n",
      "Test inds:  [(9, 1799)]\n",
      "Ann_id in getitem:  181\n",
      "Test inds:  [(2804, 2158)]\n",
      "Ann_id in getitem:  64707\n",
      "Test inds:  [(2349, 3464)]\n",
      "Ann_id in getitem:  53057\n",
      "Test inds:  [(298, 2372)]\n",
      "Ann_id in getitem:  7032\n",
      "Test inds:  [(1208, 53)]\n",
      "Ann_id in getitem:  28145\n",
      "Test inds:  [(3249, 269)]\n",
      "Ann_id in getitem:  74646\n",
      "Test inds:  [(3152, 925)]\n",
      "Ann_id in getitem:  72637\n",
      "Test inds:  [(1141, 1508)]\n",
      "Ann_id in getitem:  26670\n",
      "Test inds:  [(2179, 1348)]\n",
      "Ann_id in getitem:  49124\n",
      "Test inds:  [(1848, 3257)]\n",
      "Ann_id in getitem:  42557\n",
      "Test inds:  [(400, 2210)]\n",
      "Ann_id in getitem:  9862\n",
      "Test inds:  [(2532, 523)]\n",
      "Ann_id in getitem:  57478\n",
      "Test inds:  [(3411, 2904)]\n",
      "Ann_id in getitem:  78612\n",
      "Test inds:  [(729, 2296)]\n",
      "Ann_id in getitem:  17588\n",
      "Test inds:  [(3356, 3159)]\n",
      "Ann_id in getitem:  77006\n",
      "Test inds:  [(1921, 1339)]\n",
      "Ann_id in getitem:  43968\n",
      "Test inds:  [(1576, 1378)]\n",
      "Ann_id in getitem:  37316\n",
      "Test inds:  [(201, 3202)]\n",
      "Ann_id in getitem:  5010\n",
      "Test inds:  [(1654, 3137)]\n",
      "Ann_id in getitem:  38736\n",
      "Test inds:  [(875, 1025)]\n",
      "Ann_id in getitem:  21022\n",
      "Test inds:  [(1318, 2791)]\n",
      "Ann_id in getitem:  30830\n",
      "Test inds:  [(2391, 318)]\n",
      "Ann_id in getitem:  54119\n",
      "Test inds:  [(99, 1763)]\n",
      "Ann_id in getitem:  2167\n",
      "Test inds:  [(256, 3543)]\n",
      "Ann_id in getitem:  6151\n",
      "Test inds:  [(572, 773)]\n",
      "Ann_id in getitem:  13805\n",
      "Test inds:  [(2259, 2640)]\n",
      "Ann_id in getitem:  51079\n",
      "Test inds:  [(466, 1012)]\n",
      "Ann_id in getitem:  11235\n",
      "Test inds:  [(440, 2842)]\n",
      "Ann_id in getitem:  10730\n",
      "Test inds:  [(2055, 3361)]\n",
      "Ann_id in getitem:  46796\n",
      "Test inds:  [(2313, 3470)]\n",
      "Ann_id in getitem:  52133\n",
      "Test inds:  [(1626, 1447)]\n",
      "Ann_id in getitem:  38109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(480, 2687)]\n",
      "Ann_id in getitem:  11542\n",
      "Test inds:  [(1706, 716)]\n",
      "Ann_id in getitem:  39906\n",
      "Test inds:  [(1642, 1537)]\n",
      "Ann_id in getitem:  38504\n",
      "Test inds:  [(3516, 3320)]\n",
      "Ann_id in getitem:  81120\n",
      "Test inds:  [(1156, 1103)]\n",
      "Ann_id in getitem:  26881\n",
      "Test inds:  [(2102, 2977)]\n",
      "Ann_id in getitem:  47580\n",
      "Test inds:  [(2465, 135)]\n",
      "Ann_id in getitem:  56083\n",
      "Test inds:  [(1179, 1137)]\n",
      "Ann_id in getitem:  27439\n",
      "Test inds:  [(3359, 1991)]\n",
      "Ann_id in getitem:  77075\n",
      "Test inds:  [(55, 1511)]\n",
      "Ann_id in getitem:  1137\n",
      "Test inds:  [(3034, 1537)]\n",
      "Ann_id in getitem:  69918\n",
      "Test inds:  [(854, 813)]\n",
      "Ann_id in getitem:  20773\n",
      "Test inds:  [(999, 2756)]\n",
      "Ann_id in getitem:  23697\n",
      "Test inds:  [(1328, 599)]\n",
      "Ann_id in getitem:  31105\n",
      "Test inds:  [(1768, 1497)]\n",
      "Ann_id in getitem:  40851\n",
      "Test inds:  [(1525, 1834)]\n",
      "Ann_id in getitem:  36111\n",
      "Test inds:  [(796, 1896)]\n",
      "Ann_id in getitem:  19268\n",
      "Test inds:  [(2011, 3218)]\n",
      "Ann_id in getitem:  45775\n",
      "Test inds:  [(2874, 3185)]\n",
      "Ann_id in getitem:  66053\n",
      "Test inds:  [(3380, 2975)]\n",
      "Ann_id in getitem:  77732\n",
      "Test inds:  [(1630, 1714)]\n",
      "Ann_id in getitem:  38253\n",
      "Test inds:  [(1972, 3594)]\n",
      "Ann_id in getitem:  44986\n",
      "Test inds:  [(2534, 3198)]\n",
      "Ann_id in getitem:  57536\n",
      "Test inds:  [(813, 3621)]\n",
      "Ann_id in getitem:  19578\n",
      "Test inds:  [(1001, 553)]\n",
      "Ann_id in getitem:  23725\n",
      "Test inds:  [(1873, 982)]\n",
      "Ann_id in getitem:  43075\n",
      "Test inds:  [(428, 3652)]\n",
      "Ann_id in getitem:  10539\n",
      "Test inds:  [(3422, 923)]\n",
      "Ann_id in getitem:  78853\n",
      "Test inds:  [(1681, 2803)]\n",
      "Ann_id in getitem:  39449\n",
      "Test inds:  [(2233, 2607)]\n",
      "Ann_id in getitem:  50232\n",
      "Test inds:  [(1393, 1974)]\n",
      "Ann_id in getitem:  33092\n",
      "Test inds:  [(1781, 1755)]\n",
      "Ann_id in getitem:  41090\n",
      "Test inds:  [(1498, 2122)]\n",
      "Ann_id in getitem:  35589\n",
      "Test inds:  [(2232, 2214)]\n",
      "Ann_id in getitem:  50228\n",
      "Test inds:  [(2604, 1769)]\n",
      "Ann_id in getitem:  59664\n",
      "Test inds:  [(596, 2432)]\n",
      "Ann_id in getitem:  14428\n",
      "Test inds:  [(408, 1052)]\n",
      "Ann_id in getitem:  10002\n",
      "Test inds:  [(2449, 2525)]\n",
      "Ann_id in getitem:  55671\n",
      "Test inds:  [(1706, 98)]\n",
      "Ann_id in getitem:  39906\n",
      "Test inds:  [(3599, 773)]\n",
      "Ann_id in getitem:  83057\n",
      "Test inds:  [(1296, 2177)]\n",
      "Ann_id in getitem:  30399\n",
      "Test inds:  [(2224, 859)]\n",
      "Ann_id in getitem:  50042\n",
      "Test inds:  [(3466, 1346)]\n",
      "Ann_id in getitem:  80030\n",
      "Test inds:  [(2885, 1901)]\n",
      "Ann_id in getitem:  66392\n",
      "Test inds:  [(1433, 386)]\n",
      "Ann_id in getitem:  33989\n",
      "Test inds:  [(3066, 177)]\n",
      "Ann_id in getitem:  70643\n",
      "Test inds:  [(3075, 3524)]\n",
      "Ann_id in getitem:  70904\n",
      "Test inds:  [(474, 463)]\n",
      "Ann_id in getitem:  11460\n",
      "Test inds:  [(1720, 1575)]\n",
      "Ann_id in getitem:  40136\n",
      "Test inds:  [(3592, 3468)]\n",
      "Ann_id in getitem:  82841\n",
      "Test inds:  [(3449, 1084)]\n",
      "Ann_id in getitem:  79547\n",
      "Test inds:  [(2029, 3464)]\n",
      "Ann_id in getitem:  46188\n",
      "Test inds:  [(3065, 3331)]\n",
      "Ann_id in getitem:  70637\n",
      "Test inds:  [(1259, 2777)]\n",
      "Ann_id in getitem:  29503\n",
      "Test inds:  [(1942, 3069)]\n",
      "Ann_id in getitem:  44241\n",
      "Test inds:  [(2058, 2121)]\n",
      "Ann_id in getitem:  46850\n",
      "Test inds:  [(205, 1057)]\n",
      "Ann_id in getitem:  5098\n",
      "Test inds:  [(163, 2698)]\n",
      "Ann_id in getitem:  4142\n",
      "Test inds:  [(2716, 2417)]\n",
      "Ann_id in getitem:  62454\n",
      "Test inds:  [(2716, 2641)]\n",
      "Ann_id in getitem:  62454\n",
      "Test inds:  [(1432, 873)]\n",
      "Ann_id in getitem:  33929\n",
      "Test inds:  [(2397, 816)]\n",
      "Ann_id in getitem:  54242\n",
      "Test inds:  [(1472, 643)]\n",
      "Ann_id in getitem:  34923\n",
      "Test inds:  [(2804, 394)]\n",
      "Ann_id in getitem:  64707\n",
      "Test inds:  [(1573, 318)]\n",
      "Ann_id in getitem:  37210\n",
      "Test inds:  [(3469, 2281)]\n",
      "Ann_id in getitem:  80073\n",
      "Test inds:  [(3631, 860)]\n",
      "Ann_id in getitem:  83792\n",
      "Test inds:  [(328, 3699)]\n",
      "Ann_id in getitem:  8051\n",
      "Test inds:  [(205, 2223)]\n",
      "Ann_id in getitem:  5098\n",
      "Test inds:  [(497, 3528)]\n",
      "Ann_id in getitem:  11906\n",
      "Test inds:  [(288, 619)]\n",
      "Ann_id in getitem:  6725\n",
      "Test inds:  [(89, 2788)]\n",
      "Ann_id in getitem:  2049\n",
      "Test inds:  [(2421, 723)]\n",
      "Ann_id in getitem:  54756\n",
      "Test inds:  [(100, 62)]\n",
      "Ann_id in getitem:  2192\n",
      "Test inds:  [(1125, 1084)]\n",
      "Ann_id in getitem:  26216\n",
      "Test inds:  [(1658, 237)]\n",
      "Ann_id in getitem:  38806\n",
      "Test inds:  [(1453, 3184)]\n",
      "Ann_id in getitem:  34392\n",
      "Test inds:  [(2134, 1703)]\n",
      "Ann_id in getitem:  48348\n",
      "Test inds:  [(528, 1595)]\n",
      "Ann_id in getitem:  12570\n",
      "Test inds:  [(498, 2315)]\n",
      "Ann_id in getitem:  11931\n",
      "Test inds:  [(549, 3282)]\n",
      "Ann_id in getitem:  13155\n",
      "Test inds:  [(3218, 1336)]\n",
      "Ann_id in getitem:  74015\n",
      "Test inds:  [(3242, 2640)]\n",
      "Ann_id in getitem:  74523\n",
      "Test inds:  [(1583, 423)]\n",
      "Ann_id in getitem:  37390\n",
      "Test inds:  [(3469, 826)]\n",
      "Ann_id in getitem:  80073\n",
      "Test inds:  [(923, 2110)]\n",
      "Ann_id in getitem:  22116\n",
      "Test inds:  [(83, 3384)]\n",
      "Ann_id in getitem:  1886\n",
      "Test inds:  [(399, 2683)]\n",
      "Ann_id in getitem:  9861\n",
      "Test inds:  [(2103, 2388)]\n",
      "Ann_id in getitem:  47624\n",
      "Test inds:  [(2968, 2410)]\n",
      "Ann_id in getitem:  68298\n",
      "Test inds:  [(1531, 497)]\n",
      "Ann_id in getitem:  36245\n",
      "Test inds:  [(1114, 890)]\n",
      "Ann_id in getitem:  25816\n",
      "Test inds:  [(1677, 1923)]\n",
      "Ann_id in getitem:  39281\n",
      "Test inds:  [(1390, 1286)]\n",
      "Ann_id in getitem:  33008\n",
      "Test inds:  [(225, 2233)]\n",
      "Ann_id in getitem:  5509\n",
      "Test inds:  [(839, 2255)]\n",
      "Ann_id in getitem:  20148\n",
      "Test inds:  [(3588, 385)]\n",
      "Ann_id in getitem:  82754\n",
      "Test inds:  [(540, 1513)]\n",
      "Ann_id in getitem:  12851\n",
      "Test inds:  [(3516, 3496)]\n",
      "Ann_id in getitem:  81120\n",
      "Test inds:  [(3363, 1015)]\n",
      "Ann_id in getitem:  77203\n",
      "Test inds:  [(828, 1305)]\n",
      "Ann_id in getitem:  19865\n",
      "Test inds:  [(2947, 101)]\n",
      "Ann_id in getitem:  67910\n",
      "Test inds:  [(616, 1744)]\n",
      "Ann_id in getitem:  15155\n",
      "Test inds:  [(3181, 2124)]\n",
      "Ann_id in getitem:  73268\n",
      "Test inds:  [(980, 3375)]\n",
      "Ann_id in getitem:  23129\n",
      "Test inds:  [(1565, 2400)]\n",
      "Ann_id in getitem:  36992\n",
      "Test inds:  [(707, 2448)]\n",
      "Ann_id in getitem:  17147\n",
      "Test inds:  [(971, 3133)]\n",
      "Ann_id in getitem:  22910\n",
      "Test inds:  [(2188, 3633)]\n",
      "Ann_id in getitem:  49282\n",
      "Test inds:  [(2698, 3147)]\n",
      "Ann_id in getitem:  62010\n",
      "Test inds:  [(636, 1559)]\n",
      "Ann_id in getitem:  15457\n",
      "Test inds:  [(1646, 647)]\n",
      "Ann_id in getitem:  38566\n",
      "Test inds:  [(1309, 2056)]\n",
      "Ann_id in getitem:  30639\n",
      "Test inds:  [(407, 1418)]\n",
      "Ann_id in getitem:  9990\n",
      "Test inds:  [(555, 3075)]\n",
      "Ann_id in getitem:  13423\n",
      "Test inds:  [(1644, 2315)]\n",
      "Ann_id in getitem:  38515\n",
      "Test inds:  [(222, 1259)]\n",
      "Ann_id in getitem:  5440\n",
      "Test inds:  [(83, 3082)]\n",
      "Ann_id in getitem:  1886\n",
      "Test inds:  [(1073, 1368)]\n",
      "Ann_id in getitem:  25160\n",
      "Test inds:  [(1361, 1460)]\n",
      "Ann_id in getitem:  32080\n",
      "Test inds:  [(727, 1173)]\n",
      "Ann_id in getitem:  17571\n",
      "Test inds:  [(2683, 345)]\n",
      "Ann_id in getitem:  61622\n",
      "Test inds:  [(2434, 796)]\n",
      "Ann_id in getitem:  55038\n",
      "Test inds:  [(3696, 2424)]\n",
      "Ann_id in getitem:  85427\n",
      "Test inds:  [(631, 3612)]\n",
      "Ann_id in getitem:  15384\n",
      "Test inds:  [(166, 2796)]\n",
      "Ann_id in getitem:  4193\n",
      "Test inds:  [(1484, 2388)]\n",
      "Ann_id in getitem:  35252\n",
      "Test inds:  [(1033, 2354)]\n",
      "Ann_id in getitem:  24383\n",
      "Test inds:  [(2266, 2627)]\n",
      "Ann_id in getitem:  51182\n",
      "Test inds:  [(3092, 3381)]\n",
      "Ann_id in getitem:  71268\n",
      "Test inds:  [(14, 1678)]\n",
      "Ann_id in getitem:  342\n",
      "Test inds:  [(241, 3065)]\n",
      "Ann_id in getitem:  5862\n",
      "Test inds:  [(442, 2133)]\n",
      "Ann_id in getitem:  10823\n",
      "Test inds:  [(3043, 256)]\n",
      "Ann_id in getitem:  70139\n",
      "Test inds:  [(2714, 1226)]\n",
      "Ann_id in getitem:  62433\n",
      "Test inds:  [(1310, 2145)]\n",
      "Ann_id in getitem:  30641\n",
      "Test inds:  [(101, 307)]\n",
      "Ann_id in getitem:  2219\n",
      "Test inds:  [(1414, 1923)]\n",
      "Ann_id in getitem:  33453\n",
      "Test inds:  [(1216, 2004)]\n",
      "Ann_id in getitem:  28401\n",
      "Test inds:  [(3017, 1102)]\n",
      "Ann_id in getitem:  69532\n",
      "Test inds:  [(3647, 3676)]\n",
      "Ann_id in getitem:  84161\n",
      "Test inds:  [(45, 2111)]\n",
      "Ann_id in getitem:  945\n",
      "Test inds:  [(1651, 2611)]\n",
      "Ann_id in getitem:  38642\n",
      "Test inds:  [(2536, 477)]\n",
      "Ann_id in getitem:  57566\n",
      "Test inds:  [(2700, 3252)]\n",
      "Ann_id in getitem:  62024\n",
      "Test inds:  [(2701, 2104)]\n",
      "Ann_id in getitem:  62087\n",
      "Test inds:  [(2965, 1761)]\n",
      "Ann_id in getitem:  68275\n",
      "Test inds:  [(3325, 2075)]\n",
      "Ann_id in getitem:  76389\n",
      "Test inds:  [(3, 2248)]\n",
      "Ann_id in getitem:  89\n",
      "Test inds:  [(2832, 2515)]\n",
      "Ann_id in getitem:  65328\n",
      "Test inds:  [(2838, 1548)]\n",
      "Ann_id in getitem:  65391\n",
      "Test inds:  [(1727, 132)]\n",
      "Ann_id in getitem:  40272\n",
      "Test inds:  [(3103, 3140)]\n",
      "Ann_id in getitem:  71590\n",
      "Test inds:  [(1192, 1831)]\n",
      "Ann_id in getitem:  27755\n",
      "Test inds:  [(972, 1493)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(2801, 1440)]\n",
      "Ann_id in getitem:  64644\n",
      "Test inds:  [(2391, 3639)]\n",
      "Ann_id in getitem:  54119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1236, 2698)]\n",
      "Ann_id in getitem:  28894\n",
      "Test inds:  [(180, 156)]\n",
      "Ann_id in getitem:  4604\n",
      "Test inds:  [(2791, 2191)]\n",
      "Ann_id in getitem:  64441\n",
      "Test inds:  [(2556, 1571)]\n",
      "Ann_id in getitem:  58084\n",
      "Test inds:  [(2690, 2783)]\n",
      "Ann_id in getitem:  61838\n",
      "Test inds:  [(2532, 774)]\n",
      "Ann_id in getitem:  57478\n",
      "Test inds:  [(3385, 3360)]\n",
      "Ann_id in getitem:  77829\n",
      "Test inds:  [(3684, 3619)]\n",
      "Ann_id in getitem:  84931\n",
      "Test inds:  [(2600, 930)]\n",
      "Ann_id in getitem:  59568\n",
      "Test inds:  [(527, 486)]\n",
      "Ann_id in getitem:  12564\n",
      "Test inds:  [(3186, 3439)]\n",
      "Ann_id in getitem:  73364\n",
      "Test inds:  [(1266, 3084)]\n",
      "Ann_id in getitem:  29600\n",
      "Test inds:  [(1601, 2303)]\n",
      "Ann_id in getitem:  37728\n",
      "Test inds:  [(2329, 2761)]\n",
      "Ann_id in getitem:  52539\n",
      "Test inds:  [(1627, 3042)]\n",
      "Ann_id in getitem:  38118\n",
      "Test inds:  [(2208, 3247)]\n",
      "Ann_id in getitem:  49698\n",
      "Test inds:  [(2327, 2008)]\n",
      "Ann_id in getitem:  52386\n",
      "Test inds:  [(1959, 1916)]\n",
      "Ann_id in getitem:  44542\n",
      "Test inds:  [(3411, 665)]\n",
      "Ann_id in getitem:  78612\n",
      "Test inds:  [(2448, 963)]\n",
      "Ann_id in getitem:  55655\n",
      "Test inds:  [(3086, 1178)]\n",
      "Ann_id in getitem:  71201\n",
      "Test inds:  [(2748, 3644)]\n",
      "Ann_id in getitem:  63273\n",
      "Test inds:  [(503, 1454)]\n",
      "Ann_id in getitem:  12007\n",
      "Test inds:  [(2229, 3435)]\n",
      "Ann_id in getitem:  50207\n",
      "Test inds:  [(3126, 201)]\n",
      "Ann_id in getitem:  72096\n",
      "Test inds:  [(1674, 786)]\n",
      "Ann_id in getitem:  39208\n",
      "Test inds:  [(1808, 3216)]\n",
      "Ann_id in getitem:  41703\n",
      "Test inds:  [(235, 2772)]\n",
      "Ann_id in getitem:  5749\n",
      "Test inds:  [(2950, 466)]\n",
      "Ann_id in getitem:  67958\n",
      "Test inds:  [(3054, 1675)]\n",
      "Ann_id in getitem:  70504\n",
      "Test inds:  [(2939, 1185)]\n",
      "Ann_id in getitem:  67698\n",
      "Test inds:  [(3110, 2199)]\n",
      "Ann_id in getitem:  71760\n",
      "Test inds:  [(2314, 854)]\n",
      "Ann_id in getitem:  52171\n",
      "Test inds:  [(2428, 1539)]\n",
      "Ann_id in getitem:  54859\n",
      "Test inds:  [(3012, 2410)]\n",
      "Ann_id in getitem:  69468\n",
      "Test inds:  [(2780, 2185)]\n",
      "Ann_id in getitem:  64039\n",
      "Test inds:  [(2370, 2661)]\n",
      "Ann_id in getitem:  53599\n",
      "Test inds:  [(1166, 1890)]\n",
      "Ann_id in getitem:  27152\n",
      "Test inds:  [(1552, 2088)]\n",
      "Ann_id in getitem:  36700\n",
      "Test inds:  [(2176, 1899)]\n",
      "Ann_id in getitem:  49028\n",
      "Test inds:  [(178, 1233)]\n",
      "Ann_id in getitem:  4571\n",
      "Test inds:  [(975, 1833)]\n",
      "Ann_id in getitem:  22991\n",
      "Test inds:  [(672, 3201)]\n",
      "Ann_id in getitem:  16341\n",
      "Test inds:  [(2165, 2926)]\n",
      "Ann_id in getitem:  48865\n",
      "Test inds:  [(1934, 233)]\n",
      "Ann_id in getitem:  44115\n",
      "Test inds:  [(482, 2661)]\n",
      "Ann_id in getitem:  11605\n",
      "Test inds:  [(2985, 2069)]\n",
      "Ann_id in getitem:  68876\n",
      "Test inds:  [(866, 2490)]\n",
      "Ann_id in getitem:  20914\n",
      "Test inds:  [(1338, 59)]\n",
      "Ann_id in getitem:  31425\n",
      "Test inds:  [(3541, 1403)]\n",
      "Ann_id in getitem:  81674\n",
      "Test inds:  [(1922, 1463)]\n",
      "Ann_id in getitem:  43980\n",
      "Test inds:  [(892, 3003)]\n",
      "Ann_id in getitem:  21361\n",
      "Test inds:  [(2592, 255)]\n",
      "Ann_id in getitem:  59430\n",
      "Test inds:  [(197, 2266)]\n",
      "Ann_id in getitem:  4957\n",
      "Test inds:  [(1564, 2560)]\n",
      "Ann_id in getitem:  36955\n",
      "Test inds:  [(2877, 1021)]\n",
      "Ann_id in getitem:  66124\n",
      "Test inds:  [(3319, 825)]\n",
      "Ann_id in getitem:  76271\n",
      "Test inds:  [(274, 2185)]\n",
      "Ann_id in getitem:  6501\n",
      "Test inds:  [(3189, 2749)]\n",
      "Ann_id in getitem:  73403\n",
      "Test inds:  [(734, 1818)]\n",
      "Ann_id in getitem:  17848\n",
      "Test inds:  [(1527, 322)]\n",
      "Ann_id in getitem:  36178\n",
      "Test inds:  [(2591, 678)]\n",
      "Ann_id in getitem:  59405\n",
      "Test inds:  [(3699, 9)]\n",
      "Ann_id in getitem:  85453\n",
      "Test inds:  [(1892, 2776)]\n",
      "Ann_id in getitem:  43427\n",
      "Test inds:  [(3604, 2666)]\n",
      "Ann_id in getitem:  83162\n",
      "Test inds:  [(410, 2655)]\n",
      "Ann_id in getitem:  10031\n",
      "Test inds:  [(1116, 288)]\n",
      "Ann_id in getitem:  25851\n",
      "Test inds:  [(2150, 231)]\n",
      "Ann_id in getitem:  48576\n",
      "Test inds:  [(3189, 2278)]\n",
      "Ann_id in getitem:  73403\n",
      "Test inds:  [(1130, 1372)]\n",
      "Ann_id in getitem:  26429\n",
      "Test inds:  [(240, 1582)]\n",
      "Ann_id in getitem:  5835\n",
      "Test inds:  [(3086, 3631)]\n",
      "Ann_id in getitem:  71201\n",
      "Test inds:  [(1039, 2268)]\n",
      "Ann_id in getitem:  24546\n",
      "Test inds:  [(1018, 3422)]\n",
      "Ann_id in getitem:  24116\n",
      "Test inds:  [(1599, 3278)]\n",
      "Ann_id in getitem:  37713\n",
      "Test inds:  [(1841, 72)]\n",
      "Ann_id in getitem:  42253\n",
      "Test inds:  [(3258, 2804)]\n",
      "Ann_id in getitem:  74793\n",
      "Test inds:  [(2578, 1620)]\n",
      "Ann_id in getitem:  58767\n",
      "Test inds:  [(2711, 2905)]\n",
      "Ann_id in getitem:  62385\n",
      "Test inds:  [(514, 1012)]\n",
      "Ann_id in getitem:  12312\n",
      "Test inds:  [(26, 2665)]\n",
      "Ann_id in getitem:  540\n",
      "Test inds:  [(3151, 2726)]\n",
      "Ann_id in getitem:  72632\n",
      "Test inds:  [(1100, 236)]\n",
      "Ann_id in getitem:  25581\n",
      "Test inds:  [(3532, 2404)]\n",
      "Ann_id in getitem:  81499\n",
      "Test inds:  [(3203, 1954)]\n",
      "Ann_id in getitem:  73697\n",
      "Test inds:  [(3314, 1580)]\n",
      "Ann_id in getitem:  76128\n",
      "Test inds:  [(682, 1744)]\n",
      "Ann_id in getitem:  16613\n",
      "Test inds:  [(3207, 3370)]\n",
      "Ann_id in getitem:  73741\n",
      "Test inds:  [(318, 3561)]\n",
      "Ann_id in getitem:  7748\n",
      "Test inds:  [(654, 310)]\n",
      "Ann_id in getitem:  15969\n",
      "Test inds:  [(3137, 203)]\n",
      "Ann_id in getitem:  72344\n",
      "Test inds:  [(3254, 454)]\n",
      "Ann_id in getitem:  74750\n",
      "Test inds:  [(3366, 19)]\n",
      "Ann_id in getitem:  77283\n",
      "Test inds:  [(2485, 2375)]\n",
      "Ann_id in getitem:  56558\n",
      "Test inds:  [(3235, 1408)]\n",
      "Ann_id in getitem:  74370\n",
      "Test inds:  [(3268, 1068)]\n",
      "Ann_id in getitem:  74929\n",
      "Test inds:  [(440, 423)]\n",
      "Ann_id in getitem:  10730\n",
      "Test inds:  [(637, 713)]\n",
      "Ann_id in getitem:  15462\n",
      "Test inds:  [(2202, 295)]\n",
      "Ann_id in getitem:  49584\n",
      "Test inds:  [(2058, 1988)]\n",
      "Ann_id in getitem:  46850\n",
      "Test inds:  [(1746, 1442)]\n",
      "Ann_id in getitem:  40540\n",
      "Test inds:  [(590, 2632)]\n",
      "Ann_id in getitem:  14330\n",
      "Test inds:  [(3533, 2523)]\n",
      "Ann_id in getitem:  81544\n",
      "Test inds:  [(3478, 2005)]\n",
      "Ann_id in getitem:  80220\n",
      "Test inds:  [(2310, 2919)]\n",
      "Ann_id in getitem:  52078\n",
      "Test inds:  [(3485, 2287)]\n",
      "Ann_id in getitem:  80284\n",
      "Test inds:  [(1030, 2958)]\n",
      "Ann_id in getitem:  24314\n",
      "Test inds:  [(175, 3621)]\n",
      "Ann_id in getitem:  4397\n",
      "Test inds:  [(2224, 885)]\n",
      "Ann_id in getitem:  50042\n",
      "Test inds:  [(3379, 3413)]\n",
      "Ann_id in getitem:  77729\n",
      "Test inds:  [(1607, 851)]\n",
      "Ann_id in getitem:  37779\n",
      "Test inds:  [(2917, 231)]\n",
      "Ann_id in getitem:  67144\n",
      "Test inds:  [(1089, 1337)]\n",
      "Ann_id in getitem:  25412\n",
      "Test inds:  [(3689, 3410)]\n",
      "Ann_id in getitem:  85233\n",
      "Test inds:  [(2180, 3354)]\n",
      "Ann_id in getitem:  49130\n",
      "Test inds:  [(2867, 281)]\n",
      "Ann_id in getitem:  65912\n",
      "Test inds:  [(2050, 2236)]\n",
      "Ann_id in getitem:  46688\n",
      "Test inds:  [(2443, 3633)]\n",
      "Ann_id in getitem:  55515\n",
      "Test inds:  [(3657, 3137)]\n",
      "Ann_id in getitem:  84471\n",
      "Test inds:  [(2322, 2136)]\n",
      "Ann_id in getitem:  52293\n",
      "Test inds:  [(3607, 891)]\n",
      "Ann_id in getitem:  83301\n",
      "Test inds:  [(1689, 357)]\n",
      "Ann_id in getitem:  39564\n",
      "Test inds:  [(184, 2578)]\n",
      "Ann_id in getitem:  4710\n",
      "Test inds:  [(2735, 3310)]\n",
      "Ann_id in getitem:  62956\n",
      "Test inds:  [(1449, 3605)]\n",
      "Ann_id in getitem:  34312\n",
      "Test inds:  [(1210, 700)]\n",
      "Ann_id in getitem:  28225\n",
      "Test inds:  [(1034, 1995)]\n",
      "Ann_id in getitem:  24392\n",
      "Test inds:  [(2299, 1699)]\n",
      "Ann_id in getitem:  51855\n",
      "Test inds:  [(1249, 14)]\n",
      "Ann_id in getitem:  29273\n",
      "Test inds:  [(1047, 1812)]\n",
      "Ann_id in getitem:  24725\n",
      "Test inds:  [(1303, 3033)]\n",
      "Ann_id in getitem:  30491\n",
      "Test inds:  [(2936, 1455)]\n",
      "Ann_id in getitem:  67660\n",
      "Test inds:  [(2728, 739)]\n",
      "Ann_id in getitem:  62756\n",
      "Test inds:  [(2950, 3387)]\n",
      "Ann_id in getitem:  67958\n",
      "Test inds:  [(2412, 3585)]\n",
      "Ann_id in getitem:  54580\n",
      "Test inds:  [(2824, 3038)]\n",
      "Ann_id in getitem:  65096\n",
      "Test inds:  [(2461, 1360)]\n",
      "Ann_id in getitem:  55976\n",
      "Test inds:  [(2368, 1824)]\n",
      "Ann_id in getitem:  53573\n",
      "Test inds:  [(2766, 1329)]\n",
      "Ann_id in getitem:  63593\n",
      "Test inds:  [(2890, 826)]\n",
      "Ann_id in getitem:  66469\n",
      "Test inds:  [(2630, 739)]\n",
      "Ann_id in getitem:  60215\n",
      "Test inds:  [(921, 687)]\n",
      "Ann_id in getitem:  22052\n",
      "Test inds:  [(832, 1265)]\n",
      "Ann_id in getitem:  19992\n",
      "Test inds:  [(1738, 3584)]\n",
      "Ann_id in getitem:  40426\n",
      "Test inds:  [(908, 3024)]\n",
      "Ann_id in getitem:  21641\n",
      "Test inds:  [(2342, 3232)]\n",
      "Ann_id in getitem:  52873\n",
      "Test inds:  [(461, 2155)]\n",
      "Ann_id in getitem:  11138\n",
      "Test inds:  [(1487, 3617)]\n",
      "Ann_id in getitem:  35350\n",
      "Test inds:  [(811, 1952)]\n",
      "Ann_id in getitem:  19545\n",
      "Test inds:  [(3577, 3384)]\n",
      "Ann_id in getitem:  82448\n",
      "Test inds:  [(250, 2578)]\n",
      "Ann_id in getitem:  6032\n",
      "Test inds:  [(1901, 3088)]\n",
      "Ann_id in getitem:  43609\n",
      "Test inds:  [(244, 976)]\n",
      "Ann_id in getitem:  5922\n",
      "Test inds:  [(2687, 3205)]\n",
      "Ann_id in getitem:  61673\n",
      "Test inds:  [(1629, 2291)]\n",
      "Ann_id in getitem:  38235\n",
      "Test inds:  [(533, 3315)]\n",
      "Ann_id in getitem:  12675\n",
      "Test inds:  [(2416, 3610)]\n",
      "Ann_id in getitem:  54650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1941, 28)]\n",
      "Ann_id in getitem:  44231\n",
      "Test inds:  [(1869, 3142)]\n",
      "Ann_id in getitem:  43048\n",
      "Test inds:  [(2171, 3067)]\n",
      "Ann_id in getitem:  48943\n",
      "Test inds:  [(2119, 1622)]\n",
      "Ann_id in getitem:  48004\n",
      "Test inds:  [(2002, 3081)]\n",
      "Ann_id in getitem:  45579\n",
      "Test inds:  [(1580, 926)]\n",
      "Ann_id in getitem:  37362\n",
      "Test inds:  [(3385, 583)]\n",
      "Ann_id in getitem:  77829\n",
      "Test inds:  [(2875, 3483)]\n",
      "Ann_id in getitem:  66059\n",
      "Test inds:  [(1103, 512)]\n",
      "Ann_id in getitem:  25651\n",
      "Test inds:  [(2777, 569)]\n",
      "Ann_id in getitem:  63977\n",
      "Test inds:  [(3564, 3285)]\n",
      "Ann_id in getitem:  82213\n",
      "Test inds:  [(761, 3527)]\n",
      "Ann_id in getitem:  18483\n",
      "Test inds:  [(1519, 666)]\n",
      "Ann_id in getitem:  35969\n",
      "Test inds:  [(254, 976)]\n",
      "Ann_id in getitem:  6108\n",
      "Test inds:  [(3157, 78)]\n",
      "Ann_id in getitem:  72771\n",
      "Test inds:  [(121, 3194)]\n",
      "Ann_id in getitem:  2884\n",
      "Test inds:  [(2794, 639)]\n",
      "Ann_id in getitem:  64476\n",
      "Test inds:  [(3454, 1930)]\n",
      "Ann_id in getitem:  79706\n",
      "Test inds:  [(921, 1424)]\n",
      "Ann_id in getitem:  22052\n",
      "Test inds:  [(2596, 2915)]\n",
      "Ann_id in getitem:  59482\n",
      "Test inds:  [(2871, 619)]\n",
      "Ann_id in getitem:  66019\n",
      "Test inds:  [(1855, 659)]\n",
      "Ann_id in getitem:  42683\n",
      "Test inds:  [(1805, 1642)]\n",
      "Ann_id in getitem:  41643\n",
      "Test inds:  [(3397, 1660)]\n",
      "Ann_id in getitem:  78099\n",
      "Test inds:  [(2564, 340)]\n",
      "Ann_id in getitem:  58323\n",
      "Test inds:  [(1986, 667)]\n",
      "Ann_id in getitem:  45303\n",
      "Test inds:  [(2104, 2578)]\n",
      "Ann_id in getitem:  47658\n",
      "Test inds:  [(1704, 3332)]\n",
      "Ann_id in getitem:  39872\n",
      "Test inds:  [(1915, 212)]\n",
      "Ann_id in getitem:  43843\n",
      "Test inds:  [(551, 1416)]\n",
      "Ann_id in getitem:  13271\n",
      "Test inds:  [(2818, 922)]\n",
      "Ann_id in getitem:  64942\n",
      "Test inds:  [(3222, 1792)]\n",
      "Ann_id in getitem:  74083\n",
      "Test inds:  [(107, 640)]\n",
      "Ann_id in getitem:  2450\n",
      "Test inds:  [(2113, 2581)]\n",
      "Ann_id in getitem:  47924\n",
      "Test inds:  [(1805, 1087)]\n",
      "Ann_id in getitem:  41643\n",
      "Test inds:  [(6, 3348)]\n",
      "Ann_id in getitem:  109\n",
      "Test inds:  [(1544, 2096)]\n",
      "Ann_id in getitem:  36524\n",
      "Test inds:  [(3568, 2709)]\n",
      "Ann_id in getitem:  82290\n",
      "Test inds:  [(3491, 364)]\n",
      "Ann_id in getitem:  80445\n",
      "Test inds:  [(299, 127)]\n",
      "Ann_id in getitem:  7039\n",
      "Test inds:  [(3323, 454)]\n",
      "Ann_id in getitem:  76368\n",
      "Test inds:  [(80, 1129)]\n",
      "Ann_id in getitem:  1828\n",
      "Test inds:  [(1562, 688)]\n",
      "Ann_id in getitem:  36886\n",
      "Test inds:  [(2623, 301)]\n",
      "Ann_id in getitem:  59971\n",
      "Test inds:  [(607, 3064)]\n",
      "Ann_id in getitem:  14791\n",
      "Test inds:  [(1955, 1366)]\n",
      "Ann_id in getitem:  44461\n",
      "Test inds:  [(2138, 1245)]\n",
      "Ann_id in getitem:  48446\n",
      "Test inds:  [(181, 277)]\n",
      "Ann_id in getitem:  4633\n",
      "Test inds:  [(569, 2592)]\n",
      "Ann_id in getitem:  13745\n",
      "Test inds:  [(292, 1143)]\n",
      "Ann_id in getitem:  6802\n",
      "Test inds:  [(2711, 182)]\n",
      "Ann_id in getitem:  62385\n",
      "Test inds:  [(3645, 3390)]\n",
      "Ann_id in getitem:  84145\n",
      "Test inds:  [(62, 3194)]\n",
      "Ann_id in getitem:  1373\n",
      "Test inds:  [(3459, 1189)]\n",
      "Ann_id in getitem:  79802\n",
      "Test inds:  [(2912, 3414)]\n",
      "Ann_id in getitem:  67098\n",
      "Test inds:  [(2709, 1869)]\n",
      "Ann_id in getitem:  62332\n",
      "Test inds:  [(2839, 63)]\n",
      "Ann_id in getitem:  65396\n",
      "Test inds:  [(3111, 3406)]\n",
      "Ann_id in getitem:  71777\n",
      "Test inds:  [(426, 1777)]\n",
      "Ann_id in getitem:  10527\n",
      "Test inds:  [(3465, 2519)]\n",
      "Ann_id in getitem:  80003\n",
      "Test inds:  [(3207, 1858)]\n",
      "Ann_id in getitem:  73741\n",
      "Test inds:  [(825, 2046)]\n",
      "Ann_id in getitem:  19798\n",
      "Test inds:  [(350, 2107)]\n",
      "Ann_id in getitem:  8479\n",
      "Test inds:  [(1794, 2427)]\n",
      "Ann_id in getitem:  41445\n",
      "Test inds:  [(2231, 3458)]\n",
      "Ann_id in getitem:  50219\n",
      "Test inds:  [(889, 2682)]\n",
      "Ann_id in getitem:  21210\n",
      "Test inds:  [(3323, 900)]\n",
      "Ann_id in getitem:  76368\n",
      "Test inds:  [(1435, 3005)]\n",
      "Ann_id in getitem:  34020\n",
      "Test inds:  [(1851, 3353)]\n",
      "Ann_id in getitem:  42630\n",
      "Test inds:  [(1483, 728)]\n",
      "Ann_id in getitem:  35229\n",
      "Test inds:  [(2970, 1491)]\n",
      "Ann_id in getitem:  68330\n",
      "Test inds:  [(2786, 3310)]\n",
      "Ann_id in getitem:  64310\n",
      "Test inds:  [(1244, 2668)]\n",
      "Ann_id in getitem:  29129\n",
      "Test inds:  [(3194, 260)]\n",
      "Ann_id in getitem:  73515\n",
      "Test inds:  [(1908, 1155)]\n",
      "Ann_id in getitem:  43706\n",
      "Test inds:  [(2362, 1207)]\n",
      "Ann_id in getitem:  53393\n",
      "Test inds:  [(1886, 2520)]\n",
      "Ann_id in getitem:  43376\n",
      "Test inds:  [(1609, 11)]\n",
      "Ann_id in getitem:  37795\n",
      "Test inds:  [(3214, 353)]\n",
      "Ann_id in getitem:  73941\n",
      "Test inds:  [(3596, 2279)]\n",
      "Ann_id in getitem:  82933\n",
      "Test inds:  [(112, 1282)]\n",
      "Ann_id in getitem:  2620\n",
      "Test inds:  [(887, 1493)]\n",
      "Ann_id in getitem:  21168\n",
      "Test inds:  [(3369, 3082)]\n",
      "Ann_id in getitem:  77385\n",
      "Test inds:  [(3126, 1556)]\n",
      "Ann_id in getitem:  72096\n",
      "Test inds:  [(2745, 3240)]\n",
      "Ann_id in getitem:  63173\n",
      "Test inds:  [(1176, 1645)]\n",
      "Ann_id in getitem:  27403\n",
      "Test inds:  [(2668, 10)]\n",
      "Ann_id in getitem:  61233\n",
      "Test inds:  [(1266, 643)]\n",
      "Ann_id in getitem:  29600\n",
      "Test inds:  [(2687, 3427)]\n",
      "Ann_id in getitem:  61673\n",
      "Test inds:  [(1678, 2551)]\n",
      "Ann_id in getitem:  39292\n",
      "Test inds:  [(3026, 657)]\n",
      "Ann_id in getitem:  69816\n",
      "Test inds:  [(3092, 1364)]\n",
      "Ann_id in getitem:  71268\n",
      "Test inds:  [(1607, 909)]\n",
      "Ann_id in getitem:  37779\n",
      "Test inds:  [(1488, 2984)]\n",
      "Ann_id in getitem:  35357\n",
      "Test inds:  [(1486, 166)]\n",
      "Ann_id in getitem:  35288\n",
      "Test inds:  [(2131, 1170)]\n",
      "Ann_id in getitem:  48279\n",
      "Test inds:  [(3443, 737)]\n",
      "Ann_id in getitem:  79362\n",
      "Test inds:  [(1061, 1086)]\n",
      "Ann_id in getitem:  24983\n",
      "Test inds:  [(3467, 2165)]\n",
      "Ann_id in getitem:  80049\n",
      "Test inds:  [(1013, 1383)]\n",
      "Ann_id in getitem:  24056\n",
      "Test inds:  [(955, 3664)]\n",
      "Ann_id in getitem:  22603\n",
      "Test inds:  [(655, 1493)]\n",
      "Ann_id in getitem:  15980\n",
      "Test inds:  [(2155, 948)]\n",
      "Ann_id in getitem:  48653\n",
      "Test inds:  [(2802, 3668)]\n",
      "Ann_id in getitem:  64667\n",
      "Test inds:  [(2768, 1822)]\n",
      "Ann_id in getitem:  63693\n",
      "Test inds:  [(2483, 2817)]\n",
      "Ann_id in getitem:  56525\n",
      "Test inds:  [(152, 2092)]\n",
      "Ann_id in getitem:  3759\n",
      "Test inds:  [(3318, 2238)]\n",
      "Ann_id in getitem:  76269\n",
      "Test inds:  [(833, 1343)]\n",
      "Ann_id in getitem:  20019\n",
      "Test inds:  [(894, 2471)]\n",
      "Ann_id in getitem:  21430\n",
      "Test inds:  [(542, 426)]\n",
      "Ann_id in getitem:  12941\n",
      "Test inds:  [(3493, 3003)]\n",
      "Ann_id in getitem:  80490\n",
      "Test inds:  [(2621, 1242)]\n",
      "Ann_id in getitem:  59957\n",
      "Test inds:  [(614, 947)]\n",
      "Ann_id in getitem:  15059\n",
      "Test inds:  [(3180, 804)]\n",
      "Ann_id in getitem:  73252\n",
      "Test inds:  [(619, 2757)]\n",
      "Ann_id in getitem:  15172\n",
      "Test inds:  [(3392, 2395)]\n",
      "Ann_id in getitem:  77970\n",
      "Test inds:  [(505, 1109)]\n",
      "Ann_id in getitem:  12029\n",
      "Test inds:  [(3625, 526)]\n",
      "Ann_id in getitem:  83643\n",
      "Test inds:  [(1284, 2229)]\n",
      "Ann_id in getitem:  30063\n",
      "Test inds:  [(922, 3399)]\n",
      "Ann_id in getitem:  22094\n",
      "Test inds:  [(2424, 64)]\n",
      "Ann_id in getitem:  54798\n",
      "Test inds:  [(2352, 830)]\n",
      "Ann_id in getitem:  53192\n",
      "Test inds:  [(1345, 3135)]\n",
      "Ann_id in getitem:  31701\n",
      "Test inds:  [(738, 1121)]\n",
      "Ann_id in getitem:  17883\n",
      "Test inds:  [(1795, 902)]\n",
      "Ann_id in getitem:  41460\n",
      "Test inds:  [(2770, 1736)]\n",
      "Ann_id in getitem:  63766\n",
      "Test inds:  [(444, 3365)]\n",
      "Ann_id in getitem:  10831\n",
      "Test inds:  [(1304, 3024)]\n",
      "Ann_id in getitem:  30493\n",
      "Test inds:  [(2612, 129)]\n",
      "Ann_id in getitem:  59845\n",
      "Test inds:  [(236, 431)]\n",
      "Ann_id in getitem:  5757\n",
      "Test inds:  [(1753, 1600)]\n",
      "Ann_id in getitem:  40575\n",
      "Test inds:  [(1547, 1923)]\n",
      "Ann_id in getitem:  36568\n",
      "Test inds:  [(309, 1781)]\n",
      "Ann_id in getitem:  7481\n",
      "Test inds:  [(197, 2535)]\n",
      "Ann_id in getitem:  4957\n",
      "Test inds:  [(995, 3494)]\n",
      "Ann_id in getitem:  23655\n",
      "Test inds:  [(2371, 559)]\n",
      "Ann_id in getitem:  53610\n",
      "Test inds:  [(371, 471)]\n",
      "Ann_id in getitem:  9108\n",
      "Test inds:  [(1826, 2292)]\n",
      "Ann_id in getitem:  42020\n",
      "Test inds:  [(2650, 491)]\n",
      "Ann_id in getitem:  60694\n",
      "Test inds:  [(1813, 3624)]\n",
      "Ann_id in getitem:  41747\n",
      "Test inds:  [(2315, 3007)]\n",
      "Ann_id in getitem:  52174\n",
      "Test inds:  [(3497, 455)]\n",
      "Ann_id in getitem:  80554\n",
      "Test inds:  [(373, 2354)]\n",
      "Ann_id in getitem:  9115\n",
      "Test inds:  [(1688, 2804)]\n",
      "Ann_id in getitem:  39530\n",
      "Test inds:  [(2980, 1409)]\n",
      "Ann_id in getitem:  68758\n",
      "Test inds:  [(2907, 2242)]\n",
      "Ann_id in getitem:  67051\n",
      "Test inds:  [(3675, 3055)]\n",
      "Ann_id in getitem:  84758\n",
      "Test inds:  [(428, 783)]\n",
      "Ann_id in getitem:  10539\n",
      "Test inds:  [(648, 1862)]\n",
      "Ann_id in getitem:  15817\n",
      "Test inds:  [(650, 2140)]\n",
      "Ann_id in getitem:  15861\n",
      "Test inds:  [(2202, 2023)]\n",
      "Ann_id in getitem:  49584\n",
      "Test inds:  [(2966, 45)]\n",
      "Ann_id in getitem:  68278\n",
      "Test inds:  [(2782, 891)]\n",
      "Ann_id in getitem:  64161\n",
      "Test inds:  [(581, 1369)]\n",
      "Ann_id in getitem:  14119\n",
      "Test inds:  [(2925, 2924)]\n",
      "Ann_id in getitem:  67308\n",
      "Test inds:  [(633, 535)]\n",
      "Ann_id in getitem:  15411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(63, 3209)]\n",
      "Ann_id in getitem:  1392\n",
      "Test inds:  [(1929, 1992)]\n",
      "Ann_id in getitem:  44065\n",
      "Test inds:  [(1985, 3140)]\n",
      "Ann_id in getitem:  45252\n",
      "Test inds:  [(730, 2406)]\n",
      "Ann_id in getitem:  17696\n",
      "Test inds:  [(220, 2494)]\n",
      "Ann_id in getitem:  5431\n",
      "Test inds:  [(433, 129)]\n",
      "Ann_id in getitem:  10657\n",
      "Test inds:  [(1718, 2468)]\n",
      "Ann_id in getitem:  40106\n",
      "Test inds:  [(2792, 2784)]\n",
      "Ann_id in getitem:  64467\n",
      "Test inds:  [(1228, 407)]\n",
      "Ann_id in getitem:  28712\n",
      "Test inds:  [(1269, 2137)]\n",
      "Ann_id in getitem:  29634\n",
      "Test inds:  [(3698, 3227)]\n",
      "Ann_id in getitem:  85452\n",
      "Test inds:  [(1933, 367)]\n",
      "Ann_id in getitem:  44105\n",
      "Test inds:  [(1172, 2100)]\n",
      "Ann_id in getitem:  27254\n",
      "Test inds:  [(1193, 2345)]\n",
      "Ann_id in getitem:  27827\n",
      "Test inds:  [(2250, 2591)]\n",
      "Ann_id in getitem:  50843\n",
      "Test inds:  [(129, 2560)]\n",
      "Ann_id in getitem:  3106\n",
      "Test inds:  [(3634, 3639)]\n",
      "Ann_id in getitem:  83867\n",
      "Test inds:  [(2253, 3699)]\n",
      "Ann_id in getitem:  50937\n",
      "Test inds:  [(1293, 2324)]\n",
      "Ann_id in getitem:  30350\n",
      "Test inds:  [(2432, 3025)]\n",
      "Ann_id in getitem:  55017\n",
      "Test inds:  [(2518, 2359)]\n",
      "Ann_id in getitem:  57251\n",
      "Test inds:  [(1, 2526)]\n",
      "Ann_id in getitem:  38\n",
      "Test inds:  [(616, 1849)]\n",
      "Ann_id in getitem:  15155\n",
      "Test inds:  [(2919, 3240)]\n",
      "Ann_id in getitem:  67228\n",
      "Test inds:  [(3001, 2813)]\n",
      "Ann_id in getitem:  69144\n",
      "Test inds:  [(3437, 283)]\n",
      "Ann_id in getitem:  79227\n",
      "Test inds:  [(294, 3206)]\n",
      "Ann_id in getitem:  6822\n",
      "Test inds:  [(1196, 3524)]\n",
      "Ann_id in getitem:  27851\n",
      "Test inds:  [(1738, 1412)]\n",
      "Ann_id in getitem:  40426\n",
      "Test inds:  [(3650, 245)]\n",
      "Ann_id in getitem:  84238\n",
      "Test inds:  [(3045, 3612)]\n",
      "Ann_id in getitem:  70235\n",
      "Test inds:  [(716, 1242)]\n",
      "Ann_id in getitem:  17353\n",
      "Test inds:  [(1411, 3031)]\n",
      "Ann_id in getitem:  33420\n",
      "Test inds:  [(340, 1087)]\n",
      "Ann_id in getitem:  8272\n",
      "Test inds:  [(1817, 3225)]\n",
      "Ann_id in getitem:  41838\n",
      "Test inds:  [(1779, 156)]\n",
      "Ann_id in getitem:  41078\n",
      "Test inds:  [(1900, 2195)]\n",
      "Ann_id in getitem:  43579\n",
      "Test inds:  [(2276, 3509)]\n",
      "Ann_id in getitem:  51482\n",
      "Test inds:  [(338, 1450)]\n",
      "Ann_id in getitem:  8233\n",
      "Test inds:  [(2760, 2575)]\n",
      "Ann_id in getitem:  63458\n",
      "Test inds:  [(1605, 3648)]\n",
      "Ann_id in getitem:  37771\n",
      "Test inds:  [(2755, 1891)]\n",
      "Ann_id in getitem:  63381\n",
      "Test inds:  [(973, 2491)]\n",
      "Ann_id in getitem:  22960\n",
      "Test inds:  [(485, 1847)]\n",
      "Ann_id in getitem:  11673\n",
      "Test inds:  [(1163, 1673)]\n",
      "Ann_id in getitem:  27101\n",
      "Test inds:  [(2342, 1285)]\n",
      "Ann_id in getitem:  52873\n",
      "Test inds:  [(389, 749)]\n",
      "Ann_id in getitem:  9624\n",
      "Test inds:  [(269, 1228)]\n",
      "Ann_id in getitem:  6394\n",
      "Test inds:  [(1314, 3512)]\n",
      "Ann_id in getitem:  30769\n",
      "Test inds:  [(2469, 1126)]\n",
      "Ann_id in getitem:  56160\n",
      "Test inds:  [(2774, 3212)]\n",
      "Ann_id in getitem:  63885\n",
      "Test inds:  [(2680, 3596)]\n",
      "Ann_id in getitem:  61526\n",
      "Test inds:  [(2372, 1779)]\n",
      "Ann_id in getitem:  53613\n",
      "Test inds:  [(426, 1535)]\n",
      "Ann_id in getitem:  10527\n",
      "Test inds:  [(2031, 65)]\n",
      "Ann_id in getitem:  46238\n",
      "Test inds:  [(1620, 628)]\n",
      "Ann_id in getitem:  37987\n",
      "Test inds:  [(1663, 2781)]\n",
      "Ann_id in getitem:  38907\n",
      "Test inds:  [(1445, 971)]\n",
      "Ann_id in getitem:  34246\n",
      "Test inds:  [(2594, 3659)]\n",
      "Ann_id in getitem:  59476\n",
      "Test inds:  [(1392, 3476)]\n",
      "Ann_id in getitem:  33072\n",
      "Test inds:  [(2564, 2711)]\n",
      "Ann_id in getitem:  58323\n",
      "Test inds:  [(1311, 341)]\n",
      "Ann_id in getitem:  30678\n",
      "Test inds:  [(3581, 3517)]\n",
      "Ann_id in getitem:  82517\n",
      "Test inds:  [(3269, 40)]\n",
      "Ann_id in getitem:  74930\n",
      "Test inds:  [(2948, 1330)]\n",
      "Ann_id in getitem:  67914\n",
      "Test inds:  [(2299, 1125)]\n",
      "Ann_id in getitem:  51855\n",
      "Test inds:  [(986, 1269)]\n",
      "Ann_id in getitem:  23444\n",
      "Test inds:  [(39, 1506)]\n",
      "Ann_id in getitem:  856\n",
      "Test inds:  [(250, 3459)]\n",
      "Ann_id in getitem:  6032\n",
      "Test inds:  [(647, 1898)]\n",
      "Ann_id in getitem:  15755\n",
      "Test inds:  [(0, 3668)]\n",
      "Ann_id in getitem:  37\n",
      "Test inds:  [(2429, 173)]\n",
      "Ann_id in getitem:  54907\n",
      "Test inds:  [(2795, 906)]\n",
      "Ann_id in getitem:  64487\n",
      "Test inds:  [(158, 1520)]\n",
      "Ann_id in getitem:  4036\n",
      "Test inds:  [(2834, 951)]\n",
      "Ann_id in getitem:  65337\n",
      "Test inds:  [(375, 170)]\n",
      "Ann_id in getitem:  9174\n",
      "Test inds:  [(1417, 2279)]\n",
      "Ann_id in getitem:  33495\n",
      "Test inds:  [(475, 2349)]\n",
      "Ann_id in getitem:  11508\n",
      "Test inds:  [(2925, 257)]\n",
      "Ann_id in getitem:  67308\n",
      "Test inds:  [(2423, 2092)]\n",
      "Ann_id in getitem:  54783\n",
      "Test inds:  [(585, 965)]\n",
      "Ann_id in getitem:  14218\n",
      "Test inds:  [(3264, 1024)]\n",
      "Ann_id in getitem:  74865\n",
      "Test inds:  [(1973, 1836)]\n",
      "Ann_id in getitem:  44991\n",
      "Test inds:  [(2860, 1168)]\n",
      "Ann_id in getitem:  65733\n",
      "Test inds:  [(1290, 2118)]\n",
      "Ann_id in getitem:  30285\n",
      "Test inds:  [(440, 398)]\n",
      "Ann_id in getitem:  10730\n",
      "Test inds:  [(1037, 1864)]\n",
      "Ann_id in getitem:  24537\n",
      "Test inds:  [(1383, 3262)]\n",
      "Ann_id in getitem:  32854\n",
      "Test inds:  [(30, 2932)]\n",
      "Ann_id in getitem:  644\n",
      "Test inds:  [(1425, 3651)]\n",
      "Ann_id in getitem:  33797\n",
      "Test inds:  [(1735, 2591)]\n",
      "Ann_id in getitem:  40385\n",
      "Test inds:  [(1209, 933)]\n",
      "Ann_id in getitem:  28210\n",
      "Test inds:  [(144, 3636)]\n",
      "Ann_id in getitem:  3506\n",
      "Test inds:  [(281, 2952)]\n",
      "Ann_id in getitem:  6637\n",
      "Test inds:  [(1764, 3679)]\n",
      "Ann_id in getitem:  40804\n",
      "Test inds:  [(375, 2206)]\n",
      "Ann_id in getitem:  9174\n",
      "Test inds:  [(2840, 2809)]\n",
      "Ann_id in getitem:  65399\n",
      "Test inds:  [(628, 1801)]\n",
      "Ann_id in getitem:  15327\n",
      "Test inds:  [(2437, 322)]\n",
      "Ann_id in getitem:  55138\n",
      "Test inds:  [(3184, 80)]\n",
      "Ann_id in getitem:  73335\n",
      "Test inds:  [(462, 325)]\n",
      "Ann_id in getitem:  11142\n",
      "Test inds:  [(1134, 1019)]\n",
      "Ann_id in getitem:  26460\n",
      "Test inds:  [(1968, 2665)]\n",
      "Ann_id in getitem:  44930\n",
      "Test inds:  [(110, 919)]\n",
      "Ann_id in getitem:  2599\n",
      "Test inds:  [(544, 3598)]\n",
      "Ann_id in getitem:  12972\n",
      "Test inds:  [(2943, 1736)]\n",
      "Ann_id in getitem:  67809\n",
      "Test inds:  [(2315, 2343)]\n",
      "Ann_id in getitem:  52174\n",
      "Test inds:  [(2601, 3355)]\n",
      "Ann_id in getitem:  59583\n",
      "Test inds:  [(733, 898)]\n",
      "Ann_id in getitem:  17818\n",
      "Test inds:  [(3139, 1016)]\n",
      "Ann_id in getitem:  72402\n",
      "Test inds:  [(1057, 3408)]\n",
      "Ann_id in getitem:  24953\n",
      "Test inds:  [(2796, 3221)]\n",
      "Ann_id in getitem:  64515\n",
      "Test inds:  [(3283, 469)]\n",
      "Ann_id in getitem:  75162\n",
      "Test inds:  [(3109, 1388)]\n",
      "Ann_id in getitem:  71745\n",
      "Test inds:  [(1797, 2793)]\n",
      "Ann_id in getitem:  41529\n",
      "Test inds:  [(401, 2198)]\n",
      "Ann_id in getitem:  9891\n",
      "Test inds:  [(3668, 3361)]\n",
      "Ann_id in getitem:  84657\n",
      "Test inds:  [(1188, 2756)]\n",
      "Ann_id in getitem:  27692\n",
      "Test inds:  [(2647, 1457)]\n",
      "Ann_id in getitem:  60662\n",
      "Test inds:  [(1335, 2464)]\n",
      "Ann_id in getitem:  31408\n",
      "Test inds:  [(1012, 2028)]\n",
      "Ann_id in getitem:  24045\n",
      "Test inds:  [(2581, 1956)]\n",
      "Ann_id in getitem:  58998\n",
      "Test inds:  [(2553, 1045)]\n",
      "Ann_id in getitem:  58014\n",
      "Test inds:  [(2014, 2056)]\n",
      "Ann_id in getitem:  45833\n",
      "Test inds:  [(676, 3284)]\n",
      "Ann_id in getitem:  16418\n",
      "Test inds:  [(3268, 1)]\n",
      "Ann_id in getitem:  74929\n",
      "Test inds:  [(1582, 2204)]\n",
      "Ann_id in getitem:  37382\n",
      "Test inds:  [(2700, 2062)]\n",
      "Ann_id in getitem:  62024\n",
      "Test inds:  [(552, 3477)]\n",
      "Ann_id in getitem:  13304\n",
      "Test inds:  [(777, 906)]\n",
      "Ann_id in getitem:  18830\n",
      "Test inds:  [(2847, 2185)]\n",
      "Ann_id in getitem:  65543\n",
      "Test inds:  [(2834, 2045)]\n",
      "Ann_id in getitem:  65337\n",
      "Test inds:  [(2677, 323)]\n",
      "Ann_id in getitem:  61404\n",
      "Test inds:  [(3143, 2965)]\n",
      "Ann_id in getitem:  72479\n",
      "Test inds:  [(2607, 790)]\n",
      "Ann_id in getitem:  59730\n",
      "Test inds:  [(1545, 1088)]\n",
      "Ann_id in getitem:  36558\n",
      "Test inds:  [(2647, 261)]\n",
      "Ann_id in getitem:  60662\n",
      "Test inds:  [(1132, 744)]\n",
      "Ann_id in getitem:  26446\n",
      "Test inds:  [(3563, 2374)]\n",
      "Ann_id in getitem:  82158\n",
      "Test inds:  [(1898, 3085)]\n",
      "Ann_id in getitem:  43542\n",
      "Test inds:  [(417, 1416)]\n",
      "Ann_id in getitem:  10146\n",
      "Test inds:  [(3224, 733)]\n",
      "Ann_id in getitem:  74118\n",
      "Test inds:  [(2528, 947)]\n",
      "Ann_id in getitem:  57432\n",
      "Test inds:  [(2738, 3170)]\n",
      "Ann_id in getitem:  63062\n",
      "Test inds:  [(2574, 2404)]\n",
      "Ann_id in getitem:  58663\n",
      "Test inds:  [(3172, 581)]\n",
      "Ann_id in getitem:  73066\n",
      "Test inds:  [(2229, 10)]\n",
      "Ann_id in getitem:  50207\n",
      "Test inds:  [(2911, 3354)]\n",
      "Ann_id in getitem:  67095\n",
      "Test inds:  [(1692, 1977)]\n",
      "Ann_id in getitem:  39685\n",
      "Test inds:  [(2268, 518)]\n",
      "Ann_id in getitem:  51216\n",
      "Test inds:  [(1707, 359)]\n",
      "Ann_id in getitem:  39944\n",
      "Test inds:  [(286, 554)]\n",
      "Ann_id in getitem:  6676\n",
      "Test inds:  [(1855, 3658)]\n",
      "Ann_id in getitem:  42683\n",
      "Test inds:  [(2085, 2630)]\n",
      "Ann_id in getitem:  47324\n",
      "Test inds:  [(1708, 2877)]\n",
      "Ann_id in getitem:  39966\n",
      "Test inds:  [(2681, 89)]\n",
      "Ann_id in getitem:  61586\n",
      "Test inds:  [(2771, 1322)]\n",
      "Ann_id in getitem:  63770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(451, 1529)]\n",
      "Ann_id in getitem:  10947\n",
      "Test inds:  [(1322, 2320)]\n",
      "Ann_id in getitem:  30914\n",
      "Test inds:  [(3489, 1622)]\n",
      "Ann_id in getitem:  80394\n",
      "Test inds:  [(2631, 3549)]\n",
      "Ann_id in getitem:  60240\n",
      "Test inds:  [(64, 2170)]\n",
      "Ann_id in getitem:  1400\n",
      "Test inds:  [(3626, 922)]\n",
      "Ann_id in getitem:  83645\n",
      "Test inds:  [(2210, 337)]\n",
      "Ann_id in getitem:  49723\n",
      "Test inds:  [(2775, 2090)]\n",
      "Ann_id in getitem:  63945\n",
      "Test inds:  [(1089, 1540)]\n",
      "Ann_id in getitem:  25412\n",
      "Test inds:  [(116, 2106)]\n",
      "Ann_id in getitem:  2688\n",
      "Test inds:  [(1721, 1273)]\n",
      "Ann_id in getitem:  40158\n",
      "Test inds:  [(780, 1695)]\n",
      "Ann_id in getitem:  18906\n",
      "Test inds:  [(3418, 1239)]\n",
      "Ann_id in getitem:  78740\n",
      "Test inds:  [(3532, 3199)]\n",
      "Ann_id in getitem:  81499\n",
      "Test inds:  [(3446, 631)]\n",
      "Ann_id in getitem:  79388\n",
      "Test inds:  [(2122, 2397)]\n",
      "Ann_id in getitem:  48071\n",
      "Test inds:  [(942, 3587)]\n",
      "Ann_id in getitem:  22356\n",
      "Test inds:  [(1217, 782)]\n",
      "Ann_id in getitem:  28419\n",
      "Test inds:  [(860, 734)]\n",
      "Ann_id in getitem:  20842\n",
      "Test inds:  [(1831, 1546)]\n",
      "Ann_id in getitem:  42080\n",
      "Test inds:  [(3484, 2892)]\n",
      "Ann_id in getitem:  80271\n",
      "Test inds:  [(1274, 1970)]\n",
      "Ann_id in getitem:  29720\n",
      "Test inds:  [(3411, 2603)]\n",
      "Ann_id in getitem:  78612\n",
      "Test inds:  [(2575, 526)]\n",
      "Ann_id in getitem:  58679\n",
      "Test inds:  [(2207, 1782)]\n",
      "Ann_id in getitem:  49688\n",
      "Test inds:  [(740, 3321)]\n",
      "Ann_id in getitem:  17962\n",
      "Test inds:  [(906, 2538)]\n",
      "Ann_id in getitem:  21608\n",
      "Test inds:  [(288, 2821)]\n",
      "Ann_id in getitem:  6725\n",
      "Test inds:  [(2690, 2888)]\n",
      "Ann_id in getitem:  61838\n",
      "Test inds:  [(24, 3508)]\n",
      "Ann_id in getitem:  478\n",
      "Test inds:  [(423, 433)]\n",
      "Ann_id in getitem:  10264\n",
      "Test inds:  [(2221, 765)]\n",
      "Ann_id in getitem:  49983\n",
      "Test inds:  [(2151, 3051)]\n",
      "Ann_id in getitem:  48589\n",
      "Test inds:  [(227, 150)]\n",
      "Ann_id in getitem:  5535\n",
      "Test inds:  [(2919, 3432)]\n",
      "Ann_id in getitem:  67228\n",
      "Test inds:  [(1564, 1613)]\n",
      "Ann_id in getitem:  36955\n",
      "Test inds:  [(3173, 2088)]\n",
      "Ann_id in getitem:  73071\n",
      "Test inds:  [(3263, 3430)]\n",
      "Ann_id in getitem:  74856\n",
      "Test inds:  [(2597, 143)]\n",
      "Ann_id in getitem:  59499\n",
      "Test inds:  [(239, 698)]\n",
      "Ann_id in getitem:  5812\n",
      "Test inds:  [(1323, 915)]\n",
      "Ann_id in getitem:  30918\n",
      "Test inds:  [(2676, 460)]\n",
      "Ann_id in getitem:  61382\n",
      "Test inds:  [(723, 1223)]\n",
      "Ann_id in getitem:  17536\n",
      "Test inds:  [(2978, 2006)]\n",
      "Ann_id in getitem:  68624\n",
      "Test inds:  [(2269, 160)]\n",
      "Ann_id in getitem:  51256\n",
      "Test inds:  [(834, 2527)]\n",
      "Ann_id in getitem:  20024\n",
      "Test inds:  [(2443, 3001)]\n",
      "Ann_id in getitem:  55515\n",
      "Test inds:  [(619, 1530)]\n",
      "Ann_id in getitem:  15172\n",
      "Test inds:  [(3136, 2475)]\n",
      "Ann_id in getitem:  72308\n",
      "Test inds:  [(1780, 2010)]\n",
      "Ann_id in getitem:  41085\n",
      "Test inds:  [(2699, 2325)]\n",
      "Ann_id in getitem:  62015\n",
      "Test inds:  [(1817, 2282)]\n",
      "Ann_id in getitem:  41838\n",
      "Test inds:  [(1121, 483)]\n",
      "Ann_id in getitem:  26049\n",
      "Test inds:  [(2684, 2322)]\n",
      "Ann_id in getitem:  61636\n",
      "Test inds:  [(1400, 411)]\n",
      "Ann_id in getitem:  33182\n",
      "Test inds:  [(563, 2725)]\n",
      "Ann_id in getitem:  13557\n",
      "Test inds:  [(3633, 3038)]\n",
      "Ann_id in getitem:  83855\n",
      "Test inds:  [(316, 1426)]\n",
      "Ann_id in getitem:  7717\n",
      "Test inds:  [(1819, 3092)]\n",
      "Ann_id in getitem:  41869\n",
      "Test inds:  [(1103, 2695)]\n",
      "Ann_id in getitem:  25651\n",
      "Test inds:  [(1567, 2714)]\n",
      "Ann_id in getitem:  36999\n",
      "Test inds:  [(3357, 2793)]\n",
      "Ann_id in getitem:  77015\n",
      "Test inds:  [(3419, 734)]\n",
      "Ann_id in getitem:  78749\n",
      "Test inds:  [(21, 3400)]\n",
      "Ann_id in getitem:  455\n",
      "Test inds:  [(3682, 84)]\n",
      "Ann_id in getitem:  84878\n",
      "Test inds:  [(3151, 3169)]\n",
      "Ann_id in getitem:  72632\n",
      "Test inds:  [(996, 217)]\n",
      "Ann_id in getitem:  23661\n",
      "Test inds:  [(3663, 3583)]\n",
      "Ann_id in getitem:  84593\n",
      "Test inds:  [(2245, 172)]\n",
      "Ann_id in getitem:  50744\n",
      "Test inds:  [(1836, 3399)]\n",
      "Ann_id in getitem:  42166\n",
      "Test inds:  [(644, 1233)]\n",
      "Ann_id in getitem:  15620\n",
      "Test inds:  [(3275, 2490)]\n",
      "Ann_id in getitem:  75029\n",
      "Test inds:  [(657, 1237)]\n",
      "Ann_id in getitem:  16073\n",
      "Test inds:  [(2655, 1847)]\n",
      "Ann_id in getitem:  60891\n",
      "Test inds:  [(1049, 596)]\n",
      "Ann_id in getitem:  24779\n",
      "Test inds:  [(377, 3094)]\n",
      "Ann_id in getitem:  9180\n",
      "Test inds:  [(3229, 2602)]\n",
      "Ann_id in getitem:  74217\n",
      "Test inds:  [(2178, 1355)]\n",
      "Ann_id in getitem:  49112\n",
      "Test inds:  [(2842, 1516)]\n",
      "Ann_id in getitem:  65439\n",
      "Test inds:  [(2297, 2859)]\n",
      "Ann_id in getitem:  51834\n",
      "Test inds:  [(770, 638)]\n",
      "Ann_id in getitem:  18651\n",
      "Test inds:  [(3345, 1532)]\n",
      "Ann_id in getitem:  76870\n",
      "Test inds:  [(1715, 1758)]\n",
      "Ann_id in getitem:  40070\n",
      "Test inds:  [(2414, 2384)]\n",
      "Ann_id in getitem:  54601\n",
      "Test inds:  [(2315, 821)]\n",
      "Ann_id in getitem:  52174\n",
      "Test inds:  [(1693, 3369)]\n",
      "Ann_id in getitem:  39688\n",
      "Test inds:  [(2910, 3021)]\n",
      "Ann_id in getitem:  67092\n",
      "Test inds:  [(2629, 1961)]\n",
      "Ann_id in getitem:  60199\n",
      "Test inds:  [(2907, 3535)]\n",
      "Ann_id in getitem:  67051\n",
      "Test inds:  [(2193, 1965)]\n",
      "Ann_id in getitem:  49374\n",
      "Test inds:  [(2939, 706)]\n",
      "Ann_id in getitem:  67698\n",
      "Test inds:  [(838, 1007)]\n",
      "Ann_id in getitem:  20143\n",
      "Test inds:  [(1256, 1843)]\n",
      "Ann_id in getitem:  29448\n",
      "Test inds:  [(2030, 1219)]\n",
      "Ann_id in getitem:  46193\n",
      "Test inds:  [(2211, 3407)]\n",
      "Ann_id in getitem:  49740\n",
      "Test inds:  [(2129, 991)]\n",
      "Ann_id in getitem:  48222\n",
      "Test inds:  [(340, 2521)]\n",
      "Ann_id in getitem:  8272\n",
      "Test inds:  [(1958, 1183)]\n",
      "Ann_id in getitem:  44511\n",
      "Test inds:  [(2892, 2488)]\n",
      "Ann_id in getitem:  66507\n",
      "Test inds:  [(1366, 2111)]\n",
      "Ann_id in getitem:  32215\n",
      "Test inds:  [(2186, 1360)]\n",
      "Ann_id in getitem:  49244\n",
      "Test inds:  [(1849, 493)]\n",
      "Ann_id in getitem:  42562\n",
      "Test inds:  [(3341, 1747)]\n",
      "Ann_id in getitem:  76812\n",
      "Test inds:  [(1578, 1359)]\n",
      "Ann_id in getitem:  37339\n",
      "Test inds:  [(2641, 2707)]\n",
      "Ann_id in getitem:  60472\n",
      "Test inds:  [(1207, 3665)]\n",
      "Ann_id in getitem:  28141\n",
      "Test inds:  [(3323, 957)]\n",
      "Ann_id in getitem:  76368\n",
      "Test inds:  [(1760, 2182)]\n",
      "Ann_id in getitem:  40732\n",
      "Test inds:  [(1296, 1177)]\n",
      "Ann_id in getitem:  30399\n",
      "Test inds:  [(1281, 707)]\n",
      "Ann_id in getitem:  29996\n",
      "Test inds:  [(635, 894)]\n",
      "Ann_id in getitem:  15441\n",
      "Test inds:  [(1959, 1849)]\n",
      "Ann_id in getitem:  44542\n",
      "Test inds:  [(1137, 887)]\n",
      "Ann_id in getitem:  26499\n",
      "Test inds:  [(2146, 1004)]\n",
      "Ann_id in getitem:  48531\n",
      "Test inds:  [(315, 1107)]\n",
      "Ann_id in getitem:  7679\n",
      "Test inds:  [(98, 2017)]\n",
      "Ann_id in getitem:  2158\n",
      "Test inds:  [(972, 133)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(334, 592)]\n",
      "Ann_id in getitem:  8173\n",
      "Test inds:  [(1957, 2433)]\n",
      "Ann_id in getitem:  44503\n",
      "Test inds:  [(1422, 2551)]\n",
      "Ann_id in getitem:  33737\n",
      "Test inds:  [(1393, 2324)]\n",
      "Ann_id in getitem:  33092\n",
      "Test inds:  [(1808, 3628)]\n",
      "Ann_id in getitem:  41703\n",
      "Test inds:  [(665, 173)]\n",
      "Ann_id in getitem:  16182\n",
      "Test inds:  [(2553, 3033)]\n",
      "Ann_id in getitem:  58014\n",
      "Test inds:  [(2900, 3564)]\n",
      "Ann_id in getitem:  66668\n",
      "Test inds:  [(3376, 2273)]\n",
      "Ann_id in getitem:  77651\n",
      "Test inds:  [(57, 1102)]\n",
      "Ann_id in getitem:  1221\n",
      "Test inds:  [(1811, 839)]\n",
      "Ann_id in getitem:  41728\n",
      "Test inds:  [(513, 3606)]\n",
      "Ann_id in getitem:  12261\n",
      "Test inds:  [(197, 1052)]\n",
      "Ann_id in getitem:  4957\n",
      "Test inds:  [(1269, 2045)]\n",
      "Ann_id in getitem:  29634\n",
      "Test inds:  [(3400, 1091)]\n",
      "Ann_id in getitem:  78214\n",
      "Test inds:  [(2460, 2503)]\n",
      "Ann_id in getitem:  55940\n",
      "Test inds:  [(864, 2835)]\n",
      "Ann_id in getitem:  20900\n",
      "Test inds:  [(2816, 3249)]\n",
      "Ann_id in getitem:  64887\n",
      "Test inds:  [(535, 1873)]\n",
      "Ann_id in getitem:  12731\n",
      "Test inds:  [(2357, 2912)]\n",
      "Ann_id in getitem:  53296\n",
      "Test inds:  [(1947, 2206)]\n",
      "Ann_id in getitem:  44320\n",
      "Test inds:  [(2148, 577)]\n",
      "Ann_id in getitem:  48554\n",
      "Test inds:  [(3403, 432)]\n",
      "Ann_id in getitem:  78319\n",
      "Test inds:  [(2689, 466)]\n",
      "Ann_id in getitem:  61729\n",
      "Test inds:  [(560, 335)]\n",
      "Ann_id in getitem:  13506\n",
      "Test inds:  [(2614, 3164)]\n",
      "Ann_id in getitem:  59861\n",
      "Test inds:  [(4, 2518)]\n",
      "Ann_id in getitem:  98\n",
      "Test inds:  [(340, 2547)]\n",
      "Ann_id in getitem:  8272\n",
      "Test inds:  [(2202, 2975)]\n",
      "Ann_id in getitem:  49584\n",
      "Test inds:  [(3652, 2373)]\n",
      "Ann_id in getitem:  84310\n",
      "Test inds:  [(3038, 3322)]\n",
      "Ann_id in getitem:  70026\n",
      "Test inds:  [(708, 1042)]\n",
      "Ann_id in getitem:  17161\n",
      "Test inds:  [(1, 3439)]\n",
      "Ann_id in getitem:  38\n",
      "Test inds:  [(2836, 279)]\n",
      "Ann_id in getitem:  65379\n",
      "Test inds:  [(296, 1702)]\n",
      "Ann_id in getitem:  6842\n",
      "Test inds:  [(204, 2016)]\n",
      "Ann_id in getitem:  5037\n",
      "Test inds:  [(514, 1291)]\n",
      "Ann_id in getitem:  12312\n",
      "Test inds:  [(2538, 813)]\n",
      "Ann_id in getitem:  57603\n",
      "Test inds:  [(3457, 1980)]\n",
      "Ann_id in getitem:  79754\n",
      "Test inds:  [(1884, 2836)]\n",
      "Ann_id in getitem:  43361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(1750, 1288)]\n",
      "Ann_id in getitem:  40556\n",
      "Test inds:  [(3394, 3316)]\n",
      "Ann_id in getitem:  78013\n",
      "Test inds:  [(1962, 1888)]\n",
      "Ann_id in getitem:  44627\n",
      "Test inds:  [(877, 3445)]\n",
      "Ann_id in getitem:  21051\n",
      "Test inds:  [(793, 3084)]\n",
      "Ann_id in getitem:  19206\n",
      "Test inds:  [(325, 490)]\n",
      "Ann_id in getitem:  7993\n",
      "Test inds:  [(2267, 674)]\n",
      "Ann_id in getitem:  51199\n",
      "Test inds:  [(409, 1762)]\n",
      "Ann_id in getitem:  10030\n",
      "Test inds:  [(2521, 665)]\n",
      "Ann_id in getitem:  57302\n",
      "Test inds:  [(1167, 2196)]\n",
      "Ann_id in getitem:  27174\n",
      "Test inds:  [(2304, 2482)]\n",
      "Ann_id in getitem:  51975\n",
      "Test inds:  [(3658, 2113)]\n",
      "Ann_id in getitem:  84486\n",
      "Test inds:  [(477, 2319)]\n",
      "Ann_id in getitem:  11517\n",
      "Test inds:  [(520, 3612)]\n",
      "Ann_id in getitem:  12426\n",
      "Test inds:  [(138, 1138)]\n",
      "Ann_id in getitem:  3365\n",
      "Test inds:  [(3163, 2459)]\n",
      "Ann_id in getitem:  72875\n",
      "Test inds:  [(2137, 2182)]\n",
      "Ann_id in getitem:  48404\n",
      "Test inds:  [(2062, 2822)]\n",
      "Ann_id in getitem:  46911\n",
      "Test inds:  [(3223, 1907)]\n",
      "Ann_id in getitem:  74111\n",
      "Test inds:  [(2693, 2738)]\n",
      "Ann_id in getitem:  61915\n",
      "Test inds:  [(1150, 1958)]\n",
      "Ann_id in getitem:  26767\n",
      "Test inds:  [(1570, 1398)]\n",
      "Ann_id in getitem:  37172\n",
      "Test inds:  [(2664, 1570)]\n",
      "Ann_id in getitem:  61098\n",
      "Test inds:  [(2757, 685)]\n",
      "Ann_id in getitem:  63417\n",
      "Test inds:  [(1932, 1466)]\n",
      "Ann_id in getitem:  44097\n",
      "Test inds:  [(79, 238)]\n",
      "Ann_id in getitem:  1774\n",
      "Test inds:  [(3523, 271)]\n",
      "Ann_id in getitem:  81287\n",
      "Test inds:  [(234, 2597)]\n",
      "Ann_id in getitem:  5689\n",
      "Test inds:  [(2456, 2598)]\n",
      "Ann_id in getitem:  55772\n",
      "Test inds:  [(2624, 3497)]\n",
      "Ann_id in getitem:  59987\n",
      "Test inds:  [(2834, 1511)]\n",
      "Ann_id in getitem:  65337\n",
      "Test inds:  [(699, 563)]\n",
      "Ann_id in getitem:  16995\n",
      "Test inds:  [(3107, 3095)]\n",
      "Ann_id in getitem:  71706\n",
      "Test inds:  [(1929, 757)]\n",
      "Ann_id in getitem:  44065\n",
      "Test inds:  [(2194, 3237)]\n",
      "Ann_id in getitem:  49381\n",
      "Test inds:  [(3398, 2987)]\n",
      "Ann_id in getitem:  78160\n",
      "Test inds:  [(2092, 2831)]\n",
      "Ann_id in getitem:  47407\n",
      "Test inds:  [(834, 1410)]\n",
      "Ann_id in getitem:  20024\n",
      "Test inds:  [(1486, 926)]\n",
      "Ann_id in getitem:  35288\n",
      "Test inds:  [(1741, 2524)]\n",
      "Ann_id in getitem:  40458\n",
      "Test inds:  [(3415, 107)]\n",
      "Ann_id in getitem:  78683\n",
      "Test inds:  [(3324, 3221)]\n",
      "Ann_id in getitem:  76380\n",
      "Test inds:  [(715, 2015)]\n",
      "Ann_id in getitem:  17336\n",
      "Test inds:  [(2947, 3548)]\n",
      "Ann_id in getitem:  67910\n",
      "Test inds:  [(3043, 1439)]\n",
      "Ann_id in getitem:  70139\n",
      "Test inds:  [(2227, 1979)]\n",
      "Ann_id in getitem:  50158\n",
      "Test inds:  [(2319, 3500)]\n",
      "Ann_id in getitem:  52223\n",
      "Test inds:  [(1308, 1792)]\n",
      "Ann_id in getitem:  30609\n",
      "Test inds:  [(1874, 304)]\n",
      "Ann_id in getitem:  43127\n",
      "Test inds:  [(2976, 9)]\n",
      "Ann_id in getitem:  68563\n",
      "Test inds:  [(471, 2874)]\n",
      "Ann_id in getitem:  11319\n",
      "Test inds:  [(2502, 2964)]\n",
      "Ann_id in getitem:  57008\n",
      "Test inds:  [(1300, 2291)]\n",
      "Ann_id in getitem:  30486\n",
      "Test inds:  [(2632, 3067)]\n",
      "Ann_id in getitem:  60263\n",
      "Test inds:  [(634, 3202)]\n",
      "Ann_id in getitem:  15425\n",
      "Test inds:  [(330, 2529)]\n",
      "Ann_id in getitem:  8089\n",
      "Test inds:  [(1300, 769)]\n",
      "Ann_id in getitem:  30486\n",
      "Test inds:  [(131, 482)]\n",
      "Ann_id in getitem:  3192\n",
      "Test inds:  [(1086, 737)]\n",
      "Ann_id in getitem:  25327\n",
      "Test inds:  [(1318, 2747)]\n",
      "Ann_id in getitem:  30830\n",
      "Test inds:  [(1678, 1948)]\n",
      "Ann_id in getitem:  39292\n",
      "Test inds:  [(896, 2898)]\n",
      "Ann_id in getitem:  21497\n",
      "Test inds:  [(1575, 2930)]\n",
      "Ann_id in getitem:  37304\n",
      "Test inds:  [(966, 47)]\n",
      "Ann_id in getitem:  22854\n",
      "Test inds:  [(1841, 3243)]\n",
      "Ann_id in getitem:  42253\n",
      "Test inds:  [(1822, 1966)]\n",
      "Ann_id in getitem:  41928\n",
      "Test inds:  [(980, 1308)]\n",
      "Ann_id in getitem:  23129\n",
      "Test inds:  [(2451, 2789)]\n",
      "Ann_id in getitem:  55680\n",
      "Test inds:  [(1195, 2751)]\n",
      "Ann_id in getitem:  27841\n",
      "Test inds:  [(2954, 2567)]\n",
      "Ann_id in getitem:  68034\n",
      "Test inds:  [(2247, 416)]\n",
      "Ann_id in getitem:  50758\n",
      "Test inds:  [(3380, 3600)]\n",
      "Ann_id in getitem:  77732\n",
      "Test inds:  [(1300, 1062)]\n",
      "Ann_id in getitem:  30486\n",
      "Test inds:  [(837, 2306)]\n",
      "Ann_id in getitem:  20078\n",
      "Test inds:  [(1581, 1291)]\n",
      "Ann_id in getitem:  37371\n",
      "Test inds:  [(2158, 2835)]\n",
      "Ann_id in getitem:  48679\n",
      "Test inds:  [(1022, 813)]\n",
      "Ann_id in getitem:  24168\n",
      "Test inds:  [(3007, 817)]\n",
      "Ann_id in getitem:  69275\n",
      "Test inds:  [(2304, 2854)]\n",
      "Ann_id in getitem:  51975\n",
      "Test inds:  [(2090, 3239)]\n",
      "Ann_id in getitem:  47399\n",
      "Test inds:  [(3645, 287)]\n",
      "Ann_id in getitem:  84145\n",
      "Test inds:  [(283, 2217)]\n",
      "Ann_id in getitem:  6647\n",
      "Test inds:  [(1693, 1907)]\n",
      "Ann_id in getitem:  39688\n",
      "Test inds:  [(1950, 825)]\n",
      "Ann_id in getitem:  44354\n",
      "Test inds:  [(2195, 1077)]\n",
      "Ann_id in getitem:  49448\n",
      "Test inds:  [(3131, 1891)]\n",
      "Ann_id in getitem:  72184\n",
      "Test inds:  [(2390, 1012)]\n",
      "Ann_id in getitem:  54109\n",
      "Test inds:  [(1298, 1716)]\n",
      "Ann_id in getitem:  30473\n",
      "Test inds:  [(2581, 780)]\n",
      "Ann_id in getitem:  58998\n",
      "Test inds:  [(3645, 2810)]\n",
      "Ann_id in getitem:  84145\n",
      "Test inds:  [(1900, 2938)]\n",
      "Ann_id in getitem:  43579\n",
      "Test inds:  [(731, 1407)]\n",
      "Ann_id in getitem:  17755\n",
      "Test inds:  [(354, 3044)]\n",
      "Ann_id in getitem:  8522\n",
      "Test inds:  [(1250, 10)]\n",
      "Ann_id in getitem:  29280\n",
      "Test inds:  [(1275, 3133)]\n",
      "Ann_id in getitem:  29838\n",
      "Test inds:  [(2323, 2379)]\n",
      "Ann_id in getitem:  52330\n",
      "Test inds:  [(3273, 2945)]\n",
      "Ann_id in getitem:  74988\n",
      "Test inds:  [(185, 1316)]\n",
      "Ann_id in getitem:  4731\n",
      "Test inds:  [(1928, 1409)]\n",
      "Ann_id in getitem:  44042\n",
      "Test inds:  [(1660, 610)]\n",
      "Ann_id in getitem:  38852\n",
      "Test inds:  [(1248, 2660)]\n",
      "Ann_id in getitem:  29247\n",
      "Test inds:  [(2583, 3217)]\n",
      "Ann_id in getitem:  59052\n",
      "Test inds:  [(2933, 3200)]\n",
      "Ann_id in getitem:  67558\n",
      "Test inds:  [(185, 1998)]\n",
      "Ann_id in getitem:  4731\n",
      "Test inds:  [(3211, 586)]\n",
      "Ann_id in getitem:  73815\n",
      "Test inds:  [(972, 496)]\n",
      "Ann_id in getitem:  22947\n",
      "Test inds:  [(1506, 2976)]\n",
      "Ann_id in getitem:  35757\n",
      "Test inds:  [(690, 2939)]\n",
      "Ann_id in getitem:  16819\n",
      "Test inds:  [(486, 2368)]\n",
      "Ann_id in getitem:  11702\n",
      "Test inds:  [(110, 1748)]\n",
      "Ann_id in getitem:  2599\n",
      "Test inds:  [(2709, 321)]\n",
      "Ann_id in getitem:  62332\n",
      "Test inds:  [(3446, 2533)]\n",
      "Ann_id in getitem:  79388\n",
      "Test inds:  [(863, 2542)]\n",
      "Ann_id in getitem:  20885\n",
      "Test inds:  [(2020, 2820)]\n",
      "Ann_id in getitem:  45905\n",
      "Test inds:  [(3621, 1631)]\n",
      "Ann_id in getitem:  83575\n",
      "Test inds:  [(981, 2078)]\n",
      "Ann_id in getitem:  23182\n",
      "Test inds:  [(461, 2297)]\n",
      "Ann_id in getitem:  11138\n",
      "Test inds:  [(2736, 761)]\n",
      "Ann_id in getitem:  63007\n",
      "Test inds:  [(2589, 523)]\n",
      "Ann_id in getitem:  59359\n",
      "Test inds:  [(1679, 2029)]\n",
      "Ann_id in getitem:  39303\n",
      "Test inds:  [(3301, 289)]\n",
      "Ann_id in getitem:  75728\n",
      "Test inds:  [(2451, 1320)]\n",
      "Ann_id in getitem:  55680\n",
      "Test inds:  [(2339, 2944)]\n",
      "Ann_id in getitem:  52740\n",
      "Test inds:  [(3089, 3671)]\n",
      "Ann_id in getitem:  71229\n",
      "Test inds:  [(2243, 2556)]\n",
      "Ann_id in getitem:  50665\n",
      "Test inds:  [(614, 1297)]\n",
      "Ann_id in getitem:  15059\n",
      "Test inds:  [(2047, 2350)]\n",
      "Ann_id in getitem:  46652\n",
      "Test inds:  [(604, 2325)]\n",
      "Ann_id in getitem:  14618\n",
      "Test inds:  [(2163, 3229)]\n",
      "Ann_id in getitem:  48782\n",
      "Test inds:  [(1062, 1921)]\n",
      "Ann_id in getitem:  24993\n",
      "Test inds:  [(319, 2215)]\n",
      "Ann_id in getitem:  7777\n",
      "Test inds:  [(2260, 2544)]\n",
      "Ann_id in getitem:  51083\n",
      "Test inds:  [(21, 272)]\n",
      "Ann_id in getitem:  455\n",
      "Test inds:  [(1017, 3268)]\n",
      "Ann_id in getitem:  24110\n",
      "Test inds:  [(2157, 1927)]\n",
      "Ann_id in getitem:  48662\n",
      "Test inds:  [(172, 691)]\n",
      "Ann_id in getitem:  4355\n",
      "Test inds:  [(601, 770)]\n",
      "Ann_id in getitem:  14564\n",
      "Test inds:  [(889, 2721)]\n",
      "Ann_id in getitem:  21210\n",
      "Test inds:  [(2538, 513)]\n",
      "Ann_id in getitem:  57603\n",
      "Test inds:  [(2843, 3302)]\n",
      "Ann_id in getitem:  65444\n",
      "Test inds:  [(2540, 1146)]\n",
      "Ann_id in getitem:  57675\n",
      "Test inds:  [(1510, 2145)]\n",
      "Ann_id in getitem:  35827\n",
      "Test inds:  [(2682, 2251)]\n",
      "Ann_id in getitem:  61596\n",
      "Test inds:  [(2894, 3143)]\n",
      "Ann_id in getitem:  66573\n",
      "Test inds:  [(1697, 3185)]\n",
      "Ann_id in getitem:  39786\n",
      "Test inds:  [(2067, 679)]\n",
      "Ann_id in getitem:  46993\n",
      "Test inds:  [(3171, 136)]\n",
      "Ann_id in getitem:  73055\n",
      "Test inds:  [(2569, 34)]\n",
      "Ann_id in getitem:  58460\n",
      "Test inds:  [(700, 2215)]\n",
      "Ann_id in getitem:  17004\n",
      "Test inds:  [(285, 4)]\n",
      "Ann_id in getitem:  6672\n",
      "Test inds:  [(1799, 219)]\n",
      "Ann_id in getitem:  41575\n",
      "Test inds:  [(1878, 3057)]\n",
      "Ann_id in getitem:  43176\n",
      "Test inds:  [(105, 2831)]\n",
      "Ann_id in getitem:  2383\n",
      "Test inds:  [(713, 100)]\n",
      "Ann_id in getitem:  17324\n",
      "Test inds:  [(1413, 2773)]\n",
      "Ann_id in getitem:  33452\n",
      "Test inds:  [(1151, 1381)]\n",
      "Ann_id in getitem:  26781\n",
      "Test inds:  [(470, 2127)]\n",
      "Ann_id in getitem:  11318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inds:  [(2344, 1147)]\n",
      "Ann_id in getitem:  52889\n",
      "Test inds:  [(3226, 1360)]\n",
      "Ann_id in getitem:  74133\n",
      "Test inds:  [(2951, 537)]\n",
      "Ann_id in getitem:  68015\n",
      "Test inds:  [(150, 1479)]\n",
      "Ann_id in getitem:  3728\n",
      "Test inds:  [(3560, 1)]\n",
      "Ann_id in getitem:  82096\n",
      "Test inds:  [(3677, 225)]\n",
      "Ann_id in getitem:  84816\n",
      "Test inds:  [(659, 174)]\n",
      "Ann_id in getitem:  16114\n",
      "Test inds:  [(1611, 1132)]\n",
      "Ann_id in getitem:  37821\n",
      "Test inds:  [(239, 1670)]\n",
      "Ann_id in getitem:  5812\n",
      "Test inds:  [(156, 1118)]\n",
      "Ann_id in getitem:  3903\n",
      "Test inds:  [(3486, 2017)]\n",
      "Ann_id in getitem:  80301\n",
      "Test inds:  [(3263, 3556)]\n",
      "Ann_id in getitem:  74856\n",
      "Test inds:  [(1208, 3630)]\n",
      "Ann_id in getitem:  28145\n",
      "Test inds:  [(1283, 2200)]\n",
      "Ann_id in getitem:  30022\n",
      "Test inds:  [(3149, 585)]\n",
      "Ann_id in getitem:  72598\n",
      "Test inds:  [(3343, 3348)]\n",
      "Ann_id in getitem:  76833\n",
      "Test inds:  [(3167, 3509)]\n",
      "Ann_id in getitem:  72946\n",
      "Test inds:  [(178, 1197)]\n",
      "Ann_id in getitem:  4571\n",
      "Test inds:  [(1894, 2266)]\n",
      "Ann_id in getitem:  43476\n",
      "Test inds:  [(2026, 2876)]\n",
      "Ann_id in getitem:  46047\n",
      "Test inds:  [(2562, 1758)]\n",
      "Ann_id in getitem:  58233\n",
      "Test inds:  [(3434, 66)]\n",
      "Ann_id in getitem:  79157\n",
      "Test inds:  [(2019, 3298)]\n",
      "Ann_id in getitem:  45891\n",
      "Test inds:  [(2528, 1652)]\n",
      "Ann_id in getitem:  57432\n",
      "Test inds:  [(1320, 2730)]\n",
      "Ann_id in getitem:  30875\n",
      "Test inds:  [(2443, 2454)]\n",
      "Ann_id in getitem:  55515\n",
      "Test inds:  [(801, 2465)]\n",
      "Ann_id in getitem:  19378\n",
      "Test inds:  [(52, 3016)]\n",
      "Ann_id in getitem:  1104\n",
      "Test inds:  [(1170, 2963)]\n",
      "Ann_id in getitem:  27224\n",
      "Test inds:  [(748, 708)]\n",
      "Ann_id in getitem:  18037\n",
      "Test inds:  [(237, 1564)]\n",
      "Ann_id in getitem:  5786\n",
      "Test inds:  [(102, 903)]\n",
      "Ann_id in getitem:  2242\n",
      "Test inds:  [(718, 379)]\n",
      "Ann_id in getitem:  17374\n",
      "Test inds:  [(3104, 2818)]\n",
      "Ann_id in getitem:  71627\n",
      "Test inds:  [(2524, 490)]\n",
      "Ann_id in getitem:  57326\n",
      "Test inds:  [(3302, 2341)]\n",
      "Ann_id in getitem:  75751\n",
      "Test inds:  [(1909, 2246)]\n",
      "Ann_id in getitem:  43728\n",
      "Test inds:  [(123, 1950)]\n",
      "Ann_id in getitem:  2946\n",
      "Test inds:  [(2668, 2222)]\n",
      "Ann_id in getitem:  61233\n",
      "Test inds:  [(3387, 1797)]\n",
      "Ann_id in getitem:  77849\n",
      "Test inds:  [(1810, 1561)]\n",
      "Ann_id in getitem:  41711\n",
      "Test inds:  [(378, 3434)]\n",
      "Ann_id in getitem:  9195\n",
      "Test inds:  [(2961, 2283)]\n",
      "Ann_id in getitem:  68145\n",
      "Test inds:  [(267, 1350)]\n",
      "Ann_id in getitem:  6343\n",
      "Test inds:  [(1260, 2398)]\n",
      "Ann_id in getitem:  29512\n",
      "Test inds:  [(3048, 2833)]\n",
      "Ann_id in getitem:  70269\n",
      "Test inds:  [(3326, 2686)]\n",
      "Ann_id in getitem:  76397\n",
      "Test inds:  [(843, 1722)]\n",
      "Ann_id in getitem:  20421\n",
      "Test inds:  [(167, 1775)]\n",
      "Ann_id in getitem:  4205\n",
      "Test inds:  [(468, 3170)]\n",
      "Ann_id in getitem:  11279\n",
      "Test inds:  [(1972, 3126)]\n",
      "Ann_id in getitem:  44986\n",
      "Test inds:  [(687, 2138)]\n",
      "Ann_id in getitem:  16726\n",
      "Test inds:  [(745, 1916)]\n",
      "Ann_id in getitem:  18018\n",
      "Test inds:  [(1317, 1305)]\n",
      "Ann_id in getitem:  30813\n",
      "Test inds:  [(316, 3329)]\n",
      "Ann_id in getitem:  7717\n",
      "Test inds:  [(545, 3235)]\n",
      "Ann_id in getitem:  12973\n",
      "Test inds:  [(2138, 641)]\n",
      "Ann_id in getitem:  48446\n",
      "Test inds:  [(188, 318)]\n",
      "Ann_id in getitem:  4774\n",
      "Test inds:  [(2089, 120)]\n",
      "Ann_id in getitem:  47397\n",
      "Test inds:  [(2162, 3041)]\n",
      "Ann_id in getitem:  48777\n",
      "Test inds:  [(1632, 2616)]\n",
      "Ann_id in getitem:  38294\n",
      "Test inds:  [(3077, 1405)]\n",
      "Ann_id in getitem:  70935\n",
      "Test inds:  [(2295, 2065)]\n",
      "Ann_id in getitem:  51786\n",
      "Test inds:  [(2864, 1402)]\n",
      "Ann_id in getitem:  65865\n",
      "Test inds:  [(2186, 567)]\n",
      "Ann_id in getitem:  49244\n",
      "Test inds:  [(1329, 2400)]\n",
      "Ann_id in getitem:  31225\n",
      "Test inds:  [(1228, 2074)]\n",
      "Ann_id in getitem:  28712\n",
      "Test inds:  [(1363, 1335)]\n",
      "Ann_id in getitem:  32112\n",
      "Test inds:  [(1884, 2674)]\n",
      "Ann_id in getitem:  43361\n",
      "Test inds:  [(902, 150)]\n",
      "Ann_id in getitem:  21581\n",
      "Test inds:  [(1135, 1010)]\n",
      "Ann_id in getitem:  26486\n",
      "Test inds:  [(2722, 542)]\n",
      "Ann_id in getitem:  62553\n",
      "Test inds:  [(242, 1463)]\n",
      "Ann_id in getitem:  5871\n",
      "Test inds:  [(1311, 86)]\n",
      "Ann_id in getitem:  30678\n",
      "Test inds:  [(562, 1029)]\n",
      "Ann_id in getitem:  13542\n",
      "Test inds:  [(2803, 367)]\n",
      "Ann_id in getitem:  64675\n",
      "Test inds:  [(1575, 492)]\n",
      "Ann_id in getitem:  37304\n",
      "Test inds:  [(2886, 439)]\n",
      "Ann_id in getitem:  66410\n",
      "Test inds:  [(336, 3270)]\n",
      "Ann_id in getitem:  8206\n",
      "Test inds:  [(1324, 3473)]\n",
      "Ann_id in getitem:  30963\n",
      "Test inds:  [(2898, 230)]\n",
      "Ann_id in getitem:  66643\n",
      "Test inds:  [(2313, 3690)]\n",
      "Ann_id in getitem:  52133\n"
     ]
    }
   ],
   "source": [
    "# create dicts\n",
    "orig_captions = []\n",
    "decoder_token0_captions = []\n",
    "decoder_prepend_captions = []\n",
    "\n",
    "# iterate over dataset\n",
    "for i in range(len(test_ds)):\n",
    "    test_indices = data_loader_test.dataset.get_func_train_indices() \n",
    "    print(\"Test inds: \", test_indices)\n",
    "    # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "    new_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices=test_indices)\n",
    "    data_loader_test.batch_sampler.sampler = new_sampler  \n",
    "\n",
    "    orig_image, dist_image, cap = next(iter(data_loader_test))\n",
    "    orig_captions.append(cap)\n",
    "    \n",
    "    # get the predictions\n",
    "    # model with prepended images\n",
    "    features_t_emb, _ = encoder_prepend(orig_image)\n",
    "    features_d_emb, _ = encoder_prepend(dist_image)\n",
    "    both_images = torch.cat((features_t_emb, features_d_emb), dim=-1)\n",
    "\n",
    "    output_prepend, log_p, raw = decoder_prepend.sample(both_images.unsqueeze(1), 27)\n",
    "    sentence_prepend = clean_sentence(output_prepend)\n",
    "    decoder_prepend_captions.append(sentence_prepend)\n",
    "    \n",
    "    # model with token 0 images\n",
    "    features_t_emb, _ = encoder_token0(orig_image)\n",
    "    features_d_emb, _ = encoder_token0(dist_image)\n",
    "    both_images = torch.cat((features_t_emb, features_d_emb), dim=-1)\n",
    "\n",
    "    output_token0, log_p, raw = decoder_token0.sample(both_images.unsqueeze(1), 27)\n",
    "    sentence_token0 = clean_sentence(output_token0)\n",
    "    decoder_token0_captions.append(sentence_token0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae7e2e5f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-ebe6c98e1674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdecoder_token0_captions_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder_token0_captions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoder_prepend_captions_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder_prepend_captions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0morig_caption_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morig_captions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbleu_token0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_token0_captions_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_caption_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-ebe6c98e1674>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdecoder_token0_captions_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder_token0_captions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoder_prepend_captions_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder_prepend_captions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0morig_caption_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morig_captions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbleu_token0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_token0_captions_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_caption_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \"\"\"\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \"\"\"\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \"\"\"\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \"\"\"\n\u001b[1;32m   1420\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m             \u001b[0msentence1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/msc-thesis/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_match_potential_end_contexts\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0mbefore_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;31m# Ignore matches that have already been captured by matches to the right of this match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbefore_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score \n",
    "from nltk import word_tokenize\n",
    "\n",
    "decoder_token0_captions_tokenized = [word_tokenize(s) for s in decoder_token0_captions]\n",
    "decoder_prepend_captions_tokenized = [word_tokenize(s) for s in decoder_prepend_captions]\n",
    "orig_captions_cleaned = [word_tokenize(clean_sentence(s)) for s in orig_captions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cc05f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for token0 model:  0.0\n",
      "BLEU score for prepending model:  0.0\n"
     ]
    }
   ],
   "source": [
    "bleu_token0 = bleu_score(decoder_token0_captions_tokenized, orig_captions_cleaned, max_n=2, weights=[0.5, 0.5])\n",
    "bleu_prepend = bleu_score(decoder_prepend_captions_tokenized, orig_captions_cleaned, max_n=2, weights=[0.5, 0.5])\n",
    "print(\"BLEU score for token0 model: \", bleu_token0)\n",
    "print(\"BLEU score for prepending model: \", bleu_prepend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7183caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_df = pd.DataFrame({\"ground_truth\": [clean_sentence(s) for s in orig_captions],\n",
    "                       \"prepend_model\": decoder_prepend_captions,\n",
    "                       \"token0_model\": decoder_token0_captions})\n",
    "bleu_df.to_csv(\"decoder_test_BLEU_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1439a7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prepend_model</th>\n",
       "      <th>token0_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A bathroom with a sink and a toilet</td>\n",
       "      <td>Toilet and a toilet in a bathroom . end . end ...</td>\n",
       "      <td>A bathroom with a toilet and sink in it . end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A bathroom with a black and white checkered fl...</td>\n",
       "      <td>Bathroom with a toilet and a toilet . end . en...</td>\n",
       "      <td>A bathroom with a sink and a mirror . end . en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An older man unk up a truck with a bicycle in ...</td>\n",
       "      <td>Red truck is parked in a parking lot . end . e...</td>\n",
       "      <td>A person is standing next to a car . end . end...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A brown purse is sitting on a green bench .</td>\n",
       "      <td>Cat is sitting on a bench . end . end . end . ...</td>\n",
       "      <td>A woman is sitting on a bench in front of a mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A desk with multiple computer screens forming ...</td>\n",
       "      <td>Desk with a laptop computer on a desk . end . ...</td>\n",
       "      <td>A desk with a laptop computer and a keyboard ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A man in a red shirt and black pants resting o...</td>\n",
       "      <td>Man is standing on a bench . end . end . end ....</td>\n",
       "      <td>A woman is sitting on a bench in the rain . en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A lap top computer next to a computer monitor ...</td>\n",
       "      <td>Laptop computer on a desk with a laptop comput...</td>\n",
       "      <td>A laptop computer sitting on a desk . end . en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A black cat standing in front of a motorcycle</td>\n",
       "      <td>Black and white dog standing next to a motorcy...</td>\n",
       "      <td>A black and white photo of a train on a track ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A well decorated toilet seat with unk surround...</td>\n",
       "      <td>White toilet sitting on a table . end . end . ...</td>\n",
       "      <td>A bathroom with a toilet and sink in it end . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Three adults and one child skiing on a snow co...</td>\n",
       "      <td>Group of skiers skiers skiers on skis . end . ...</td>\n",
       "      <td>A man is skiing down a hill on skis . end . en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A black cat with arched back walking past a mo...</td>\n",
       "      <td>Black and white dog is parked in the backgroun...</td>\n",
       "      <td>A black and white dog sitting on a bench . end...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A small girl sitting at a round table next to ...</td>\n",
       "      <td>Kitchen with a white and white cabinets and a ...</td>\n",
       "      <td>A kitchen with a stove top oven and a microwav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A laptop linked with a small screen using cabl...</td>\n",
       "      <td>Laptop computer desk with a laptop computer . ...</td>\n",
       "      <td>A desk with a laptop computer and a keyboard ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A motorcyclist drives down the road with a dog...</td>\n",
       "      <td>Group of people riding a horse on a motorcycle...</td>\n",
       "      <td>A man riding a bike on a street . end . end . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A picture of a bathroom with a toilet , rug , ...</td>\n",
       "      <td>Bathroom with a white toilet and a toilet . en...</td>\n",
       "      <td>A bathroom with a sink and a toilet end . end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A man on a bicycle stands in unk waters .</td>\n",
       "      <td>Woman walking down a street . end . end . end ...</td>\n",
       "      <td>A woman is standing on a street . end . end . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The motorcycle riders are driving down the road .</td>\n",
       "      <td>Person riding a bike on a road . end . end . e...</td>\n",
       "      <td>A person riding a motorcycle on a street . end...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A bathroom with a toilet a sink and a shower</td>\n",
       "      <td>Bathroom with a toilet and a toilet . end . en...</td>\n",
       "      <td>A bathroom with a sink and a toilet end . end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A stone clock tower sits beneath a cloudy blue...</td>\n",
       "      <td>Clock tower with a clock tower . end . end . e...</td>\n",
       "      <td>A clock tower with a clock on it . end . end ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A woman riding a horse in front of a fence wit...</td>\n",
       "      <td>Horse is standing on a horse . end . end . end...</td>\n",
       "      <td>A man riding a horse on a horse . end . end . ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ground_truth  \\\n",
       "0                 A bathroom with a sink and a toilet   \n",
       "1   A bathroom with a black and white checkered fl...   \n",
       "2   An older man unk up a truck with a bicycle in ...   \n",
       "3         A brown purse is sitting on a green bench .   \n",
       "4   A desk with multiple computer screens forming ...   \n",
       "5   A man in a red shirt and black pants resting o...   \n",
       "6   A lap top computer next to a computer monitor ...   \n",
       "7       A black cat standing in front of a motorcycle   \n",
       "8   A well decorated toilet seat with unk surround...   \n",
       "9   Three adults and one child skiing on a snow co...   \n",
       "10  A black cat with arched back walking past a mo...   \n",
       "11  A small girl sitting at a round table next to ...   \n",
       "12  A laptop linked with a small screen using cabl...   \n",
       "13  A motorcyclist drives down the road with a dog...   \n",
       "14  A picture of a bathroom with a toilet , rug , ...   \n",
       "15          A man on a bicycle stands in unk waters .   \n",
       "16  The motorcycle riders are driving down the road .   \n",
       "17       A bathroom with a toilet a sink and a shower   \n",
       "18  A stone clock tower sits beneath a cloudy blue...   \n",
       "19  A woman riding a horse in front of a fence wit...   \n",
       "\n",
       "                                        prepend_model  \\\n",
       "0   Toilet and a toilet in a bathroom . end . end ...   \n",
       "1   Bathroom with a toilet and a toilet . end . en...   \n",
       "2   Red truck is parked in a parking lot . end . e...   \n",
       "3   Cat is sitting on a bench . end . end . end . ...   \n",
       "4   Desk with a laptop computer on a desk . end . ...   \n",
       "5   Man is standing on a bench . end . end . end ....   \n",
       "6   Laptop computer on a desk with a laptop comput...   \n",
       "7   Black and white dog standing next to a motorcy...   \n",
       "8   White toilet sitting on a table . end . end . ...   \n",
       "9   Group of skiers skiers skiers on skis . end . ...   \n",
       "10  Black and white dog is parked in the backgroun...   \n",
       "11  Kitchen with a white and white cabinets and a ...   \n",
       "12  Laptop computer desk with a laptop computer . ...   \n",
       "13  Group of people riding a horse on a motorcycle...   \n",
       "14  Bathroom with a white toilet and a toilet . en...   \n",
       "15  Woman walking down a street . end . end . end ...   \n",
       "16  Person riding a bike on a road . end . end . e...   \n",
       "17  Bathroom with a toilet and a toilet . end . en...   \n",
       "18  Clock tower with a clock tower . end . end . e...   \n",
       "19  Horse is standing on a horse . end . end . end...   \n",
       "\n",
       "                                         token0_model  \n",
       "0   A bathroom with a toilet and sink in it . end ...  \n",
       "1   A bathroom with a sink and a mirror . end . en...  \n",
       "2   A person is standing next to a car . end . end...  \n",
       "3   A woman is sitting on a bench in front of a mi...  \n",
       "4   A desk with a laptop computer and a keyboard ....  \n",
       "5   A woman is sitting on a bench in the rain . en...  \n",
       "6   A laptop computer sitting on a desk . end . en...  \n",
       "7   A black and white photo of a train on a track ...  \n",
       "8   A bathroom with a toilet and sink in it end . ...  \n",
       "9   A man is skiing down a hill on skis . end . en...  \n",
       "10  A black and white dog sitting on a bench . end...  \n",
       "11  A kitchen with a stove top oven and a microwav...  \n",
       "12  A desk with a laptop computer and a keyboard ....  \n",
       "13  A man riding a bike on a street . end . end . ...  \n",
       "14  A bathroom with a sink and a toilet end . end ...  \n",
       "15  A woman is standing on a street . end . end . ...  \n",
       "16  A person riding a motorcycle on a street . end...  \n",
       "17  A bathroom with a sink and a toilet end . end ...  \n",
       "18  A clock tower with a clock on it . end . end ....  \n",
       "19  A man riding a horse on a horse . end . end . ...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c407e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count occurences of images in the sampled img IDs\n",
    "train_ids = torch.load(\"../pretrain_img_IDs_2imgs_512dim_100000imgs.pt\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d485ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_ids = [train_coco.anns[i][\"image_id\"] for i in train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fad164b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[246376, 83328, 302129, 561180, 12224, 184371, 137836, 552052, 263600, 105768]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b8041ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counter = Counter(train_img_ids)\n",
    "train_counter.items()\n",
    "train_counter_singletons = [c for c in list(train_counter.items()) if c[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d30fd76",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(505113, 5),\n",
       " (121557, 5),\n",
       " (72646, 5),\n",
       " (75450, 5),\n",
       " (280494, 5),\n",
       " (10321, 5),\n",
       " (108293, 5),\n",
       " (518124, 5),\n",
       " (314044, 5),\n",
       " (481120, 5),\n",
       " (456035, 5),\n",
       " (43971, 5),\n",
       " (354268, 5),\n",
       " (78667, 5),\n",
       " (473462, 5),\n",
       " (172012, 5),\n",
       " (119979, 5),\n",
       " (159723, 5),\n",
       " (268105, 5),\n",
       " (236759, 5),\n",
       " (325206, 5),\n",
       " (63109, 5),\n",
       " (4978, 5),\n",
       " (462261, 5),\n",
       " (362591, 5),\n",
       " (326750, 5),\n",
       " (121589, 5),\n",
       " (31017, 5),\n",
       " (173482, 5),\n",
       " (479949, 5),\n",
       " (188482, 5),\n",
       " (87234, 5),\n",
       " (450212, 5),\n",
       " (342681, 5),\n",
       " (424867, 5),\n",
       " (222411, 5),\n",
       " (369230, 5),\n",
       " (382958, 5),\n",
       " (234000, 5),\n",
       " (487245, 5),\n",
       " (507828, 5),\n",
       " (127268, 5),\n",
       " (482984, 5),\n",
       " (295280, 5),\n",
       " (85731, 5),\n",
       " (40732, 5),\n",
       " (79513, 5),\n",
       " (526312, 5),\n",
       " (226899, 5),\n",
       " (418135, 5),\n",
       " (525660, 5),\n",
       " (64350, 5),\n",
       " (355629, 5),\n",
       " (266486, 5),\n",
       " (237903, 5),\n",
       " (209304, 5),\n",
       " (438479, 5),\n",
       " (550353, 5),\n",
       " (399001, 5),\n",
       " (288397, 5),\n",
       " (521775, 5),\n",
       " (399332, 5),\n",
       " (34039, 5),\n",
       " (106874, 5),\n",
       " (197780, 5),\n",
       " (134712, 5),\n",
       " (125699, 5),\n",
       " (556763, 5),\n",
       " (190084, 4),\n",
       " (563986, 4)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(train_counter.items(), key=lambda item: item[1], reverse = True)[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "edc1c899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33051"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_counter_singletons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fedda987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the train image features with ann ids\n",
    "saved_fts = torch.load(\"../COCO_train_ResNet_features_reshaped.pt\")\n",
    "raw_ann_ids = list(coco_train.anns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f79d756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(raw_ann_ids)\n",
    "raw_ann_ids[0]\n",
    "saved_fts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "329a62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict\n",
    "saved_fts_dict = {}\n",
    "for num, i in enumerate(raw_ann_ids):\n",
    "    saved_fts_dict[str(i)] = saved_fts[num, :].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42f770c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(saved_fts_dict.keys())[0]\n",
    "saved_fts_dict['48'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dd0de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(saved_fts_dict, \"../COCO_train_ResNet_features_reshaped_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a94bccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../imgID2annID.json\", \"r\") as fp:\n",
    "    f = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7338d99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[693783, 695214, 698544, 699405, 702189]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['507882']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d827f8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82783"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61509810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "msc-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
