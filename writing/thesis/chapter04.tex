This chapter introduces the notion of language drift and reviews work investigating this phenomenon. Literature often distinguishes between \textit{syntactic} (also sometimes called \textit{structural}), \textit{semantic} and \textit{pragmatic} drift \parencite{lazaridou2020multi}. \pt{add some relation or examples from human language development, cf. \cite{jacob2021multitasking} p. 3.}

First, metrics aiming to capture these different kinds of drift which are also used in presented experiments are reviewed. Then, novel aspects in investigating language drift tested in this thesis are described. Finally, specific hypotheses regarding expected language drift in the presently conducted experiments are presented along with their operationalizations. 

\section{Mitigating Language Drift}

\pt{maybe add images with examples of diverse drift}
The phenomenon of \textit{language drift} was first detected by \cite{lewis2017deal} who train artificial agents to cooperate on a negotation task in natural language, given a corpus of human dialogues. They show that the negotiation skills are significantly improved by optimizing the pretrained sequence-to-sequence agents with a preformance-based reward via REINFORCE. However, this comes at a cost of divergence from human language---i.e., the human intelligibility of the communication produced by the agents drastically decreases. This phenomenon is called language drift. To combat that, they switch between reinforcment learning and supervised learning. However, no precise quantification of the drift is presented. 

Building upon this work, \cite{lee2019countering} observe that counteracting drift by imposing a supervised learning constraint on the produced language, i.e., by trying to maximize the likelihood of the communication under a pretrained language model, mainly the \textit{surface structure} of the learned language is preserved. However, there is no guarantee that the \textit{semantics} are not drifting. That is, there is no constraint for the model to mean a cat with the word ``cat''; it could instead attach a different meaning to it.  To address this issue, they suggest to ground the language usage task in visual data, the idea being that the by co-occuring with images, the words keep the semantics. As described in Section \ref{mac}, they cast a translation task into a multi-agent task wherein the agents communicate via the pivot language English which is used for investigating drift. It is also used to compare the efficacy of grounding to a direct lanuage-model likelihood regularization, as performed by \cite{lewis2017deal}. \pt{check if regularizer description should be ported over here.}. Interestingly, the visual model they use for grounding is an image-caption retrieval model, determining the likelihood of the target image under the produced message, in  contrast to the grounding model by \cite{lazaridou2020multi} where the likelihood of the message given the image is maximized.
They first estimate language drift within the evaluation of the overall translation quality by reporting BLEU scores. The observe a drop in French-Englis translations in the vanilla model when the scores for the French-German performance increase. The highest scores were achieved with the model containing both constraints both on French-Eglish translation and the French-German translation. LM regularization has shown better improvement of the English scores, though this is partly due to the preference of the BLEU score for the surface form which is better regulated by an LM. Yet combining the LM and the image retrieval model yielded the best results, indicating that the drift may also occur at semantic level which is mitigated by grounding. Second, they look at by part-of-speech recall at inference time, finding that the vanilla model has difficulties with function words as well as produces in a flat toke distribution, compared to the combined regularized model. Further, the vanilla model is more prone to repeating words. To sum up, their results hint that both syntactic and semantic drift take place when optimizing agents with external task reward. However, they capture it by task-specific metrics (i.e., translation BLEU scores) which might make it difficult to extend their diagnostics to other experiments.

A different approach to mitigating language drift, focusing rather on stabilizing the language by creating community pressures in the agents is taken by \cite{lu2020countering}. They test the so-called \textit{seeded iterated learning} approach whereby they periodically finetune the pretrained speaker agent to imitate the behaviour of a teacher agent finetuned on the task. It is motivated by iterated learning models which are prominent in research on emergence and evolution of language structure. More precisely, the teacher agent is initially a duplicate of the learning speaker agent which essentially provides the \textit{seed} for the supervision iterations. The imitation sequences consists of supervised training on data sampled from the fnetuned teacher agent. They test this approach on a reference game and the translation game from \cite{lee2019countering}. The success of countering the drift in the reference game is measured via the ``Sender Language Score'' and the ``Task Scores'' (p. 5). The former compares the generated ang ground-truth captions by-token. The latter is the referential accuracy. The SIL model is shown to outperfrom several baselines.
For the latter task it is measured via BLEU scores, negative log likelihood of the messages (NLL, for capturing structural drift) and ranking scores under a pretrained image ranker (for capturing semantic drift). The SIL model is shown to be more robust against BLEU and ranking and NLL decrease than baselines.
%--  evolutionary / community / stabilisation via listener variation / against coadaptation.

Last but not least, \cite{jacob2021multitasking} study semantic drift of the so-called \textit{latent language policies} (LLP) which are used to train instructor and executor agent pairs. Semantic drift refers to the phenomenon whereby instuctors use messages in ways inconsistent with their initial semantics. Applied to the signalling game setting, they propose an executor (i.e., speaker) which simulataneously receives reward functions based on two different tasks and two different executors (i.e., listeners), respectively. Yet it remains a task for future research if this approach can be applied to training agents in the reference game setting.

\pt{from proposal below.}
The approaches outlined above test specific architectural constraints tailored towards reducing language drift. The goal of this thesis, however, is to take one step back and first effectively \textit{measure} language drift within a given architecture in order to \textit{explain} its possible sources, before making some recommendations about potential architecture improvements. Therefore, the next section summarizes existing and newly applied language drift metrics which are employed in own experiments.  

\section{Measuring Language Drift}

Some language drift metrics have been identified in the reviewed work. In particular, \cite{lazaridou2020multi} identify several measurements which are adopted in this thesis. These can be summarized as follows. 
\begin{itemize}
	\item \textit{Structural}, or, syntactic language drift can be measured as the log probability $P(m)$ of the generated message $m$ under a pre-trained unconditional language model. In this thesis, the pretrained TransformerXL model accessed through the \texttt{huggingface} library is used \parencite{dai2019transformer, wolf2019huggingface}.
	\item \textit{Semantic} language drift can be measured as the conditional log probability $P(m|i)$ of the generated message $m$ given the image $i$. %Another measure includes the $n$-gram overlap of generated messages and the ground-truth captions (ignoring stopwords) \cite{lazaridou2020multi}. Semantic drift is also addressed by \cite{lee2019countering}, \parencite{} but their approaches rather propose specific training methods than measures for identifying language drift, so their proposals wouldn't be considered here.
%	In alternative framings, semantic drift has been measured as the difference between the message semantics and the action taken by the receiver agent \cite{}. lu2020countering.
	\item Finally, \textit{pragmatic} language drift is assessed as the discrepancy in referential success in absense of structural or semantic drift between human and listener agents. This is assessed by comparing the performance of humans to the performance of trained listener agents with a speaker trained to rerank the ground truth image captions (see Chapter \ref{chapter03} for details). 
\end{itemize}

However, given that the conducted experiments won't have access to human baseline data, pragamtic drift will have to be assessed differently. Although the proposed approach has the advantage of being task-agnostic, this work proposes to focus on a referential task drift approximating pragmatic one. This approximation is referred to as \textit{functional} drift. 

In this context, funtional drift refers to the deterioration of language which would make the referential task impossible for humans (e.g., leaving out critical content words). Crucially, the the goal is to capture this drift in absense of human experiments. The difference between the proposed metric and pragmatic drift is that functional drift is proposed in terms of the presense of discriminative words in the discription, which can be approximated as words or caption parts which have a higher probability for the target image than for the distractor. Thereby the metric becomes operationalizable under open-source pretrained models and does not depend on the availability of human data anymore. \pt{check if all this is correct, makes sense, aligns with the actual metrics I use and whether it is different from pragmatic drift.}
In contrast, other kinds of drift like structural drift might involve mixing up the word order, which nevertheless does not necessarily hinder the referential task, if distinctive content words are still present. \pt{For instance, the caption ``A plate food with'' would exemplify functional drift, while the caption ``A plate red food with'' wouldn't, if was the target image and Fig.2 was the distractor. Check is this can be exemplified with some images already used elsewhere or at intro of the chapter.} 

The following concrete operationalizations are tested in the experiments in order to capture functional drift. \begin{itemize}
	\item One idea approach for identifying functional language drift which is stable against compositional alternations within the caption and, therefore, isolates functional discriminativity is the word overlap between the generated captions and the target and distractor ground truth captions, respectively. From a functional perspective, an optimal generated target caption maximizes the overlap with the target ground truth, while minimizing the overlap with the distractor ground truth. This idea is related to the omission score suggested by \cite{havrylov2017emergence} (also cf. \cite{andreas2016reasoning, gunel2020supervised}). This is also similar to the unigram metric employed by \cite{lazaridou2020multi}. To sum up, the difference between the word overlap of the target and generated captions and the overlap of the distractor and generated caotions is computed.
	\item Complementarily, the idea described above is also formalized by computing the cosine similarity between the caption embeddings instead of word overlap scores. Again, the respective difference is computed as the drift metric.
	\item Finally, a rather exploratory approach is taken to measuring the recoverability of the target image based on the caption. \pt{add an explanation of recoverability} Again, discriminative captions would present higher recoverability of the target comapred to the distractor. \pt{This is operationalized via a pretrained image-text retrieval model. Alternatively, this can be operationalized via a text-to-image model, where, ideally, the image produced from the generated caption would be more similar to the target than the distractor image. However, these metrics both heavily depend on the nature of the pretrained models as well as in the chosen similarity metric. This metric is rather used in an exploratory way, in order to investigate if it alignes with intuitions and other metrics.}
	\item \pt{check if i do some POS based tests}
\end{itemize}
These metrics are used as diagnostic measures in order to identify potential sources of language drift. To this end, different experiments are conduceted. The section below outlines the hypothesized language drift behavior in the different experiments, as can be expected based on results from the literature.

\section{Hypotheses}

First, hypotheses regarding language drift in the main experiments on the MS COCO dataset are described.
Specifically, Ls weight X drift?
Similar pairs to random pairs. Granularity.
Difference between joint and fixed listener.

MS COCO vocab size, if there is time.

In order to investigate the influence of the characteristics of the dataset on the drift, experiments with the manually annotated 3dshapes dataset are conducted.

Message length, grammatical structure. 
Granularity in random vs similar pairs.
Again Ls, difference between joint and fixed listener.
