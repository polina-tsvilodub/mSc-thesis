This chapter introduces the notion of language drift and reviews work investigating this phenomenon. Literature often distinguishes between \textit{syntactic} (also sometimes called \textit{structural}), \textit{semantic} and \textit{pragmatic} drift \parencite{lazaridou2020multi}. \pt{add some relation or examples from human language development, cf. \cite{jacob2021multitasking} p. 3.}

First, metrics aiming to capture these different kinds of drift which are also used in presented experiments are reviewed. Then, novel aspects in investigating language drift tested in this thesis are described. Finally, specific hypotheses regarding expected language drift in the presently conducted experiments are presented along with their operationalizations. 

\section{Mitigating Language Drift}

\pt{maybe add images with examples of diverse drift}
The phenomenon of \textit{language drift} was first detected by \cite{lewis2017deal} who train artificial agents to cooperate on a negotation task in natural language, given a corpus of human dialogues. They show that the negotiation skills are significantly improved by optimizing the pretrained sequence-to-sequence agents with a preformance-based reward via REINFORCE. However, this comes at a cost of divergence from human language---i.e., the human intelligibility of the communication produced by the agents drastically decreases. This phenomenon is called language drift. To combat that, they switch between reinforcment learning and supervised learning. However, no precise quantification of the drift is presented. 

Building upon this work, \cite{lee2019countering} observe that counteracting drift by imposing a supervised learning constraint on the produced language, i.e., by trying to maximize the likelihood of the communication under a pretrained language model, mainly the \textit{surface structure} of the learned language is preserved. However, there is no guarantee that the \textit{semantics} are not drifting. That is, there is no constraint for the model to mean a cat with the word ``cat''; it could instead attach a different meaning to it.  To address this issue, they suggest to ground the language usage task in visual data, the idea being that the by co-occuring with images, the words keep the semantics. As described in Section \ref{mac}, they cast a translation task into a multi-agent task wherein the agents communicate via the pivot language English which is used for investigating drift. It is also used to compare the efficacy of grounding to a direct lanuage-model likelihood regularization, as performed by \cite{lewis2017deal}. \pt{check if regularizer description should be ported over here.}. Interestingly, the visual model they use for grounding is an image-caption retrieval model, determining the likelihood of the target image under the produced message, in  contrast to the grounding model by \cite{lazaridou2020multi} where the likelihood of the message given the image is maximized.
They first estimate language drift within the evaluation of the overall translation quality by reporting BLEU scores. The observe a drop in French-Englis translations in the vanilla model when the scores for the French-German performance increase. The highest scores were achieved with the model containing both constraints both on French-Eglish translation and the French-German translation. LM regularization has shown better improvement of the English scores, though this is partly due to the preference of the BLEU score for the surface form which is better regulated by an LM. Yet combining the LM and the image retrieval model yielded the best results, indicating that the drift may also occur at semantic level which is mitigated by grounding. Second, they look at by part-of-speech recall at inference time, finding that the vanilla model has difficulties with function words as well as produces in a flat toke distribution, compared to the combined regularized model. Further, the vanilla model is more prone to repeating words. To sum up, their results hint that both syntactic and semantic drift take place when optimizing agents with external task reward. However, they capture it by task-specific metrics (i.e., translation BLEU scores) which might make it difficult to extend their diagnostics to other experiments.

A different approach to mitigating language drift, focusing rather on stabilizing the language by creating community pressures in the agents is taken by \cite{lu2020countering}. They test the so-called \textit{seeded iterated learning} approach whereby they periodically finetune the pretrained speaker agent to imitate the behaviour of a teacher agent finetuned on the task. It is motivated by iterated learning models which are prominent in research on emergence and evolution of language structure. More precisely, the teacher agent is initially a duplicate of the learning speaker agent which essentially provides the \textit{seed} for the supervision iterations. The imitation sequences consists of supervised training on data sampled from the fnetuned teacher agent. They test this approach on a reference game and the translation game from \cite{lee2019countering}. The success of countering the drift in the reference game is measured via the ``Sender Language Score'' and the ``Task Scores'' (p. 5). The former compares the generated ang ground-truth captions by-token. The latter is the referential accuracy. The SIL model is shown to outperfrom several baselines.
For the latter task it is measured via BLEU scores, negative log likelihood of the messages (NLL, for capturing structural drift) and ranking scores under a pretrained image ranker (for capturing semantic drift). The SIL model is shown to be more robust against BLEU and ranking and NLL decrease than baselines.
%--  evolutionary / community / stabilisation via listener variation / against coadaptation.

Last but not least, \cite{jacob2021multitasking} study semantic drift of the so-called \textit{latent language policies} (LLP) which are used to train instructor and executor agent pairs. Semantic drift refers to the phenomenon whereby instuctors use messages in ways inconsistent with their initial semantics. Applied to the signalling game setting, they propose an executor (i.e., speaker) which simulataneously receives reward functions based on two different tasks and two different executors (i.e., listeners), respectively. Yet it remains a task for future research if this approach can be applied to training agents in the reference game setting.

\pt{from proposal below.}
The approaches outlined above test specific architectural constraints tailored towards reducing language drift. The goal of this thesis, however, is to take one step back and first effectively \textit{measure} language drift within a given architecture in order to \textit{explain} its possible sources, before making some recommendations about potential architecture improvements. Therefore, the next section summarizes existing and newly applied language drift metrics which are employed in own experiments.  

\section{Measuring Language Drift}

Some language drift metrics have been identified in the reviewed work. In particular, \cite{lazaridou2020multi} identify several measurements which are adopted in this thesis. These can be summarized as follows. 
\begin{itemize}
	\item \textit{Structural}, or, syntactic language drift can be measured as the log probability $P(m)$ of the generated message $m$ under a pre-trained unconditional language model. In this thesis, the pretrained TransformerXL model accessed through the \texttt{huggingface} library is used \parencite{dai2019transformer, wolf2019huggingface}.
	\item \textit{Semantic} language drift can be measured as the conditional log probability $P(m|i)$ of the generated message $m$ given the image $i$. %Another measure includes the $n$-gram overlap of generated messages and the ground-truth captions (ignoring stopwords) \cite{lazaridou2020multi}. Semantic drift is also addressed by \cite{lee2019countering}, \parencite{} but their approaches rather propose specific training methods than measures for identifying language drift, so their proposals wouldn't be considered here.
%	In alternative framings, semantic drift has been measured as the difference between the message semantics and the action taken by the receiver agent \cite{}. lu2020countering.
	\item Finally, \textit{pragmatic} language drift is assessed as the discrepancy in referential success in absense of structural or semantic drift between human and listener agents. This is assessed by comparing the performance of humans to the performance of trained listener agents with a speaker trained to rerank the ground truth image captions (see Chapter \ref{chapter03} for details). 
\end{itemize}

However, given that the conducted experiments won't have access to human baseline data, pragamtic drift will have to be assessed differently. Although the proposed approach has the advantage of being task-agnostic, this work proposes to focus on a referential task drift approximating pragmatic one. This approximation is referred to as \textit{functional} drift. 

In this context, funtional drift refers to the deterioration of language which would make the referential task impossible for humans (e.g., leaving out critical content words). Crucially, the the goal is to capture this drift in absense of human experiments. The difference between the proposed metric and pragmatic drift is that functional drift is proposed in terms of the presense of discriminative words in the discription, which can be approximated as words or caption parts which have a higher probability for the target image than for the distractor. Thereby the metric becomes operationalizable under open-source pretrained models and does not depend on the availability of human data anymore. \pt{check if all this is correct, makes sense, aligns with the actual metrics I use and whether it is different from pragmatic drift.}
In contrast, other kinds of drift like structural drift might involve mixing up the word order, which nevertheless does not necessarily hinder the referential task, if distinctive content words are still present. \pt{For instance, the caption ``A plate food with'' would exemplify functional drift, while the caption ``A plate red food with'' wouldn't, if was the target image and Fig.2 was the distractor. Check is this can be exemplified with some images already used elsewhere or at intro of the chapter.} 

The following concrete operationalizations are tested in the experiments in order to capture functional drift. \begin{itemize}
	\item One idea approach for identifying functional language drift which is stable against compositional alternations within the caption and, therefore, isolates functional discriminativity is the word overlap between the generated captions and the target and distractor ground truth captions, respectively. From a functional perspective, an optimal generated target caption maximizes the overlap with the target ground truth, while minimizing the overlap with the distractor ground truth. This idea is related to the omission score suggested by \cite{havrylov2017emergence} (also cf. \cite{andreas2016reasoning, gunel2020supervised}). This is also similar to the unigram metric employed by \cite{lazaridou2020multi}, but it adds the functional aspect via the difference computation. To sum up, the difference between the word overlap of the target and generated captions and the overlap of the distractor and generated captions is computed. This is an intuitive step to take since ground truth captions are available for all images in the dataset.
	\item Complementarily, the idea described above is also formalized by computing the cosine similarity between the caption embeddings instead of word overlap scores. This also hints at whether the trained embedding layer of the speaker, i.e., a representational layer, is affected by the functional learning signal. Again, the respective difference is computed as the drift metric and is expected to increase with successful task learning.
	\item Finally, a rather exploratory approach is taken to measuring the recoverability of the target image based on the caption. \pt{add an explanation of recoverability} Again, discriminative captions would present higher recoverability of the target comapred to the distractor. \pt{This is operationalized via a pretrained image-text retrieval model. Alternatively, this can be operationalized via a text-to-image model, where, ideally, the image produced from the generated caption would be more similar to the target than the distractor image. However, these metrics both heavily depend on the nature of the pretrained models as well as in the chosen similarity metric. This metric is rather used in an exploratory way, in order to investigate if it alignes with intuitions and other metrics.}
	\item \pt{check if i do some POS based tests}
\end{itemize}
These metrics are used as diagnostic measures in order to identify potential sources of language drift. To this end, different experiments are conduceted. The section below outlines the hypothesized language drift behavior in the different experiments, as can be expected based on results from the literature.

\section{Hypotheses}

For simplicity of reference in the discussion of results, the different hypotheses are enumerated.
First, hypotheses regarding language drift in the main experiments on the MS COCO dataset are described. As the speaker improves on the functional task, i.e., as the functional loss is minimized, the following observations are hypothesized: \\
\newline 
% The speaker vocab size relation also to previous work 
\textbf{H1:} The structural drift is expected to increase. That is, the log probability of the generated captions under a pretrained model is expected to decrease. \newline
\textbf{H2:} The semantic drift is expected to increase. That is, the log probability of the generated caption given the target under the pretrained frozen speaker model is expected to decrease. \newline
\textbf{H3:} The discriminativity of the captions is expected to increase. That is, the word overlap difference is expected to increase, both for the word overlap based metric and the cosine similarity based metric. \newline
\textbf{H4:} Given that the pressure to stay close to a natural language distribution is provided by the structural loss component in the chosen model architecture, it is expected that both the structural and the semantic drifts increase as the weight of the structural loss component decreases. To investigate this, four reference games with the strctural loss weights $\lambda_s = [0, 0.25, 0.5, 0.75, 1]$ are conducted. the functional loss component is computed as $\lambda_f = 1 - \lambda_s$. \newline
%Based on exploratory experiments (see Appendix \ref{appendix}) and on literature regarding the learnability of large action spaces by REINFORCE, 
\textbf{H5:} The discriminativity of the captions is expected to increase less than in the baseline experiment on random target-distractor pairs. That is, the overlap values are expected to be smaller than in the baseline experiment. This is expected due to the higher perceptual difficulty of discriminating images depicting similar things. Due to the intuitive necessity to produce more specific messages in the similar pairs experiment, it is also expected that the message length and possibly the specificity of the words increases. This will be approximated by analysing the occuring parts of speech and message lengths until the first END token, possibly accompanied by manual sample message inspection.\newline
\textbf{H6:}  The semantic and structural drifts are expected to be smaller in experiments where in the speaker is trained against a fixed (i.e., pretrained) listener compared to a listener trained jointly with the speaker. This is due to the observation made in prior work that especially semantic drift arises due to speaker-listener co-adaptation and the emergence of conventions among them. \newline
\textbf{H7*\footnote{The * indicated the optionality of this hypothesis based on available time}:} \pt{MS COCO vocab size, if there is time. What exactly is the language drift H here though? It is more about the functional optimization potential} \newline
\textbf{H8*:} The recoverability of the target given the sampled caption is expected to increase. That is, the metric provided by the image-text retrieval model is expected to improve. \pt{add direction and check} \newline

\pt{maybe emphasize once again that this cannot plausibly be expected if no functional learning is observed, re reinforce thing.}
In order to investigate the influence of the characteristics of the dataset on the drift, experiments with the manually annotated 3dshapes dataset are conducted. Hypotheses ]textbf{H1--H6} are also tested on 3dshapes, but additional hypotheses about the comparison between MS COCO and 3dshapes are explored. \\
\newline
\textbf{H9:} The strucutral drift is expected to be smaller compared to the MS COCO experiments. That is, the message log probability under the pretrained language model is expected to be higher. This is expected due to the a priori given availability of exhasutively descriptive features in the training data. This availability is expected to alleviate the need of resorting to structurally misformed messages in order to adapt to the functional needs for the agents. \newline
%Message length, grammatical structure. 
%Granularity in random vs similar pairs.
%Again Ls, difference between joint and fixed listener.
\textbf{H10:} To deconfound the role of the availability of fully exhaustive descriptive captions and the size of the action space learned by the agent, an experiment is conducted wherein the speaker is pretrained on non-exhaustive captions. Comparing this experiment to the baseline 3dshapes experiment, higher structural drift is expected, as operationalized by lower cpation log likelihoods of the messages under the pretrained models.

It is important to note that absolute values of the presented drift metrics should be interpreted with caution. Especially the structural drift metric is based on a model pretrained on possibly very different data distributions. Therefore, absolute log likelihood might be artifacts due to differences between the reference games data and pretraining data. Therefore, the metrics are intended to be interpreted comparatively within the training dynamics of the experiments, or between experiments varying training configurations.

The next chapter finally turns to experiments in scope of which language drift is investigated. \pt{maybe chpater summary}