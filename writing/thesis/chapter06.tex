Discussion goes here. 

Competition vs cooperation of agents. 

My intuition that the state space is too large to observe any influence of REINFORCE is supported by marginal comments in \cite{havrylov2017emergence}; therefore, future work should try a combination of the structural loss with a Gumbel-Softmax component.

My architecture, esp for MS COCO, can essentially be interpreted as just show-casing that you can ground a second (receiver) agent against a pretrained image captioner. It is hard to consider this a multi-agent communication result since the effect or reinforce propagating the functional signal is so marginal. 

Discuss how this multi-agent communication is one approach to building pragmatic language behaviour based on neural models. But there are other options with a more explicit underlying cognitive motivation, as e.g. done by Monroe and Potts, but which faces computational challenges. 