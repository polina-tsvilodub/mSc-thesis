Communicating about the ever-changing world around us in a context-appropriate way is a fascinating human ability. Yet training artificial neural agents to communicate in the same way is a non-trivial task. This thesis set out to investigate how this task can be approached by training artificial agents to use natural language in order to communicate about realistic images in a multi-agent communication setting. More specifically, the agents were trained to play a \emph{reference game} in which they had to produce maximally \emph{discriminative} messages in order to succeed on the task. The phenomenon of \emph{language drift} which occurs as agents improve on their task was the focus of this work.

\section{Experiments}
My intuition that the state space is too large to observe any influence of REINFORCE is supported by marginal comments in \cite{havrylov2017emergence}; therefore, future work should try a combination of the structural loss with a Gumbel-Softmax component.

My architecture, esp for MS COCO, can essentially be interpreted as just show-casing that you can ground a second (receiver) agent against a pretrained image captioner. It is hard to consider this a multi-agent communication result since the effect or reinforce propagating the functional signal is so marginal. 

Discuss relation to Lazaridous work and how I extend the speaker to be conditioned on both images in all experiments. This is more plausible from a task-functional perspective, but, of course, make the model more hard-coded (to specific set of distractors). Would be interesting to compare frozen samples from such a model (oracle speaker) to their results. I argue that the fine-tuning of the language module is more plausible in that it is motivated by trying to teach the speaker to select words that are right for the referential task. However, Asya's point is well taken in that this should not affect core linguistic capabilities which seem to be affected by co-adaptation. It remains an open question how to mitigate this issue; I think, fine-tuning the model yet using different listeners is the most plausible strategy; a completely different approach would be one to generation procedure (low-level conditioning vs. strucutred feature extraction ). 


Conditioning of the sepaker: during pretraining it already saw both images (necessary for architectural reasons), but we cannot know if it did not result in an implicit spill over and discriminativity already during pretraining. also this makes the model task specific (pairs of images only). 


Beam search in decoding.
\pt{maybe structure discussion according to: summary, experimental methods, conceptual aspects, relation to extant work and future directions, conclusion.}

Potential other future investigation: using pretrained embeddings.
Also different pretrianing strategies, potentially start with auto-regression and then transition to teacher forcing. 

Overall, we see how important the combination of particular hyperparameters and training configurations are, indicating that future research should focus on architectures which might be more stable against the alternations. 

\section{Multi-Agent Communication}

\pt{This could be the section for discussing less technical, more conceptual points regarding LD which are not discussed in last section of previous chapter.}
Competition vs cooperation of agents. 

Discuss how this multi-agent communication is one approach to building pragmatic language behaviour based on neural models. But there are other options with a more explicit underlying cognitive motivation, as e.g. done by Monroe and Potts, but which faces computational challenges. 


An interesting direction for future research is also testing the present system against other datasets, e.g., for testing referential expressions like the dataset constructed by \cite{mao2016generation}. An interesting question there would be to quantify inhowfar discriminativity in a reference game aligns with good referential expressions; if it does, this dataset could provide a good benchmark for evaluating the functional success of the speaker. In order to connect to their work, one would need to to formalize the step of inferring a suitable target region or bounding box for the reference game (i.e., identify a discriminative referent), and then generate the discriminative expression. 

Andreas and Klein 2016 seems highly relevant to my intuition about regularization and strucutral weight. 


\section{Cognitive Perspective}
Discriminativity vs reference vs relevance. Level of discriminativity extraction (as related to future directions for different agent architectures). Multi-turn interactions. Testing against humans. Other pragmatic abilities. 
Program induction, neuro-symbolic architectures. 

\section{Summary}
...hinting at the fragility of extant approaches to building artificial agents. Therefore, there might be a lot of potential for improvement in attempting to build cognitively-inspired / plausible architectures. This thesis hopes to inspire such future work. 