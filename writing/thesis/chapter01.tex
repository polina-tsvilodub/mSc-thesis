The way in which humans effortlessly communicate even in previously never observed situations is a fascinating phenomenon. Not only are humans able to communicate with each other about an infinite variety of contexts---they do so in a highly flexible and context-appropriate way. For instance, in a context where two persons are surrounded by many cars and houses in a lively street, intuitively, the speaker might utter a sentence like ``Look at that red polka-dotted car!'' in order to draw the listener's attention to a particular funny-looking car. In contrast, if the interlocutors were in a field where there are no cars but a single abandoned funny-looking one, the speaker might likely rather say ``Look at that car!'', ommitting details unnecessary for drawing the listener's attention to a particular object \parencite[cf.][]{graf2016animal}. This \textit{context-dependent} selection of the necessary level of details in utterances is part of the basic communicative act of \textit{reference}, and present only one example of how humans flexibly accomodate the requirements of the communicative task in their use of natural language \parencite{searle1969speech}. \pt{more reference regarding context}

Despite rapid progress in the area of artificial intelligence producing impressive results, teaching machines to communicate in a way understandable and natural for humans is still a far from solved task \parencite{lazaridou2020multi, lake2017building, lecun2015deep}. Tackling this task involves at least three skills artificial agents need to learn: using natural language in a structurally well-formed way, using it in a semantically correct and grounded way, and being able to adjust their language use to the communicative task at hand \pt{references}. 

Moedling these skills has been addressed in different areas of research. For instance, work in computer vision focuses on the aspect of grounding and strucutral well-formedness in developing \textit{image captioning} models.
In contrast, training agents to communicate in order to complete tasks has been addressed in the growing body of work on multi-agent communication in the reinforcement learning domain, where artificial agents are trained to develop or learn an effective communication protocols \parencite{foerster2016learning, lazaridou2020multi}.
This approach allows to both encorporate interactional aspects of language, as well as ground the language into the interaction environment. Furthermore, it allows to investigate the communication from an evolutionary perspective, as it evolves between the agents. 

Multi-agent communication experiments have made use of different communicative environments. Some experiments investigate communication protocols emerging when agents have to play a game \pt{REF}, navigate in a 2D or 3D environment \parencite{das2019tarmac, jaques2019social}, learn to translate sentences \parencite{lee2019countering}, or let the agents play a variety of the Lewis signalling game---a \textit{reference game}. In the latter environment, agents' main task is the communication itself. The goal hereby is for a sender agent to communicate in a way such that receiver agent(s) successfully identify a target object in context of distractors. The objects are typically represented by images. 

Such a set up approximates the basic act of reference to objects in the real world, thereby presenting a step towards teaching artificial agents skills necessary for successful communication in a human-like way.
Therefore, this thesis sets out to investigate how artificial agents can be trained to use natural language in order to effectively refer to real-world situations in the reference game setting. That is, presented work focuses on training agents to produce \textit{discriminative} natural language. \pt{such goal formulation can be slightly misleading, since i actually focus on language drift}

Previous work on multi-agent reference games has shown that artificial agents are able to develop communication protocols allowing them to successfully play reference games in a variety of different visual environments. More specifically, the agents have been trained to communicate about geometric shapes \pt{Xenia's work}, synthetically generated scenes \parencite{lazaridou2020multi} or even real photos of natural scenes in the MS COCO dataset \parencite{lazaridou2016multi, lin2014microsoft, havrylov2017emergence}. However, the communication protocols employed by the agents mostly are not human-interpretable; i.e., they communicate by emmiting symbols sampled from an arbitrary vocabulary \parencite{foerster2016learning}. \pt{more refs} Some experiments employed single word natural language labels of the objects agents communicated about \parencite{lazaridou2016multi}. Yet to the author's knowledge, there is only one reference game experiment in which the agents use a full natural language (English) as their communication protocol \parencite{lazaridou2020multi} \pt{double check}. However, the agents communicate about synthetically generated scenes from the \textit{Abstract Scenes} dataset. 

Furthermore, it has been observed in the literature that training agents to complete certain tasks while sticking to a given communicative protocol does not come without difficulties. More precisely, when optimizing the agents' behavior by providing task success  based rewards, the agents \textit{drift away} from the communicative protocol, i.e., forget how to properly use natural language \parencite{lee2019countering, lazaridou2020multi, lu2020countering}. \pt{add that dialogue ref. aslo this gets quite techy very abruptly} While some work has proposed ways to mitigate such \textit{language drift}, not much work has been done on investigating the precise reasons behind language drift, and especially not in connection with applying natural language communication to real-world visual input. 

Therefore, this thesis sets out to take a step towards explaining language drift when employing natural language in reference games about realistic images. The starting point for this thesis is the work by \cite{lazaridou2020multi}. The main  experiments focus on reference games on the MS COCO dataset which provides real world images annotated with English captions from which agents can learn the desired communicative skills. The dynamics of the quality of language used by the agents while learning the game are investigated with both extant and new language drift metrics. More specifically, new language drift metrics attempt to formalize the functional adequacy of the used language by computing the recoverability of the intended image from the agent's messages. \pt{cheeeeck}. Furthermore, the agents' capacity to flexibly adapt the specificity of their messages to the fine-grained differences in the visual context is investigated by varying the similarity of the target and distractor images in the game. %pairs experiment) of producing discriminative captions; failure to do taht could be dues to: noise in images, details of captions, incapability to vary caption length beyond what was observed in the training data

In order to investigate potential sources of language drift, this work looks into the properties of the MS COCO dataset and whether the lack of discriminative details in the captions on which the model is trained is responsible for the models resorting to strategies which on the surface appear as language drift in order to achieve the functional task. To this end, experiments on a manually annotated dataset are conducted which guarantees to include training captions of maximal descriptive granularity. The 3dshapes dataset is used in these experiments. \pt{ref} Using this dataset also allows to have comparison to a dataset where the visual input is not as noisy as MS COCO images. Finally, the speaker-listener agent co-adaptation as a potential source for language drift is investigated by conducting experiments wherein the spekaer agent is trained against a pretrained fixed listener. This also approximates an environment with a community of different listeners with which the speaker has to be able to communicate, as is arguably the case in human communication. 
\pt{Strucutral weight variation hypothesis!}
%	\item fixed pretrained listener: check if the drift is due to an emergence of conventions between speaker and listener which do not match human grounding, when listener and speaker are trained jointly. Therefore, a fixed listener can also be used. 
%	\item additional drift sources to be discussed, but not experimentally investigated: architectural constraints like vocabulary size

%Overall upshot: create task-specific communication about naturalistic visual input, investigate the influence of the dataset on the quality. Implications for what needs to be taken care of when creating systems to be used e.g. in human-machine interaction. 

This thesis is structured as follows: first, some technical background required for presented work is introduced in Chapter \ref{chapter02}. Then, related work on multi-agent communication is reviewed in Chapter \ref{chapter03}, especially focusing on experiments involving reference games. The reference game task is also discussed from a cognitive perspective, along with other modeling work on discriminative image caption generation. Chapter \ref{chapter04} then introduces language drift and reviews metrics employed to capture it, proposing novel approaches to detecting language drift in reference games on real-world images.\pt{double check} Then, the experiments conducted in this work are presented in Chapter \ref{chapter05}. To this end, the architectures of the agents are discussed, followed by a discussion of the employed datasets, training details, and results. Finally, a general discussion of the results and their implications is provided in Chapter \ref{chapter06}. %The following sections presuppose faimiliarity with basic concepts in machine learning and deep learning. For an introduction, see, e.g., \cite{goodfellow2016deep, bishop2006pattern}.

\pt{Have actual visual image and caption examples, and task conditional examples here.}

\pt{maybe add basics of artificial agent interaction: \cite{tan1993multi}}

\pt{a good general picture ML reference: Tomas Mikolov, Armand Joulin, and Marco Baroni. 2018. A roadmap towards machine intelligence. Lecture Notes in Computer Science,}

%General flow: Correct, efficient communication appropriate in a given context as human feature -- basic type of cimmunication is reference (basic speech act), joint attention at a terget with another interlocutor. We want to model that, operationalized as a reference game which has also been studied extensively in cognitive science. We want artififical agents to do it, but for having potential to communicate with humans -- in natural language. It boils down to image captioning and learning statistical properties of language, yet in a task appropriate way. Therefore, multi-agent communication for task-specific finetuning. 