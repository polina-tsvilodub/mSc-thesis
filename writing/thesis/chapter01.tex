The way in which humans effortlessly communicate even in previously never observed situations is a fascinating phenomenon. Not only are humans able to communicate with each other about an infinite variety of contexts---they do so in a highly flexible and context-appropriate way. For instance, in a context where two persons are surrounded by many cars and houses in a lively street, intuitively, the speaker might utter a sentence like ``Look at that red polka-dotted car!'' in order to draw the listener's attention to a particular funny-looking car. In contrast, if the interlocutors were in a field where there are no cars but a single abandoned funny-looking one, the speaker might likely rather say ``Look at that car!'', ommitting details unnecessary for drawing the listener's attention to a particular object \parencite[cf.][]{graf2016animal, degen2020redundancy}. This \textit{context-dependent} selection of the necessary level of details in utterances is part of the basic communicative act of \textit{reference}, and presents only one example of how humans flexibly accomodate the requirements of a communicative task like reference in their use of natural language \parencite{searle1969speech, grice1975logic}.

Despite rapid progress in the area of artificial intelligence, teaching machines to communicate in a way understandable and natural for humans is still a far from solved task \parencite{lazaridou2020emergent, lake2017building, lecun2015deep}. Tackling this task involves at least three skills artificial agents need to learn: using natural language in a structurally well-formed way, using it in a semantically correct and grounded way, and being able to adjust their language use to the communicative task at hand \parencite{lazaridou2020emergent}. In context of multi-agent communication, \textit{grounding} is usually defined as aligning the natural language tokens agents use to visual input in the same way humans do (i.e., making sure that agents refer to images of cats with the word ``cat''; \cite{jurafsky2000speech}).

Modeling these skills has been addressed in different areas of research. For instance, work in computer vision focuses on the aspect of grounding and structural well-formedness in developing \textit{image captioning} models.
In contrast, training agents to communicate in order to complete tasks has been addressed in the growing body of work on \textit{multi-agent communication} in the reinforcement learning domain, where artificial agents are trained to develop or learn effective communication protocols \parencite[e.g.,][]{foerster2016learning, lazaridou2020emergent}.
This approach allows to both incorporate interactional aspects of language, as well as ground the language into the interaction environment. Furthermore, it allows to investigate the communication from an evolutionary perspective, as it evolves between the agents through interaction in context, allowing to investigate the roots of different communication protocol properties like compositionality \parencite{lazaridou2020emergent}. 

Multi-agent communication experiments have made use of different communicative environments. Some experiments investigate communication protocols emerging when agents have to play a game \parencite{jacob2021multitasking}, navigate in a 2D or 3D environment \parencite{das2019tarmac, jaques2019social}, learn to translate sentences \parencite{lee2019countering}, or let the agents play a variety of the Lewis signaling game---a \textit{reference game}. The goal hereby is for a sender agent to communicate in a way such that receiver agent(s) successfully identify a target object among distractors. The objects are typically represented by images. 

This thesis sets out to investigate \textbf{how artificial agents can be trained to use natural language in order to effectively refer to real-world situations in the reference game setting}. That is, presented work focuses on \textbf{training agents to produce \textit{discriminative} natural language and investigating the quality of the used language}. The reference game set up offers an ideal avenue for that by approximating the basic communicative act of referencing objects in the real world, thereby presenting a step towards teaching artificial agents skills necessary for successful communication in a human-like way. 

Previous work on multi-agent reference games has shown that artificial agents are able to develop communication protocols allowing them to successfully play reference games in a variety of different visual environments. More specifically, the agents have been trained to communicate about geometric shapes \parencite{ohmer2021and}, synthetically generated scenes \parencite{lazaridou2020multi} or even real photos of natural scenes in the MS COCO dataset \parencite{lazaridou2016multi, lin2014microsoft, havrylov2017emergence}. However, the communication protocols employed by the agents often are not human-interpretable; i.e., they communicate by emmiting symbols sampled from an arbitrary vocabulary \parencite{foerster2016learning, lazaridou2016multi}. Some experiments employed single word natural language labels of the objects agents communicated about \parencite{lazaridou2016multi}. Yet there are only few reference game experiments in which the agents use a full natural language (English) as their communication protocol \parencite[e. g.,][]{lazaridou2020multi}. However, \cite{lazaridou2020multi} who use full natural language made a compromise in complexity of the set up by applying the communication to simpler synthetically generated scenes from the \textit{Abstract Scenes} dataset \parencite{zitnick2013bringing}. This work aims to fill this gap by using both natural language and natural images in multi-agent communication experiments. 

Furthermore, it has been observed in the literature that training agents to complete certain tasks while sticking to a given communicative protocol does not come without difficulties. More precisely, when optimizing the agents' behavior by providing rewards based on task success, the agents \textit{drift away} from the communicative protocol, i.e., forget how to properly use natural language and produce unintelligible sentences like ``a a a red a cat.'' \parencite{lee2019countering, lazaridou2020multi, lu2020countering, lewis2017deal}. While some work has proposed ways to mitigate such \textit{language drift}, not much work has been done on investigating the precise reasons behind language drift, and especially not in connection with applying natural language communication to real-world visual input. 

To fill this gap in the literature, this thesis sets out to take a step towards \textbf{explaining language drift when employing natural language in reference games about realistic images}. The starting point for this thesis is the work by \cite{lazaridou2020multi}. The main  experiments focus on reference games on the MS COCO dataset, which provides \textit{real world images} annotated with English captions by humans \parencite{chen2015microsoft}, from which agents can learn to communicate about images in natural language. By using real world images, this work extends beyond previous studies in that it investigates language drift in a scenario which is close to potential interactions between artificial agents and humans in the real world. 
The dynamics of the quality of language used by the agents while learning the game are investigated with both extant and new language drift metrics. More specifically, new language drift metrics attempt to formalize the functional adequacy of the used language. 
%pairs experiment) of producing discriminative captions; failure to do taht could be dues to: noise in images, details of captions, incapability to vary caption length beyond what was observed in the training data
In order to investigate potential sources of language drift, the strength of structural contraints put on the agents' communication is varied in the experiments. Furthermore, the difficulty of the visual context is manipulated by varying the similarity of the target and distractor images in the game. This work also looks into the properties of the MS COCO dataset and whether the lack of discriminative details in the captions on which the model is trained is responsible for the models resorting to strategies which on the surface appear as language drift in order to complete the functional task. To this end, experiments on a manually annotated dataset which guarantees to include training captions of maximal descriptive granularity are conducted. The 3Dshapes dataset is used in these experiments \parencite{burgess20183d}. Using this dataset also allows to have a comparison to a dataset where the visual input is not as complex as MS COCO images because it depicts rather simple geometric shapes, as opposed to photographic images of many different scenes in diferent physical conditions. Finally, the speaker-listener agent co-adaptation as a potential source for language drift is investigated by conducting experiments wherein the speaker agent is trained against a fixed listener. This approximates an environment with a community of different listeners with which the speaker has to be able to communicate by maintaining certain linguistic conventions across individuals, as is arguably the case in human communication \parencite{kirby2014iterated, clark1991grounding}. 

Results from various experiments show that, while mostly being able to learn the reference game, the agents' task success was susceptible to the difficulty of the context, while their language quality was susceptible to the agents' co-adaptation, the speaker architecture details and the surface structure of the annotations in the training dataset. Overall, all considered drift sources entered into intricate interactions.

This thesis is structured as follows: first, some technical background is introduced in Chapter \ref{chapter02}. Then, related work on multi-agent communication is reviewed in Chapter \ref{chapter03}, especially focusing on experiments involving reference games. The reference game task is also discussed from a cognitive perspective, along with other modeling work on discriminative image caption generation. Chapter \ref{chapter04} then introduces language drift and reviews metrics employed to capture it, proposing novel approaches to detecting language drift in reference games on real-world images. Then, the experiments conducted in this work are presented in Chapter \ref{chapter05}. To this end, the architectures of the agents are explained, followed by a discussion of the employed datasets, training details, and results. Evaluation of language drift is presented alongside with the results. Finally, a general discussion of the results and their implications is provided in Chapter \ref{chapter06}. %The following sections presuppose faimiliarity with basic concepts in machine learning and deep learning. For an introduction, see, e.g., \cite{goodfellow2016deep, bishop2006pattern}.

%\pt{Have actual visual image and caption examples, and task conditional examples here.}

%\pt{maybe add basics of artificial agent interaction: \cite{tan1993multi}}

%\pt{a good general picture ML reference: Tomas Mikolov, Armand Joulin, and Marco Baroni. 2018. A roadmap towards machine intelligence.  Lecture Notes in Computer Science,}

%General flow: Correct, efficient communication appropriate in a given context as human feature -- basic type of cimmunication is reference (basic speech act), joint attention at a terget with another interlocutor. We want to model that, operationalized as a reference game which has also been studied extensively in cognitive science. We want artififical agents to do it, but for having potential to communicate with humans -- in natural language. It boils down to image captioning and learning statistical properties of language, yet in a task appropriate way. Therefore, multi-agent communication for task-specific finetuning. 