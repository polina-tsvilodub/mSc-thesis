The way in which human communicate seemingly effortlessly across all kinds of context, even in preveiously never observed situations, is a fascinating phenomenon. Not only are humans able to communicate with each other about an infinite variety of contexts---they do so in a highly sophisticated and efficient way. For instance, in a context where a pair of interlocutors observes a variety of different objects like cars and houses in a lively street, intuitively, the speaker might utter a sentence like ``Look at that red car!'' in order to draw the listener's attention to a praticular car. In contrast, if they interlocutors were in a field where there are no cars but a single abandoned one, the speaker might likely rather say ``Look at that car!'', ommitting details unnecessary for the successful completion of their goal of drawing the listener's attention to a particular object. This task of efficient selection of the level of details depending on the context of reference, or, put differently, producing \textit{production of discriminative utterances}, is a highly non-trivial task to be taught to machines. 

This type of \textit{context and task-specific} behavior has been addressed in the growing body of work on multi-agent communication, where artificial agents are trained to develop communication protocol which helps them solve a task \pt{refs}.

One of the most fascinating human abilities is the way we effortlesly communicate about the everchanging world around is. Yet teaching machines to communicate the way humans do is a long-standing yet far from solved task \pt{ref}. While recent advances in artificial intelligence, and especially in deep learning have made impressive progress in tackling the task of modeling natural language tasks, the task of \textit{grounding natural language} into the physical world remains quite challenging \pt{ref}.
\pt{The task of grounding language can be approached in different ways. Computer-vision focused work with image captioning. More interaction based work in multi-agent communication. Introduce the first part in the lit review section.}

An increasing body of work tackles this task by modeling the dynamics of language with artificial (neural) agents who have to develop and use a communication protocol in order to complete a task. This approach allows to both encorporate interactional aspects of language, as well as ground the language into the interaction environment. Furthermore, it allows to investigate the communication from an evolutionary perspective, as it evolves between the agents.

Multi-agent communication experiments have made use of different environments. Some experiments investigate communication protocols emerging when agents have to play a game \pt{REF}, navigate in a 2D or 3D environment \parencite{das2019tarmac, jaques2019social}, learn to translate sentences \parencite{lee2019countering}, or let the agent play a variety of the \textit{Lewis}, or, \textit{reference game}. In the latter environment, agents' main task is the communication itself, with the goal for the sender agent to communicate in a way such that receiver agent(s) successfully identify a target object in context of distractors. The objects are typically represented by images. \pt{Check if this is too specific for Lewis game already}

This thesis also conducts experiments in the reference game environment. Previous work on multi-agent reference games has shown that artificial agents are able to develop communication protocols allowing them to successfully complete the task \parencite{lazaridou2016multi} for a variety of different visual environments. More specifically, the agents communicated about geometric shapes \pt{Xenia's work}, synthetically generated scenes \parencite{lazaridou2020multi} or even real photos of natural scenes in the MS COCO dataset \parencite{lazaridou2016multi, lin2014microsoft}. However, the communication protocols employed by the agents mostly are not human-interpretable; i.e., they communicate by emmiting symbols sampled from an arbitrary vocabulary \pt{ref}. Some experiments employed single word natural language labels of the objects agents communicated about \parencite{lazaridou2016multi}. Yet to the author's knowledge, there is only one experiment in which the agents use natural language (English) as their communication protocol \parencite{lazaridou2020multi} \pt{double check}. The agents communicated in natural language about synthetically generated scenes from the \textit{Abstract Scenes} dataset, trained on the annotated natural language captions. \pt{Superficial prose about language drift here tbd.}

This thesis sets out to combine the two main aspects required for modelling human-interpretable communication in the real world within the multi-agent communication framework---namely, realistic visual input in form of photographic images, and natural language as the communication protocol. To the current knowledge, this is the first attempt to train such agents. 
Furthermore, the current work seeks to take one step further the observations regarding the difficulties to emply natural language as the communication protocol made by \parencite{lazaridou2020multi}. More precisely, they address the phenomenon of so-called \textit{language drift} where the agents' language abilities deteriorate, as reference game performance increases. Therefore, the goals of this thesis can be summarized as follows: 
\begin{itemize}
	\item investigate language drift applied to a different / novel dataset
	\item test out new language drift metrics: surface metrics (LM based metrics), recoverability metric attempt (text2image model), "functional" metrics independent of human evaluation
	\item dynamics of language drift throughout training
	\item investigate the capacity of the agents' to adapt the specificity of their messages to the fine-grained differences in the visual task (similar pairs experiment) of producing discriminative captions; failure to do taht could be dues to: noise in images, details of captions, incapability to vary caption length beyond what was observed in the training data
	\item connected to that: take apart potential sources of language drift by looking into the properties of the dataset and whether the lack of details in the caprions on which the model is trained is responsible: 3dshapes dataset (also as a baseline) 
	\item 3dshapes also allows to have some comparison to a dataset where the visual input is not as noisy \pt{I should also conduct a similar pairs experiment here}
	\item fixed pretrained listener: check if the drift is due to an emergence of conventions between speaker and listener which do not match human grounding, when listener and speaker are trained jointly. Therefore, a fixed listener can also be used. 
	\item additional drift sources to be discussed, but not experimentally investigated: architectural constraints like vocabulary size
\end{itemize}

Overall upshot: create task-specific communication about naturalistic visual input, investigate the influence of the dataset on the quality. Implications for what needs to be taken care of when creating systems to be used e.g. in human-machine interaction. 

This thesis is structured as follows: first, prior work on multi-agent communication and image captioning is reviewed. Then, the experiments conducted in this work are presented. To this end, the architectures of the agents are discussed, followed by a discussion of the dataset, training details, and results. Finally, a general discussion of the results and their implications is provided. The following section presuppose faimiliarity with basic concepts in machine learning and deep learning. For an introduction, see, e.g., \cite{goodfellow2016deep, bishop2006pattern}.

\pt{Have actual visual image and caption examples, and task conditional examples here.}

\pt{Add a description of the very general idea of multi agent tasks and communication as one of them. Basics of artificial agent interaction: \cite{tan1993multi}}

General flow: Correct, efficient communication appropriate in a given context as human feature -- basic type of cimmunication is reference (basic speech act), joint attention at a terget with another interlocutor. We want to model that, operationalized as a reference game which has also been studied extensively in cognitive science. We want artififical agents to do it, but for having potential to communicate with humans -- in natural language. It boils down to image captioning and learning statistical properties of language, yet in a task appropriate way. Therefore, multi-agent communication for task-specific finetuning. 