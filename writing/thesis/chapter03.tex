Literature review notes go here.

Karpathy and Fei-Fei, 2015:
\begin{itemize}
	\item CNN extracting regions: A Region CNN, pretrained on ImageNet and finetuned on 200 classes from ImageNet Detection Challenge, top 19 detected regions + whole image are kept and embedded intp 4096 dimensional space
	\item BRNN over captions, to address isue of dependencies etc when embedding words into visual space, using 300-dimensional word2vec embeddings. 
	\item compute alignment between them, predict captions based on inferred alignment through new Multimodal RNN architecture
	\item basic assumption: sentences are weak labels, which corespond to some unknown location in the image
	\item mention previous work where sentence templates are filled based on image content -- important for 3Dshapes experiment
	\item bidirectional recurrent net used to compute word representations, novel objective when learning alignment
	\item new objective: image-sentence score: dot product as single best alignment of a word to one image region, with margin maximization between align image-sentence pairs vs non-aligned ones
	\item goal: align text snippets, not only single words, to bounding boxes. This is achieved by treating the true alignment as a Markov Random Field, such that interactions between neighbouring words encourage alignment to the sam region.
	\item Multimpdal RNN: takes image pixels and a sequence of input vectors as input, where the image embedding is input as an additional bias at timestep 1. Hidden layer size is 512. The hidden layers are initialized with 0. They provide other important optimization details.
	\item They preprocess the sentences to lower-case, discarding non-alphanumeric characters. Importantly, they only keep words with frequency at least 5, resulting in 8791 words for 123000 MS COCO images. 
	\item the critical novelty is in the max margin loss which integrates the alignment score, which is used to train the BRNN
	\item ranking comparison on MS COCO reported -- check if I'll be able to compare to their performance.
	\item unclear how they train the MultimodelRNN on the alignment input -- they actually take the predicted labels for given bounding boxes from step before. For some reason, the annotators were asked to draw the bounding boxes, as opposed to receiving the ones proposed by the model.
\end{itemize}

Lazaridou, Peysakovich, Baroni, 2017:
\begin{itemize}
	\item They use REINFORCE for training the speaker. Overall framing: interactive communicative setting for training agents allows to capture functional aspects of communication, i.e., the goal-directed nature of communication, as opposed to purely supervised conversational agent training. 
	\item \textit{multi-agent coordination communication game}: first functional task (a basic function of language): reference
	\item research questions: can tabula rasa agents devlop successful communication protocols; which features of the environment facilitate NL like communication protocol properties
	\item  sender's policy: choice of a symbol from vocabulary V given (image-target, image-distractor, target-index), parametrized by the speaker's parameters
	\item receiver's policy = the guessed image (index) - if receiver guessed the target, both agents receive a payoff of 1, otherwise a payoff of 0 \pt{In my case, it is -1 and 1, so there is a reward and a penalty}.
	\item They actually feed both images into the sender agent!
	\item \pt{What is my activation function(s) in the model????}
	\item To this end, \textcite{lazaridou2016multi} conduct several experiments. In particular, in their main experiments, they set up a variation of Lewis' signalling game, a reference game environment, where a sender agent emits a single symbol to refer to one of two images provided to both the sender and the receiver agent, sampled from the ImageNet dataset. They use a subset of the dataset containing images crepresenting 20 general categories with 100 images per category. The receiver agent has to guess  which image is the intended target, based on the symbol received from the sender.\footnote{The terms \textit{sender} and \textit{speaker} agent will be used interchangeably in order to refer to the agent generating the message. Similarly, the terms \textit{receiver} and \textit{listener} agent both refer to the agent receiving the message and deciding which image is the intended target.} \textcite{lazaridou2016multi} set up two versions of the sende. First the ``agnistic sender'' consists of a two-layer feed forward network, embedding both images and producing a score over the vocabulary given the concatenation of the embeddings (p. 3). The ``informed sender'' consists of a three-layer network, applying two convolutional layers to embeddings of both images which are treated as different channels (p. 3). It also outputs scores over the vocabulary. For both architecures the scores are converted into a Gibbs distribution from which the emitted  message symbol is sampled. The receiver agent consists if a two-layer network which embeds both images and computes the dot products between the embeddings and the one-hot encoded message. The final target choice is the sample from the Gibbs distribution computed from the dot products. Crucially, the agents are trianed using the \texttt{reinforce} rule which updates parameters of the speaker and listener policies by minimizing the negative expected reward. \textcite{lazaridou2016multi} set the reward to 1 if the image picked by the receiver is the target and 0 otherwise. 
	\item They find that agents achieve high referential success after around 50000 training games and 1000 test games for different hyperparameter settings. Furthermore, it is found that the informed sender produces more semantically natural symbols (i.e., the same ones for the same categories) than the agnostic one, although the purity of the smeantics-based clusters is far from perfect. The agnostic speaker consistenly only uses two symbols. 
	\item In a further experiment, the authors pressure the agents to communicate more about high-level properties by sampling instances of different subcategories for the image pairs, and achieve a small increase in label purity. 
	\item Finally, they perform an experiment grounding the communication in natural language. More precisely, they combine the reference game with a supervised image labeling task wherein the agent has to use natural language labels. The sender is trained by switching between between game play and image classification on ImgaeNet data. They observe much larger vocabulary sized and higher symbol purity in this experiment, while retaining communicative / referential success. 
	
\end{itemize}

A number of recent research projects have addressed various aspects of multi-agent communication.  