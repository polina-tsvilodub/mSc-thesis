
This chapter reviews related work on multi-agent communication---the core domain in which the presented experiments are situated. First, the task and communicative setting which are used in this work are presented in Sections \ref{reference_games}--\ref{discriminative_lang}. Then, different architectures used for building the agents as well as related studies are reviewed in Section~\ref{mac}. Finally, additional communciative settings are summarized.

%\section{Introduction}
%\label{related_work_intro}
Research on multi-agent communication has received increasing attention over the recent years, as this domain focuses on research questions of high relevance to cognitive science \parencite{lazaridou2020emergent}. More precisely, two main areas of research are often addressed: first, the conditions under which a language emerges and which emergent properties can be observed; and second, the ability of artificial agents to pick up a given language system. % thus investigating whether tractable human-agent communication channels can be learned via realistic interaction.
The second direction has also been considered with respect to \textit{grounding} a given language in the visual world, i.e., teaching agents to use language applied to realistic visual input is investigated. Grounding is important both from modeling and cognitive perspectives: for instance, \cite{bruni2014multimodal} show that representations learned from both text and image data are more plausible than purely text-based representations; furthermore, vision is an integral part of human communication \parencite{tomasello2010origins, harnad1990symbol, clark1991grounding}. 

These two research directions have different implications for understanding human language: the former often focuses on what the causal factors behind prominent features of human language like compositionality are, allowing to shed light on human language evolution \parencite{christiansen2003language, kirby2014iterated}; the second rather addresses how we can train agents to communicate optimally for interacting with humans. Equivalently, these two main directions can be classified as investigating \textit{language emergence} and \textit{language acquisition} among and by artificial agents \parencite{lazaridou2018emergence, lazaridou2020emergent}.
Presented work focuses on the latter question, aiming to train agents to use English language grounded in real-world images.
%Irrespectively of the research focus, artifical agents which interact with each other are at the core of multi-agent communication studies. Therefore, first, different agent architectures are presented in the next section.
%\pt{I feel like a section on super general aspects, like having two agents doing some task and being jointly trained, is missing. Maybe visuals would be cool.}

Communication has been embedded in various tasks simulated in multi-agent settings. In some studies the idea was to use communication for improved cooperation \parencite[e.g.,][]{foerster2016learning, mordatch2018emergence}; in other tasks, communication about the environment itself was the core task \parencite[e.g.,][]{lazaridou2018emergence}. The latter allows to focus on properties of communicative systems that artificial agents might develop or acquire, thus allowing to compare them to human language. Since studying the ability of artificial agents to produce \textit{discriminative captions} for images in context within reference games is the goal of this work, this task and related work with human participants is described first, before transitioning to related work on multi-agent communication.

\section{Reference Games}
\label{reference_games}

Reference games are a type of the so-called \textit{Lewis signaling game} \parencite{lewis1969convention, skyrms2010signals}.
Signaling games were developed as an account of \textit{conventional meaning} \parencite{grice1975logic}. Traditionally, these games include two agents, a sender and a receiver. Only the sender observes a state sampled at random and chooses a message which is sent to the receiver. The set of all possible messages is known to both agents. Based on the message, the receiver selects an action based on the message. The set of actions is often identified with the set of states the sender may observe, rendering the interaction an \emph{interpretation game} \parencite{franke2016reasoning}. The game is then a success if the state guessed by the receiver and the state observed by the sender match, such that this game is driven by the agents having a common interest (\cite{lewis1969convention}, although see \cite{jager2014rationalizable} for a relaxation of the common interest assumption). 

\textit{Reference games} are a specific instance of signaling games in which the meaning of the messages is already conventionally established. Here, the sender samples a particular target among a set of distractors which may be a subset of all possible objects in the given world and \textit{refers} to it with her message. The target and the set of distractors are accessible to both agents. All possible messages are also known to both agents. The receiver's task is then the identification of the target given the message. Thus, the target and the distractors which in practice are often represented by visual context play a critical role in reference games.

Although presented work considers reference games in the narrow sense of discriminative expression generation in reference to a target among visual distractors, in a broader sense, many communicative tasks can be conceived of as related to reference games. 
For one, reference games have a close connection to the study of reference which has received considerable amount of attention in, e.g., more theoretical philosophy and linguistics literature \parencite[e.g., ][]{searle1969speech, krifka2008basic, sep-reference}; however discussing these directions goes beyond the scope of present work which focuses more on (computational) experiments. 
Furthermore, a lot of research in cognitive science and pragmatics has focused on pragmatic reasoning involved in reference (or language) games \parencite[e.g.,][]{frank2012predicting, wittgenstein2010philosophical}, which gained popularity especially with the rise of the RSA framework \parencite{goodman2016pragmatic}.  
For instance, pragmatic reasoning involved in the interpretation of implicatures has received a lot of attention \parencite[e.g.,][]{bergen2016pragmatic, rothschild2013game, van2012explaining}.
Other work concentrates on the role of context for referential expressions, e.g., investigating phenomena like reference and ambiguity resolution \parencite{frank2016rational, potts2016embedded}. \cite{golland2010game} addressed the role of social context, proposing that pragmatic speaker models generate optimal referential messages when producing them with respect to an explicit listener model. 
Following this direction of studying the communicating agents themselves, several studies employed the narrow sense visual reference games in experiments with humans. \cite{franke2016reasoning} used data from a reference game for comparing different models of pragmatic reasoning in signaling games, investigating whether experimental data is better explained by assuming only Gricean pragmatic reasoning throughout all participants or by assuming a heterogenous population using different reasoning models. %They found that while participants' production could be explained by the Gricean model, a non-negligible portion of participants' comprehension was not best explained as Gricean reasoning, although on a population level, the data may be explained by a Gricean model. % a comprehension and a production study to study pragmatic reasoning. They investigated whether pragmatic reasoning is pervasive throughout individual interlocutors or arises at population level. 
\cite{hawkins2020characterizing} studied learning in communication as it occurs during adaptation to speaker variabiliy and formation of novel meanings in so-called \emph{repeated reference game} tasks. These extended the standard reference game to multiple interactions betwen speaker and listener about the same object. 

Particularly relevant to presented work, \cite{graf2016animal} study the interlocutors' sensitivity to the visual context of distractors in which the target occurs within the reference task. They conducted an experiment wherein participants generated referential expressions for a target image presented in context of distractors which either belonged to the same or to a different basic-level object category.\footnote{Basic-level categories refer to general conceptual categories like dogs, birds or flowers. Several subordinate, i.e., more specific categories like Great Danes or hummingbirds, are comprised within basic-level categories. On the other hand, more general categories like mammals or plants subsuming basic-level categories are called superordinate categories \parencite{rosch1976basic}.} They showed that participants generated subordinate category level, i.e., more specific, referential expressions for the target in presence of similar distractors from the same basic-level category, but not in presence of dissimilar ones. Thus, they showed that humans flexibly adapt the specificity of nominal expressions they use in order to unambiguously refer to the target, when required by the context. 

However, human speech also presents abundant examples of \textit{overmodification} in referential expressions, i.e., of use of additional modifiers like color expressions even when it is not strictly necessary for discriminating the target in the given conext. \cite{degen2020redundancy} explained this phenomenon in terms of complexity of the visual scenes, typicality of the referents and of the described features. They revealed complex pragmatic reasoning underlying this phenomenon. Much more work has been done on referential expressions both experimentally and theoretically; these selected studies go to show that, guided by pragmatic reasoning, humans inherently generate highly discriminative, or, contrastive, messages in situations like reference games. Even further, they also expect and anticipate such behavior from other interlocutors, as has been shown in the processing literature \parencite[e.g.,~cf.][]{sedivy1999achieving}. Now the intriguing and challenging computational task as approached in multi-agent communication is learning this sophisticated reasoning in communication with neural agents.

Based on the success of reference games as a tool for studying communication in human experiments, it became a popular framing for computational modeling. A computational perspective on studying reference was first taken by \cite{dale1995computational}. Followingly, many studies have used reference games in computational simulations. Applied to artificial agents, a reference game (in the narrow sense) proceeds as follows: arrays containing a target image among $n \geq 1$ distractor images are sampled from the set of all images $I$. Both agents have access to the images and usually share the same representations; the sender agent knows which image is the target, the receiver does not. The sender emits a message $m, \; |m| \geq 1$ (assuming discrete communication; see Section \ref{multi_agent_arch}) sampled from the shared vocabulary $V$. Given $m$, the receiver has to correctly guess which of the images in the array is the target. Experiments in this thesis are limited to using one target image in context of only one distractor, but qualitative results are not expected to depend on this confinement.


\section{Discriminative Language Use}
\label{discriminative_lang}

Before turning to approaches wherein agents learn discriminative message generation from interaction in reference games, rather machine learning-based approaches to building discriminative image captioning systems are reviewed. Additionally, work inspired by the Rational Speech Act family of models is reviewed \parencite{goodman2016pragmatic}.

\cite{sadovnik2012image} first approached discriminative image captioning by looking at visual discriminability and saliency, and constructing captions based on hand-crafted rules. However, the manual approach to constructing captions potentially limits the scalability of such a system to new image domains, and requires time-intensive manual work. 

Moving to more scalable deep architectures, \cite{mao2016generation} proposed a system which both generated unambiguous referential expressions for objects in images and interpreted such expressions for identifying described image regions. They tested their system on a referential expression dataset derived from the MS COCO dataset \parencite{chen2015microsoft}. %Their model consisted of a CNN based visual module and an LSTM based language module, closely resembling the work by \cite{vinyals2015show}. It is additionally used to generated and embed bounding boxes in the images which represent the objects. \pt{more training details?} 
The generation task was to produce a referential expression for an object marked by a bounding box in a given image. The comprehension task was to identify the target object bounding box given an image and the expression, by reranking a set of proposed regions.
They used a baseline which had a standard image captioning architecture \parencite[cf.][]{vinyals2015show} enriched with CNN embeddings of the target region and its location information. These representations were input to an LSTM layer, which was trained to maximize the likelihood of the referential expression given the input. Their proposed discriminative model had the same architecture, yet it was trained with an approximation of the so-called \textit{softmax loss}. Intuitively, it favored expressions which identified the target unambiguously, compared to other distractor regions. 
That is, their approach aimed to generate discriminative referential messages by building in the bias towards discriminativity via the objective function.  
They found that their model generated messages which allowed more successful retrieval of the target region by the comprehension model, compared to the baseline. Furthermore, the expressions generated under their model were judged by human annotators to be at least as good as human referential expressions more often than the expressions from the baseline. They also observed that their discriminative expressions were typically longer than the baseline ones (cf. Section \ref{expt:3dshapes_short}). 

\cite{vedantam2017context} built an image captioning model which performed joint inference over a language model that was context-agnostic and a listener model which provided feedback on discriminativity of the sampled captions. That is, they introduced a ``reasoning speaker'' consisting of a basic image captioning speaker and a listener model. The basic speaker was an image captioner, additionally conditioned on target concepts represented in the images. The listener only depended on the basic speaker, as it computed the log-likelihood ratio between the speaker's utterances for a given image but for different concepts in that image. The overall speaker was then trained to maximize the basic speaker message probability while also maximizing the likelihood ratio representing the discriminativity of the caption for the correct concept over others.
%They applied the model to a justification task wherein the image features corresponding to a given discriminative aspect of the caption had to be explained. They also applied it to standard image captioning on similar image pairs from the MS COCO dataset. 
Their architecture was able to generate captions which led to higher discrimination success by human evaluators, compared to non-discriminative baselines.

\cite{dai2017contrastive} proposed the ``Contrastive Learning'' training objective for this task which constrained the image captioner to maximize the true caption likelihood compared to a pretrained reference image captioner, while learning to assign lower probabilities to mismatching captions for the target image, compared to that same reference model. That is, in contrast to the previous approach, the discriminativity was operationalized at the level of the entire image, as opposed to concepts within the target image. %Given that the discriminativity is measured in terms of the difference between correct and incorrect captions relative to the reference model, the quality of the system depends on the quality of the reference model. 
Their model achieved competitive captioning results on the MS COCO test set.

While alleviating some modeling issues like language drift (see Chapter \ref{chapter04} for details), these systems miss a critical component in their approach to the reference task---they are missing the communicative and interactive context of applying such image captions for successful reference establishment. Yet interactivity and social aspects of the communicative task are critical for developing systems which are supposed to have potential for interacting with humans \parencite{lazaridou2020emergent}. One of the most prominent frameworks formalizing social and cooperative aspects of communication is the Rational Speech Act (RSA) framework \parencite{goodman2016pragmatic}. Some approaches to discriminative image captioning are directly inspired by RSA and thereby incorporate interactive communication aspects into their models.\footnote{Basic knowledge of the RSA family of models is presupposed. For an introduction, see, e.g., \cite{goodman2016pragmatic, problang}.}

\cite{andreas2016reasoning} first employed an RSA-style Bayesian model wherein agents learned to produce discriminative messages in a reference game by reasoning about each other. The architecture consisted of a base speaker, base listener and a reasoning speaker. All agent modules were based on fully-connected linear layers with non-linear activations. The literal listener consisted of modules embedding input images and the received message, computing scores over image-message pairs. The literal speaker was used to sample possible messages for a given image by computing scores over vocabulary tokens given the image with a feed-forward language model. The reasoning speaker then derived the optimal message by sampling candidate messages from the literal speaker and reasoning about their utility by ``passing'' them through the literal listener and choosing the message maximizing the listener's referential success probability. 
%\cite{andreas2016reasoning} found that referential success increased with the number of samples taken from the literal speaker, as well as with increasing weight of reasoning about the listener in the reasoning speaker model. 
Crucially, they found that the reasoning speaker outperformed the literal speaker, indicating that pragmatic reasoning might be critical for modeling discriminative language use. 

\cite{cohn2018pragmatically} also built a model following the standard RSA principles. Their model performed character-wise caption generation. This generation strategy was chosen in order to constrain the space of possible alternatives the speaker may choose among when generating the caption. Therefore, their generation process was an incremental one, modeled by an LSTM-based speaker agent. Otherwise, their model was similar to \cite{andreas2016reasoning}. Their model  turned out to outperform word-level generation and non-pragmatic models, further supporting the importance of considering an interactive setting for successful discriminative language generation.

\cite{nie2020pragmatic} proposed an issue-sensitive image captioner, also based on the RSA family of models. Issue-sensitivity was represented as partitioning the space of images into cells with images that shared the same relevant (i.e., \textit{at-issue}) feature as the target belonging to a given cell. Their base speaker was a standard  pretrained image captioning model. Additionally to standard RSA mechanics, they extended the pragmatic speaker to be sensitive to the relevant partitioning. They further included a utility term in order to tackle arising semantic drift (e.g., mentioning features that are not true of the target, see Chapter \ref{chapter04}) of the captions and constrain the speaker from overgenerating. Akin to \cite{cohn2018pragmatically}, this model also employed an incremental message generation procedure. Evaluations included visual question answering (VQA) on MS COCO \parencite{chen2015microsoft}, showing that the model learned adequate issue representations from questions as well as generated promising issue-sensitive captions. Such issue sensitivity might be seen as a promising step towards generating messages which are sensitive to particular contextual features necessary to produce discriminative messages. 

Finally, an approach fully embracing the idea of learning language use from active interaction, not just representations of other agents,  is multi-agent communication. The next section turns to work on discriminative language learning and other related research in this domain.

\section{Multi-Agent Communication}
\label{mac}
Irrespectively of the research focus as distinguished in the introduction, artificial agents which interact with each other are at the core of multi-agent communication studies.
The main architectural differences concern the type of model representing the artificial agent and the type of communication channel they use.
As described in Section \ref{rl}, experiments wherein agents learn to complete a task by interacting with the environment and with each other are typically trained with reinforcement learning. Multi-agent communication is a specific type of RL tasks in that (one of) the tasks agents learn are communicative and cooperative, and one of the agents can be considered the sender and the other the receiver of the communication \parencite[cf.][]{tan1993multi, lazaridou2016multi}.\footnote{Although see \cite{bouchacourt2019miss} for experiments with changing agent roles.}
Based on the chosen communication channel and the precise communicative task, specific architectural decisions and optimization algorithms differ. This section first turns towards architectures employed in reference games, before discussing other tasks.

\subsection{Agent Architectures and Training in Reference Games}
\label{multi_agent_arch}

While early work in multi-agent communication focuses on structured agents \parencite[e.g.,~see][for reviews]{christiansen2003language, cangelosi2002symbol}, deep agent architectures became increasingly dominant in the domain over the last years \parencite{lazaridou2020emergent}. As this thesis also uses deep neural network agents, the review of related work focuses on deep multi-agent communication experiments. 

%Architectural considerations: 
%1) agent architecture: hand crafted vs deep; for deep: kind of network, esp. recurrent layer
%2) loss and training approach: Q-learning \parencite{foerster2016learning}, Gumbel-Softmax \parencite{havrylov2017emergence}, REINFORCE.  \parencite{lazaridou2020emergent, williams1992simple}. 

\cite{lazaridou2016multi} first showed that neural agents can efficiently reference realistic visual inputs in the presence of distractors by developing a communication protocol from scratch. To this end, \textcite{lazaridou2016multi} conducted several experiments employing feed-forward and CNN agents. In particular, in their main experiment, they set up a reference game, where a sender agent emitted a single discrete symbol referring to one of two images provided to both the sender and the receiver, sampled from the ImageNet dataset \parencite{deng2009imagenet}. The discretization of the agents' communication channel is sometimes also called the \textit{discrete bottelneck} \parencite{lazaridou2020emergent}. 
The receiver agent had to guess  which image was the intended target, based on the symbol received from the sender (see Section \ref{reference_games} for details of such a task). %They use a subset of the dataset containing 100 images from each of 20 general categories.
\cite{lazaridou2016multi} set up two versions of the sender. The ``agnostic sender'' consisted of a two-layer feed forward neural network, embedding both images and producing a score over the vocabulary given the concatenation of image embeddings \parencite[][p. 3]{lazaridou2016multi}. The ``informed sender'' consisted of a three-layer neural network, applying two convolutional layers to embeddings of both images which were treated as different channels \parencite[][p.~3]{lazaridou2016multi}. It also output scores over the vocabulary. %For both architecures the vocabulary scores were converted into a Gibbs distribution from which the emitted message symbol was sampled. 
The receiver agent consisted of a two-layer feed forward network which embedded both images and computed the dot products between these embeddings and the one-hot encoded message. The final target image choice was sampled from the Gibbs distribution computed from the dot products. %The agents are trained with REINFORCE which updates parameters of the speaker and listener policies by minimizing the negative expected reward. The speaker and listener policies are parametrised by the weights of the respective neural networks. The sender policy is $\pi(v \in V \mid i_L, i_R, t \in \{L, R\})$ where $V$ is the vocabulary, $i_L, i_R$ are the left and right images and $t$ is the position of the target. The receiver policy is $\pi(t \in \{L, R\}\mid v_s, i_L, i_R)$, where $v_s$ is the message received from the sender and $t$ is the guessed position of the target image. \textcite{lazaridou2016multi} set the reward to 1 if the image picked by the receiver is the target and 0 otherwise. 
They found that agents achieved high referential success, and that the informed sender produced semantically more natural symbols (i.e., the same ones for the same image categories) than the agnostic one. In a further experiment, the authors successfully pressured the agents to communicate about more high-level properties by sampling instances of different subcategories within the same basic-level category for the image pairs (cf. Section \ref{expt:3dsapes_similar}). %, and achieve a small increase in label purity (i. e., in the proportion of labels agreeing with the major cluster label). 
Finally, they performed an experiment grounding the communication in natural language wherein the sender agent had to use natural language category labels as message symbols. The sender was trained by switching between reference game play and image classification on ImageNet data. However, the vocabulary was limited to 100 words, and the sender only produced one-word messages, making the experiment rather far from realistic scenarios. %They observe a higher symbol purity in this experiment, while retaining referential success. 	
%	\item They use REINFORCE for training the speaker. Overall framing: interactive communicative setting for training agents allows to capture functional aspects of communication, i.e., the goal-directed nature of communication, as opposed to purely supervised conversational agent training. 
%	\item \textit{multi-agent coordination communication game}: first functional task (a basic function of language): reference
	
Another foundational study in deep multi-agent communication was conducted by \cite{foerster2016learning}. In contrast to \cite{lazaridou2016multi}, the authors let the agents use a centrally trained system in their ``DIAL'' architecture (i.e., with parameter sharing across agents)  which could also be extended to continuous communication. This system was compared to the ``RIAL'' system where agents used traditional discrete communication \parencite[][p. 2]{foerster2016learning}. This was one of the first studies using a recurrent network in the sender architecture.
For both systems, the sender consisted of an input network with a fully connected layer and lookup tables creating embeddings of the task environment, two recurrent GRU layers, and two feed-forward output layers.
The receiver had the same architecture. The DIAL agents were additionally connected via a continuous vector which can be seen as an activation layer passing the internal state of the sender to the receiver.
Experiments with different variants of a reasoning and an image classification task on the MNIST dataset were conducted. Results on the former task showed that the agents were able to learn an optimal policy although DIAL agents converged faster, yet sharing the weights between the sender and receiver agents was critical for RIAL. DIAL with parameter sharing outperformed other experiments. Furthermore, they found that adding noise to the communication was critical for successful learning for RIAL. Results of the second task provided similar results for DIAL, while RIAL failed to converge stably on the multi-step interaction version of this task. 
The discrete system was trained with deep $Q$-learning (see Section \ref{rl_methods}), while the continuous system was trained by additionally backpropagating gradients end-to-end between the two agents. 
The DIAL results pose an interesting question regarding the comparability of such a system where the internal representations of a speaker are directly passed to the listener to human communication \parencite[cf.][]{lazaridou2020emergent, hockett1960origin}. The authors, however, argue that this direct error propagation can be interpreted as communicative feedback which is also part of human communication. Further challenging conceptual interpretability, while the possibility to use DIAL with continuous communication is attractive from a machine learning perspective due to its differentiability, human languages are typically considered discrete signaling systems \parencite{hockett1960origin}. 

\cite{havrylov2017emergence} further extended work on multi-agent communication by modeling agents which communicated with variable-length strings of symbols in a reference game. 
Their architecture was based on the proposal by \cite{lazaridou2016multi} with the difference that the sender agent only had access to the target image. Furthermore, their agents consisted of LSTM layers. Information about the target image was injected by initializing the hidden state of the sender LSTM with the image feature vector, extracted from a pretrained VGG CNN \parencite{simonyan2014very}. The sender generated the message by sampling tokens from the vocabulary similarly to the image captioning system by \cite{vinyals2015show} described in Section \ref{image_captioning}. The vocabulary consisted of 10,000 tokens, the LSTM hidden size was 512, and the token embeddings were 256-dimensional. 
The receiver interpreted the message by encoding it with an LSTM and computing a probability distribution over dot products of image features and the affine-transformed hidden states of the LSTM. The image with the highest probability was chosen as the target. \cite{havrylov2017emergence} further attempted to make the statistical properties of the emergent protocol as similar to natural language as possible by minimizing the KL-divergence between the learned conditional token distribution and a pretrained language model.
They compared agents trained via the \textit{straight-through Gumbel-softmax estimator} to agents trained with REINFORCE. The straight-through Gumbel-softmax estimator is a differentiable approximation of discrete actions (i.e., tokens) with a continuous relaxation applied in the backward pass of backpropagation, while still using discrete representations in the forward pass. 
That is, one-hot encoded tokens are replaced with samples $w_k$ obtained by sampling $K$ samples  $\{u_k\}_{k=1}^K$ from the random variable $u \sim U(0,1)$. Each $u_k$ is transformed and then used in the sample computation
\begin{equation}
\begin{aligned}
g_k = -log(-log(u_k)) \\
w_k = \frac{exp((log \; p_k + g_k) / \tau)}{\sum_{i=1}^{K} exp((log \; p_i + g_i) / \tau)}
\end{aligned}
\end{equation}
where $\tau$ is the temperature, $p_i$ and $p_k$ are token probabilites. The samples are discretized with argmax for the forward pass. Thus, it is an alternative to REINFORCE in this setting.
It is argued in the literature that this approximation allows for more efficient gradient estimation given larger action spaces for which REINFORCE produces very high variance estimates---e.g., when the vocabulary size is large \parencite{havrylov2017emergence}.
Experiments on the MS COCO dataset were conducted, selecting one image in batches of 128 as the target. \cite{havrylov2017emergence} showed that agents trained with Gumbel-softmax converged faster than those trained with REINFORCE, but both were able to achieve high referential success. Further, they found that communication success increased with maximum message length for both algorithms. They also found that the emergent communication protocol had multiple representations of the same information and that the messages seemed to have hierarchical coding. They also conducted an experiment wherein the sender was trained with a combined loss on both an image captioning and reference game task in order to attempt grounding the tokens in the images. However, this system didn't improve in terms of caption quality. To sum up, this work showed that agents can successfully develop multi-token communication protocols for solving referential tasks.

Similar work was conducted by \cite{lazaridou2018emergence}. The agent architecture closely matched \cite{havrylov2017emergence}, yet the study focused on comparing reference games with realistic images to games on symbolic data. The protocol learned on symbolic data was shown to exhibit more compositional features compared to raw pixel input experiments. Nevertheless, agents were able to successfully develop a protocol based on raw input, as well. These results suggested that the proposed architecture did not have an inductive bias sufficient for extracting symbolic compositional features from raw inputs. 

\cite{lazaridou2020multi} whose work is replicated and extended in this thesis used an architecture which combined the architectures by \cite{lazaridou2016multi} and \cite{havrylov2017emergence} in that they also used LSTM-based agents in a reference game, but conditioned them on combined image features of both the target and the distractor. They explored different speaker architectures. More precisely, they compared a speaker learning an emergent communication protocol by maximizing the reference game success (``functional learning''), a speaker learning to emit image captions as messages based on ground truth captions in a supervised manner (``structural learning''), and speakers trained with a combination of the two learning approaches \parencite[][p.~4]{lazaridou2020multi}. The functional learning signal was based on REINFORCE (see Chapter \ref{chapter02} for details), while the structural learning was conducted with the standard cross-entropy loss against the ground truth image captions. Multiple combined speaker parametrizations were compared: a speaker pretrained on an image captioning task which was then fine-tuned with functional learning on the reference game (conditioned on the target image only; ``reward finetuning''), a speaker trained with a weighted combination of the structural and functional losses (``multi-task learning'') and a speaker pretrained on image captioning and then learning a reranking function based on the reference game (``reward-learned rerankers'') \parencite[][p.~4--5]{lazaridou2020multi}. Two variations of the reranking model were presented. Both speakers learned to rerank samples obtained from the pretrained image captioner. The ``product of experts'' model reranked the samples proportionally to the message probability times the probability of the message given the image pair. The latter was obtained by re-embedding the sampled captions with a trainable layer as bag-of-words vectors and computing dot products between the vectors and image embeddings, renormalizing the scores.  The ``noisy channel'' reranker learned the reranking according to Bayes' rule, i.e., proportionally to the likelihood of obtaining the target image given the sample times the sample probability. The likelihood can be seen as the speaker's internal listener model and was also computed as the re-normalized dot products between a learned bag-of-words caption representation and each image embedding \parencite[][p.~5--6]{lazaridou2020multi}. The noisy channel reranker model by \cite{lazaridou2020multi} is closely related to work by \cite{andreas2016reasoning} (see Section \ref{discriminative_lang}).
The agents were trained on a reference game on the \textit{Abstract Scenes} dataset \parencite{zitnick2013bringing}.
Overall, they showed that the ``product of experts'' model outperformed other speakers with respect to referential success in the game, while also best counteracting \textit{language drift} (see Chaper \ref{chapter04} for details). 
Experiments in this thesis focus on the ``multi-task learning'' architecture. This choice is discussed in more detail in Chapter \ref{chapter05}.

To sum up, several studies investigated multi-agent communication in a reference game setting and employed different agent architefctures for that goal. The next section outlines how similar architectures can be used in order to address other research questions.

\subsection{Other Tasks}

Next to studying communicative success and the ability of agents to use natural language in reference games, multi-agent communication work has also focused on other aspects in reference games as well as studied other tasks.
 
For instance, \cite{evtimova2017emergent} extended one-iteration reference games to \textit{multi-step interactions}, wherein agents could exchange information back and forth several times. More specifically, their sender agent only had access to visual representations of the set of objects in a reference game, while the receiver only had access to textual descriptions of the target and distractors. Therefore, the agents needed to align their communication across modalities. They compared a feed-forward and an attention-based sender architecture, and a GRU-based and an attenion-based receiver, training them with REINFORCE. They found that agents successfully made use of back-and-forth communication about ImageNet images with WordNet based descriptions, showing that agents produced longer conversations on more difficult concepts. Further, they observed an increase in sender's message specificity with progressing conversation iterations.
Their experiments were also related to the multi-step MNIST task variation in \cite{foerster2016learning}.

A further step was taken by \cite{bouchacourt2019miss} who modeled a decision task wherein one agent was assigned a fruit and the other two tools, the latter having to decide which tool was more suitable for using with the given fruit. The tool utility was retrieved from human judgements. Noteworthily, the type of objects assigned to an agents was varied at random. They observed that the agents developed role-dependent communicative protocols, assigning different messages to the same concepts depending on their role. 

Other work studied the communication in more complex cooperative environments like 2D or 3D grid worlds \parencite{das2019tarmac}. In contrast to other studies, they used the Actor-Critic training method and continuous communication protocols (cf.~Chapter \ref{chapter02}). In short, they found that the benifit of including communication increased with task complexity, and that the learned communication and underlying agent behaviour were intuitive and interpretable. However, \cite{lowe2019pitfalls} also highlight the difficulty of adequately evaluating the added value of communication in complex multi-agent environments. \cite{mordatch2018emergence} situated a population of agents in a 2D continuous environment populated with objects of different shapes and colors, the goal of each agent being to, ~e.g., move to a particular location. They studied communication protocols emerging as the agents coordinated on the goals. Similar to work described below, they studied compositionality of the protocols, finding that it was more likely to emerge under a pressure to keep the vocabulary size small, and when the training environment and task were variable. They further observed the emergence of non-verbal communication such as guiding in absence of a language communication channel.

Finally, a body of work focuses on investigating the properties of emergent languages with the goal of understanding how natural language properties might have developed \parencite{lazaridou2020emergent}. For instance, \cite{graesser2019emergent} showed, among other findings, that a shared communication protocol emerged from distinct ones in presence of a single new agent in the community participating in the communication. This presents an important connection to natural language which preserves its structure precisely because of the pressure to communicate with different interlocutors and transmit the language to further generations \parencite{tomasello2010origins, kirby2014iterated}. \cite{chaabouni2019anti} investigated whether emergent communicative protocols followed Zipf's law which posits that frequency of messages in a language is anti-correlated with message length. Surprisingly, they found that emergent protocols were \textit{anti-efficient}---that is, the messages that had to be used most frequently were the longest ones. This was explained by a lack of production cost pressure in emergent communication.

Similarly, aiming to investigate properties of natural language, a lot of work has focused on \textit{compositionality}.\footnote{Measuring compositionality is an important and not trivial aspect of this line of work. For an overview of different approaches, see, e.g., \cite{lazaridou2020emergent}.} For instance, \cite{lazaridou2018emergence} showed that compositional communication emerges more easily from symbolic input than raw pixel input. 
\cite{chaabouni2020compositionality} showed that compositionality in emergent protocols facilitated language transmission \parencite[cf.][]{kirby2014iterated, lazaridou2020emergent}, but was not predictive of its generalization potential. The emergence of compositionality was shown to be strongly dictated by the variability of the input environment. Importantly, they also used a structured symbolic input representation.
\cite{luna2020internal} investigated cognitively plausible internal and external pressures which might influence compositionality---the ``principle of least effort'' (i.e., keeping the messages as short as possible) and ``object constancy'' (i.e., grouping together constant patterns into conceptual classes by abstracting away from context-contingent variation; p.~1). More precisely, operationalizations of the latter principle in terms of sensitivity towards location invariance, color constancy and the distribution of objects in the environment were compared. The results showed that the least effort pressure made the protocols less redundant. Furthermore, agents pressured towards object constancy produced protocols with highest compositionality scores, while some other operationalizations also improved zero-shot generalization abilities. 

Overall, these studies show that emergent communicative protocols often exhibit properties that are far from natural language. Nevertheless, the possibility to test the effect of different environmental and architectural pressures on emergent properties makes multi-agent communication a fascinating avenue for further research regarding properties of natural language. 
%Other evolutionary perspective: agent co-evolution \parencite{dagan2020co}.

%\textbf{Properties of the communication \parencite{lazaridou2020multi}}: difficulty to converge on consistent meanings of tokens for color values, generally task-oriented codes with complexity minimization. Anti-efficient code development --> I am looking somewhat into this with my different-lengths experiments and grammars.  Larger communities lead to more systematic languages --> fixed listener experiment.

To sum up, this chapter reviewed conceptual and experimental aspects of reference games, prior work on discriminative language generation and multi-agent communication, in particular focusing on how artificial agents have been trained to communicate in reference game settings, putting the presented thesis in context of state-of-the-art research. However, little has been said about the issues connected to teaching artificial agents to use natural language in reference games. Therefore, the next chapter turns towards these issues.